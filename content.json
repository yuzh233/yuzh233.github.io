{"pages":[{"title":"About Me","text":"主题配置相关Brand 标识hexo 根目录 _config.yml 配置 title 生成 categories 和 tags 页面将 themes/icarus/_source 下的 categories 和 tags 目录拷贝到 hexo/source 目录 Profile主题的 _config.yml 配置 RECENT 略缩图设置每一篇文章添加标签：thumbnail: /img/random/14.jpg, img 文件夹是属于 hexo 根目录的。 首页显示文章摘要侵入性较强，在文章的指定部分添加标签：&lt;!-- more --&gt;，该标签之前的内容被作为摘要。 更改主题内容模块页面宽度../hexo/themes/icarus/source/css/_variables.styl 123456789// Layoutblock-margin = 40pxarticle-padding = 20pxmobile-nav-width = 280px# 自定义宽度，默认 7main-column = 10sidebar-column = 3profile-column = 3sidebar-column-tablet = 4 更改代码样式样式存在于：/opt/hexo/themes/icarus/source/css/_highlight 文件夹，60余种。 修改主题 _config.yml 的 highlight： Valine 评论12345678valine: # Valine Comment System https://github.com/xCss/Valine on: true # enter true to enable appId: IaNb4n1EqHakKzNDh6jR1qYJ-gzGzoHsz # enter the leancloud application appId here appKey: Hg7CxatEfuCfhqOsl7XYtEOv # enter the leancloud application appKey here notify: true # enter true to enable &lt;Mail notifier&gt; https://github.com/xCss/Valine/wiki/Valine-%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E9%82%AE%E4%BB%B6%E6%8F%90%E9%86%92%E8%AE%BE%E7%BD%AE # 需要设置true，否则插件不生效。 verify: true # enter true to enable &lt;Validation code&gt; placeholder: Just Do It... # enter the comment box placeholder TOC 支持每篇文件添加标签：toc: true 即可。","link":"/about/index.html"}],"posts":[{"title":"Docker 补救指南（四）—— dockerfile-maven-plugin","text":"dockerfile-maven-plugin 插件介绍该插件帮助 Maven 集成 Docker 不需要任何花里胡哨的操作🤪。这个插件使用 Dockerfile 构建镜像，并且是强制性的。 使 Docker 的构建\b过程集成 Maven 的构建过程，如果绑定了\b默认「阶段（phases）」，当输入 mvn package 时，将会构建\b一个镜像；当输入 mvn deploy 时，该镜像将会被推送到远程仓库。 让目标「goals」记住你要做什么（通过 goals 标签定制处理过程）。可以通过输入 mvn dockerfile:tag、mvn dockerfile:build、mvn dockerfile:push 来构建并推送一个镜像，作为替代的可以使用：mvn dockerfile:build dockerfile:push。 reference：https://github.com/spotify/dockerfile-maven 以下是简单的实例配置，在此配置中，执行 mvn package 将构建一个镜像，执行 mvn deploy 将推送镜像。当然可以\b通过执行 mvn dockerfile:build 明确的说明构建\b。 1234567891011121314151617181920212223&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${dockerfile-maven-version}&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default&lt;/id&gt; &lt;!-- 这里没有指定 phase 就是默认 mvn package 时执行 build 操作，mvn deploy 时执行 push操作 --&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;repository&gt;spotify/foobar&lt;/repository&gt; &lt;tag&gt;${project.version}&lt;/tag&gt; &lt;buildArgs&gt; &lt;JAR_FILE&gt;${project.build.finalName}.jar&lt;/JAR_FILE&gt; &lt;/buildArgs&gt; &lt;/configuration&gt;&lt;/plugin&gt; 该插件的所有可用的构建目标（goals） Goal Description Default Phased docker:build 从 Dockerfile 构建一个\b镜像 package docker:tag 为镜像设置一个标签 package docker:push 推送镜像到远程仓库 deploy 使 maven 的某个构建过程跳过 dockerfile-plugin 的某个目标 Maven Option What Does it Do? Default Value dockerfile.skip 关闭全部 dockerfile 插件 fals dockerfile.build.skip 关闭 build 目标 false dockerfile.tag.skip 关闭 tag 目标 false dockerfile.push.skip 关闭 push 目标 false 默认 mvn package 会执行 dockerfile:build 操作（Goal），如果我们在执行 mvn package 时指定参数：mvn package -Ddockerfile.build.skip 那么该过程不会执行镜像的构建。 reference: https://github.com/spotify/dockerfile-maven/blob/master/docs/usage.md \b认证 See authentication docs. reference：https://github.com/spotify/dockerfile-maven/blob/master/docs/authentication.md 我的翻译 依靠 Dockerfile 插件的其他 Docker 工具 TODO \b使用 dockerfile-maven-plugin 插件遇到的一些问题完整配置： 123456789101112131415161718192021222324252627282930313233&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.3&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default&lt;/id&gt; &lt;!-- 如果不指定 phase 则会使用默认的 goals，即：package -&gt; build, deploy -&gt; push --&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;repository&gt;registry.cn-shanghai.aliyuncs.com/yuzh/microservice-userservice&lt;/repository&gt; &lt;!-- 如果不想在 pom 中指定 username password 可以在 setting.xml 中\b添加 server 节点。 注意：server 节点中的 id 值必须和 这里的 repository 仓库前缀地址\b保持一致！如 &lt;server&gt; &lt;id&gt;registry.cn-shanghai.aliyuncs.com&lt;/id&gt; &lt;username&gt;&lt;/username&gt; &lt;password&gt;&lt;/password&gt; &lt;/server&gt; --&gt; &lt;username&gt;${username}&lt;/username&gt; &lt;password&gt;${password}&lt;/password&gt; &lt;tag&gt;${project.version}&lt;/tag&gt; &lt;useMavenSettingsForAuth&gt;true&lt;/useMavenSettingsForAuth&gt; &lt;/configuration&gt;&lt;/plugin&gt; 0）如果不想指定 push 到远程仓库的用户名和密码的话，可以先登陆远程仓库。（否则，需要在 pom 中或 setting.xml 中配置远程仓库用户名和密码） 1e.g: docker login --username=yuzh233 registry.cn-shanghai.aliyuncs.com 1） 使用最新的 1.4.10 版本 push 会有点问题，可能缺少什么配置，从官方 github 没有找出问题出来。目前使用 1.4.3 没问题。 2） 需要注意命令行执行 mvn 命令和 \bIDE 图形化操作 mvn 时所使用的 setting.xml 文件不是一致的。 terminal 默认加载的配置文件是全局的：${MAVEN_HOME/conf/setting.xml，如有需要可以在命令行执行携带参数设置\b备用加载路径：--settings=/User/xxxx/settings.xml 3）如果不指定 phase 标签，dockerfile-plugin 将会在 deploy 时\b push Docker 镜像，需要\b注意的是：\b往往这个时候会报错，提示\b👇 1Deployment failed: repository element was not specified in the POM inside distributionManagement element 检查后发现，docker 远程仓库的配置看起来没问题（在 setting.xml 中配置了私有仓库用户名和密码或者在 pom 中指明了仓库地址和用户名密码），但是就是一直报错？！ 手动执行 mvn dockerfile:push 发现成功推送到了远程仓库，所以可以确定的是 这里报错是 jar 包推送到 maven 的远程仓库时没有\b配置好环境导致的，而不是 docker 仓库的配置问题。所以要么配置好maven远程仓库，要么指定 phase 不等于 deploy。 maven 打包到远程仓库相关细节，先晾着吧\b🙄。","link":"/2019/05/30/\bDocker 补救指南（四）—— dockerfile-maven-plugin/"},{"title":"Docker 补救指南（三）—— Docker Swarm","text":"是什么Docker Swarm 是一个创建和管理 Docker 集群的工具，该工具主要用于 Docker 的\b集群管理和容器编排。其特点有下： 方便创建和管理集群 可拓展 可实现期望的状态调节 集群中多主机网络自动拓展管理 提供服务发现功能 可实现负载均衡 安全性\b强 支持延迟更新和服务回滚 Docker Swarm 是 Docker 官方在 Docker1.12 后自带支持的新型容器集群管理工具。在此之前比较成熟的容器集群管理工具有 Google 的 Kubernetes 和 Apache 的分布式管理框架 Mesos 等。 核心概念：节点、服务、任务的描述 搭建 Swarm 集群环境准备 三台装有 Docker 的主机，版本要求是 1.12 以上。 集群管理节点的 IP 必须固定，保证其他工作节点\b能够访问该管理节点。 集群节点之间必须使用相同的协议并保证以下端口可用： \b用于集群管理通信的 TCP 接口 2377 用于\b节点间通信的 TCP/UDP 端口 7946 用于覆盖网络流量的 UDP \b端口 4789 由于主机有限，这里使用本地 Mac 主机和云端 ECS 主机，出口 IP 分别为： 12本地（worker）：113.246.94.216远程（manager）：120.78.69.82 常用命令：123456789101112131415Usage: docker swarm COMMANDManage SwarmCommands: ca Display and rotate the root CA init Initialize a swarm join Join a swarm as a node and/or manager join-token Manage join tokens leave Leave the swarm unlock Unlock swarm unlock-key Manage the unlock key update Update the swarmRun 'docker swarm COMMAND --help' for more information on a command. 创建 Docker Swarm 集群在 manager \b创建一个集群：docker swarm init –advertise-addr 120.78.69.82 集群创建成功，当前节点默认成为了管理节点。查看集群中的所有节点：docker node ls 接下来，让工作节点加入 Swarm 集群，使用：docker swarm join123456789101112[root@izwz90qcppq4b8dajq7j3uz ~]# docker swarm join --helpUsage: docker swarm join [OPTIONS] HOST:PORTJoin a swarm as a node and/or managerOptions: --advertise-addr string Advertised address (format: &lt;ip|interface&gt;[:port]) --availability string Availability of the node (\"active\"|\"pause\"|\"drain\") (default \"active\") --data-path-addr string Address or interface to use for data path traffic (format: &lt;ip|interface&gt;) --listen-addr node-addr Listen address (format: &lt;ip|interface&gt;[:port]) (default 0.0.0.0:2377) --token string Token for entry into the swarm 有很多种方式加入集群，这里\b使用创建集群成功之后的提示命令就可以了。如果忘记了加入集群的指令，可以使用 docker swarm join-tokens [worker / manager] 查看\b加入集群的 token 信息： 工作节点加入集群，在工作节点终端执行： 此时在工作节点上可以看到该集群中有两个节点，注意：工作节点不能执行 docker swarm 的其他命令，只能执行 docker \bswarm leave 离开此集群。 向 Docker Swarm 部署服务使用 docker service 来管理 Swarm 集群中的服务，此命令只能在管理节点执行。 123456789101112131415161718[root@izwz90qcppq4b8dajq7j3uz ~]# docker service --helpUsage: docker service COMMANDManage servicesCommands: create Create a new service inspect Display detailed information on one or more services logs Fetch the logs of a service or task ls List services ps List the tasks of one or more services rm Remove one or more services rollback Revert changes to a service's configuration scale Scale one or multiple replicated services update Update a serviceRun 'docker service COMMAND --help' for more information on a command. 在 Docker Swarm 集群中运行一个 nginx 的服务：docker service create –replicas 1 -p 8086:80 –name swarm-nginx nginx --replicas 1 指定该服务的副本数量 --name 与创建容器一样 -p 与创建容器一样 1PS: Docker 服务管理的命令\b与容器管理类似，只不过一个是 docker service，一个是 docker contianer。但有个别服务的特例命令如：--replicas 接下来可以查看集群中的服务列表：docker service ls 查看服务在集群上的分配和运行情况：docker service ps swarm-nginx \b由前面知道：一个服务是多个任务的集合，任务是 Swarm 中的最小调度单元，一个任务可以看作是单个容器。我们运行一个服务之后，Swarm 分配任务到不同的副本执行，在不同副本中的体现\b可以查看容器运行\b情况。 任务被分配到了工作节点，通过查看\u001d容器进程可以看到： 在集群中部署的服务，如果只运行一个副本，就无法体现集群的优势。一旦该机器或副本奔溃，该服务就无法访问，所以通常一个服务会创建多个副本。 添加副本的\b命令是：docker service scale 服务名=数量 添加副本之后再查看服务运行情况： 1PS：Docker Swarm 部署服务下的容器，默认网络方式都是使用 overlay 驱动的 ingress 网络，一般情况下我们会自定义一个基于 overlay 覆盖网络驱动的网络。使用方式与创建容器一样，都是指定 `--network 网络名` 最终，两个\b节点都运行着我们的 nginx 服务，\b打开浏览器分别访问： 故意 down 掉一个容器（本地容器），查看是否动态分配了节点？ down 掉一个容器之后，过不了多久又开启了一个容器。Docker Swarm 始终保持 swarm-nginx 服务有两个节点运行。 删除服务：docker service rm 服务名 总结集群管理命令： docker swarm init –advertise-addr [IP] docker node ls docker swarm join docker swarm join-tokens [worker / manager] docker swarm leave \b集群服务命令： docker service create -p [port:port] –replicas n [镜像名:TAG/ID] docker service ls [服务名/ID] docker service inspect [服务名/ID] docker service ps [服务名/ID] docker service scale=[n] [服务名/ID] docker service rm [服务名/ID]","link":"/2019/05/18/Docker 补救指南（三）—— Docker Swarm/"},{"title":"Docker 补救指南（二）—— 网络管理","text":"网络管理Docker 默认使用 bridge（单主机互联）和 overlay（可跨主机互联）两种网络驱动来进行容器的网络管理。如果需要，用户可以自定义网络驱动插件进行 Docker 的网络管理。以下内容针对 Docker 默认的网络管理和自定义网络管理进行演示学习。 查看指令不管其他细节，先看有哪些常用命令： 1234567891011Usage: docker network COMMANDManage networksCommands: connect Connect a container to a network create Create a network disconnect Disconnect a container from a network inspect Display detailed information on one or more networks ls List networks prune Remove all unused networks rm Remove one or more networksRun 'docker network COMMAND --help' for more information on a command. 可以看到对于网络的操作大概都有这些操作：连接、创建、取消连接、查看细节、查看列表、移除。 Docker 默认网络管理Docker 安装时会自动创建三种网络。查看所有网络指令：docker netwok ls 可以看到三种网络分别是 bridge、host、none。bridge网络是默认的 bridge 驱动网络，也是容器创建时默认的网络管理方式，配置后可以与宿主机通信从而实现与互联网通信的功能。host、和none属于无线网络，容器添加到这两个网络不能与外界网路通信。 「演示默认的网络管理方式」 1）启动一个以默认网络管理的容器 docker run -it –name=network-test centos 2）使用网络指令查看网络详情 docker network inspect bridge 执行命令后可以看到 birdge 网络的详细信息，其中包括了刚刚以默认的 bridge 网络管理方式启动的 network-test 容器。 1PS：这里的三种网络方式 bridge、host、none都是非集群环境下 Docker 提供的默认网络。而在 Docker Swarm 集群环境下，除了这三种方式外，Docker 还提供了 docker_gwbridge 和 ingress 两种默认网络。 自定义网络介绍在 Docker 中，可以自定义 bridge 网络（桥接网络）、overlay 网络（覆盖网络），也可以创建 network plugin或者远程网络以实现容器网络的完全定制和控制，以下是简要介绍。 1）Bridge Network 为了容器的安全性，可以使用基于 bridge 的驱动创建新的 bridge 网络，这种基于 bridge 驱动的自定义网络可以较好的实现容器隔离。 需要注意的是，这种用户自定义的基于 bridge 驱动的网络对于单主机的小型网络管理环境是个不错的选择，但是对于大型的网络环境管理（如集群）就需要考虑使用自定义的 overlay 集群网络。 2）Overlay network in swarm mode 在 Docker Swram 集群环境下可以创建基于 Overlay 驱动的自定义网络。为了保证安全性，Swarm集群使自定义的 overlay 网络只适用于需要服务的集群中的节点，而不会对外部其他服务或者 Docker 主机开放。 mark 3）Custome network plugins 了解即可 自定义 bridge 网络并启动容器创建网络：docker network create –driver 驱动名 网络名 --driver：可省略为 -d，用于指定网络驱动类型。 创建一个基于 bridge 驱动的名为 isolated_nw 的网络：1docker network create --driver bridge isolated_nw 查看是否创建成功：docker network ls 查看网络详情：docker network inspect 网络ID 自定义网络创建成功之后，使用该网络启动一个容器：docker run -d –network=isolated_nw centos 查看容器网络细节：docker inspect bb68248d7f847b7302 给正在运行的容器新增网络：docker network connect 网络名 容器ID给刚刚以 isolated_nw 连接的容器再连接一个默认网络： 1docker network connect birdge bb68248d7f847b7302 此时 centos 容器已连接到两个网络环境： 断开容器网络连接：docker disconnect 网络名 容器ID 删除自定义网络：docker network rm 网络名 PS：删除之前，需要断开所有与该网络连接的容器 容器之间的网络通信步骤： 创建两个容器，均连接至默认网络 创建第三个容器，连接新建网络：isolated_nw 给第二个容器增加一个网络环境：isolated_nw 测试容器1能否 ping 通容器2、3 测试容器2能否 ping 通容器1、3 测试容器3能否 ping 通容器1、2 12345678910# docker run -itd --name=container1 centos# docker run -itd --name=container2 centos# docker run -itd --name=container3 --network=isolated_nw centos# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES803165d19df0 centos \"/bin/bash\" 3 seconds ago Up 2 seconds container3fc4210dba15c centos \"/bin/bash\" About a minute ago Up About a minute container1d465908beb23 centos \"/bin/bash\" About a minute ago Up About a minute container2------------------------------------------------------------# docker network connect isolated_nw container2 分别查看三个容器详情： container1 container2 container3 分别进入三个容器查看IP： container1 container2 container3 可以看到，容器2由于连接了两个网络内部有两个网卡，ip分别对应为 172.17.0.2 和 172.18.0.3 测试连通性 container1 ping container2、container3: container2 ping container1、container3: container3 ping container1、container2: 通过上面的测试得出结论： 不同的容器之间想要互相通信必须在同一个网络环境下。 使用默认的 bridge 网络的容器可以互相之间使用容器IP通信，但是无法通过容器名称互相通信。 使用自定义网络管理的容器可以同时使用容器IP和容器名称进行互联。 TIPS：使用命令行参数 –link 通过容器名称进行通信如：docker run -it –name=container4 –link container1:c1 centos以上命令意思为与容器1通信并给容器1分配一个别名c1 不建议使用 –link 参数，在未来可能会废弃此参数。但是对于默认网络连接方式的容器之间只能通过 –link 指定容器名连接到其他容器。虽然默认网络方式下可以通过容器IP连接，但是容器IP是可变的。最好的方式是自定义网络连接，既可以通过容器IP、容器名互联，又保证了安全性。","link":"/2019/05/12/Docker 补救指南（二）—— 网络管理/"},{"title":"First Post","text":"第一篇，心情却不是很好。 &emsp;&emsp;起初只是室友不经意间的一句话，说：某某人现在在自学，还参加了学校的软件杯比赛，还报名了培训班，说应该学的比我还要好的多了。当时听完心里挺不舒服的，想说点什么证明自己来怼他，不过还是算了，毕竟我们关系还不错，没必要为了这点小事伤了和气显得自己多小气的样子，我知道和他辩解没有用，我也不想怪他什么，毕竟软件这个专业只有自己真心投入了才知道过程的艰辛。可是今天这种情况让我有点莫名的心酸… &emsp; &emsp;和往常一样一起吃完中午饭回来，路上看到他的许多同学去上课。说点题外的：大二了，这垃圾学校知道自己教学水平不行和培训机构合作怂恿同学们去培训，培训还得自己出钱。培训老师抓住大多数人的普遍心理让他们醒悟过来觉得现在开始学习，四个月后轻轻松松就可以学到所有技术点，然后坐着办公室拿高薪，敲着小代码，喝着下午茶，过着轻轻松松的生活，好不惬意… 一个个积极的报名去培训上课。我不想说培训机构有什么不好，我自己这两年学习过来的资料大多数都是培训机构的，论师资力量这垃圾学校是没得比的。 &emsp; &emsp;回来的路上自然的聊起培训的事，说什么记不太清，反正字里行间意思就是说他们多努力，多自觉的样子，周末还一个个去上课，这就算了，拿我比较干什么！心里压抑的情绪顿时忍不住了，我说没什么了不起的，他们要是自觉想学的话也不会想到现在去报班，如果不是大二培训机构隔三岔五的来洗脑会有这么多 焕然大悟、怎么就要毕业了、再不学习来不及了、我还什么都没学到怎么找工作的同志们回头赎罪的吗？ “我说我大一入学就自学 C语言 他们在干什么”； “大一第一个学期后的寒假自学 Java 他们又在做什么”； “大一毕业后的暑假自学 Web基础 他们又在干什么”； “大二第一个学期毕业的寒假自学 J2EE框架，练习项目他们又在想些什么！”； “现在大二下学期了，大三在校一个月学校就要求必须出去实习了，我在学习热门 开源框架 巩固基础参加 中国软件杯 比赛写项目而他们，才想起来知道要学习了吗？！”（当然并不是说暑假只能学习，我强调的是自主学习的态度。） &emsp; &emsp;“—— 他们在学习啊”。 &emsp; &emsp;回味深长的一句话，我笑笑，没付出过真的不知道过程的艰辛，付出了被人一句话否定的感觉也真是挺不好受的。算了算了，室友的性格我知道，不能怪他。 &emsp; &emsp;昨天高考结束了，有人欢喜有人愁，不管怎么说，他们都解放了，心中的石头也算放下了，该想什么做什么，毕业前想做不能做的现在可以随着自己了，接下来的就是尽人事听天命吧。突然之间感觉两年过的好快，仿佛我的高考就在昨天，还记得那天晚上和着班上的几个男男女女叫着肖哥一起去唱K，回来在宾馆一起打着扑克，最主要的是那晚鼓起勇气跟赖着坐了一年的 同桌or前后排or左右斜对面 对的同一个女生说了自己的想法，这也是我唯一没有感到遗憾的事了。 &emsp; &emsp;两个月后不情愿的来到了这个地方，和我一起的有高中同一个班上很努力搞学习的被老师看好乖乖男孩，他励志要考上二本（对于我们小学开始就在这种教学质量不高一类的学校读到高中的并且平行班的人来说，能考上二本已经很不错了）。虽然考的不好，但我们都没有选择复读，对于我来说高中那几年想读却不知道如何发力，仅仅靠着考上大学就轻松了的想法读书逼迫自己学习的那种迷茫，看不清道路感觉真的难以言表。话又说回来，我这个高中朋友到了新学校我不知道他哪来的乐观心态，计划着往后的三年“大学生活”如何过的多姿多彩，搞不懂这破地方有什么好憧憬的，有时候也蛮欣赏他们这种心态的。可是我满脑子里想的是，高中阶段不知所措的那几年我现在要以这种方式补回来，我是来赎罪的，我愧对自己，也愧对家人。 &emsp; &emsp;军训后上的第一门专业课叫 C语言程序设计 ，给我们上课的老师是一个实习生，搞IOS开发的，兼职来给我们上课。一个礼拜一节专业课，好充实的呢，MD。学校的初衷是让我们接触计算机语言的思想，字节啊、变量常量啊、语句啊、基本数据结构啊（虽然只粗略的提到了数组，仅此而已）。这就算了，由于是第一次上这种专业课，觉得老师讲的还可以，但是看书的目录总觉得讲的少了太多太多，老师也说了没想过给我们讲太多，当时我就不乐意了，我TM是来赎罪的你给我讲这么点我怎么学习知识！于是我开始接触网络学习，最开始下载了 网易云课堂 在里面看到邵发老师的 C/C++学习指南，看了有170多个课时，开始听了几节，觉得这个老师很有风格，由浅入深并且讲的很好很好，当时不知道哪来的毅力决定了把这个课程全部搞完。每天看视频当连续剧一样看，睡觉之前醒来之后都是视频，买了作者的书籍，在线练习题也全部自己认真练习并且整理成错题（高中养来的习惯）。就不知不觉培养了我对编程的兴趣。现在想想这都是缘分，如果不是这个课程对我的影响或许我和大多数在校生一样迷茫把！ &emsp; &emsp;后来的学习过程就不说了，无数次遇到困难，由于进度比学校都要快，没人帮我，只能自己百度查资料翻博客，久而久之我觉得网上的资源比在校老师实用的多，遇到过手贱、环境、语法、逻辑等各种无厘头的错误，但是从来没想到过放弃。最近日常解决bug看到网上一个妹子的博客简介是：从哪里跌倒，就在那里趴下，起来之后你会发现新大陆的。 这句话写的真的不错，深有体会，bug fix 之后的喜悦感真的只有自己经历过才知道。 &emsp; &emsp;就这样我带着不甘心的情绪学习到了现在，记得入学后我发的第一条朋友圈是 既然当不了鸡头，就争取做到凤尾。 语文水平不好只能说成这样了，不过我确实也做到了，最起码在班上专业上来说，我觉得自己水平第二没人有自信说第一，不过和他们比专业这毫无意义。当然不能自大，除了学习方面我还有很多方面需要向他们学习。 &emsp; &emsp;两年过来，结识了其他班上很多志同道合的朋友，学习到了很多，认识到自己的不足，即将步入找工作的浪潮，压力很大，任务很重，要学的很多，我会继续努力。 &emsp; &emsp;说了这么多，气也消了，想想也没必要，做好自己就行了何必在意别人怎么看呢。曾经是文科生，但是本身很恶心鸡汤，从来不想记录什么，生活重要的是过程，也没什么文采，写给自己看的。 &emsp; &emsp;—— 就这样。 &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp;","link":"/2018/06/09/First Post/"},{"title":"Hexo迁移至Docker","text":"一、本地迁移一）将之前的博客地址根文件夹拷贝一份复制到指定位置，用作\b与容器共享的数据卷。 1234567~/Workspace/docker-hexo $ pwd/Users/harry/Workspace/docker-hexo~/Workspace/docker-hexo $ lltotal 8-rw-r--r--@ 1 harry staff 482B Jun 17 17:10 Dockerfiledrwxr-xr-x@ 15 harry staff 480B Jun 17 17:19 harrys-blog # 根目录~/Workspace/docker-hexo $ 二）\b编写 Dockerfile 脚本，构建镜像。 docker build -f Dockerfile -t harrys-blog:latest . 12345678910111213141516171819202122FROM centosMAINTAINER harry&lt;yuzh233@gmail&gt;EXPOSE 4000RUN cd / &amp;&amp; mkdir docker-hexo &amp;&amp; cd docker-hexoWORKDIR /docker-hexo# install latest nodeRUN yum install -y gcc-c++ make \\&amp;&amp; curl -sL https://rpm.nodesource.com/setup_12.x | bash - \\&amp;&amp; yum -y install nodejs \\&amp;&amp; node -v# install gitRUN yum -y install git \\&amp;&amp; git --version# install hexoRUN npm install -g hexo-cli# CMD [\"sh\",\"-c\",\"hexo g &amp;&amp; hexo s\"]ENTRYPOINT [\"sh\",\"-c\",\"cd /harrys-blog &amp;&amp; hexo g &amp;&amp; hexo s\"] 三）运行容器，指定数据卷文件路径 docker run -d -p 4000:4000 -v ~/Workspace/docker-hexo/harrys-blog/:/harrys-blog harrys-blog:latest 二、迁移到远程服务器一）创建阿里云私有仓库并推送镜像 123$ sudo docker login --username=yuzh233 registry.cn-hangzhou.aliyuncs.com$ sudo docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/yuzh/harrys-blog:[镜像版本号]$ sudo docker push registry.cn-hangzhou.aliyuncs.com/yuzh/harrys-blog:[镜像版本号] 二）使用 source copy 上传文件到服务器\b 1scp hexo.gz root@120.78.69.82:/hexo.gz 三）运行容器，指定数据卷文件路径 docker run -d -v ~/harrys-blog:/harrys-blog -p 4000:4000 registry.cn-hangzhou.aliyuncs.com/yuzh/harrys-blog 四）运行 nginx 容器，将其中 /etc/nginx 目录拷贝到宿主机，停止容器 五）运行一个新的容器，挂载本地 nginx 配置到容器中 docker run -d -p 80:80 -v ~/nginx-container-config/:/etc/nginx nginx nginx.conf: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859user nginx;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events { worker_connections 1024;}http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; upstream hexo { server 120.78.69.82:4000; } server { # 默认监听80端口，这样就不需要指定端口访问。 listen 80;# listen 443; # 用户访问时的域名。 server_name yuzh.xyz;# ssl on;listen 443 ssl; ssl_certificate cert/yuzh.xyz.pem; ssl_certificate_key cert/yuzh.xyz.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; #使用此加密套件。 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #使用该协议进行配置。 ssl_prefer_server_ciphers on; location / { # nginx通过前面的 hexo 转发到指定的网站，访问 hexo 就是访问 120.78.69.82:4000 proxy_pass http://hexo; index index.html index.htm; } }}","link":"/2019/06/18/Hexo迁移至Docker/"},{"title":"IDEA+Maven+Tomcat插件实现热部署","text":"傻了吧唧的其实不是什么大问题，但是这几天脑子有点混乱，情绪很低迷，搞得自己很郁闷。😔切记戒骄戒躁，遇到问题不要心急，静下心来，佛系调bug~~😵 一直都把热部署的概念搞错了，热部署是指项目发布到服务器之后，以不重启服务器为前提本地重新打包发布到服务器上面运行。 说起来很好理解，但是本地tomcat热部署和Maven的Tomcat插件热部署还是有些区别的，一直没走出这个误区，静下心来想下真傻😔 Tomcat本地热部署本地启动服务器，本地重新打包发布，run和redeploy是同一个工具本地启动tomcat服务，不重启服务器的前提下更新war包资源。配置很简单当需要更新资源时点击右上角选择redeploy重新发布即可。 Maven+Tomcat插件热部署不一定是本地启动服务器，本地重新打包发布，run和redeploy不是同一个工具 搞清原理，热部署主要的作用是在不关闭服务器的时候添加或修改项目，tomcat必须要开着，并且保证能访问manager手动管理里面的项目。 就是说插件热部署有一个前提，就是服务器已经在运行，maven的tomcat插件不负责启动服务器，只是负责重新发布到指定的服务器资源中（远程服务器）。 第一步：修改tomcat的conf/tomcat-users.xml配置文件。注意：该tomcat是在本地虚拟机中的，当然也可以本地win开一个添加用户名、密码、权限。 123&lt;role rolename=\"manager-gui\" /&gt;&lt;role rolename=\"manager-script\" /&gt;&lt;user username=\"admin\" password=\"admin\" roles=\"manager-gui, manager-script\"/&gt; 然后 启动Tomcat ，通过CMD或批处理命令或其他工具启动，不要用Tomcat插件启动就行。此时已经可以通过访问 http://192.168.184.130:8080/manager/text 进入tomcat的管理页面发布部署项目了，但是一般不会这么做，我们使用tomcat插件进行热部署。 第二步：配置maven和tomcat关联关系maven当然是在本地开发环境了账号密码同上配置，在maven安装目录中的settings.xml中配置。 1234567&lt;!-- 在&lt;servers&gt;节点下添加 --&gt;&lt;server&gt; &lt;!-- 配置服务器名，maven插件需要引用该插件名 --&gt; &lt;id&gt;tomcat7&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin&lt;/password&gt;&lt;/server&gt; 第三步：pom引入插件1234567891011121314151617181920&lt;build&gt; &lt;plugins&gt; &lt;!-- 配置Tomcat插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;path&gt;/hotDeploy&lt;/path&gt; &lt;port&gt;8080&lt;/port&gt; &lt;!-- 用于配置热部署 --&gt; &lt;url&gt;http://192.168.184.130:8080/manager/text&lt;/url&gt; &lt;server&gt;tomcat7&lt;/server&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin&lt;/password&gt; &lt;update&gt;true&lt;/update&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 第四步：配置好引用本地maven的setting文件 第五步：重新打包发布，实现热部署tomcat已经启动了，这里只重新打包发布.命令：tomcat7:deploy 发布成功： 可算把这个搞清楚了~","link":"/2018/07/29/IDEA-Maven-Tomcat插件实现热部署/"},{"title":"Lombook 插件与 xXxx 格式命名变量带来的问题","text":"使用 Lombok 插件时，JavaBean 命名需要注意一个地方： 变量名命名最好是不要「第二个字母大写」，如：iPhone，应该写成 iphone。 JavaBean 的规范是第二个字母不能大写，如果第二个字母大写那么 getter / setter 方法我们想象中的应该会是这样： getIPhone() / setIPhone() 因为根据 JavaBean 规范，get / set 方法是取每个属性的第一个字母转大写其他字母不变，这也是 lombok 插件自动生成 getter / setter 的样子，比如： 但是请注意：这样写会导致一些问题！！！！首先 Spring 是不认识的，Jackson 的解析也是会和我们的期望值不一样的。 我们希望返回的 json 字段是和属性名一样如：iPhone，但是此时我们的 getter 方法是这样的：「getIPhone()」，jackson 会根据方法名作为 key，根据方法返回的值作为 value，生成 json 字符串，结果是： 123{ \"iphone\": \"xxx\"} 这显然不是前端需要的。 让我们去掉 lombok 的 @Data 注解，使用 IDEA 自动生成的 getter / setter 方法看看： 注意到了没？编辑器生成的方法是没做任何处理的，直接把变量名拼接到 get / set 后面，此时 Jackson 根据方法名获取到的 key 是：sCard，json 串也就理所当然是： 1{\"sCardNum\":\"xxx\"} 而不是 1{\"scardNum\":\"xxx\"} IDE 和 Spring 和 Jackson 这样做是不符合 JavaBean 规范的，但是大厂都是这么用的，我们也默认习惯了这样用。Lombok 为了遵循 JavaBean 规范与这种大的框架反其道而行之使得我们遇到一些坑。 所以解决办法有： 遵循约定大于配置原则，不使用 xXxx 命令方式。但是如果非要这样做，请看以下： 修改 lombok 源码，不推荐，破坏依赖管理，成本高。 继续使用 @Data 注解，但是有第二个字母大写的属性就自己通过工具生成一下 get / set 方法即可，会覆盖掉 lombok 生成的，无需担心。","link":"/2019/08/05/Lombook 插件与 xXxx 格式命名变量带来的问题/"},{"title":"Linux下搭建Hexo博客环境","text":"Linux下搭建Hexo博客环境 前不久在自己电脑上搭建了基于 Github+Hexo 的个人博客，今天试着在Linux下搭建hexo环境并通过域名解析本地IP运行起来。刚好前几天在阿里云买了ECS云服务器和域名，还不是很熟练，不用白不用。😄 Steps 1 ：安装Git 安装git依赖包 1 yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel gcc perl-ExtUtils-MakeMaker 删除已有的git 1 yum remove git 下载git源码 切换到包文件目录： 1 cd /usr/src 下载git安装包 1 wget https://www.kernel.org/pub/software/scm/git/git-2.8.3.tar.gz 解压git安装包 12 tar -zxvf git-2.8.3.tar.gz cd git-2.8.3 配置git安装路径，usr目录一般用于存放共享的系统资源 1 ./configure prefix=/usr/local/git/ 编译并且安装 1 make &amp;&amp; make install 将git指令添加到环境变量中 1 vi /etc/profile 在最后一行加入 1 export PATH=$PATH:/usr/local/git/bin 刷新配置文件 1 source /etc/profile 然后，查看git版本号 1 git --version next… Steps 2 ：安装Node.js环境 安装Node.js依赖包 1yum -y install gcc-c++ openssl-devel 检查Python版本 1python --version 检查Python的版本，必须在2.6及以上才可以，如果低于这个版本还需要安装Python，当前Centos6系统，默认支持2.6。 下载和安装Node.js，注意先到opt目录下 12345wget http://nodejs.org/dist/node-latest.tar.gztar -zxvf node-latest.tar.gzcd node-v0.12.7./configuremake &amp;&amp; make install 我以为源码编译安装十几分钟就行了，然而足足安装了一个多小时。。。😭不过还好成功了。 接下来的才是主角 Steps 3： 安装Hexo环境 采用npm方式来部署hexo静态博客 1npm install -g hexo 安装期间出现了警告，有点小紧张，安装了这么久不会前功尽弃把！还好最后成功了，警告无所谓了只要不是错误~~ 查看hexo版本信息 创建hexo部署的文件夹，初始化hexo在该目录 成功 安装依赖包 1npm install 生成hexo静态页面 1hexo generate / 或者 hexo g &nbsp;&nbsp;&nbsp;至此，hexo已搭建成功并且能够在本机（linux）访问了；然而，这里是远程连接阿里云的ECS实例，没有图形化界面无法从浏览器直观的看到服务跑起来之后的页面。所以我们需要在自己的电脑从公网访问 http://39.106.15.140:4000 嗯看起来是这样子的，试试把… 无法连接服务器，不对啊，我不是开了服务了嘛！有毒把~(￢︿̫̿￢☆) Steps 4 ： 阿里云ECS云服务器安全组设置呵呵天真，天真的以为开了服务就可以从公网访问了，看看这个。 什么鬼？这是阿里云安全组规则列表，相当于防火墙。从列表看出并没有开放hexo默认的4000，所以外网是访问不到的。 栗子：22/22 代表开放端口的范围是22-22，只开放22号端口的意思，linux默认开放22端口用于ssh远程登陆，这也是可以远程XShell6登陆成功的原因。 知道了原因下面添加一条安全组规则 添加之后记得刷新！ 然后再次访问，会出现hexo默认博客界面了 over~ 0点17了，好怕猝😵�😵，睡了睡了。。。","link":"/2018/06/15/Linux下搭建Hexo博客环境/"},{"title":"Linux下部署个人站点后的运行问题","text":"Linux下部署个人站点后的运行问题 &nbsp;&nbsp;昨天已经把个人站点部署在linux成功并可以发布运行，有一个问题，就是当退出远程登陆SSH之后，hexo的进程会被杀死导致无法访问，今天早上看了几篇博客之后知道怎么回事了，做一下记录。 1、进程杀死原因1.1、进程与会话 进程组： 一个或多个进程的集合，每一个进程组都有唯一一个进程组ID，即进程组 会话期： 一个或多个进程组的集合，有唯一一个会话期首进程（session leader）。会话期ID为首进程的ID。 控制进程: 与控制终端（如ssh）连接的会话期首进程叫做控制进程。当前与终端交互的进程称为前台进程组， 其余进程组称为后台进程组。 PID = 进程ID （由内核根据延迟重用算法生成）PPID = 父进程ID（只能由内核修改）PGID = 进程组ID（子进程、父进程都能修改）SID = 会话ID（进程自身可以修改，但有限制，详见下文）TPGID= 控制终端进程组ID（由控制终端修改，用于指示当前前台进程组） 关键点：每次用户登陆终端会产生一个会话session，session从登陆开始到结束为止，而这一段时间内在该会话中执行的所有进程都属于本会话。 1.2、挂断信号SIGHUP挂断信号默认操作是终止进程 当终端接口检测到网络连接断开，将挂断信号发送给控制进程（会话期首进程） 如果会话期首进程终止，则该挂断信号发送到该会话期前台进程组. 一个进程退出导致一个孤儿进程组中产生时，如果任意一个孤儿进程组进程处于STOP状态，发送SIGHUP和SIGCONT信号到该进程组中所有进程. 1.3、hexo 进程中断原因： SSH退出连接或因网络问题中断连接，ssh终端检测到连接中断会将挂断信号SIGHUP发送到与终端连接的控制进程。 控制进程被终止了，属于同一个会话期的其他进程也被终止了。 2、解决办法说了那么多，意思就是说ssh 打开以后，bash等都是他的子程序，一旦ssh关闭，系统将所有相关进程杀掉！！ 导致一旦ssh关闭，执行中的任务就取消了。 2.1、nohub命令与&amp;命令作用：后台执行 当平时在终端操作时，不希望运行一个程序占满了屏幕导致无法进行其他操作时，这时候就需要后台运行了。本情形下：退出ssh后希望hexo依然继续工作，也需要后台运行了。 &amp; 命令比如 1hexo s &amp; 虽然前台有打印，但是ctrl+c之后程序并没有退出，依然可以从公网访问。但是有一个弊端就是：当退出控制进程之后该后台进程会被杀死，所以希望退出之后继续运行需要使用 nohup nohup 命令1nohup hexo s &amp; 此时hexo进程已经后台运行了，可以看到一句话“忽略输入并将输出追加到’nohup.out’”，就是说把当前 hexo s 命令的输出文件追加到当前目录的 nohup.out 文件中去了，vim看一下。 可以让程序输入到指定位置 1nohup hexo s &gt;/opt/output/out.file 2&gt;&amp;1 &amp; 什么意思不记录了。 后台运行之后可以通过 jobs 查看当前后台进程，注意：jobs只显示当前会话期的后台进程，如果退出之后是查看不到 hexo的后台进程的，不过可以通过 ps -aux 进程命令查看到。 1ps -aux | grep hexo 当不需要后台运行时 1kill PID 可以发现退出之后jobs是看不到后台进程的. 3、将ip地址映射到域名 &nbsp;&nbsp;这里就需要用到域名的DNS解析了，由于前面已经搭建了放在Github的Hexo环境，自己的 yuzh.xyz 域名DNS解析中 A记录 和 @记录 均指向到了github博客仓库地址 https://github.com/yuzh233/yuzh233.github.io 所对应的ip。所以通过 www.yuzh.xyz 和 yuzh.xyz 是不能够访问 linux下的hexo的。 3.1、 GitHub仓库作为服务器部署办法 修改hexo根目录配置文件 _config.yml 1234567# Deployment## Docs: https://hexo.io/zh-cn/docs/deployment.htmldeploy: type: git # 仓库地址，不是url地址，是拷贝仓库时的地址。 repo: https://github.com/yuzh233/yuzh233.github.io.git branch: master hexo是依据这个部署到git仓库的。 上传到git仓库 先安装上传的插件 1npm install hexo-deployer-git --save 上传命令，每次有更新都需要 “生成 -&gt; 部署” 123hexo cleanhexo generatehexo deploy 绑定域名 该步可以跳过，不过我就是要绑定。 在source文件夹下新建一个名为CNAME的文件，里面写指定的域名 比如 www.yuzh.xyz 添加一条 DNS 解析。添加一条 A 记录和 @ 记录，IP地址填写hexo部署到git的仓库的地址，怎么获取仓库地址对应的ip？ ping yuzh233.github.io 可以得到ip，这里有一个问题，仅仅通过这个ip就访问到了我的仓库吗？为什么不需要设置端口号啊(・∀・(・∀・ ) ，不管了，反正就是访问到了。 然后访问的时候输入 www.yuzh.xyz 或 yuzh.xyz 就到了我的仓库了（设置了解析的结果），我的仓库由于添加了CNAME记录，将仓库的域名指向了文本中的域名了。 3.2、 云ECS linux环境服务器部署办法 首先当然是 linux后台运行hexo s进程了。 然后 ECS 安全组不能把默认4000端口拦截了。 绑定域名 由于一级域名已经被git中的仓库绑定了，这里可以更换DNS解析重新绑定到我的linux主机中，访问方式：www.yuzh.xyz:4000 为什么这里要加端口而绑定到git仓库时却不需要端口呢？鬼知道为什么~ 部署到git的时候通过一个ip直接访问到了仓库地址。但是访问linux主机中的应用本来就是要加端口的。 这里不想更改DNS解析，但是可以使用二级域名解析哦~ 二级域名是免费的 可以设置多个二级域名，指向到不同的主机地址 如： 这样通过 blog.yuzh.xyz:4000可以访问到linux下的hexo环境了。 然而，还是要加个端口号，不想显式加端口，怎么办？—— 使用隐形URL作为解析记录 如此，通过访问 bg.yuzh.xyz 转发到了 blog.yuzh.xyz:4000 再访问到了hexo应用了。 注意：使用隐形URL或显性URL跳转需要备案。备案条件：1.主机在国内 2.ECS租用3个月以上 3.域名已经实名验证","link":"/2018/06/16/Linux下部署个人站点后的运行问题/"},{"title":"Linux - SSH-别名登陆","text":"编辑 ~/.ssh/config，添加： 123456789101112# 设置别名登陆Host harry # 主机地址 HostName 120.78.69.82 # 端口，非必填 Port 22 # 用户名 User root # 登陆的公钥文件，非必须 # IdentityFile ~/.ssh/id_rsa.pub # 只接受 SSH Key 登陆 IdentitiesOnly yes","link":"/2019/06/22/SSH-别名登陆/"},{"title":"Linux - SSH-保持连接","text":"方式一：服务端配置vim /etc/ssh/sshd_config修改参数： 123ClientAliveInterval 60 # 服务端每 60s 向客户端发起\b一次响应ClientAliveCountMax 10 # 如果客户端超过 10 次每响应则\b掐断连接restart ssh / service ssh reload 方式二：客户端配置（推荐）/etc/ssh/ssh_config 或者 ~/ssh/config 添加： 12Host *ServerAliveInterval 60 then: 1chmod 600 ~/.ssh/config","link":"/2019/06/21/SSH-保持连接/"},{"title":"SpringAop中JoinPoint对象使用时出现的问题","text":"介绍不写了，API也不写了，记录问题解决。 切面类： 123456789101112131415161718192021222324252627282930313233package xyz.yuzh.aspect;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.AfterReturning;import org.aspectj.lang.annotation.Aspect;import org.springframework.stereotype.Component;/** * 日志切面 * * @Author: z.yu * @Date: 2018/06/19 20:35 */@Aspect@Componentpublic class LogAspect { /** * 如果代理Handler，该Handler不能继承类。 */ @AfterReturning(pointcut = \"execution(* xyz.yuzh.service.*.*(..))\") public void log(JoinPoint point) { Object[] args = point.getArgs(); for (Object a : args) { System.out.println(\"入参数 -&gt; \" + a + \",\"); } System.out.println(\"方法签名：\" + point.getSignature()); System.out.println(\"目标对象：\" + point.getTarget()); System.out.println(\"代理对象：\" + point.getThis()); System.out.println(\"-----------------------\"); }} 1、 自动代理aop的配置需要写在 spring.xml 中，因为 spring-mvc.xml 配置成只扫描的到 handler，spring.xml才能扫描到其他Component（如切面类：LogAspect）。 true代表CGLIB动态代理 false代表JDK动态代理（默认） 1&lt;aop:aspectj-autoproxy proxy-target-class=\"false\"&gt;&lt;/aop:aspectj-autoproxy&gt; 2、 使用 @AfterReturning时，如果指定了返回值，那么目标方法有返回值的才会匹配的到1234@AfterReturning(pointcut = \"execution(* xyz.yuzh.service.*.*(..))\",returning = \"returnValue\")public void log2(JoinPoint point,Object returnValue) { //...} 3、目标方法如果是继承或实现得到的，是代理不到的，除非覆盖其父级方法。4、如果目标方法是 Handler中的方法，没有被代理到？ web容器加载顺序：ServletContext -&gt; context-param -&gt; listener-&gt; filter -&gt; servlet 首先一点：spring的Bean和springMVC的Bean所在的上下文是不同的 前面切入点在service层时，自动代理 &lt;aop:aspectj-autoproxy/&gt; 配置到spring.xml，即这里的bean是可以被代理到的。serviceBean被spring.xml扫描到，LogAspect作为切面才会生效。 @Component 作为spring容器中的bean被加载到了。 @Aspect 施加了该注解的spring容器的bean的切面应用成功。 代理handler中的方法步骤： &lt;aop:aspectj-autoproxy/&gt; 放到spring-mvc.xml ，该配置文件才是扫描handler的。 手动创建bean -&gt; &lt;bean id=&quot;logAspect&quot; class=&quot;xyz.yuzh.aspect.LogAspect&quot;&gt;&lt;/bean&gt;，因为扫描不到。 移除LogAspect的@Component注解，因为已经手动创建了，重复创建可能会出现错误。 good night(￣o￣) . z Z","link":"/2018/06/19/SpringAop中JoinPoint对象使用时出现的问题/"},{"title":"20190528 Announcing GitHub Sponsors 💖","text":"Hi @yuzh233 ,We’re thrilled to announce the beta of GitHub Sponsors, a tool to financially support the developers who build the open source software you use every day. These extraordinary developers can now receive funding from the community that depends on their work, seamlessly through their GitHub profiles.Learn more To kick start this new program and boost community funding, we’re also launching the GitHub Sponsors Matching Fund. For each dollar that a developer contributes, GitHub will double that sponsorship for each sponsored developer’s first year in the program. GitHub Sponsors is launching small and simple, but our mission is vast: to expand the opportunities to participate in and build on open source. We’re here to serve the developer community, and we’re eagerly listening for your input about what else you’d like to see in GitHub Sponsors. Today’s launch is just the beginning.Read the blog Hi yuzh233:我们很高兴宣布（announce） Github 赞助商（Sponsors）的测试版，该工具从经济上（financially）支持开发者构建您每天使用的开源软件。 这些杰出的（extraordinary）的开发人员可以他们的工作从开源社区接受资助（receive funding）。通过他们的github资料无缝（seamlessly）完成（捐助）。 启动这个（to kick start this）新的项目并增加（boots）社区资金，我们还启动了「github 赞助商匹配基金」。开发者贡献的每一（for each）美元，GITHUB 将为每一个受赞助的开发者在该项目的第一年中提供双倍的赞助资金。 GitHub 赞助商正推出（is launching发行）小型和简单的，但我们的使命（mission）是巨大（vast）的：扩大（expand）参与（opporunities）机会（participate）和构建开源社区。我们是为开源社区服务的，我们热切地（eagerly）倾听您的建议和关于您还希望在GitHub贡献商看到什么。今天的推行只是一个开始。","link":"/2019/05/28/[20190528] Announcing GitHub Sponsors 💖/"},{"title":"20190601 spring-boot | overview","text":"OverviewSpring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can “just run”. We take an opinionated view of the Spring platform and third-party libraries so you can get started with minimum fuss. Most Spring Boot applications need very little Spring configuration. Features Create stand-alone Spring applications Embed Tomcat, Jetty or Undertow directly (no need to deploy WAR files) Provide opinionated ‘starter’ dependencies to simplify your build configuration Automatically configure Spring and 3rd party libraries whenever possible Provide production-ready features such as metrics, health checks and externalized configuration Absolutely no code generation and no requirement for XML configuration You can also join the Spring Boot community on Gitter! 概述Spring Boot 让单体\b应用的创建变得简单，基于生产级别的 \b\bspring 应用你可以 ‘直接运行’。 我们对spring\b平台和第三方类库采取（take on）自己的（opinionated固执己见的\b）看法（view 看法，观念），所以您可以以最小的麻烦快速启动。大多数的spring应用只需要少量的配置。 特性（功能） 创建soring单体应用 内嵌 tomcat，jetty或者undertow directly（不需要部署 war 文件） 提供自己的 starer \b依赖简化你的配置 \b尽可能做到（whenever possible）动态配置 spring 和第三方平台类库 提供可供生产的（production-ready ）功能如 metrics, 健康检查和外部化（externalized）配置\b。","link":"/2019/06/01/[20190601] spring-boot | overview/"},{"title":"20190529 dockerfile-plugin | authentication","text":"https://github.com/spotify/dockerfile-maven/blob/master/docs/authentication.md Authentication and private Docker registry supportSince version 1.3.0, the plugin will automatically use any configuration in your ~/.dockercfg or ~/.docker/config.json file when pulling, pushing, or building images to private registriesAdditionally the plugin will enable support for Google Container Registry if it is able to successfully load Google’s “Application Default Credentials”. The plugin will also load Google credentials from the file pointed to by the environment variable DOCKER_GOOGLE_CREDENTIALS if it is defined. Since GCR authentication requires retrieving short-lived access codes for the given credentials, support for this registry is baked into the underlying docker-client rather than having to first populate the docker config file before running the plugin. GCR users may need to initialize their Application Default Credentials via gcloud. Depending on where the plugin will run, they may wish to use their Google identity by running the following command 1gcloud auth application-default login or create a service account instead. Authenticating with maven settings.xmlSince version 1.3.6, you can authenticate using your maven settings.xml instead of docker configuration. Just add configuration similar to: 12345&lt;configuration&gt; &lt;repository&gt;docker-repo.example.com:8080/organization/image&lt;/repository&gt; &lt;tag&gt;latest&lt;/tag&gt; &lt;useMavenSettingsForAuth&gt;true&lt;/useMavenSettingsForAuth&gt;&lt;/configuration&gt; You can also use -Ddockerfile.useMavenSettingsForAuth=true on the command line.Then, in your maven settings file, add configuration for the server: 1234567&lt;servers&gt; &lt;server&gt; &lt;id&gt;docker-repo.example.com:8080&lt;/id&gt; &lt;username&gt;me&lt;/username&gt; &lt;password&gt;mypassword&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt; exactly as you would for any other server configuration. Since version 1.4.3, using an encrypted password in the Maven settings file is supported. For more information about encrypting server passwords in settings.xml, read the documentation here. Authenticating with maven pom.xmlSince version 1.3.XX, you can authenticate using config from the pom itself. Just add configuration similar to: 12345678910111213 &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${version}&lt;/version&gt; &lt;configuration&gt; &lt;username&gt;repoUserName&lt;/username&gt; &lt;password&gt;repoPassword&lt;/password&gt; &lt;repository&gt;${docker.image.prefix}/${project.artifactId}&lt;/repository&gt; &lt;buildArgs&gt; &lt;JAR_FILE&gt;target/${project.build.finalName}.jar&lt;/JAR_FILE&gt; &lt;/buildArgs&gt; &lt;/configuration&gt;&lt;/plugin&gt; or simpler, 1234567891011&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${version}&lt;/version&gt; &lt;configuration&gt; &lt;repository&gt;${docker.image.prefix}/${project.artifactId}&lt;/repository&gt; &lt;buildArgs&gt; &lt;JAR_FILE&gt;target/${project.build.finalName}.jar&lt;/JAR_FILE&gt; &lt;/buildArgs&gt; &lt;/configuration&gt;&lt;/plugin&gt; with this command line call 1mvn goal -Ddockerfile.username=... -Ddockerfile.password=... 认证身份认证和私有 Docker 仓库支持从 1.3.0 版本起（since 自…以来，由于，因为），该插件动态（automatically）使用您的配置文件：~/.dockercfg 或 ~/.docker/config.json 其中的一种当拉取、推送、构建镜像到私有仓库时。 此外（Additionally），该插件将支持「谷歌的容器注册」，如果它能够成功（if it is able to successfully）地加载谷歌的“应用程序默认凭据”。如果定义了环境变量 DOCKER_GOOGLE_CREDENTIALS ，该插件也可以从环境变量 DOCKER_GOOGLE_CREDENTIALS 指向的文件中（from the file pointed to by 从什么指向的文件）加载谷歌凭证。由于 GCR 认证需要从给定的凭证中检索（retrieving）短效访问码，对这个容器注册（服务）的支持被合成（baked into）到底层（underlying）的 docker-client ，而不是（rather than）在容器插件运行之前第一时间填充（having to first populate） docker 配置文件。 GCR 用户可能需要通过 gcloud 初始化他们的应用默认凭证，这取决于（depending on 依靠、依赖、取决于）插件运行的位置，他们可能希望通过运行一下命令使用他们的 Google identity 1gcloud auth application-default login 或者 create a service account 作为替代. 用 maven settings.xml 认证从 1.3.6 版本开始，你可以使用你的 maven setting.xml 文件认证作为 docker 配置文件的替代。只需要添加以下类似的（similar to）配置： 12345&lt;configuration&gt; &lt;repository&gt;docker-repo.example.com:8080/organization/image&lt;/repository&gt; &lt;tag&gt;latest&lt;/tag&gt; &lt;useMavenSettingsForAuth&gt;true&lt;/useMavenSettingsForAuth&gt;&lt;/configuration&gt; 你同样可以在命令行执行命令 -Ddockerfile.useMavenSettingsForAuth=true （替代 true ）然后，在您的 maven setting 文件中，添加以下服务配置： 1234567&lt;servers&gt; &lt;server&gt; &lt;id&gt;docker-repo.example.com:8080&lt;/id&gt; &lt;username&gt;me&lt;/username&gt; &lt;password&gt;mypassword&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt; 对于其他任意（for any other）的服务器你会使用完全一样（exactly as）的配置。从 1.4.3 版本开始，maven setting 文件中支持使用加密密码，关于更多在 setting.xml 中加密服务器密码的信息，read the documentation here. 用 maven pom.xml 认证从 1.3.X 开始，你可以使用 pom 本身的配置认证，只需要添加以下类似的配置： 12345678910111213 &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${version}&lt;/version&gt; &lt;configuration&gt; &lt;username&gt;repoUserName&lt;/username&gt; &lt;password&gt;repoPassword&lt;/password&gt; &lt;repository&gt;${docker.image.prefix}/${project.artifactId}&lt;/repository&gt; &lt;buildArgs&gt; &lt;JAR_FILE&gt;target/${project.build.finalName}.jar&lt;/JAR_FILE&gt; &lt;/buildArgs&gt; &lt;/configuration&gt;&lt;/plugin&gt; 或者更简单的, 1234567891011&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${version}&lt;/version&gt; &lt;configuration&gt; &lt;repository&gt;${docker.image.prefix}/${project.artifactId}&lt;/repository&gt; &lt;buildArgs&gt; &lt;JAR_FILE&gt;target/${project.build.finalName}.jar&lt;/JAR_FILE&gt; &lt;/buildArgs&gt; &lt;/configuration&gt;&lt;/plugin&gt; 使用此命令行调用： 1mvn goal -Ddockerfile.username=... -Ddockerfile.password=...","link":"/2019/05/29/[20190529] dockerfile-plugin | authentication/"},{"title":"20190602 spring-boot | part1","text":"Spring Boot Reference Guide2.1.5.RELEASEhttps://docs.spring.io/spring-boot/docs/2.1.5.RELEASE/reference/htmlsingle/ Part I. Spring Boot Documentation Part I. Spring Boot Documentation 1. About the Documentation 2. Getting Help 3. First Steps 4. Working with Spring Boot 5. Learning about Spring Boot Features 6. Moving to Production 7. Advanced Topics 第一单元：Spring Boot 文档 1. 关于文档 2. 获得帮助 3. 第一步 4. 使用 spring boot 工作 5. 学习 spring boot 的特性功能 6. 移动到生产 7. 高级主题 Part I. Spring Boot DocumentationThis section provides a brief overview of Spring Boot reference documentation. It serves as a map for the rest of the document. 1. About the DocumentationThe Spring Boot reference guide is available as HTML PDF EPUB The latest copy is available at docs.spring.io/spring-boot/docs/current/reference. Copies of this document may be made for your own use and for distribution to others, provided that you do not charge any fee for such copies and further provided that each copy contains this Copyright Notice, whether distributed in print or electronically. 2. Getting HelpIf you have trouble with Spring Boot, we would like to help. Try the How-to documents. They provide solutions to the most common questions. Learn the Spring basics. Spring Boot builds on many other Spring projects. Check the spring.io web-site for a wealth of reference documentation. If you are starting out with Spring, try one of the guides. Ask a question. We monitor stackoverflow.com for questions tagged with spring-boot. Report bugs with Spring Boot at github.com/spring-projects/spring-boot/issues. All of Spring Boot is open source, including the documentation. If you find problems with the docs or if you want to improve them, please get involved. 3. First StepsIf you are getting started with Spring Boot or ‘Spring’ in general, start with the following topics: From scratch: Overview | Requirements | Installation Tutorial: Part 1 | Part 2 | Running your example: Part 1 | Part 2 4. Working with Spring BootReady to actually start using Spring Boot? We have you covered: Build systems: Maven | Gradle | Ant | Starters Best practices: Code Structure | @Configuration | @EnableAutoConfiguration | Beans and Dependency Injection Running your code: IDE | Packaged | Maven | Gradle Packaging your app: Production jars Spring Boot CLI: Using the CLI 5. Learning about Spring Boot FeaturesNeed more details about Spring Boot’s core features? The following content is for you: Core Features: SpringApplication | External Configuration | Profiles | Logging Web Applications: MVC | Embedded Containers Working with data: SQL | NO-SQL Messaging: Overview | JMS Testing: Overview | Boot Applications | Utils Extending: Auto-configuration | @Conditions 6. Moving to ProductionWhen you are ready to push your Spring Boot application to production, we have some tricks that you might like: Management endpoints: Overview | Customization Connection options: HTTP | JMX Monitoring: Metrics | Auditing | Tracing | Process 7. Advanced TopicsFinally, we have a few topics for more advanced users: Spring Boot Applications Deployment: Cloud Deployment | OS Service Build tool plugins: Maven | Gradle Appendix: Application Properties | Auto-configuration classes | Executable Jars 第一单元：Spring Boot 文档这一章节提供对spring boot参考文档的简要概述（a brief overview）。它可以作为（serves as）文档其余部分（rest of）的映射。 1. 关于文档该 spring boot 参考文档可用有 html pdf EPUB 最新的副本可在 docs.spring.io/spring-boot/docs/current/reference. 此文档的副本（copies of this document）可以\b为（made for）你自己使用，也可以分发（distribution）给别人。但需（provided that）要你对这些副本（such copies）不收取（charge）任何费用，并且每一个副本需要包含版权申明，无论（whether）是印刷发行还是电子发行。 2. 获得帮助如果你使用 spring boot 有问题，我们愿意（would like）帮助： 尝试使用操作（how-do）文档。他们对大多数问题提供了解决方案。 学习 spring 基础，spring boot 建立在许多 spring 项目之上。查看spring.io网站获取大量（a wealth of）参考文档。如果您从 \bspring 开始，尝试其中一个指南。 询问问题，我们会监视（monitor） stackoverflow.com 获取标签为 spring-boot 的问题。 在 github.com/spring-projects/spring-boot/issues. 上反馈 spring boot 的bug。 1spring boot 的所有都是开源的，包裹参考文档。如果你在该文档中发现问题并想改善（improve）他们，请参与进来（get \binvolved）。 3. 第一步如果您要开始使用 spring boot 或者通用的 \bspring，从\b以下主题开始： 从头开始（From scratch）：概览 | 要求 | 安装 指南：单元1 | 单元2 运行你的案例：单元1 | 单元2 4. 使用 spring boot 工作确定（actually）准备开始\b使用 spring boot？我们为您涵盖了（以下内容）： 构建系统：maven | gradle | ant starters 最佳实战（parctices）：代码结构 | @Configuration | @EnableAutoConfiguration | Beans 和依赖注入（Dependency Injection） 运行你的代码：\bIDE | Packaged | Maven | Gradle 打包你的应用：生产的jar spring boot CLI： 使用 CLI 5. 学习 spring boot 的特性功能想要更多 spring boot 核心功能的细节？以下内容供您参考： 核心功能：SpringApplication | External Configuration外部配置 | Profiles | Logging web 容器：MVC | Embedded（嵌入式） Containers 使用数据：SQL | NO-SQL 消息：概述 | JMS 测试：概述 | Boot 应用 | 单元测试 拓展（Extending）：自动配置 | @Conditions 6. 移动到生产\b当您准备推送你的 spring boot 应用到生产环境，我们提供一个\b一些小窍门（some tricks ）你可能喜欢： 管理\b\b端点（Management endpoints）: Overview | Customization 链接选项（Connection options）: HTTP | JMX 监测（Monitoring）: Metrics | Auditing | Tracing | Process 7. 高级主题最后，我们为更高级用户提供了一些（a few）的主题： spring boot 应用部署：Cloud Deployment | OS Service 构建工具插件：Maven | Gradle 附录（Appendix）：Application Properties | Auto-configuration classes | Executable Jars 可执行jar","link":"/2019/06/02/[20190602] spring-boot | part1/"},{"title":"centos7 上操作 mysql","text":"查看是否启动方式一：通过进程查看 1ps aux | grep mysqld 方式二：通过端口查看 1netstat -tulnp | gerp 3306 方式三：查看 mysql 服务状态 1service mysql status 启动service mysqld start 停止service mysqld stop 重启service restart mysqld 查看服务状态service mysqld status 使用 systemctl 代替 service 命令启动： 1systemctl start mysqld 停止： 1systemctl stop mysqld 重启： 1systemctl restart mysqld 查看服务状态： 1systemctl status mysqld 配置文件路径/etc/my.cnf 忘记了 root 密码 需要先保证服务器绝对安全，修改密码期间 mysql 完全没密码保护。 停止 mysql 服务 编辑配置文件 /etc/my.cnf，添加一行：skip-grant-tables。 可以免密登陆 mysql 了：mysql -u root use mysql; 修改密码：UPDATE user SET Password = password ('harry@admin') WHERE User = 'root';（centos7 下需要将 Password 改为 authentication_string） 退出，删除配置文件中的 skip-grant-tables. 重启服务：systemctl restart mysql 备份mysqldump -u root -p [database name] &gt; ~/blog.sql 恢复 连接 mysql 创建需要备份的数据库（如没有） use database-name; source 服务器上的备份文件.sql","link":"/2019/08/01/centos7 上操作 mysql/"},{"title":"mysql 命令行方式执行备份恢复","text":"备份一个库 PS：在 mysql 客户端非连接状态下执行 mysqldump -h localhost -u root -p &lt;database-name&gt; &gt; ~/Downloads/backup.sql 1如果本机 mysqldump 是 8+ 版本，目标数据库非 8+ 版本，需要添加参数：--column-statistics=0 还原 PS：需要保证有这个数据库，如果没有需要手动创建。 方式一： mysqldump -h localhost -u root -p &lt;database-name&gt; &lt; ~/Downloads/backup.sql 执行成功，但是表未恢复。应该是备份脚本里面未指定数据库。 方式二： mysql -h localhost -u root -p use databasename; source ~/Downloads/backup.sql 执行成功，恢复成功。 备份指定表只需要在备份库的命令中多加一个参数：表名。 mysqldump -h localhost -u root -p databasename table1 table2 table3 &gt; backup.sql","link":"/2019/07/28/mysql 命令行方式执行备份恢复/"},{"title":"dubbo监控中心-dubbo-admin.war的打包和部署","text":"dubbo监控中心-dubbo-admin.war的打包和部署 一个 dubbo-admin.war 的打包从昨晚搞到今天中午，差点没吐出一口老血🤮错误的过程不记录了，都是泪。 Sept 1克隆dubbo源码，地址：https://github.com/apache/incubator-dubbo/tree/dubbo-2.5.4克隆之后看到的： Sept 2接下来，安装所有工程。注意：如果是用IDE克隆下来的，不要直接install，直接安装会进行测试，这里不需要测试，直接使用cmd方式。 12将dubbo的jar安装到本地maven仓库mvn install -Dmaven.test.skip=true 然后，进入到dubbo-admin目录，给dubbo-admin打包 1mvn package -Dmaven.test.skip 然后会在编译后的目录target中看到打包文件： Sept 3理所当然的把 dubbo-admin-2.5.4-SNAPSHOT.war 放在webapps下跑一下试试，还没跑起来启动就报错：信息是“找不到applicationContext.xml”按道理直接拷贝下来的应该不会有问题啊！ 版本有冲突，只好改了，注意：版本控制的模块是 dubbo-parent ，但是在没有发现这个工程目录，怎么改？将根目录导入到IDEA，全部的工程就都导入进来了。 然后修改spring版本为 1&lt;spring_version&gt;3.2.9.RELEASE&lt;/spring_version&gt; 指定注册中心的地址： Sept 4cmd重新编译安装，发布到本地tomcat做测试 可以看到已经是修改后的版本了，启动tomcat。 注意：得先开启zookepper注册中心。 Sept 5部署监控中心到远程服务器，这里以本地linux为例。上传war包： 复制到webapps： 进入到tomcat/bin，启动tomcat： 注意：得先开启zookepper注册中心。 默认root登陆密码是root，guest登陆密码是guest 这里将练习的一个项目发布到了zookeeper，可以看到如下监控信息： 坑安装duboo-admin.war的环境和部署dubbo-admin.war的环境最好保持一致，否则各种问题。本机windows:jdk1.8.0_172+apache-tomcat-8.5.32linux保持一致 参考博客：https://blog.csdn.net/qq_32349641/article/details/52488003","link":"/2018/07/06/dubbo监控中心-dubbo-admin-war的打包和部署/"},{"title":"spring与aspectJ版本冲突问题","text":"版本冲突真是让人脑阔疼。用这个 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;4.2.7&lt;/version&gt;&lt;/dependency&gt; 代替这个 12345678910&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.8.7&lt;/version&gt;&lt;/dependency&gt; maven会自动处理spring与aspect的依赖关系。依赖了 aspectwearer.jar，没有引用 aspectjrt.jar 但是也可以用，主要是可以看到aspect的版本号，以便于手动加入想要的aspect包。","link":"/2018/06/19/spring与aspectJ版本冲突问题/"},{"title":"分布式技术入坑指南（六）","text":"15. SSO单点登陆系统搭建模块划分： sso.taotao.interface sso.taotao.service sso.taotao.web 两个问题： 不同域名之间Cookie是不能共享的，这也意味着用户在 sso.taotao.com 系统登陆之后，跳转到 taotao.com 后记录用户登陆凭证(token)的Cookie不存在，访问某些个人信息时提示重新登陆。 不同域名之间的跨域请求是不会返回数据的，比如 item.taotao.com 下一个订单需要发送一个请求到 sso.taotao.com 校验当前用户是否登陆，请求发送成功并且会被处理，但是数据是返回不到 item.taotao.com 系统的。 解决办法： 设置Cookie的doMain属性 以JSONP的方式请求获得数据 Cookie跨域学习cookie的两个属性： pathpath属性是设置cookie存在的路径的，比如在当前目录下存入了一个cookie，那么该目录及子目录下的所有资源请求都能查看到这个cookie，但是父级目录是看不到的。 * 设置 path=“/” ,即cookie可被站点根目录下所有文件访问到。 * 设置 path=“/AAA/” ,即cookie可被站点根目录下的AAA目录下的所有文件访问到。 domain前面实现了cookie同域之间的访问，但在分布式系统中，跨域访问频繁，怎么做到跨域访问cookie不丢失呢？比如在 sso.taotao 登陆之后用户的token存入浏览器，想要在 order.taotao.com 系统中获取这个token，需要存放cookie的时候设置domain属性： domain=“taotao.com” 跨域访问前提是域名之间具有相同部分，一般是二级域名之间的访问。 参考博客：https://www.cnblogs.com/st-leslie/p/5720460.html JSONP JSONP与JSON不是一回事JSON是一种数据交换格式，而JSONP是一种非官方跨域数据交互协议 Ajax： 123456789101112131415161718192021&lt;html&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;jsonp&lt;/title&gt; &lt;script type=\"text/javascript\" src=\"jquery-1.6.4.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; $(document).ready(function(){ $.ajax({ type:\"get\", url:\"local.js\", // url:\"http://192.168.184.130:82/remote.js\", dataType:\"json\", success:function(json){ alert(json.data); } }); }); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; local.js 1{data:\"local\"} 结果是可以请求到本地json数据，但是当访问远程的remote.js时资源无法访问😔 值得庆幸的是：在Web页面调用Js文件却不受跨域的影响，注意：不是ajax请求，凡是通过有src属性的标签调用跨域资源都是不受影响的，比如&lt;script&gt;标签 既然能够远程调用js文件，那么怎么获取文件中的数据为我所用呢？其实很简单。 测试：本地一个方法要获得远程的json数据： 1234567&lt;script type=\"text/javascript\"&gt; //回调方法 function method(json){ alert(json.data); }&lt;/script&gt;&lt;script type=\"text/javascript\" src=\"http://192.168.184.130:82/remote.js\"&gt;&lt;/script&gt; remote.js 12/*远程js中调用*/method({data:\"remote\"}) 其实就是远程的js中调用了本地所需要数据的回调方法。 同样的道理，在Ajax请求中，跨域请求一个url，我们要求控制器返回的数据格式为：callbackMethod(jsonStr)，也就是对返回的json包裹一个前台js的回调方法名称。我们需要做的：1. 告诉控制器回调方法叫什么； 2.在回调方法写获得数据后的逻辑，而控制器返回json的同时回调了该方法。 知道原理，异步请求跨域数据的方法应该这么写： 12345678910111213141516171819&lt;html&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;jsonp&lt;/title&gt; &lt;script type=\"text/javascript\" src=\"jquery-1.6.4.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; //回调方法 function callbackMethod(json){ alert(json.data); } //通过标签调用json数据 var url = \"http://192.168.184.130:82/remote.js\"; var script = document.createElement('script'); script.setAttribute('src', url); document.getElementsByTagName('head')[0].appendChild(script); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; Jquery对JSONP实现了封装，自动生成了回调函数并取出数据给success方法调用： 1234567891011121314151617181920212223&lt;html&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;jsonp&lt;/title&gt; &lt;script type=\"text/javascript\" src=\"jquery-1.6.4.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; $(document).ready(function(){ $.ajax({ type:\"get\", url:\"http://192.168.184.130:82/remote.js\", dataType:\"jsonp\", //下面两行可不写，意思就是 http://192.168.184.130:82/remote.js?callback=callbackMethod，不写会自动生成。 jsonp: \"callback\", jsonpCallback:\"callbackMethod\", success:function(json){ alert(json.data); } }); }); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 参考博文：https://www.cnblogs.com/dowinning/archive/2012/04/19/json-jsonp-jquery.htmlhttps://www.cnblogs.com/JinQuanLi/p/6551415.html 注册登陆业务实现sso-interface定义注册登陆的接口 根据参数和类型来校验参数； 注册用户； 根据用户名和密码登录； 根据token获取用户的信息； 用户登出 sso-service登陆逻辑： 校验数据； 与数据库对比，如果成功将密码设为null，要求存入redis中的用户对象不保存密码； 随机生成用户Token，传给controller，用于创建cookie； 模拟Session。以key=XXX:Token，value=用户对象Json字符串存入Redis，设置Redis中的key过期时间 校验用户的Token是否存在： 根据token拼接Redis中的Key，查找Redis中是否存在对应的value； 如果查到，返回用户对象，重新设置Redis中key的过期时间； 未查到，返回错误 发布服务，以便其他系统调用 sso-web登陆逻辑： 调用服务，接收用户登陆后的Token 创建Cookie（跨域），key为指定标识符，value=token，设置cookie的过期时间（模拟session） 校验用户的Token是否存在：可能会存在其他系统跨域调用本控制器检查用户是否登陆，本系统中跨域请求使用JSONP的方式，因此方法签名应提供一个callback的参数，用来以方法名包裹返回Json的数据。 判断是否是JONSP请求，如果是：调用服务检测Redis是否存在token返回检测结果，并用函数名包裹json数据； 如果不是，调用服务正常返回json数据 访问认证以拦截器形式实现 依赖sso-service、sso-web工程 从cookie中取token。 没有token，需要跳转到登录页面。 有token。调用sso系统的服务，根据token查询用户信息。 如果查不到用户信息。用户登录已经过期。需要跳转到登录页面。 查询到用户信息。放行。 方案一：拦截器写在sso-web中，其他系统依赖sso-web工程，mvc配置文件配置Interceptor的类在sso-web工程中，优点是不需要每个系统都写拦截器，只需要配置，缺点是拦截条件不方便定制。 方案一：每个系统实现自己的拦截器，调用sso-service服务进行校验用户token。 可把我累坏了🤮","link":"/2018/07/27/分布式技术入坑指南（六）/"},{"title":"分布式技术入坑指南（五）","text":"13.网页静态化之FreeMarker14.反向代理/负载均衡服务器：Nginx 网页静态化 什么是静态化？通过一些技术手段（Freemarker/valocity）将动态的页面（jsp,asp.net,php) 转换成静态的页面，通过浏览器直接访问静态页面。为什么要静态化？ 通过浏览器直接访问静态的页面,不需要经过程序处理，它的访问速度高。稳定性好。 更有效的防止安全漏洞问题，比如不易遭受黑客攻击。 静态的页面更容易被搜索引擎收录。 更多概念见笔记文档，快速入门及整合Spring访问项目学习仓库地址：https://github.com/yuzh233/FreeMarker 反向代理/负载均衡Nginx应用场景 http服务器Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。虚拟主机可以实现在一台服务器虚拟出多个网站。例如个人网站使用的虚拟主机。反向代理，负载均衡当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群时可以使用nginx做反向代理。并且多台服务器可以平均分担负载，不会因为某台服务器负载高宕机而某台服务器闲置的情况。 安装及编译步骤见笔记文档 Nginx配置虚拟主机通过端口区分…/nginx/conf/nginx.conf中配置以下节点 123456789101112131415161718192021222324252627# 一个server节点就是一个虚拟主机server { # 第一个web应用的端口 listen 80; # 所在地址 server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { # Html是nginx安装目录下的html目录，也是该应用的静态资源文件存放的根目录 / root html; index index.html index.htm; }}# 第二台虚拟主机server { # 第二个web应用的端口 listen 81; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { # 第二个web应用的资源文件放在html-81中，访问的时候 / 代表该目录 root html-81; index index.html index.htm; }} 修改配置重新加载 ./nginx -s reload ，无需重启。访问第一个web服务：http://localhost:80访问第二个web服务：http://localhost:81其实就是充当了tomcat. 通过域名区分域名概念：略略略域名访问流程：略略略配置方式：…/nginx/conf/nginx.conf 中 123456789101112131415161718192021222324# 前面已经有一个虚拟主机用了这个端口，删了。这是第一个虚拟主机server { listen 80; # 域名 server_name www.taobao.com; #charset koi8-r; #access_log logs/host.access.log main; location / { root html-taobao; index index.html index.htm; }}# 第二个虚拟主机server { listen 80; # 域名 server_name www.baidu.com; #charset koi8-r; #access_log logs/host.access.log main; location / { root html-baidu; index index.html index.htm; }} 修改本机host文件才能访问伪域名 nginx服务器IP：www.taobao.com nginx服务器IP：www.baidu.com 其实访问的都是同一个应用。 Nginx配置反向代理正向代理：反向代理 反向代理服务器决定哪台服务器提供服务。 反向代理服务器不提供服务器。也只是请求的转发。 实现反向代理两个域名指向同一台nginx服务器，用户访问不同的域名显示不同的网页内容。配置：两只猫、两个域名、一个nginx服务器。 12345678910111213141516171819202122232425262728293031323334# 反向代理服务器下的第一个服务器upstream tomcat1 { # 访问该服务器的ip及端口 server 192.168.184.130:8080;}server { # 默认监听80端口，这样就不需要指定端口访问。 listen 80; # 用户访问时的域名。 server_name www.sina.com.cn; #charset koi8-r; #access_log logs/host.access.log main; location / { # nginx通过前面的tomcat1转发到指定的网站，访问tomcat1就是访问192.168.25.148:8080 proxy_pass http://tomcat1; index index.html index.htm; }}# 反向代理服务器下的第二个服务器upstream tomcat2 { # 访问该服务器的ip及端口 server 192.168.184.130:8081;}server { listen 80; server_name www.sohu.com; #charset koi8-r; #access_log logs/host.access.log main; location / { proxy_pass http://tomcat2; index index.html index.htm; }} Nginx配置负载均衡一个服务由多台服务器提供，需要把负载分配到不同的服务器处理。负载均衡的策略: 默认轮询，即一个一个轮着来 分配权重 server 192.168.25.148:8082 weight=2; ,weight代表权重 通过IP地址的hash值 做映射 通过URL的方式计算出Hash值 随机策略 最少并发量。 12345678910111213141516171819# 反向代理服务器下的第三个服务器，用于测试Nginx负载均衡upstream tomcat3 { # 假如该WEB服务下有多个服务器提供 server 192.168.184.130:8080; server 192.168.184.130:8081;}server { # 默认监听80端口，这样就不需要指定端口访问。 listen 80; # 用户访问时的域名。 server_name www.yuzhtest.xyz; #charset koi8-r; #access_log logs/host.access.log main; location / { # nginx通过前面的tomcat1转发到指定的网站，访问tomcat1就是访问192.168.25.148:8080 proxy_pass http://tomcat3; index index.html index.htm; }}","link":"/2018/07/26/分布式技术入坑指南（五）/"},{"title":"单例设计模式","text":"单例设计模式，即某个类在整个系统中只能有一个实例对象可被获取和使用的代码模式。例如：代表JVM运行环境的Runtime类 要点： 某个类只能有一个实例； 构造器私有化 是它必须自行创建这个实例； 含有一个该类的静态变量来保存这个唯一的实例 是它必须自行向整个系统提供这个实例; 对外提供获取该实例对象的方式：（1）直接暴露（2）用静态变量的get方法获取 饿汉式直接创建对象，不存在线程安全问题 缺点：不管是否需要这个对象，都会创建。 方式1：直接实例化饿汉式好处：简洁直观，外部可以直接获取这个实例。 1234567public class Singleton1 { public static final Singleton1 SINGLETON = new Singleton1(); private Singleton1(){ }} 方式2：枚举式最简洁的方式：枚举类型，表示该类型的对象是有限的几个，我们可以限定为一个，就成了单例。 123public enum Singleton2 { SINGLETON} 方式3：静态代码块饿汉式适合在实例化时需要进行复杂的初始化操作时使用，比如初始化实例时需要加载配置文件中的参数作为实例变量。 12345678910111213141516171819202122232425262728293031public class Singleton3 { private static Singleton3 SINGLETON; private String info; static{ Properties properties = new Properties(); try { // 配置文件加载之后会在编译目录里面，通过获取字节码加载器对象取到编译目录中的文件。 properties.load(Singleton3.class.getClassLoader().getResourceAsStream(\"xyz/yuzh/interview/singleton/info.properties\")); } catch (IOException e) { } SINGLETON = new Singleton3(properties.getProperty(\"info\")); } private Singleton3(String info){ this.info = info; } public static Singleton3 getInstance(){ return SINGLETON; } @Override public String toString() { return \"Singleton3{\" + \"info='\" + info + '\\'' + '}'; }} 懒汉式延迟创建对象 方式1：线程不安全单线程下是线程安全的，但是多线程下是不安全的。 123456789101112public class Singleton4 { private static Singleton4 singleton; private Singleton4() { } public static Singleton4 getInstance() { if (singleton == null) { singleton = new Singleton4(); } return singleton; }} 用例： 123456789101112131415161718192021222324public class Singleton4Test { public static void main(String[] args) throws ExecutionException, InterruptedException { /*Callable&lt;Singleton4&gt; callable = new Callable&lt;Singleton4&gt;() { @Override public Singleton4 call() throws Exception { return Singleton4.getInstance(); } };*/ Callable&lt;Singleton4&gt; callable = () -&gt; { return Singleton4.getInstance(); }; ExecutorService es = Executors.newFixedThreadPool(5); Future&lt;Singleton4&gt; future1 = es.submit(callable); // 提交一个任务 Future&lt;Singleton4&gt; future2 = es.submit(callable); // 再提交一个任务 es.shutdown(); Singleton4 s1 = future1.get(); Singleton4 s2 = future2.get(); System.out.println(s1 == s2); }} 结果： false 方式2：线程安全123456789101112131415161718public class Singleton5 { private static Singleton5 singleton; private Singleton5() { } public static Singleton5 getInstance() { if (singleton == null) { synchronized (Singleton5.class) { if (singleton == null) { singleton = new Singleton5(); } } } return singleton; }} 方式3：静态内部类形式，线程安全最简洁的方式，在内部类被加载和初始化时，才创建 SINGLETON 实例对象。静态内部类不会自动随着外部类的加载和初始化而初始化，它是要单独去加载和初始化的。因为是在内部类加载和初始化时，创建的，因此是线程安全的 12345678910111213public class Singleton6{ private Singleton6() { } public static class Inner{ private static final Singleton6 SINGLETON = new Singleton6(); } public static Singleton6 getInstance(){ return Inner.singleton; }}","link":"/2018/10/30/单例设计模式/"},{"title":"Linux - 文件上传与下载","text":"scp命令 scp 是 source copy 的缩写，菜鸟教程 从服务器下载文件到本地如\b：将服务器中 hexo.tar.gz 复制到本地当前路径 scp root@120.78.69.82:/opt/hexo.tar.gz . 1\bnote：远程服务器文件路径需要是\b绝对路径 上传文件到服务器\b上传本地当前路径下的 \bnginx.conf 到远程服务器根目录下\b\b\bscp nginx.conf root@120.78.69.82:~/ note：不支持上传文件夹，但是可以上传多个文件，如： 123scp ./* root@120.78.69.82:~/nginx-container-config/cert2190670_yuzh.xyz.key 100% 1675 40.0KB/s 00:002190670_yuzh.xyz.pem 100% 3651 116.9KB/s 00:00","link":"/2019/06/21/文件上传与下载/"},{"title":"数据库常用事务传播行为与隔离级别","text":"事务传播行为当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。例如：方法可能继续在现有事务中运行，也可能开启一个新的事务，并在自己的事务中运行。 事务传播行为由事务传播属性指定，以下是 Spring 支持的 7 种传播行为： 传播属性 描述 REQUIRED* 如果由事务在运行，当前的方法就在这个事务内运行。否则，就开启一个新的事务，并在自己的事务中运行。 REQUIRES_NEW* 当前方法必须启动新事务，并在自己的事务中运行。如果有事务正在运行，将该事务挂起。 SUPPORTS 如果有事务在运行，当前的方法就在这个事务中运行。否则它可以不运行在事务中。（有事务环境可以运行在事务，没有也行） NOT_SUPPORT 当前的方法不应该运行在事务中，如果有运行的事务，将它挂起。 MANDATORY 当前方法必须运行在事务内部，如果没有正在运行的事务，就抛出异常。 NERVER 当前的方法不应该运行在事务中，如果有运行的事务，就抛出异常。 NESTED 如果有事务在运行，当前的方法就应该在这个事务的嵌套事务中运行。否则，就开启一个新的事务，并在它自己的事务内运行。 [ 模拟一个事务方法调用另一个事务方法 ] 123456789101112131415161718192021222324@Service(\"userService\")public class UserServiceImpl{ @Autowired BookService bookService; @Transactional(propagation = Propagation.REQUIRED) // 默认值 public void buyBooks(int userId, int[] booksId){ for(int bookId : booksId){ bookService.pay(userId, bookId); } }}@Service(\"bookService\")public class BookServiceImpl{ @Transactional public void pay(int userId, int bookId){ // TODO 查询图书实体 // TODO 查询用户实体 // TODO 减少库存 // TODO 减少账户余额 }} 上面的伪代码意思是用户调用事务方法：buyBooks() 购买多本图书，buyBooks() 多次调用事务方法：pay()。默认情况下，两个方法的传播行为都是 REQUIRED,即： 虽然pay()自带事务，但是不起作用，因为调用方buyBooks()本身是事务方法，所以共用一个事务。 考虑这样一种情况：假如用户需要购买两本书，当 buyBooks() 第一次正常调用 pay() 后，库存减少一本书，用户余额减少对应的书的价格。但是第二次调用 buyBooks() 时发生异常：用户余额不足以购买第二本书，数据库回滚。此时用户是购买了一本书成功？还是两本书购买都没成功？ 当传播行为是 REQUIRED 时：两本书都购买失败。尽管第一本书购买成功了，但是第二次购买还是在 buyBooks() 方法发生的，pay() 并没有起作用，所以事务一起失败。 当传播行为是 REQUIREDS_NEW 时：第一本书购买成功，第二本书购买失败。buyBooks() 方法处在一个事务环境中，pay() 也处在自己的事务环境中，当 buyBooks() 执行到调用 pay() 时，当前的事务会挂起，去执行完毕 pay() 的事务之后再继续执行自己的事务。注意：buyBooks() 方法中除了 pay() 不受自己的事务控制之外，其他代码仍处于自己的事务环境之中。 事务隔离级别事务隔离控制一般应用在多线程并发访问操作数据库的时出现的并发问题上 数据库并发问题假设现有两个事务：Transactional-1 和 Transactional-2 并发执行。 脏读 Transactional-1 将某条记录的 age 值从 20 修改为 30。（未提交） Transactional-2 读取了 Transactional-1 更新后的值：30。 Transactional-1 回滚，age 值回到了 20。 Transactional-2 读到的 30 就是一个无效的值。（读到了其他事务更新但未提交的值） 不可重复读 Transactional-1 读取了 age 的值为 20。（读取无需事务） Transactional-2 将 age 的值修改为 30。（已提交） Transactional-1 再次读取 age 的值为 30，和第一次读取的不一致。 幻读 Transactional-1 读取了 student 表中的一部分数据。 Transactional-2 向 student 表中插入了新的行。 Transactional-1 读取 student 表时，多出了新的行。 隔离级别隔离级别越高，数据一致性越好。并发性能越弱。 读未提交：READ UNCOMMITTED 允许 Transactional-1 读取 Transactional-2 未提交的修改。 读已提交：READ COMMITTED 一般设置这个级别 要求 Transactional-1 只能读取 Transactional-2 已提交的修改 可重复度：REPEATABLE READ 确保 Transactional-1 可以多次从一个字段中读取相同的值，即：Transactional-1 执行期间禁止其他事务对这个字段更新。（可理解为行锁） 串行化：SERIALIZABLE 确保 Transactional-1 可以多次从一个表读取到相同的行，在 Transactional-1 执行期间禁止其他事务对这个表进行添加、更新、删除操作。可以避免任务并发问题，但性能下降。（可理解为表锁）","link":"/2018/11/04/数据库常用事务传播行为与隔离级别/"},{"title":"如何给通过脚本添加的元素注册事件","text":"前端弱渣，记录一下问题解决： 1234// 事件冒泡：给动态添加的 html 元素注册事件$(\"body\").on(\"click\", \".blog-edit-user\", function () { // .blog-edit-user 是需要被注册事件的元素标签} 参考：https://www.jb51.net/article/120018.htm","link":"/2018/10/13/如何给通过脚本添加的 元素注册事件/"},{"title":"成员变量与局部变量","text":"12345678910111213141516171819202122232425public class Demo1 { static int s; int i; int j; { int i = 1; i++; j++; s++; } public void test(int j) { j++; i++; s++; } public static void main(String[] args) { Demo1 obj1 = new Demo1(); Demo1 obj2 = new Demo1(); obj1.test(10); obj1.test(20); obj2.test(30); System.out.println(obj1.i + \",\" + obj1.j + \",\" + obj1.s); System.out.println(obj2.i + \",\" + obj2.j + \",\" + obj2.s); }} 执行结果： 2,1,5 1,1,5 考点： 就近原则 变量的分类 成员变量：类变量、实例变量 局部变量 非静态代码块的执行：每次创建实例对象都会执行 方法的调用规则：调用一次执行一次 局部变量与成员变量的区别： 值存储的位置 局部变量：栈 实例变量：堆 类变量：方法区，与类相关联，仅存一份 作用域 局部变量：从声明处开始，到所属的 } 结束 实例变量：在当前类中“this.”(有时this.可以缺省)，在其他类中“对象名.”访问 类变量：在当前类中“类名.”(有时类名.可以省略)，在其他类中“类名.”或“对象名.”访问 生命周期 局部变量：每一个线程，每一次调用执行都是新的生命周期 实例变量：随着对象的创建而初始化，随着对象的被回收而消亡，每一个对象的实例变量是独立的 类变量：随着类的初始化而初始化，随着类的卸载而消亡，该类的所有对象的类变量是共享的 分析： 一、运行 main 方法，开始执行类初始化方法&lt;clinit&gt;()，该方法由静态类变量显示赋值代码、静态代码块组成，在此用例中，只有静态变量赋值语句：static int s; 类变量 s 存在于方法区中，该类的所有实例共享这一份变量 此时 s = 0 二、line1： Demo1 obj1 = new Demo1(); 创建实例，执行 &lt;init&gt;()，该方法由非静态变量显示赋值代码、非静态代码块、构造器组成，此用例中根据顺序先执行非静态变量显示赋值代码，然后执行非静态代码块，构造器无赋值语句可忽略。创建 obj1 对象，在堆中开辟了一份 obj1 实例的内存空间，保存着 i、j 两个实例变量 非静态变量显示赋值代码执行后： obj1.i = 0 obj1.j = 0 -------------------------- 非静态代码块执行后： // i 还是为0，根据就近原则，非静态代码块中的自增的变量 i 不是实例变量i，而是局部变量i，代码块结束之后该变量消亡 obj1.i = 0 obj1.j = 1 Demo.s = 1 // 共享变量，类变量 三、line2： Demo1 obj2 = new Demo1(); 创建实例，执行 &lt;init&gt;() 后,实例变量和 obj1 一样，但是类变量发生变化 obj2.i = 0 obj2.j = 1 Demo.s = 2 // 由于是共享变量，此时类变量递增为2 四、line3： obj1.test(10); main 方法传了形参 10 的值给 test 方法，JVM 为 test() 在栈中开辟了一个空间存储局部变量 j ,由于未指明自增的 j 是哪个变量，根据就近原则，给局部变量 j 自增为 11，然后再给obj1的其他实例变量赋值 obj1.i = 1 // 自增1 obj1.j = 1 // 自增的局部变量j，要想指定自增实例变量，可以通过指定 this.j++ Demo.s = 3 // 继续自增 五、line4： obj1.test(20); obj1.i = 2 obj1.j = 1 Demo.s = 4 六、line5： obj2.test(30); obj2.i = 1 obj2.j = 1 Demo.s = 5 每创建一个Demo的实例，就会在堆中开辟新的这个该对象实例的变量空间，不同实例变量之间互不影响，随着实例的回收而消亡，但是类变量是独有一份的，每个实例操作的是同一份。故此时 obj1 和 obj2 的输出： obj1.i = 2 obj1.j = 1 obj1.s = 5 // 类变量也可以通过实例引用调用 obj2.i = 1 obj2.j = 1 obj2.s = 5","link":"/2018/11/03/成员变量与局部变量/"},{"title":"Linux - 无密码访问 linux 服务器","text":"本地生成 SSKEY \bcommand： ssh-keygen then： 123-rw-------@ 1 harry staff 1.8K Apr 6 09:38 id_rsa 密钥-rw-r--r--@ 1 harry staff 399B Apr 6 09:38 id_rsa.pub 公钥-rw-r--r-- 1 harry staff 4.5K May 28 11:43 known_hosts 将公钥复制到远程服务器的 ./ssh/authorized_keys 中","link":"/2019/06/21/无密码访问 linux 服务器/"},{"title":"Linux - 查看端口占用及网络情况","text":"netstat常用参数 -a 所有信息 -u 显示 UDP 协议的连接状况 -t 显示 TCP 协议的连接状况 -l listening，\b显示监控中的通信 -n numeric，直接显示 IP -p programs，与此通信绑定的程序 如何解决端口占用？ netstat -tulnp 根据端口号找到PID kill -9 PID","link":"/2019/06/21/查看端口占用及网络情况/"},{"title":"方法的参数传递机制","text":"1234567891011121314151617181920212223242526272829public class Demo1 { public static void main(String[] args) { int i = 1; String str = \"hello\"; Integer num = 200; int[] arr = {1, 2, 3, 4, 5}; MyData my = new MyData(); change(i, str, num, arr, my); System.out.println(\"i = \" + i); System.out.println(\"str = \" + str); System.out.println(\"num = \" + num); System.out.println(\"arr = \" + Arrays.toString(arr)); System.out.println(\"my.a = \" + my.a); } public static void change(int j, String s, Integer n, int[] a, MyData m) { j += 1; s += \"world\"; n += 1; a[0] += 1; m.a += 1; }}class MyData { int a = 10;} 运行结果 i = 1 str = hello num = 200 arr = [2,2,3,4,5] my.a = 11 考点： 方法的参数传递机制 String、Integer 等包装类的不可变性 方法传递机制： 基本数据类型是值传递 引用类型是地址值传递 特殊类型如 String、包装类等对象不可变 分析： 方法中的变量称为局部变量，每个方法在栈中有属于自己的方法区，局部变量存在自己的方法区。change() 方法执行之前，内存结构简单如下： 执行 change() 方法，参数传递代码执行之前： change() 方法执行完毕： change() 执行之后，change 方法区被释放，观察 main 方法区的箭头指向： i 只是将值复制了一份给 j，本身的值没变 str 代表的 “hello” 这一份常量，由于 String 不可变性，change 对这个常量拼接形成了新的常量，但是 str 指向的还是原来的 “hello” num 是 Integer 不可变类型，在堆中也创建了另外一份变量，本身没变 arr 是基本数据类型，值被改变 m 是引用类型，change 中保存了这个引用，并将实例变量 a 改变了","link":"/2018/10/30/方法的参数传递机制/"},{"title":"源码角度分析 CharacterEncodingFilter 解决 Post 请求中文乱码问题","text":"Post 乱码Spring MVC 提供 CharacterEncodingFilter 拦截请求处理编码格式问题12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package org.springframework.web.filter;public class CharacterEncodingFilter extends OncePerRequestFilter { private String encoding; // 指定的编码格式 private boolean forceRequestEncoding = false; // 是否设置请求编码格式 private boolean forceResponseEncoding = false; // 是否设置响应编码格式 public CharacterEncodingFilter() { } /** * xml配置：一般只需要设置编码格式即可，默认支持请求编码转换 */ public CharacterEncodingFilter(String encoding) { this(encoding, false); } /** * 也可以设置指定编码 and 是否设置请求和响应的编码转换 */ public CharacterEncodingFilter(String encoding, boolean forceEncoding) { this(encoding, forceEncoding, forceEncoding); } /** * 设置指定编码 and 单独设置是否进行请求编码转换 或 响应的编码转换 */ public CharacterEncodingFilter(String encoding, boolean forceRequestEncoding, boolean forceResponseEncoding) { Assert.hasLength(encoding, \"Encoding must not be empty\"); this.encoding = encoding; this.forceRequestEncoding = forceRequestEncoding; this.forceResponseEncoding = forceResponseEncoding; } public void setEncoding(String encoding) { this.encoding = encoding; } public String getEncoding() { return this.encoding; } public void setForceEncoding(boolean forceEncoding) { this.forceRequestEncoding = forceEncoding; this.forceResponseEncoding = forceEncoding; } public void setForceRequestEncoding(boolean forceRequestEncoding) { this.forceRequestEncoding = forceRequestEncoding; } public boolean isForceRequestEncoding() { return this.forceRequestEncoding; } public void setForceResponseEncoding(boolean forceResponseEncoding) { this.forceResponseEncoding = forceResponseEncoding; } public boolean isForceResponseEncoding() { return this.forceResponseEncoding; } @Override protected void doFilterInternal( HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { String encoding = getEncoding(); if (encoding != null) { // 若 foreceRequestEncoding 参数为 true 则进行请求参数编码转换，没有设置字符编码时默认设置请求字符编码。 if (isForceRequestEncoding() || request.getCharacterEncoding() == null) { request.setCharacterEncoding(encoding); } // 若 foreceResponseEncoding 参数为 true 则进行响应参数编码转换 if (isForceResponseEncoding()) { response.setCharacterEncoding(encoding); } } filterChain.doFilter(request, response); }} 所以我们可以在xml文件中配置加载 CharacterEncodingFilter，通过配置不同的构造器参数决定是否将请求和响应的字符编码转换还是单独设置请求和响应。 注意：字符编码过滤器需要放在最前面。 123456789101112131415161718192021222324252627&lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;!-- 必须指定。若只配置一个 encoding 参数，将处理请求的字符编码，不处理响应的字符编码 --&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 若设置 encoding 和 forceEncoding 参数，请求和响应都处理字符编码 --&gt; &lt;!-- &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; --&gt; &lt;!-- 分别指定是否处理请求字符编码和响应字符编码 --&gt; &lt;init-param&gt; &lt;param-name&gt;forceRequestEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceResponseEncoding&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; Get 乱码若服务器是 tomcat，修改 tomcat 的配置文件 server.xml。在第一个 Connerctor 节点添加 URIEncoding 标签： 1&lt;Connector URIEncoding=\"UTF-8\" port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt;","link":"/2018/11/06/源码角度分析 CharacterEncodingFilter 解决 Post 请求中文乱码问题/"},{"title":"根据树的前序和后序表达式构造唯一树","text":"原题是“根据树的前序和后序表达式求中序表达式”，构造出了树求中序表达式还是问题吗？ 构造树是需要一定技巧的，需要不断的递归分析。将大规模分为小规模，将每个小规模再细分，直到不可再分，树也就构建好了。就跟 归并排序 一样 前序和中序分别是： pre: A B D E G C F on: D B G E A C F 分析（选择题）从前序表达式入手：我们知道前序遍历的第一个节点是根节点，由此确定 A 就是根节点 再来看中序表达式，根据中序表达式规则，先遍历左子节点，再遍历父节点，再遍历右子节点，我们可以确定 A 左边的都是左子树，右边的都是右子树。 在 on 中看得出 A 的左子树个数是 4，于是我们可以在 pre 中定位 A 的左子树和右子树： A 的左子树前序序列是 B D E G，右子树前序序列是 C F，根据前序表达式规则，每一个序列的第一个是整个序列的根节点，于是可以推断出 A 的左子树的根节点和右子树的根节点分别是 B、C 循环上面的的方法，分析 B 的左子树。（右子树暂时不管，等左子树分析完毕之后再分析。） pre: B D E G on: D B G E 由 B 的左边只有 D 可推导出 D 是 B 的左子树，并且是唯一节点。E 是 B 的右子树的根节点。 然后推断 B 的右子树 pre: E G ——&gt; （序列的第一个是头，因为总是从头先遍历）E 是 G 的父节点 on: G E ——&gt; “左、父、右” 推导出 G 是 E 的左子节点 至此，根节点 A 的左子树有了归宿，现在分析右子树： pre: C F ——&gt; C 是 F 的头节点 on: C F ——&gt; “先左再头再右” 推导出 F 是 C 的右子节点 所以它的后序表达式是：DGEBFCA 归纳 对于一串前序表达式和中序表达式，我们总是先取前序表达式的第一个节点，因为它是头。 再根据这个头在中序中的位置来 划分 头的左子树和右子树，根据中序中的左子树和右子树的个数在前序中确定左子树范围和右子树范围。 每一个范围的序列都有前序表达式和中序表达式，循环调用步骤 1 ，直到序列只有一个。 代码实现（编程题）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class TreeTraversal { /** * 根据前序和中序表达式构建树 */ public static TreeNode createTreeByPreOrderAndInOrder(String preOrder, String inOrder) { if (preOrder.isEmpty()) { return null; } char root = preOrder.charAt(0); // 获取前序的第一个字符 int rootIndex = inOrder.indexOf(root); // 获取根节点在中序中的位置 TreeNode rootNode = new TreeNode(preOrder.substring(0, 1)); // 创建根节点 int leftCount = rootIndex; // 根节点的左子树的中序表达式字符数量 // 递归构建左子树 rootNode.setLeftNode(createTreeByPreOrderAndInOrder( preOrder.substring(1, leftCount + 1), // 截取前序表达式中 根节点 左边的字符串 inOrder.substring(0, leftCount)) // 截取中序表达式中 根节点 左边的字符串 ); // 递归构建右子树 rootNode.setRightNode(createTreeByPreOrderAndInOrder( preOrder.substring(leftCount + 1), // 截取前序表达式中 根节点 右边的字符串 inOrder.substring(leftCount + 1) // 截取前序表达式中 根节点 右边的字符串 )); return rootNode; } public static void main(String[] args) { // 构造树 TreeNode root = TreeCreator.getInstance(); System.out.print(\"pre: \\t\"); preOrder(root); System.out.println(); System.out.print(\"in: \\t\"); inOrder(root); System.out.println(); System.out.print(\"post: \\t\"); postOrder(root); // 根据前序和中序求后序 System.out.println(\"\\n---------- createTreeByPreOrderAndInOrder ----------\"); TreeNode rootNode = createTreeByPreOrderAndInOrder(\"ABDEGCF\", \"DBGEACF\"); postOrder(rootNode); }}","link":"/2018/11/08/根据树的前序和后序表达式构造唯一树/"},{"title":"Linux - 磁盘管理","text":"查看系统磁盘占用情况：df -h 12345678[root@jstuvn95c6ed5x /]# df -hFilesystem Size Used Avail Use% Mounted on/dev/vda1 40G 36G 2.0G 95% /devtmpfs 1.9G 0 1.9G 0% /devtmpfs 1.9G 0 1.9G 0% /dev/shmtmpfs 1.9G 2.5M 1.9G 1% /runtmpfs 1.9G 0 1.9G 0% /sys/fs/cgrouptmpfs 380M 0 380M 0% /run/user/0 查看文件占用大小：du -sh * 123456789101112131415161718192021222324252627[root@jstuvn95c6ed5x /]# du -sh *401M acs0 bin138M boot4.0K data0 dev37M etc90M home0 lib0 lib6416K lost+found4.0K media501M mnt4.0K optdu: cannot access ‘proc/1743/task/1743/fd/4’: No such file or directorydu: cannot access ‘proc/1743/task/1743/fdinfo/4’: No such file or directorydu: cannot access ‘proc/1743/fd/4’: No such file or directorydu: cannot access ‘proc/1743/fdinfo/4’: No such file or directory0 proc660M root2.5M run0 sbin4.0K srv0 sys152K tmp1.9G usr17G var 删除 docker 镜像缓解磁盘压力docker rmi -f $(docker image | grep ‘erp’ | awk ‘{print $3}’) awk 是行处理器命令，通常用来格式化文本信息， 依次对每一行进行处理，然后输出。 awk '{print $3}' 的意思是提取当前文本中的第三行，$0 代表全部，不是第一行。 123其实直接使用 docker 内置命令也可以docker rmi $(docker image ls -qa)PS：不要加 `-f` 参数，线上有容器正在使用镜像运行，不是开玩笑的😂。","link":"/2019/06/21/磁盘管理/"},{"title":"树的三种遍历方式","text":"以上是一个树结构，我们需要以三种不同的方式遍历它，先创建树的节点对象： 12345678910111213141516171819/** * 树节点 * * @author yu.zh [yuzh233@gmail.com] * @date 2018/11/08 */public class TreeNode { private String value; private TreeNode leftNode; private TreeNode rightNode; public TreeNode(String value) { this.value = value; this.leftNode = null; this.rightNode = null; } // getter and setter} 再构建一棵树： 1234567891011121314151617181920212223242526272829303132/** * 创建一个树结构 * * @author yu.zh [yuzh233@gmail.com] * @date 2018/11/08 */public class TreeCreator { private TreeCreator() { } public static TreeNode getInstance() { return TreeCreatorFactory.root; } public static class TreeCreatorFactory { private static TreeNode root; static{ root = new TreeNode(\"A\"); // 一级节点 root.setLeftNode(new TreeNode(\"B\")); root.setRightNode(new TreeNode(\"C\")); // 二级节点 root.getLeftNode().setLeftNode(new TreeNode(\"D\")); root.getLeftNode().setRightNode(new TreeNode(\"E\")); root.getRightNode().setRightNode(new TreeNode(\"F\")); // 三级节点 root.getLeftNode().getRightNode().setLeftNode(new TreeNode(\"G\")); } }} 前序遍历前序遍历思想是先遍历父节点，再遍历左子节点，最后遍历右子节点。分析上面的树结构： 先打印 A； A有左子节点和右子节点，先打印左子节点 B；（前序遍历先求父节点，不管B有没有子节点都会先遍历自己） B有左子节点和右子节点，先打印左子节点 D； D没有子节点，看父节点B的右子节点，打印 E。 节点E有左子节点，打印 G A的左子节点执行完毕，执行右子节点C，打印 C C没有左子节点，有右子节点，打印 F 中序遍历中序遍历思想是先遍历左子节点，再遍历父节点，最后遍历右子节点。分析上面的树结构： A有左子节点B，B有子节点D，D没有子节点，打印 D （中序遍历先遍历左子节点再遍历父节点，所以需要往下递归直到没有子节点为止。） D节点的父节点是B，打印 B B的右子节点是E，E有子节点G，根据中序规则，先打印 G 再打印 E B的父节点是A，打印 A A右节点是C，C没有左子节点，于是打印自己 C C的右子节点是F，打印 F 后序遍历中序遍历思想是先遍历左子节点，再遍历右子节点，最后遍历父节点。分析上面的树结构： A有左子节点B，B有子节点D，D没有子节点，打印 D （后序遍历最后才遍历父节点，有子节点需要一直递归下去直到没有子节点。） D有兄弟节点E，但是E也有子节点，先打印E的子节点 G G打印完了，没有兄弟节点，打印父节点 E D和E都执行完了，打印他们的父节点 B B有兄弟节点C，C有子节点F，打印 F C的子节点都打印完了，打印自己 C A的B和C都打印完了，打印自己 A 后序遍历方式常用作简易的计算器处理，如我的算法笔记： 补全表达式转为中序表达式 中序表达式转后序表达式 后序表达式求值实现简单计算器","link":"/2018/11/08/树的三种遍历方式/"},{"title":"类初始化和实例初始化","text":"运行结果： (5)(1)(10)(6)(9)(3)(2)(9)(8)(7) (9)(3)(2)(9)(8)(7) 以上代码考察的知识点有三个： 类的初始化过程 实例初始化过程 方法的重写 类的初始化过程一个类要创建实例需要先加载并初始化该类 main 方法所在的类需要先加载和初始化，不管main方法是否有其他操作。 一个子类要初始化需要先初始化父类 一个类的初始化就是执行 &lt;clinit&gt;() 方法 &lt;clinit&gt;() 方法由静态类变量显示赋值代码 和 静态代码块组成 类变量显示赋值代码和静态代码块从上到下顺序执行 &lt;clinit&gt;() 方法只执行一次 结合用例分析运行子类的main方法，先不管执行了什么，首先会加载该类，该类如有父类会先加载父类。 执行父类的&lt;clinit&gt;() 方法，该方法中执行一次，该方法的内容由静态类变量和静态代码块组成： 静态实例变量赋值代码在前，被先执行，调用了 method() 方法，打印 (5) 其次是静态代码块被执行，打印 (1) 父类加载完毕，加载子类的&lt;clinit&gt;() 方法： 静态实例变量赋值代码在前，被先执行，打印 (10) 接着静态代码块，打印 (6) 结果就是：(5)(1)(10)(6) 实例初始化过程实例化初始化就是执行&lt;init&gt;()方法 &lt;init&gt;() 方法可能重载有多个，由几个构造器就有几个 &lt;init&gt; 方法 &lt;init&gt;() 方法由非静态实例变量赋值代码、非静态代码块、对应构造器代码组成 非静态实例变量赋值代码和非静态代码块代码按顺序执行，对应的构造器总是最后执行 每次创建实例对象，调用对应构造器，执行的就是对应的 &lt;init&gt; 方法 &lt;init&gt;() 方法首行是super()或super(参数列表)，即对应父类的&lt;init&gt;() 方法 方法的重写final、静态方法、private修饰的方法不可被重写 对象的多态性： 子类如果重写了父类的方法，通过子类对象调用的一定是子类重写过的代码 非静态方法默认的调用对象是this this对象在构造器或者说&lt;init&gt;方法中就是正在创建的对象 结合用例分析main 方法的 Son s1 = new Son(); 被执行，类加载器开始执行 &lt;init&gt;() &lt;init&gt;() 首行是 super()，于是执行父类的 &lt;init&gt;()，该方法由非静态实例变量赋值代码、非静态代码块、构造器组成 非静态实例变量赋值代码 test() 在前先被执行，应该是打印 (4)，但是因为多态的特性，子类重写了test()，init() 初始化方法中this指向的是正在创建的子类对象 Son，调用的正是子类的test()。所以打印 (9) 然后是父类的非静态代码块被执行，打印 (3) 最后是父类的指定构造器，子类调用的是无参构造器，所以父类的无参构造器先被调用，打印 (2) 父类的 &lt;init&gt;() 执行完毕，再执行子类的 &lt;init&gt;()： 子类 test() 又被执行了一次，打印 (9) 子类的非静态代码块执行，打印 (8) 最后构造器执行，打印 (7) 至此，第一行打印（空格为了区分类初始化和实例初始化）：(5)(1)(10)(6) (9)(3)(2)(9)(8)(7) main 方法又执行了一次子类对象，由于类的初始化&lt;clinit&gt;()只创建一次，所以(5)(1)(10)(6)不被打印，而(9)(3)(2)(9)(8)(7)又被执行了一次。 颠倒位置，再测试一遍 执行父类 &lt;clinit&gt;()，依次打印：类静态变量 (5)、类静态代码块 (1) 执行子类 &lt;clinit&gt;()，依次打印：类静态代码块 (6)、类静态变量 (10) 执行父类 &lt;init&gt;()，依次打印：非静态代码块 (3)、非静态实例变量（多态机制） (9)、构造器 (2) 执行子类 &lt;init&gt;()，依次打印：非静态代码块 (8)、非静态实例变量 (9)、构造器 (7) 最终结果： -- 空格为了区分类初始化和实例初始化 -- (5)(1)(6)(10) (3)(9)(2)(8)(9)(7) (3)(9)(2)(8)(9)(7)","link":"/2018/10/30/类初始化和实例初始化/"},{"title":"自增变量","text":"先看一段代码： 1234567891011public class Demo1 { public static void main(String[] args) { int i = 1; // i = 1 i = i++; // i = 1 int j = i++; // j = 1 int k = i + ++i * i++; // k = 11 System.out.println(\"i = \" + i); System.out.println(\"j = \" + j); System.out.println(\"k = \" + k); }} 结果： i = 4 j = 1 k = 11 分析： 之前在算法中学到，运算操作都是通过栈来完成的，最典型的比如双栈表达式取值，一个操作符栈、一个操作数栈。运行一串表达式，遇到数值入操作数栈，遇到符号入操作符栈，执行操作时依次弹出。 首先明确一点：自增操作是不入栈的，直接修改变量的值。 执行流程： int i = 1; 首先 常量 1 入栈，遇到 = 号，弹出 1 赋值给变量 i，此时 i = 1 i = i++; i = 1 入栈，i 变量自增：i = 2，但是此时操作数栈中的 i 依然是 1，再将操作数栈中的 1 赋值给变量 i，这一操作就原本的 i = 2 覆盖掉了变成了 1。此时 i = 1 j = i++; i = 1 入栈，i 变量自增为2，遇到 = 将 i = 1赋值给 j ,j = 1 k = i + ++i * i++; i = 2 入栈 i 自增之后入栈，i = 3 i 入栈 ，i = 3，变量自增为 4，但是操作数中的 i 依旧为 3 栈运算：2 + 3 * 3 = 11","link":"/2018/10/30/自增变量/"},{"title":"终端走代理","text":"永久\b\b方式设置：vim .zshrc根据自己代理的 ip 和 端口设置以下内容： 12export http_proxy=\"http://127.0.0.1:1087\"export https_proxy=\"http://127.0.0.1:1087\" 然后：source .zshrc 验证：curl www.google.com","link":"/2019/07/15/终端走代理/"},{"title":"解决使用 bootstrap 更新操作时-模态框回显传值问题","text":"回顾 ModelAndView之前的印象中，我使用 ModelAndView 的场景是在需要重定向页面时带上参数。最近在做博客系统开发时学到了新的一招，就是 ModelAndView 不仅可以跳转页面，还可以”跳转”页面的部分内容！比如这样：new ModelAndView(&quot;users/list :: #user_div&quot;,map); —— 这句话的意思是找到 user/list.html 将其中的指定 div 的 html 代码作为字符串返回值输出出去（如果这个 div 有取值标签将会被赋值）。如果是同步请求将会输出到浏览器实现刷新，如果是异步则会作为 data 的字符串文本数据（html代码） 解决模态框回显传值问题很多情况下有这样的需求：点击编辑按钮弹出一个固定 html 内容的模态框，怎么在弹出前根据 id 先获取数据再展示给用户看呢？ 首先点击编辑按钮触发事件发起异步请求查找一个实体对象； 控制层返回的不是 json，而是 ModelAndView 对象，并且只返回需要被填充的模态框的部分页面代码（html）比如：new ModelAndView(&quot;users/list :: #模态框表单id&quot;,map); 这样就将这部分的页面的 html 代码（包括map中的值）直接传给了前台 js 中。 js 获取的 data 数据则是需要展示给用户看的表单html 代码了（包括回显的值），通过 js 在指定的 div（模态框表单id的‘父级元素：divID ’） 中填充这个数据：$(&quot;#divID&quot;).html(data); —— data 是后台返回的模态框 html。 这样就会将后台传过来的 html 代码以及赋值好的数据作为表单回显内容 覆盖之前未填充数据的表单 展示给用户。 实例：博客系统后台管理用户管理编辑操作","link":"/2018/10/13/解决使用 bootstrap 更新操作时-模态框回显传值问题/"},{"title":"酷炫工具","text":"\bfiglet1brew install figlet toilet1brew install toilet box1brew install boxes cowsay1brew install cowsay","link":"/2019/07/16/酷炫工具/"},{"title":"Linux - 解压缩","text":"解压缩tar tar -zcvf 压缩后的文件名 目标文件 tar -zxvf 解压文件名","link":"/2019/06/21/解压缩/"},{"title":"Docker 补救指南（五）—— Docker Compose","text":"What It Is？ reference：Overview of Docker Compose Compose 是一个定义和\b运行多个容器的 Docker 应用。在 Compose，你可以使用一个 YAML 文件配置你的应用的（多个）服务。然后，\b使用一条命令你可以创建和启动所有的服务从你的配置中。\b要学习更多的关于 Compose 的特性，请参看：\b特性列表Compose 工作在所有环境：生产、开发、测试，以及 CLI 工作流。你可以学习更所的用例在：Comm Use Cases Compose 的使用基本上是以下三个\b设置的过程： 使用 Dockerfile 定义你的应用环境，它可以复制到任何地方。 在 docker-compose.yml 中定义组成你的应用的服务，他们可以在隔离的环境下\b共同运行。 运行 docker-compose up 启动 Compose，运行你的整个 app 一个 docker-compose.yml 文件看起来像这样： version: &apos;3&apos; services: web: build: . ports: - &quot;5000:5000&quot; volumes: - .:/code - logvolume01:/var/log links: - redis redis: image: redis volumes: logvolume01: {} 关于更多 compose 文件信息，请查看：Compose file reference. compose 有管理你应用整个生命周期的命令： 启动、停止、重新构建服务 查看所有运行中服务的状态 正在运行的服务的日志输出流 在服务上运行一次性命令。 特性：有效的 Compose 功能有： 单个主机上多个隔离的环境 \b保存数据卷数据当容器被创建 仅重新创建已更改的容器 变量和环境更改 …… How To Do It？一个较为详细的微服务项目所需要的 docker-compose.yml 及\b主要一级关键字： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354version: '3'# \b用来声明服务，在该节点之下\b配置多个服务。service: # web 服务 web: image: id/imagename:lable # 指定\b重启策略（on：默认值，若启动失败不做任何动作 / always：会一直重新启动 / on-failure：服务提示失败错误后会重新启动 / unless-stopped：只有服务在停止后才会\b重启） restart: on-failure container_name: my-web-container_name ports: - 8080:8080 # 指定网络，该网络引用下面的配置。 networks: - example-net # 服务依赖，指定服务启动顺序。（3版本之后该属性被忽略） depends_on: - db # 服务 swarm 集群部署，非集群下无效。 deploy: # 服务副本数量 replicas: 2 # 集群环境下的重启策略，属性值与上面的一样 restart_policy: condition: on-failure # 数据库服务 db: images: mysql:5.6 restart: on-failure container_name: mysql-container ports: - 3306:3306 volumes: - example-mysql: /var/lib/mysql networks: - example-net: # \b环境变量 environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: mysql_database deploy: replicas: 1 restart_policy: condition: on-failure # \b该服务只有管理节点才能启动 placement: constraints: [node.role == manager]networks: example-net:volumes: example-mysql: 关于 docker-compose 文件的所有细节，参考：https://docs.docker.com/compose/compose-file/ 微服务下的 Docker 部署准备微服务测试项目四个微服务，分别是： euraka-server gateway-zuul microservice-orderservice microservice-userservice 编写 Dockerfile分别为四个基础服务提供 Dockerfile 用以构建镜像上传到远程仓库，四个 Dockerfile 都是类似的： euraka-server:1234567FROM java:8-jreMAINTAINER harry&lt;yuzh233@gmail.com&gt;ADD ./target/microservice-eureka-server-0.0.1-SNAPSHOT.jar /app/microservice-eureka-service.jarCMD [\"java\", \"-Xmx200m\", \"-jar\", \"/app/microservice-eureka-service.jar\"]EXPOSE 8761 gateway-zuul:1234567FROM java:8-jreMAINTAINER harry&lt;yuzh233@gmail.com&gt;ADD ./target/microservice-gateway-zuul-0.0.1-SNAPSHOT.jar /app/microservice-gateway-zuul.jarCMD [\"java\", \"-Xmx200m\", \"-jar\", \"/app/microservice-gateway-zuul.jar\"]EXPOSE 8050 microservice-orderservice:1234567FROM java:8-jreMAINTAINER harry&lt;yuzh233@gmail.com&gt;ADD ./target/microservice-orderservice-0.0.1-SNAPSHOT.jar /app/microservice-orderservice.jarCMD [\"java\", \"-Xmx200m\", \"-jar\", \"/app/microservice-orderservice.jar\"]EXPOSE 7900 microservice-userservice:123456789FROM java:8-jreMAINTAINER harry&lt;yuzh233@gmail.com&gt;ADD ./target/microservice-userservice-0.0.1-SNAPSHOT.jar /app/microservice-userservice.jarEXPOSE 8030CMD [\"java\", \"-Xmx200m\", \"-jar\", \"/app/microservice-userservice.jar\"] 构建镜像构建后面需要部署的基础镜像，有了镜像后\b可以通过执行 docker run 命令一一启动，但是对于微服务项目来说逐个启动效率不免有点太低，我们可以通过 docker-compose 快速启动。 关于镜像的构建与推送，可以使用 maven 的 dockerfile 插件 👉 笔记\b 举例：123456789101112131415161718192021&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.3&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default&lt;/id&gt; &lt;!-- 如果不指定 phase 则会使用默认的 goals，即：package -&gt; build, deploy -&gt; push --&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;repository&gt;registry.cn-hangzhou.aliyuncs.com/yuzh/${artifactId}&lt;/repository&gt; &lt;tag&gt;${project.version}&lt;/tag&gt; &lt;useMavenSettingsForAuth&gt;true&lt;/useMavenSettingsForAuth&gt; &lt;/configuration&gt;&lt;/plugin&gt; NOTE：需要\b先安装 JDK 和 MAVEN 环境。 非集群环境下的部署一）登陆远程服务器，拉取镜像。 如果是在镜像上传的主机上运行，则\b默认存在了。 二）准备 docker-compose.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101version: \"3\"services: # 第一个服务 mysql: image: mysql restart: on-failure ports: - 3336:3306 # 容器外可以通过 3336 连接\b到容器内的服务端 volumes: - microservice-mysql:/var/lib/mysql networks: - microservice-net environment: MYSQL_ROOT_PASSWORD: harry@admin MYSQL_DATABASE: microservice_mallmanagement deploy: replicas: 1 # 副本数量 restart_policy: # 重启策略 condition: on-failure # 失败时重启 placement: constraints: [node.role == manager] # 第二个服务 eureka-server: image: registry.cn-hangzhou.aliyuncs.com/yuzh/microservice-eureka-server:0.0.1-SNAPSHOT restart: on-failure ports: - 8761:8761 networks: - microservice-net deploy: replicas: 1 restart_policy: condition: on-failure # 第三个服务 gateway-zuul: image: registry.cn-hangzhou.aliyuncs.com/yuzh/microservice-gateway-zuul:0.0.1-SNAPSHOT restart: on-failure ports: - 8050:8050 networks: - microservice-net depends_on: - eureka-server deploy: replicas: 1 restart_policy: condition: on-failure placement: constraints: [node.role == manager] # 第四个服务 order-service: image: registry.cn-hangzhou.aliyuncs.com/yuzh/microservice-orderservice:0.0.1-SNAPSHOT restart: on-failure ports: - 7900:7900 networks: - microservice-net depends_on: - mysql - eureka-server deploy: replicas: 1 restart_policy: condition: on-failure # 第五个服务 user-service: image: registry.cn-hangzhou.aliyuncs.com/yuzh/microservice-userservice:0.0.1-SNAPSHOT restart: on-failure ports: - 8030:8030 networks: - microservice-net depends_on: - mysql - eureka-server deploy: replicas: 1 restart_policy: condition: on-failure # 第六个服务 visualizer: image: dockersamples/visualizer:stable ports: - 8081:8080 volumes: - /var/run/docker.sock:/var/run/docker.sock deploy: placement: constraints: [node.role == manager] networks: - microservice-netnetworks: microservice-net:volumes: microservice-mysql: note: Mysql \b容器运行的一些细节，可见 《Docker 补救指南（一）—— 基础使用》 的 Mysql 容器 部分。 三）\b在 docker-compose.yml 目录下执行：docker-compose up 如需停止：docker-compose down 集群环境下的部署一）登陆远程仓库 二）部署服务 docker stack deploy -c docker-compose-swarm.yml --with-registry-auth mall-management -c：指定 docker-compose 文件地址 --with-registry-auth：通知所有服务节点要到\b指定的私有仓库拉取镜像 mall-management：集群服务的总名称 三）管理命令 查看所有集群服务： docker stack ps 删除指定集群服务： docker stack rm XX \b更多命令： docker stack --help","link":"/2019/05/31/Docker \b补救指南（五） —— Docker Compose/"},{"title":"Spring Annotation development","text":"https://docs.spring.io/spring/docs/5.0.9.RELEASE/spring-framework-reference/web.html 组件注册 @Configuration @ComponentScan @Bean @Scope @Lazy @Conditional @Import 生命周期 @Bean 指定初始化和销毁方法 实现 InitializingBean和DisposableBean 指定初始化和销毁方法 @PostConstruct / @PreDestroy 指定初始化和销毁方法 属性赋值 @Value 赋值 @PropertySource 加载外部配置文件 自动装配 @Autowired / @Qualifier / @Primary @Resource / @Inject 实现 Aware 注入 Spring 底层组件 @Profile 环境搭建 @Profile 环境激活 AOP @Aspect / @Pointcut / @Before / @After / @AfterReturning / @AfterThrowing / @Around @EnableAspectJAutoProxy 事务 @Transactional @EnableTransactionManagement DataSource / Template / PlatformTransactionManager Servlet 自定义组件 @WebServlet / @WebFilter / @WebListener ServletContainerInitializer 初始化器 利用 ServletContainerInitializer.ServletContext / ServletContextListener.ServletContext 添加第三方组件 SpringMVCWeb 配置类组件加载流程： 导入 webmvc 包后，lib 中多了一个 spring-web-4.3.12.RELEASE.jar web容器在启动的时候，会扫描每个jar包下的 META-INF/services/javax.servlet.ServletContainerInitializer 。此时在 spring-web-4.3.12.RELEASE.jar 包中扫描到了该文件： 加载文件中指定的类： org.springframework.web.SpringServletContainerInitializer SpringServletContainerInitializer 会加载 WebApplicationInitializer 接口下所有的组件。并且为 WebApplicationInitializer 组件创建对象（当组件不是接口，不是抽象类时） 我们的 web配置类 要继承的类： AbstractAnnotationConfigDispatcherServletInitializer 是 WebApplicationInitializer 接口的间接子类。 12345678910111213141516171819202122232425262728public class MyWebAppInitializer extends AbstractAnnotationConfigDispatcherServletInitializer { /** * 加载根容器的配置类：Spring配置 */ @Override protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class[]{RootConfig.class}; } /** * 加载webmvc容器的配置类：SpringMVC 配置 */ @Override protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class[]{MvcConfig.class}; } /** * 获取 DispatcherServlet 的映射信息 * &lt;p&gt; * - `/` 拦截所有请求（包括静态资源（xx.js,xx.png）），但是不包括*.jsp； * - `/*` 拦截所有请求；连*.jsp页面都拦截；jsp页面是tomcat的jsp引擎解析的； */ @Override protected String[] getServletMappings() { return new String[]{\"/\"}; }} SpringMVC 配置类123456789101112131415161718192021222324252627282930313233343536373839@ComponentScan(value = {\"xyz.yuzh.learn.spring.annotation\"}, includeFilters = { @ComponentScan.Filter(type = FilterType.ANNOTATION, classes = Controller.class)}, useDefaultFilters = false)@EnableWebMvc // 开启 SpringMVC 定制配置功能，等同于 &lt;mvc:annotation-driven/&gt;public class WebConfig extends WebMvcConfigurerAdapter { // WebMvcConfigurerAdapter抽象类 实现了 WebMvcConfigurer 接口来定制MVC的所有配置，实现抽象类使得我们不必重写所有所有接口方法 /** * 定制视图解析器 */ @Override public void configureViewResolvers(ViewResolverRegistry registry) { registry.jsp(\"/WEB-INF/views/\", \".jsp\"); // 若不加参数默认为：(\"/WEB-INF/\",\".jsp\") } /** * 开启静态资源访问 相当于 &lt;mvc:default-servlet-handler&gt; * springMVC 默认拦截所有的请求包括静态资源，解除静态资源访问限制，但仅对WEB根目录下文件有效，如果文件在WEB-INF解除无效。 */ /*@Override public void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) { configurer.enable(); }*/ /** * 定制拦截器 */ @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new MyIntercepter()).addPathPatterns(\"/**\"); // 拦截所有目录及文件 } /** * 这种方式访问 WEB-INF 下的静态资源 &lt;mvc:resources location=\"/WEB-INF/resources/\" mapping=\"/resources/**\"/&gt; */ @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\"/resources/**\").addResourceLocations(\"/WEB-INF/resources/\"); }} 更多配置查阅 文档 异步处理Servlet 3.0 异步处理在Servlet 3.0之前，Servlet采用Thread-Per-Request的方式处理请求。即每一次Http请求都由某一个线程从头到尾负责处理。 如果一个请求需要进行IO操作，比如访问数据库、调用第三方服务接口等，那么其所对应的线程将同步地等待IO操作完成， 而IO操作是非常慢的，所以此时的线程并不能及时地释放回线程池以供后续使用，在并发量越来越大的情况下，当线程池已满，许多请求不能及时的被处理。这将带来严重的性能问题。 即便是像Spring、Struts这样的高层框架也脱离不了这样的桎梏，因为他们都是建立在Servlet之上的。为了解决这样的问题，Servlet 3.0引入了异步处理，然后在Servlet 3.1中又引入了非阻塞IO来进一步增强异步处理的性能。 123456789101112131415161718192021222324252627282930313233@WebServlet(value = \"/async\", asyncSupported = true) // 支持异步处理asyncSupported=truepublic class HelloAsyncServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { // 开启异步模式 System.out.println(\"主线程开始。。。\" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); AsyncContext startAsync = req.startAsync(); //业务逻辑进行异步处理; 开始异步处理 startAsync.start(new Runnable() { @Override public void run() { try { System.out.println(\"副线程开始 \" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); sayHello(); startAsync.complete(); // 异步处理完 AsyncContext asyncContext = req.getAsyncContext(); // 获取到异步上下文 ServletResponse response = asyncContext.getResponse(); // 获取响应 response.getWriter().write(\"hello async...\"); System.out.println(\"副线程结束 \" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); } catch (Exception e) { } } }); System.out.println(\"主线程结束。。。\" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); } public void sayHello() throws Exception { System.out.println(Thread.currentThread() + \" processing...\"); Thread.sleep(3000); }} SpringMVC 异步处理基于 Callable 的简单异步处理。返回 Callable 结果对象，将 Callable 对象放入异步处理线程处理结果，主线程结束，等待异步线程返回结果渲染页面。 1234567891011121314151617181920212223242526272829@Controllerpublic class AsyncController { /** * 异步处理 * 1. 控制器返回 Callable * 2. Spring 异步处理，将Callable 提交到 TaskExecutor 使用一个隔离的线程进行执行 * 3. DispatcherServlet 和所有的 Filter 退出 web 容器的线程，但是 response 保持打开状态； * 4. Callable 返回结果，Spring MVC 将请求重新派发给容器，恢复之前的处理； * 5. 根据 Callable 返回的结果。Spring MVC 继续进行视图渲染流程等（从收请求-视图渲染）。 */ @ResponseBody @RequestMapping(\"/async01\") public Callable&lt;String&gt; async01() { System.out.println(\"主线程开始.\" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); Callable&lt;String&gt; callable = new Callable&lt;String&gt;() { @Override public String call() throws Exception { System.out.println(\"副线程开始.\" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); Thread.sleep(2000); System.out.println(\"副线程开始.\" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); return \"Callable&lt;String&gt; async01()\"; } }; System.out.println(\"主线程结束.\" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); return callable; }} 基于 DeferredResult 的异步处理。这种方式的特点在于可以从不同的线程异步地产生返回值，配合 JMS ，可以实现在其他控制器中返回本次请求的结果。 12345678910@GetMapping(\"/quotes\")@ResponseBodypublic DeferredResult&lt;String&gt; quotes() { DeferredResult&lt;String&gt; deferredResult = new DeferredResult&lt;String&gt;(); // 把这个对象存在一个地方 return deferredResult;}// 在某个地方获取对象并存入对象的值然后返回deferredResult.setResult(data); 用例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Controllerpublic class AsyncController { /************************************************** * DeferredResult **************************************************/ /** * 处理请求：创建订单 * - 1. 构建 DeferredResult 对象，设置超时事件，失败提示 * - 2. 通过 JMS 发送一个 DeferredResultQueue 对象的消息，该对象存储 DeferredResult. * - 3. 若接收端在限定时间内给 DeferredResult 存入了结果，则返回 DeferredResult 的结果，否则结果是失败提示。 */ @ResponseBody @RequestMapping(\"/createOrder\") public DeferredResult&lt;Object&gt; createOrder() { DeferredResult&lt;Object&gt; deferredResult = new DeferredResult&lt;&gt;((long) 3000, \"create fail...\"); // 模拟发送消息：把结果对象存入一个队列中，假设 DeferredResultQueue 队列就是消息通知内容 DeferredResultQueue.save(deferredResult); // 等待异步存入结果到 deferredResult 中并返回，超时则失败 return deferredResult; } /** * 模拟异步的存入请求结果：执行创建 * - 1. 监听 JMS 消息，获得消息内容（DeferredResultQueue对象） * - 2. 从消息对象 DeferredResultQueue 中拿到 DeferredResult 延迟异步结果对象。 * - 3. 执行业务逻辑，赋值。 */ @ResponseBody @RequestMapping(\"/create\") public String create() { //创建订单 String order = UUID.randomUUID().toString(); // 获取到消息通知，从中获取到需要存取结果的对象 DeferredResult&lt;Object&gt; deferredResult = DeferredResultQueue.get(); // 向结果对象存入值，请求返回结果 deferredResult.setResult(order); return \"success: \" + order; }}class DeferredResultQueue { private static ConcurrentLinkedQueue&lt;DeferredResult&lt;Object&gt;&gt; queue = new ConcurrentLinkedQueue&lt;DeferredResult&lt;Object&gt;&gt;(); public static void save(DeferredResult&lt;Object&gt; deferredResult) { queue.add(deferredResult); } public static DeferredResult&lt;Object&gt; get() { return queue.poll(); }} SSM 零配置整合 Web： WebInitializer spring context / spring mvc context / postFilter … Spring：RootConfig dataSource / transactionManager / sqlSessionFactory … Spring MVC: DispatcherServletConfig viewResolvers / resourceHandlers … demo","link":"/2018/09/13/Spring-Annotation-development/"},{"title":"20190531 maven | password encryption","text":"reference：https://maven.apache.org/guides/mini/guide-encryption.html Introduction How to create a master password How to encrypt server passwords How to keep the master password on removable drive Tips IntroductionMaven 2.1.0+ now supports server password encryption. The main use case, addressed by this solution is: multiple users share the same build machine (server, CI box) some users have the privilege to deploy Maven artifacts to repositories, some don’t. this applies to any server operations, requiring authorization, not only deployment settings.xml is shared between users The implemented solution adds the following capabilities: authorized users have an additional settings-security.xml file in their ${user.home}/.m2 folder this file either contains encrypted master password, used to encrypt other passwords or it can contain a relocation - reference to another file, possibly on removable storage this password is created first via CLI for now server entries in the settings.xml have passwords and/or keystore passphrases encrypted for now - this is done via CLI after master password has been created and stored in appropriate location How to create a master passwordUse the following command line: 1mvn --encrypt-master-password &lt;password&gt; Note: Since Maven 3.2.1 the password argument should no longer be used (see Tips below for more information). Maven will prompt for the password. Earlier versions of Maven will not prompt for a password, so it must be typed on the command-line in plaintext. This command will produce an encrypted version of the password, something like 1{jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+9EF1iFQyJQ=} Store this password in the ${user.home}/.m2/settings-security.xml; it should look like 123&lt;settingsSecurity&gt; &lt;master&gt;{jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+9EF1iFQyJQ=}&lt;/master&gt;&lt;/settingsSecurity&gt; When this is done, you can start encrypting existing server passwords. How to encrypt server passwordsYou will have to use the following command line: 1mvn --encrypt-password &lt;password&gt; Note:Just like --encrypt-master-password the password argument should no longer be used since Maven 3.2.1 (see Tips below for more information.). This command will produce an encrypted version of it, something like 1{COQLCE6DU6GtcS5P=} Cut-n-paste it into your settings.xml file in the server section. This will look like: 12345678910111213&lt;settings&gt;... &lt;servers&gt;... &lt;server&gt; &lt;id&gt;my.server&lt;/id&gt; &lt;username&gt;foo&lt;/username&gt; &lt;password&gt;{COQLCE6DU6GtcS5P=}&lt;/password&gt; &lt;/server&gt;... &lt;/servers&gt;...&lt;/settings&gt; Please note that password can contain any information outside of the curly brackets, so that the following will still work: 12345678910111213&lt;settings&gt;... &lt;servers&gt;... &lt;server&gt; &lt;id&gt;my.server&lt;/id&gt; &lt;username&gt;foo&lt;/username&gt; &lt;password&gt;Oleg reset this password on 2009-03-11, expires on 2009-04-11 {COQLCE6DU6GtcS5P=}&lt;/password&gt; &lt;/server&gt;... &lt;/servers&gt;...&lt;/settings&gt; Then you can use, say, deploy plugin, to write to this server: 123mvn deploy:deploy-file -Durl=https://maven.corp.com/repo \\ -DrepositoryId=my.server \\ -Dfile=your-artifact-1.0.jar \\ How to keep the master password on removable driveCreate the master password exactly as described above, and store it on a removable drive, for instance on OSX, my USB drive mounts as /Volumes/mySecureUsb, so I store 123&lt;settingsSecurity&gt; &lt;master&gt;{jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+9EF1iFQyJQ=}&lt;/master&gt;&lt;/settingsSecurity&gt; in the file /Volumes/mySecureUsb/secure/settings-security.xml And then I create ${user.home}/.m2/settings-security.xml with the following content: 123&lt;settingsSecurity&gt; &lt;relocation&gt;/Volumes/mySecureUsb/secure/settings-security.xml&lt;/relocation&gt;&lt;/settingsSecurity&gt; This assures that encryption will only work when the usb drive is mounted by OS. This addresses a use case where only certain people are authorized to deploy and are issued these devices. TipsEscaping curly-brace literals in your password (Since: Maven 2.2.0)At times, you might find that your password (or the encrypted form of it) may actually contain ‘{‘ or ‘}’ as a literal value. If you added such a password as-is to your settings.xml file, you would find that Maven does strange things with it. Specifically, Maven will treat all the characters preceding the ‘{‘ literal, and all the characters after the ‘}’ literal, as comments. Obviously, this is not the behavior you want in such a situation. What you really need is a way of escaping the curly-brace literals in your password. Starting in Maven 2.2.0, you can do just this, with the widely used ‘\\‘ escape character. If your password looks like this: 1jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+{EF1iFQyJQ= Then, the value you would add to your settings.xml would look like this: 1{jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+\\{EF1iFQyJQ=} Password SecurityEditing settings.xml and running the above commands can still leave your password stored locally in plaintext. You may want to check the following locations: Shell history (e.g. by running history). You may want to clear your history after encrypting the above passwords Editor caches (e.g. ~/.viminfo) Also note that the encrypted passwords can be decrypted by someone that has the master password and settings security file. Keep this file secure (or stored separately) if you expect the possibility that the settings.xml file may be retrieved. Password Escaping on different platformsOn some platforms it might be neccessary to quote your password based on the content of your password in particular having special characters like %, !, $ etc. in there. For example on Windows you have to be carefull about things like the following: The following example will not work on Windows: 1mvn --encrypt-master-password a!$%^b whereas the following will work on Windows: 1mvn --encrypt-master-password \"a!$%^b\" If you are on a linux/unix platform you should use single quotes for the above master password otherwise you will be astonished that the usage of the master-password will not work (caused by the dollar sign and furthermore the exclamation mark). Prompting for PasswordIn Maven before version 3.2.1 you have to give the password on command line as argument which means you might need to escape your password. In addition usually the shell stores the full history of commands you have entered, therefore anyone with access to your computer could restore the password from the shell`s history. Starting with Maven 3.2.1 the password is an optional argument which means if you omit the password you will be prompted for it which prevents all the issues mentioned above. Therefore we strongly recommend to use Maven 3.2.1 and above to prevent problems with escaping special characters and of course security issues related to bash history or environment issues in relationship with the password. 导言（\bintroduction） 如何创建主密码 如何加密服务密码 如何在可移动设备（on removable driver）上保存主密码 小贴士 导言（\bintroduction）Maven 2.1.0+ 开始支持服务密码加密。主要用例，\b解决方案（addressed by solution）是： 所有用户共享相同（same）的构建机器（server，CI box） 一些用户拥有部署 maven 制品（artifacts）到仓库的特权（privilege）。而一些人不能 这适用于（this applies to）任何需要授权的服务器操作，而不仅仅是\b部署。 setting.xml 在用户之间分享 实现的（implemented）解决方案添加了以下功能（capablities）： 认证的用户拥有额外的（additional）setting-security.xml 文件在他们的 ${user.home}/.m2 目录 这个文件要么包含（either contains）\b加密的主密码，用于加密其他密码 或者它可以包含一个迁移（relocaton）- 引用到另一个文件，也许在可移动存储设备上 这个密码先通过（first via） CLI 创建 setting.xml 中的服务条目加密了密码 或 \b密钥仓库密码 现在，主密码被创建并存储到了合适（appropriate）的位置，这是通过 CLI 完成的。 如何创建主密码使用以下命令 1mvn --encrypt-master-password &lt;password&gt; 1注意：从 maven 3.2.1 开始这个密码参数不再（should no longer）使用（查看以下的提示获得更多信息）。maven 将提示（prompt）输入密码。早期（Earlier）版本的 maven 不会提示输入密码，所以必须在\b命令行输入\b明文密码。 这个命令将会\b产生一个密码加密之后的版本，比如下面这样： 1{jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+9EF1iFQyJQ=} 在 ${user.home}/.m2/settings-security.xml 中存储该密码，像下面这样： \b译注：如果没有 settings-security.xml 文件自己创建即可。把内容复制进去。 123&lt;settingsSecurity&gt; &lt;master&gt;{jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+9EF1iFQyJQ=}&lt;/master&gt;&lt;/settingsSecurity&gt; 当上述步骤完成之后，你可以开始加密\b服务器密码了。 如何加密服务密码你必须使用以下命令： 1mvn --encrypt-password &lt;password&gt; 1提示：就像 mvn --encrypt-master-password 一样。这个密码参数从 maven 3.2.1 开始\b不再使用（见文档） 这个命令会产生一个密码加密后的版本，如： 1{COQLCE6DU6GtcS5P=} 剪切粘贴到您 \bsetting.xml 文件的服务节点，如下： 12345678910111213&lt;settings&gt;... &lt;servers&gt;... &lt;server&gt; &lt;id&gt;my.server&lt;/id&gt; &lt;username&gt;foo&lt;/username&gt; &lt;password&gt;{COQLCE6DU6GtcS5P=}&lt;/password&gt; &lt;/server&gt;... &lt;/servers&gt;...&lt;/settings&gt; 请注意：密码可以在花括号外（outside of the curly brackets）包含任意信息。所以以下仍然可以\b工作： 12345678910111213&lt;settings&gt;... &lt;servers&gt;... &lt;server&gt; &lt;id&gt;my.server&lt;/id&gt; &lt;username&gt;foo&lt;/username&gt; &lt;password&gt;Oleg reset this password on 2009-03-11, expires on 2009-04-11 {COQLCE6DU6GtcS5P=}&lt;/password&gt; &lt;/server&gt;... &lt;/servers&gt;...&lt;/settings&gt; 然后，您可以使用，比如说，部署插件。要写入此服务器，请执行以下操作: 123mvn deploy:deploy-file -Durl=https://maven.corp.com/repo \\ -DrepositoryId=my.server \\ -Dfile=your-artifact-1.0.jar \\ 如何在可移动设备上保存主密码\b和上文所述（described above）的一样（exactly as）创建主密码，然后存储到可移动设备中，以 OSX 为例，我的 USB 驱动挂载在 /Volumes/mySecureUsb，所以我存储（以下内容）： 123&lt;settingsSecurity&gt; &lt;master&gt;{jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+9EF1iFQyJQ=}&lt;/master&gt;&lt;/settingsSecurity&gt; 到 /Volumes/mySecureUsb/secure/settings-security.xml 然后我创建 ${user.home}/.m2/settings-security.xml ，内容如下： 123&lt;settingsSecurity&gt; &lt;relocation&gt;/Volumes/mySecureUsb/secure/settings-security.xml&lt;/relocation&gt;&lt;/settingsSecurity&gt; 这保证了只有当 usb 驱动挂载到了操作系统上（OS）上，加密才能工作。这解决了（this addresses a）一个用例，其中只有特定（certain）的人被授权部署和发布（issued）这些设备。 小提示在您的密码中转义（escaping）\b花括号（curly-brace）文本（literals） 有时（as time），你可能发现你的密码（或以此加密的）可能确实包含 { 或 } 作为文字值。 译注：maven 加密的密码最外层都有花括号包围，通常我们加密后的密码都是：{jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+EF1iFQyJQ==} 的形式，密码是 jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+EF1iFQyJQ==。\\但可能不排除有这样的密码，他们密码中间就包含了花括号：jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+{EF1iFQyJQ=，外面再被一个大括号包围，就成了这样：{jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+{EF1iFQyJQ=} 如果你将这样（such a）的密码原样（as-is）的放在你的 settings.xml 中，你会发现 maven 对此做了一些奇怪（strange）的事情。具体的说（Specifically），maven 会处理（treat） { 字面符\b之前\b（preceding）所有的文本（Literals），和处理 } 字面符之后的所有字符。作为评论，很明显的（Obviusly），这种情况（sush a siluation）下，这不是您想要的行为（behavior）。你真正需要的是一种转义（escaping）你密码中的花括号的方法。 从 maven 2.2.0 起，你可以这样做，与广泛使用的（widely used）的 \\ 转义字符（escape \bcharacter）。如果你的密码看起来是这样的： 1jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+{EF1iFQyJQ= \b那么，你可以像这样添加\b值到你的 settings.xml 中: 1{jSMOWnoPFgsHVpMvz5VrIt5kRbzGpI8u+\\{EF1iFQyJQ=} 密码安全 编辑 settings.xml 并运行以上命令依然可以以明文（plaintext）的形式保存（leave）你的密码到本地，你可能需要检查以下位置： shell 历史（例如：运行 history）。你可能想要在加密（encrying）上述密码（above password）之后清除你的历史记录 编辑器缓存。（例如：~/.viminfo） 同样注意（note），加密\b后的密码可以被拥有主密码和设置安全文件的某些人（someone）解密（\bdecrypted by 被解密）。保持这个文件安全（\b或分别存储）,如果你希望可以（expect polibility 期待可能性\b）检索（retried） settings.xml 文件的话。 不同平台的密码转义符 在一些平台上，你可能（neccessary）需要基于（base on）你的密码内容添加引号（quote），特别是（in particular）含有特殊字符的比如：%,!,$。例如在 window 上你需要小心比如像以下这种： 以下案例在 Windows 上\b将不起作用： 1mvn --encrypt-master-password a!$%^b 然而（whereas），以下内容适用于 Windows： 1mvn --encrypt-master-password \"a!$%^b\" 如果你在Linux/Unix平台上，你应该使用上面的主密码的单引号。否则你会惊讶的（astonished）发现使用主密码将不起作用（由美元符号（dollar sign）和感叹号（exclamation mark）引起）。 密码输入提示 在 maven 3.2.1 之前你必须在命令行参数上给定密码，这意味着你可能需要转义（escape）你的密码。此外（in addition），通常 shell 会存储你在命令行输入的完整历史。所以（therefore）\b任何人\b访问你电脑的人都可以通过 shell 的历史\b恢复（restore）你的密码。 从 Maven 3.2.1 开始，密码是一个可选参数，这意味着如果省略（omit）密码，系统将提示（prompted）您输入密码，这将阻止（prevents）上述（above）提过（mentioned）的所有问题（issues）。 译注：使用 mvn –encrypt-master-password 不带密码参数\b，会要求输入密码。这个输入是不可见的，命令行没有记录的。 因此，我们强烈建议（srongly recommend）使用 Maven 3.2.1 及更高版本来防止（prevent）转义特殊字符的问题，当然（of course）还有与bash历史相关的安全问题或与密码相关的环境问题。","link":"/2019/05/31/[20190531] maven | password encryption/"},{"title":"分布式技术入坑指南（三）","text":"11.Solr索引库的搭建与使用（单机版和集群版）下载地址：https://lucene.apache.org/solr/ 单机版搭建* 版本：solr-4.10.3 * windows下的配置完全一样。 第一步：把solr 的压缩包上传到Linux系统第二步：解压solr。第三步：把solr部署到Tomcat下。 路径：`/opt/solr-4.10.3/dist/solr-4.10.3.war` 第四步：解压缩war包。可以启动Tomcat解压。第五步：把/root/solr-4.10.3/example/lib/ext目录下的所有的jar包，添加到solr工程中。第六步：创建一个solrhome。安装包自带有一个solrhome：/example/solr，该目录就是一个solrhome。复制此目录到自己创建solrhome。第七步：关联solr及solrhome。需要修改solr工程的web.xml文件。 12345&lt;env-entry&gt; &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt; &lt;env-entry-value&gt;/opt/solrhome&lt;/env-entry-value&gt; &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt;&lt;/env-entry&gt; 第八步：启动Tomcathttp://192.168.184.130:8080/solr/ 使用添加文档必须有id域，其他域 必须在solr的schema.xml中定义。 schema.xml中定义 本系统业务所需要的业务域有：1、商品Id 使用schema.xml中的id域2、商品标题3、商品卖点4、商品价格5、商品图片6、分类名称7、商品描述 配置中文分词器创建对应的业务域。需要制定中文分析器。下载地址：https://code.google.com/archive/p/ik-analyzer/downloads 第一步：把中文分析器添加到solr工程中。 1、把IKAnalyzer2012FF_u1.jar添加到solr工程的lib目录下。 2、把扩展词典、配置文件放到solr工程的WEB-INF/classes目录下。 第二步：配置一个FieldType，制定使用IKAnalyzer 修改solrHome中的schema.xml文件，添加FieldType。 路径：`/opt/solrhome/collection1/conf/schema.xml` 123&lt;fieldType name=\"text_ik\" class=\"solr.TextField\"&gt; &lt;analyzer class=\"org.wltea.analyzer.lucene.IKAnalyzer\"/&gt;&lt;/fieldType&gt; 第三步：配置业务域，type制定使用自定义的FieldType。设置业务系统Field 123456789101112&lt;field name=\"item_title\" type=\"text_ik\" indexed=\"true\" stored=\"true\"/&gt;&lt;field name=\"item_sell_point\" type=\"text_ik\" indexed=\"true\" stored=\"true\"/&gt;&lt;field name=\"item_price\" type=\"long\" indexed=\"true\" stored=\"true\"/&gt;&lt;field name=\"item_image\" type=\"string\" indexed=\"false\" stored=\"true\" /&gt;&lt;field name=\"item_category_name\" type=\"string\" indexed=\"true\" stored=\"true\" /&gt;&lt;field name=\"item_desc\" type=\"text_ik\" indexed=\"true\" stored=\"false\" /&gt;&lt;field name=\"item_keywords\" type=\"text_ik\" indexed=\"true\" stored=\"false\" multiValued=\"true\"/&gt;&lt;copyField source=\"item_title\" dest=\"item_keywords\"/&gt;&lt;copyField source=\"item_sell_point\" dest=\"item_keywords\"/&gt;&lt;copyField source=\"item_category_name\" dest=\"item_keywords\"/&gt;&lt;copyField source=\"item_desc\" dest=\"item_keywords\"/&gt; 第四步：重启tomcat Tomcat启动后访问不了？多次出现这样的问题，启动之后访问不了，一定要看日志！/opt/apache-tomcat-8.5.32/logs/catalina.out。 由于本机中dubbo-admin和solr放在了同一个tomcat，而dubbo-admin启动需要先开启zookeeper服务，所以tomcat一直处于启动状态。 Linux中多次启动关闭Tomcat下次启动会异常，需要强制杀死进程 kill -s 9 pid 然后再启动。 测试CRUD使用SolrJ可以实现索引库的增删改查操作。 Maven: 12345&lt;!-- solr客户端 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.solr&lt;/groupId&gt; &lt;artifactId&gt;solr-solrj&lt;/artifactId&gt;&lt;/dependency&gt; 添加到文档1234567891011121314151617181920212223242526/** * 第一步：把solrJ的jar包添加到工程中。 * 第二步：创建一个SolrServer，使用HttpSolrServer创建对象。 * 第三步：创建一个文档对象SolrInputDocument对象。 * 第四步：向文档中添加域。必须有id域，域的名称必须在schema.xml中定义。 * 第五步：把文档添加到索引库中。 * 第六步：提交。 * * @throws Exception */@Testpublic void addDocument() throws Exception { // 第一步：把solrJ的jar包添加到工程中。 // 第二步：创建一个SolrServer，使用HttpSolrServer创建对象。 SolrServer solrServer = new HttpSolrServer(\"http://192.168.184.130:8080/solr\"); // 第三步：创建一个文档对象SolrInputDocument对象。 SolrInputDocument document = new SolrInputDocument(); // 第四步：向文档中添加域。必须有id域，域的名称必须在schema.xml中定义。 document.addField(\"id\", \"test001\"); document.addField(\"item_title\", \"测试商品\"); document.addField(\"item_price\", \"199\"); // 第五步：把文档添加到索引库中。 solrServer.add(document); // 第六步：提交。 solrServer.commit();} 删除文档1234567891011121314151617181920212223242526/** * 第一步：创建一个SolrServer对象。 * 第二步：调用SolrServer对象的根据id删除的方法。 * 第三步：提交。 * * @throws Exception */@Testpublic void deleteDocumentById() throws Exception { // 第一步：创建一个SolrServer对象。 SolrServer solrServer = new HttpSolrServer(\"http://192.168.184.130:8080/solr\"); // 第二步：调用SolrServer对象的根据id删除的方法。 solrServer.deleteById(\"1\"); // 第三步：提交。 solrServer.commit();} /** * 根据查询删除 */@Testpublic void deleteDocumentByQuery() throws Exception { SolrServer solrServer = new HttpSolrServer(\"http://192.168.184.130:8080/solr\"); solrServer.deleteByQuery(\"title:change.me\"); solrServer.commit();} 查询文档1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * 第一步：创建一个SolrServer对象 * 第二步：创建一个SolrQuery对象。 * 第三步：向SolrQuery中添加查询条件、过滤条件。。。 * 第四步：执行查询。得到一个Response对象。 * 第五步：取查询结果。 * 第六步：遍历结果并打印。 * * @throws Exception */@Testpublic void queryDocument() throws Exception { // 第一步：创建一个SolrServer对象 SolrServer solrServer = new HttpSolrServer(\"http://192.168.184.130:8080/solr\"); // 第二步：创建一个SolrQuery对象。 SolrQuery query = new SolrQuery(); // 第三步：向SolrQuery中添加查询条件、过滤条件。。。 query.setQuery(\"*:*\"); // 第四步：执行查询。得到一个Response对象。 QueryResponse response = solrServer.query(query); // 第五步：取查询结果。 SolrDocumentList solrDocumentList = response.getResults(); System.out.println(\"查询结果的总记录数：\" + solrDocumentList.getNumFound()); // 第六步：遍历结果并打印。 for (SolrDocument solrDocument : solrDocumentList) { System.out.println(solrDocument.get(\"id\")); System.out.println(solrDocument.get(\"item_title\")); System.out.println(solrDocument.get(\"item_price\")); }}/** * 高亮查询 */@Testpublic void queryDocumentWithHighLighting() throws Exception { // 第一步：创建一个SolrServer对象 SolrServer solrServer = new HttpSolrServer(\"http://192.168.184.130:8080/solr\"); // 第二步：创建一个SolrQuery对象。 SolrQuery query = new SolrQuery(); // 第三步：向SolrQuery中添加查询条件、过滤条件。。。 query.setQuery(\"测试\"); //指定默认搜索域 query.set(\"df\", \"item_keywords\"); //开启高亮显示 query.setHighlight(true); //高亮显示的域 query.addHighlightField(\"item_title\"); query.setHighlightSimplePre(\"&lt;em&gt;\"); query.setHighlightSimplePost(\"&lt;/em&gt;\"); // 第四步：执行查询。得到一个Response对象。 QueryResponse response = solrServer.query(query); // 第五步：取查询结果。 SolrDocumentList solrDocumentList = response.getResults(); System.out.println(\"查询结果的总记录数：\" + solrDocumentList.getNumFound()); // 第六步：遍历结果并打印。 for (SolrDocument solrDocument : solrDocumentList) { System.out.println(solrDocument.get(\"id\")); //取高亮显示 Map&lt;String, Map&lt;String, List&lt;String&gt;&gt;&gt; highlighting = response.getHighlighting(); List&lt;String&gt; list = highlighting.get(solrDocument.get(\"id\")).get(\"item_title\"); String itemTitle = null; if (list != null &amp;&amp; list.size() &gt; 0) { itemTitle = list.get(0); } else { itemTitle = (String) solrDocument.get(\"item_title\"); } System.out.println(itemTitle); System.out.println(solrDocument.get(\"item_price\")); }} 搭建搜索服务工程 分布式集群版一些概念 SolrCloud是Solr提供基于Solr和Zookeeper的分布式搜索方案，它的主要思想是使用Zookeeper作为集群的配置信息中心。 Solr集群的系统架构 需要实现的solr集群架构 Zookeeper作为集群的管理工具。1、集群管理：容错、负载均衡。2、配置文件的集中管理3、集群的入口 搭建伪分布式 需要三个zookeeper节点 需要四个tomcat节点 Zookeeper集群搭建第一步：创建solr集群的根目录 /opt/solrCloud/第二步：解压 zookeeper.tar.gz 并在根目录下复制三份 123drwxr-xr-x. 11 1000 1000 4096 7月 22 20:15 zookeeper01drwxr-xr-x. 11 root root 4096 7月 22 20:18 zookeeper02drwxr-xr-x. 11 root root 4096 7月 22 20:18 zookeeper03 第三步：在每一个zookeeper中创建data目录，在data中创建文件 myid，内容就是每个实例的id，比如：1，2，3第四步：把每一个zookeeper下的conf目录下的zoo_sample.cfg文件改名为zoo.cfg第五步：修改配置文件 dataDir clientPort 集群的节点列表 1.集群的节点列表，1、2、3代表节点的id2.ip后的端口号是zookeeper内部通讯的端口和投票选举的端口，每个端口不能重复。 第六步：启动每个zookeeper实例 12345678910[root@yuzh solrCloud]# vim zookeeper_start_all.sh cd /opt/solrCloud/zookeeper01/bin./zkServer.sh startcd /opt/solrCloud/zookeeper02/bin./zkServer.sh startcd /opt/solrCloud/zookeeper03/bin./zkServer.sh start 授权、启动。 Solr集群搭建第一步：创建四个tomcat实例。每个tomcat运行在不同的端口。8180、8280、8380、8480第二步：部署solr的war包。把单机版的solr工程复制到集群中每个的tomcat中。第三步：为每个solr实例创建一个对应的solrhome。使用单机版的solrhome复制四份。 12345678drwxr-xr-x. 4 root root 4096 7月 23 14:40 solrhome01drwxr-xr-x. 4 root root 4096 7月 23 14:40 solrhome02drwxr-xr-x. 4 root root 4096 7月 23 14:40 solrhome03drwxr-xr-x. 4 root root 4096 7月 23 14:40 solrhome04drwxr-xr-x. 9 root root 4096 7月 22 20:23 tomcat01drwxr-xr-x. 9 root root 4096 7月 22 20:24 tomcat02drwxr-xr-x. 9 root root 4096 7月 22 20:24 tomcat03drwxr-xr-x. 9 root root 4096 7月 22 20:24 tomcat04 第四步：需要修改每个tomcat实例中的solr的web.xml文件。把solrhome关联起来。 12345&lt;env-entry&gt; &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt; &lt;env-entry-value&gt;/opt/solrCloud/solrhome01&lt;/env-entry-value&gt; &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt;&lt;/env-entry&gt; 第五步：配置SolrCloud相关的配置。每个solrhome下都有一个solr.xml，把其中的ip及端口号配置好。 123456789&lt;solrcloud&gt; &lt;!-- 本机IP --&gt; &lt;str name=&quot;host&quot;&gt;192.168.184.130&lt;/str&gt; &lt;!-- 每个solr对应的solrhome所属的tomcat端口号 --&gt; &lt;int name=&quot;hostPort&quot;&gt;8180&lt;/int&gt; &lt;str name=&quot;hostContext&quot;&gt;${hostContext:solr}&lt;/str&gt; &lt;int name=&quot;zkClientTimeout&quot;&gt;${zkClientTimeout:30000}&lt;/int&gt; &lt;bool name=&quot;genericCoreNodeNames&quot;&gt;${genericCoreNodeNames:true}&lt;/bool&gt;&lt;/solrcloud&gt; 第六步：让zookeeper统一管理配置文件。 需要把`solrhome/collection1/conf`目录上传到zookeeper。上传任意solrhome中的配置文件即可。（需要保证zookeeper集群是启动的状态） 使用工具上传配置文件：执行/opt/solr-4.10.3/example/scripts/cloud-scripts/zkcli.sh注意不是zookeeper/bin中的zkCli.sh ./zkcli.sh -zkhost 192.168.184.130:2181,192.168.184.130:2182,192.168.184.130:2183 -cmd upconfig -confdir /opt/solrCloud/solrhome01/collection1/conf -confname myconf 第七步：修改每一个tomcat/bin目录下的catalina.sh 文件，关联solr和zookeeper。把此配置添加到配置文件中： 1JAVA_OPTS=&quot;-DzkHost=192.168.184.130:2181,192.168.184.130:2182,192.168.184.130:2183&quot; 第八步：启动每个tomcat实例。要保证zookeeper集群是启动状态。第九步：访问集群 http://192.168.184.130:8180/solr 创建新的Collection进行分片处理:http://192.168.184.130:8180/solr/admin/collections?action=CREATE&amp;name=collection2&amp;numShards=2&amp;replicationFactor=2删除不用的Collection:http://192.168.184.130:8180/solr/admin/collections?action=DELETE&amp;name=collection1 注意：关闭防火墙吧，端口太多了。每次开机之后防火墙会自动重启。 使用solrJ管理集群123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package xyz.taotao.search.test;import org.apache.solr.client.solrj.SolrQuery;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.impl.CloudSolrServer;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;import org.apache.solr.common.SolrInputDocument;import org.junit.Test;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/23 14:46 * Solr集群版客户端连接测试 */public class SolrCloudTest { @Test public void add() throws Exception { //1.创建集群版Solr，传入zookeeper集群地址。 CloudSolrServer solrServer = new CloudSolrServer(\"192.168.184.130:2181,192.168.184.130:2182,192.168.184.130:2183\"); //2.设置默认集合属性 solrServer.setDefaultCollection(\"collection2\"); //3.创建文档对象 SolrInputDocument document = new SolrInputDocument(); //4.向文档对象添加业务域（这些域要在配置文件 schema.xml 中存在） document.addField(\"id\", \"test01\"); document.addField(\"item_title\", \"测试商品\"); document.addField(\"item_price\", \"100\"); //5.把文档对象写入索引库 solrServer.add(document); //6.提交操作 solrServer.commit(); } @Test public void query() throws Exception { //创建solrServer对象实现类CloudSolrServer对象 CloudSolrServer solrServer = new CloudSolrServer(\"192.168.184.130:2181,192.168.184.130:2182,192.168.184.130:2183\"); //设置查询的默认集合 solrServer.setDefaultCollection(\"collection2\"); //创建SolrQuery查询 SolrQuery solrQuery = new SolrQuery(); //添加查询条件 solrQuery.setQuery(\"*:*\"); //执行查询，得到结果集对象 QueryResponse queryResponse = solrServer.query(solrQuery); //操作结果 SolrDocumentList resultList = queryResponse.getResults(); System.out.println(\"总记录数：\" + resultList.getNumFound()); for (SolrDocument solrDocument : resultList) { System.out.println(solrDocument.get(\"id\")); System.out.println(solrDocument.get(\"item_title\")); System.out.println(solrDocument.get(\"item_price\")); } }} 把搜索业务功能切换到集群版 12345678910111213141516171819202122232425&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd\"&gt; &lt;!-- 单机版 --&gt; &lt;!-- &lt;bean id=\"httpSolrServer\" class=\"org.apache.solr.client.solrj.impl.HttpSolrServer\"&gt; &lt;constructor-arg name=\"baseURL\" value=\"http://192.168.184.130:8080/solr\"/&gt; &lt;/bean&gt;--&gt; &lt;!-- 集群版 --&gt; &lt;bean id=\"cloudSolrServer\" class=\"org.apache.solr.client.solrj.impl.CloudSolrServer\"&gt; &lt;constructor-arg name=\"zkHost\" value=\"192.168.184.130:2181,192.168.184.130:2182,192.168.184.130:2183\"&gt;&lt;/constructor-arg&gt; &lt;property name=\"defaultCollection\" value=\"collection2\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; OVER~~😭","link":"/2018/07/22/分布式技术入坑指南（三）/"},{"title":"20190701 spring-boot | part4(1~2)","text":"Spring Boot Reference Guide2.2.0.BUILD-SNAPSHOThttps://docs.spring.io/spring-boot/docs/2.2.0.BUILD-SNAPSHOT/reference/htmlsingle/#boot-features Part 4. Spring Boot Features 4.1 Spring 应用 4.1.1 启动失败 4.1.2 懒加载 4.1.3 定制横幅 4.1.4 定制 Spring 应用 4.1.5 Fluent 构建 API 4.1.6 应用事件与监听 4.1.7 web 环境 4.1.8 访问应用参数 4.1.9 使用 ApplicationRunner 或者 CommandLineRunner 4.1.10 退出应用 4.1.11 管理特性功能 4.2 外部化配置 4.1 Spring 应用SpringApplication 类提供方便的（convenient）方式引导 Spring 应用从 main() 启动。通常情况下，你可以委托（delegate）静态方法 SpringApplication.run()，如下所示： 123public static void main(String[] args) { SpringApplication.run(MySpringConfiguration.class, args);} 当你的应用启动后，你可以看到类似以下的输出： . ____ _ __ _ _ /\\\\ / ___&apos;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | &apos;_ | &apos;_| | &apos;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &apos; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: v2.2.0.BUILD-SNAPSHOT 2013-07-31 00:08:16.117 INFO 56603 --- [ main] o.s.b.s.app.SampleApplication : Starting SampleApplication v0.1.0 on mycomputer with PID 56603 (/apps/myapp.jar started by pwebb) 2013-07-31 00:08:16.166 INFO 56603 --- [ main] ationConfigServletWebServerApplicationContext : Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@6e5a8246: startup date [Wed Jul 31 00:08:16 PDT 2013]; root of context hierarchy 2014-03-04 13:09:54.912 INFO 41370 --- [ main] .t.TomcatServletWebServerFactory : Server initialized with port: 8080 2014-03-04 13:09:56.501 INFO 41370 --- [ main] o.s.b.s.app.SampleApplication : Started SampleApplication in 2.992 seconds (JVM running for 3.658) 默认情况下，展示 INFO 级别的日志记录消息，包含一些有关（relevant）启动的细节，例如启动应用程序的用户。如果你不需要 INFO 级别的日志信息，你可以设置它，有关这的描述在 日志级别 4.1.1 启动失败如果你的应用启动失败，注册的 FailureAnalyzers 获得激活提供一个错误描述信息和解决问题的具体（concrete）方式。例如：如果你在 8080 端口启动 web 程序被占用，你应该看到类似以下的输出： *************************** APPLICATION FAILED TO START *************************** Description: Embedded servlet container failed to start. Port 8080 was already in use. Action: Identify and stop the process that&apos;s listening on port 8080 or configure this application to listen on another port. Spring Boot 提供许多的（numerous）FailureAnalyzer 实现，你可以添加你自己的 如果没有故障分析器能够处理异常，你仍然可以一直展示这个条件报告以便于更好的理解发生了什么错误。要这样做，你需要开启 debug 属性或者为 org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener 打开 DEBUG 日志记录。 例如，如果你通过 java -jar 运行你的应用程序，你可以开启 debug 属性，如下： 1java -jar myproject-0.0.1-SNAPSHOT.jar --debug 4.1.2 懒加载SpringApplication 允许应用懒加载。当懒加载开启，Beans 是根据需要创建的，而不是应用启动时创建。因此（as a result），开启懒加载可以减少（reduce the time）应用启动的时间。在 Web 应用中，开启懒加载将会导致（will result in）大量与 web 相关的 beans 不会初始化，\b直到一个请求进来之后。 懒加载的缺点（a downside of）是它会推迟（delay）发现应用程序出现的问题。如果配置不当（misconfigured）的 bean 被\b懒加载，启动期间将不会失败，只有当\b bean 被初始化时问题才会显露出来。创建同样需要确保 JVM 有充足的（sufficient）的内存来容纳（accommodate）所有的应用 bean，并且不仅仅是启动时的 bean。由于这些原因，懒加载默认情况下没有开启，建议在启用惰性初始化之前对 JVM 的堆大小进行微调。 懒加载可以使用 SpringApplicationBuilder 的 lazyInitilization 方法或者 SpringApplication 的 setLazyInitialization 方法编程式（programatically）的打开。或者，它也可以通过使用 spring.main.lazy-initilization 属性开启，如下： 1spring.main.lazy-initialization=true 如果你想对应用的其余部分\b使用懒加载初始化而禁用确定的（certain） bean 的懒加载。你可以使用 @Lazt(false) 注解明确的（explicitly）设置他们的懒加载属性为 false。 4.1.3 定制横幅（banner）\b\b横幅将会在应用启动时打印，可以通过添加一个 banner.txt 文件到你的类路径下或者设置 spring.banner.location 属性指定到一个类似的文件来改变\b它。如果这个文件的编码不是 UTF-8，你可以设置 spring.banner.charset。除了（in addtion to）文本文件，你同样可以添加一个 banner.git，banner.jpg，banner.png 图片文件到你的类路径下，或者设置 spring.banner.location 属性。图像被转换成 ASCII 艺术表示法（art representation），并打印在任何文字横幅之上。 在你的 banner.txt 文件中，你可以使用任意以下的\b占位符： \b变量 描述 ${application.version} 你的应用的版本号，在 MANIFEST.MF 中\b定义。如，Implementation-Version: 1.0 is printed as 1.0. ${application.formatted-version} 你的应用的版本号，在 MANIFEST.MF 中\b定义并格式化展示（用括号括起来，并用v）。如：（v1.0） ${spring-boot.version} 你使用的 Spring Boot 的版本号。如\b：2.2.0.BUILD-SNAPSHOT ${spring-boot.formatted-version} 你使用的 Spring Boot 版本号并格式化展示。如：(v2.2.0.BUILD-SNAPSHOT). ${Ansi.NAME} (or ${AnsiColor.NAME},${AnsiBackground.NAME}, ${AnsiStyle.NAME}) 其中，名称是ANSI转义代码的名称。更多细节请看 AnsiPropertySource ${application.title} 你应用的标题，在 MANIFEST.MF 中\b定义。如: MyApp is printed as MyApp. SpringApplication.setBanner(...) 方法可以\b使用，如果你想编程式生成一个横幅。使用 org.springframework.boot.Banner 接口\b并实现你自己的 printBanner() 方法。 您还可以使用 Spring.main.ban-mode 属性来确定（determine）是否必须在 System.out(控制台) 上打印横幅，发送到已配置的记录器（日志），或根本不产生（关闭）。 打印的横幅被注册成一个单例的 bean，如以下命名：\bspringBanner。 1234# yml 映射 off 为 false，请确保添加引号如果你要在你\b的应用中禁用横幅的话，如下所示：spring: main: banner-mode: \"off\" 4.1.4 定制 Spring 应用如果 SpringApplication 默认的配置不符合你的口味（taste），作为替代你可以创建一个本地的实例并定制它。例如：要关闭 banner，你可以这样写： 12345public static void main(String[] args) { SpringApplication app = new SpringApplication(MySpringConfiguration.class); app.setBannerMode(Banner.Mode.OFF); app.run(args);} 该构造参数传递给 SpringApplication 的是一个 Spr\bing Bean 的配置资源。大多数情况下，这些是对 @Configuration 的引用，但是他们同样可以引用 XML 配置或者扫描包。 同样可以通过使用 application.properties 文件配置 SpringApplication。更多细节请查看 外部配置 关于配置项的完整（complete）列表，请查看 SpringApplication 文档。 4.1.5 Fluent 构建 API如果你想构建具有层次结构的（hierarchy）的 ApplicationContext（多个上下文具有父子关系）或者你喜爱使用 “fluent” 构建 API，你可以使用 SpringApplicationBuilder。 SpringApplicationBuilder 允许你将多个方法调用连接在一起，包括允许你创建具有层级结构的父子方法，如下所示\b\b： 12345new SpringApplicationBuilder() .sources(Parent.class) .child(Application.class) .bannerMode(Banner.Mode.OFF) .run(args); 当创建具有层级结构的 ApplicationContext 会有一些限制（restrictions）例如：WEB 组件必须包含在 子上下文里面，并且父和子上下文都使用相同的环境。更多细节请查看 SpringApplicationBuilder 文档。 4.1.6 应用事件与监听除了通常使用的 Spring 框架事件，例如 ContextRefreshedEvent。SpringApplication 还会发送一些额外的事件。 一些事件实际上（actually）是在 ApplicationContext 创建之前触发的，所以你不能注册监听器为一个 @Bean。你可以使用 \bSpringApplication.addListeners(…​) 方法或者 SpringApplicationBuilder.listeners(…​) 方法注册\b他们。 如果你想这些\b监听器可以自动注册，\b不管（regardless）创建应用的\b是什么方式，你可以添加一个 META-INF/spring.factories 文件到你的项目并使用 org.springframework.context.ApplicationListener 键来引用你的监听器，如下所示\b： org.springframework.context.ApplicationListener=com.example.project.MyListener 当应用程序运行时，Application Event 以以下顺序发送： 应用启动事件（ApplicationStartingEvent）在引用\b开始启动但在\b任何处理之前发送，\b除了（except for）注册监听和初始化器之外。 应用环境准备事件（ApplicationEnvironmentPreparedEvent）发送的\b时机是当 \bEnvironment 被一个已知的上下\b文使用但是该上下文创建之前。\b\b 应用上下文初始化事件（ApplicationContextInitializedEvent）当 ApplicationContext 已准备，ApplicationContextInitializers 被调用但是任何定义的 bean 加载之前发送。 应用准备事件（ApplicationPreparedEvent）只在应用刷新开始之前但定义的 bean 加载之后发送。 应用\b开始事件（ApplicationStartedEvent）在上下文刷新之后但是任何应用和命令行\b执行器调用之前发送。 应用准备事件（ApplicationReadyEvent）是在任何应用和命令行执行器被调用之后发送的。它表明（indicates）该应用已准备好服务请求。 应用失败事件（ApplicationFailedEvent）在如果启动启动发生异常时发送。 上面的列表只包括 SpringApplicationEvents，它与 “SpringApplication” 绑定（tied to）在一起。。除了这些，以下事件同样在 ApplicationPreparedEvent 之后，ApplicationStartedEvent 之前发布： 上下文刷新事件（ContextRefreshedEvent）在 ApplicationContext 被刷新\b后发送。 web服务器\b\b初始化事件（WebServerInitializedEvent）在 web 服务器已准备好。ServletWebServerInitializedEvent 和 ReactiveWebServerInitializedEvent 分别是（respectively）servlet 和 reactive 变体。 你通常不需要使用应用事件，但是知道它们的存在是很方便（handy）的。在内部，SpringBoot 使用事件来处理各种任务。 应用事件通过使用 Spring 框架的事件发布机制发送。此机制的一部分（part of）确保事件\b\b发布到子上下文的事件时同样也会发送给祖先（ancestor）上线文的监听器。因此（As a result of this），如果你的应用使用\b具有\b层次结构的 SpringApplicatoni 实例，监听器可以接受相同类型的应用事件的多个实例。 若要允许监听器区分（distinguish）用于其上下文的事件和针对后代上下文的事件，它应该请求它的应用程序上下文被注入，然后将注入的上下文与事件的上下文进行比较。该上下文可以通过实现 ApplicationContextAware 注入，或者如果监听器是一个 Bean，通过使用 @Authwired。 4.1.7 web 环境SpringApplication 会尝试（attempts）为您（on your behalf）创建正确类型的应用上下文。用于确定（determine） Web 应用上下文类型的算法相当简单（fairly simple）： 如果存在 Spring MVC，使用 AnnotationConfigServletWebServerApplicationContext。 如果 Spring MVC 不存在但 Spring WebFlux 存在，使用 AnnotationConfigReactiveWebServerApplicationContext。 否则，使用 AnnotationConfigApplicationContext。 这意味着如果你从来自同一个（same）应用的 Spring WebFlux 使用 Spring MVC 和新的 WebClient，\bSpring MVC 将会作为默认使用。你可以通过调用 setWebApplicationType(WebApplicationType) 简单的覆盖它。 同样可以通过调用 setApplicationContextClass(…​) 完成对应用上下文类型的控制。 当在 JUnitTest 中使用 SpringApplication 时通常需要调用 setWebApplicationType(WebApplicationType.NONE) 4.1.8 访问应用参数如果你需要访问传递给 SpringApplication.run(…​) 的应用参数，你可以注册一个 org.springframework.boot.ApplicationArguments bean。ApplicationArguments 接口提供对原始 String[] 参数以及可选、\b非可选参数的访问，如下所示： 123456789101112131415import org.springframework.boot.*;import org.springframework.beans.factory.annotation.*;import org.springframework.stereotype.*;@Componentpublic class MyBean { @Autowired public MyBean(ApplicationArguments args) { boolean debug = args.containsOption(\"debug\"); List&lt;String&gt; files = args.getNonOptionArgs(); // if run with \"--debug logfile.txt\" debug=true, files=[\"logfile.txt\"] }} Spring Boot 还在 Spring 环境中注册了 CommandLinePropertySource。这允许你通过使用 @Value 注解注入单个应用参数。 4.1.9 使用 ApplicationRunner 或者 CommandLineRunner如果你需要在 Spring\b 应用启动时运行\b一些特定代码，你可以实现 ApplicationRunner 或 CommandLineRunner 接口。\b两者接口都以相同的方式工作，并且都提供了一个单个的 run 方法，只需要在 SpringApplication.run(…​) 完成之前调用。 CommandLineRunner 接口提供对应用参数的访问作为一个\b简单字符串数组，而 ApplicationRunner 使用前面讨论的 ApplicationArguments 接口。以下样例展示了一个 CommandLineRunner 运行 run 方法： 1234567891011import org.springframework.boot.*;import org.springframework.stereotype.*;@Componentpublic class MyBean implements CommandLineRunner { public void run(String... args) { // Do something... }} 如果定义了多个 ApplicationRunner 和 CommandLineRunner 的Bean，且需要以特定顺序调用。你可以另外（additionally）实现 org.springframework.core.Ordered 接口或者使用 org.springframework.core.annotation.Order 注解。 4.1.10 退出应用每一个 SpringApplication 都注册了一个宕机钩子到 JVM 以确保在 ApplicationContext 关闭时优雅（gracefully）的退出。可以使用所有标准的 Spring 生命周期回调（例如 DisposableBean 接口或 @predestroy）。 除此之外，beans 可以实现 org.springframework.boot.ExitCodeGenerator 接口如果需要当 SpringApplication.exit() 被调用后返回特定\b 退出码。这个退出码可以被传递给 System.Exit() 作为一个状态码返回，如下所示： 12345678910111213@SpringBootApplicationpublic class ExitCodeApplication { @Bean public ExitCodeGenerator exitCodeGenerator() { return () -&gt; 42; } public static void main(String[] args) { System.exit(SpringApplication.exit(SpringApplication.run(ExitCodeApplication.class, args))); }} 同样的，ExitCodeGenerator 接口可以实现一个异常。当遇到这样的异常时，SpringBoot 返回由实现的 getExitCode() 方法提供的退出代码。 4.1.11 管理功能可以通过指定 spring.application.admin.enabled 属性为应用开启与管理相关的功能。这将在 MBeanServer 平台上暴露一个 SpringApplicationAdminMXBean。您可以使用此功能远程管理您的 Spring 启动应用程序。这些特性在\b一些服务包装实现类中同样可用。 如果你想知道应用运行在哪一个端口上，通过 local.server.port 属性可以获得。 启用此特性时要小心（take\b care），因为MBean公开了关闭应用程序的方法。 4.2 外部化配置","link":"/2019/07/01/[20190701] spring-boot | part4(1~2)/"},{"title":"分布式技术入坑指南（二）","text":"10.Redis集群的搭建及业务实现Redis集群的搭建及业务实现redis集群（Redis-cluster）架构图 环境准备 至少3个节点，为了集群的高可用，为每一个节点增加一个备份机。（6台服务器）。搭建伪分布式集群方案：在一台机器里面运行6个redis实例。端口需要不同（7001-7006） 1、使用ruby脚本搭建集群。需要ruby的运行环境。安装ruby： 12yum install rubyyum install rubygems 2、从官网下载 redis-3.0.4.gem 并上传到 linux 中 地址：https://rubygems.org/gems/redis/versions 3、安装ruby运行时所使用的包 1gem install redis-3.0.0.gem 搭建步骤 需要6台redis服务器。搭建伪分布式。需要6个redis实例。需要运行在不同的端口7001-7006注意：搭建前 如果节点里有数据，需要删除（rdb文件，aof文件）。 第一步：创建6个redis实例，每个实例运行在不同的端口。需要修改redis.conf配置文件。配置文件中还需要把cluster-enabled yes前的注释去掉。 12345678910[root@localhost redis-cluster]# pwd/usr/local/redis-cluster[root@localhost redis-cluster]# ll总用量 80drwxr-xr-x. 3 root root 4096 7月 10 21:12 redis01drwxr-xr-x. 3 root root 4096 7月 10 21:53 redis02drwxr-xr-x. 3 root root 4096 7月 10 21:53 redis03drwxr-xr-x. 3 root root 4096 7月 10 21:53 redis04drwxr-xr-x. 3 root root 4096 7月 10 21:53 redis05drwxr-xr-x. 3 root root 4096 7月 10 21:54 redis06 每个实例内容如下 12345678910111213141516[root@localhost redis-cluster]# cd redis01[root@localhost redis01]# ll总用量 4drwxr-xr-x. 2 root root 4096 7月 10 22:39 bin[root@localhost redis01]# cd bin[root@localhost bin]# ll总用量 15508-rw-r--r--. 1 root root 18 7月 10 22:39 dump.rdb-rw-r--r--. 1 root root 769 7月 10 22:02 nodes.conf-rwxr-xr-x. 1 root root 4589155 7月 10 21:12 redis-benchmark-rwxr-xr-x. 1 root root 22217 7月 10 21:12 redis-check-aof-rwxr-xr-x. 1 root root 45435 7月 10 21:12 redis-check-dump-rwxr-xr-x. 1 root root 4693114 7月 10 21:12 redis-cli-rw-r--r--. 1 root root 41391 7月 10 21:14 redis.conflrwxrwxrwx. 1 root root 12 7月 10 21:12 redis-sentinel -&gt; redis-server-rwxr-xr-x. 1 root root 6466389 7月 10 21:12 redis-server 实际上一个实例就是一个redis安装文件（不是安装包），为每个实例复制一份redis.conf，分别配置不同的端口、cluster-enabled yes注释打开。 第二步：启动每个redis实例。 通过脚本批量启动全部服务 1234567891011121314151617181920vim redis-cluster-start-all.sh 添加如下：cd /usr/local/redis-cluster/redis01/bin./redis-server redis.confcd /usr/local/redis-cluster/redis02/bin./redis-server redis.confcd /usr/local/redis-cluster/redis03/bin./redis-server redis.confcd /usr/local/redis-cluster/redis04/bin./redis-server redis.confcd /usr/local/redis-cluster/redis05/bin./redis-server redis.confcd /usr/local/redis-cluster/redis06/bin./redis-server redis.conf 然后授予可执行权限、执行即可。 123456789[root@localhost redis-cluster]# ./redis-cluster-start-all.sh [root@localhost redis-cluster]# ps -ef |grep redisroot 4001 1 10 22:14 ? 00:00:00 ./redis-server *:7001 [cluster]root 4003 1 8 22:14 ? 00:00:00 ./redis-server *:7002 [cluster]root 4009 1 7 22:14 ? 00:00:00 ./redis-server *:7003 [cluster]root 4013 1 2 22:14 ? 00:00:00 ./redis-server *:7004 [cluster]root 4017 1 2 22:14 ? 00:00:00 ./redis-server *:7005 [cluster]root 4021 1 2 22:14 ? 00:00:00 ./redis-server *:7006 [cluster]root 4028 3302 0 22:14 pts/0 00:00:00 grep redis 第三步：使用ruby脚本搭建集群。 从Redis解压目录下的src下的拷贝redis-trib.rb文件到redis-cluster目录中 执行创建 1./redis-trib.rb create --replicas 1 192.168.184.130:7001 192.168.184.130:7002 192.168.184.130:7003 192.168.184.130:7004 192.168.184.130:7005 192.168.184.130:7006 第四步 创建关闭集群的脚本：（不是必须的） 12345678910111213141516171819vim 命令创建一个文件 redis-cluster-stop-all.sh cd /usr/local/redis-cluster/redis01/bin./redis-cli -p 7001 shutdowncd /usr/local/redis-cluster/redis02/bin./redis-cli -p 7002 shutdowncd /usr/local/redis-cluster/redis03/bin./redis-cli -p 7003 shutdowncd /usr/local/redis-cluster/redis04/bin./redis-cli -p 7004 shutdowncd /usr/local/redis-cluster/redis05/bin./redis-cli -p 7005 shutdowncd /usr/local/redis-cluster/redis06/bin./redis-cli -p 7006 shutdown 然后授予可执行权限、执行即可。 集群使用Redis-cli连接集群。-c：代表连接的是redis集群 123456789101112[root@localhost bin]# ./redis-cli -p 7001 -c127.0.0.1:7001&gt; set adsadsafd jkljlkjl-&gt; Redirected to slot [16142] located at 192.168.184.130:7006OK192.168.184.130:7006&gt; get adsadsafd&quot;jkljlkjl&quot;192.168.184.130:7006&gt; set key2 v2-&gt; Redirected to slot [4998] located at 192.168.184.130:7001OK192.168.184.130:7001&gt; get key2&quot;v2&quot;192.168.184.130:7001&gt; Jedis客户端连接Redis集群服务器注意：开放集群的7001-7006端口 12345678910111213141516171819@Testpublic void testJedisCluster() throws Exception { // 第一步：使用JedisCluster对象。需要一个Set&lt;HostAndPort&gt;参数。Redis节点的列表。 Set&lt;HostAndPort&gt; nodes = new HashSet&lt;&gt;(); nodes.add(new HostAndPort(\"192.168.184.130\", 7001)); nodes.add(new HostAndPort(\"192.168.184.130\", 7002)); nodes.add(new HostAndPort(\"192.168.184.130\", 7003)); nodes.add(new HostAndPort(\"192.168.184.130\", 7004)); nodes.add(new HostAndPort(\"192.168.184.130\", 7005)); nodes.add(new HostAndPort(\"192.168.184.130\", 7006)); JedisCluster jedisCluster = new JedisCluster(nodes); // 第二步：直接使用JedisCluster对象操作redis。在系统中单例存在。 jedisCluster.set(\"hello\", \"100\"); String result = jedisCluster.get(\"hello\"); // 第三步：打印结果 System.out.println(result); // 第四步：系统关闭前，关闭JedisCluster对象。 jedisCluster.close();} 实现业务 因为集群是比较消耗成本的，所以在实际开发中，一般生产环境使用集群，开发环境使用单机版。我们在项目整合中都需要有。可以开发一个接口，有单机版的实现类和集群版的实现类。使用时可以面向接口开发，不影响业务逻辑，使用spring管理实现类，部署时切换实现类即可。 接口封装常用的操作redis的方法抽取出一个接口，分别对应单机版和集群版创建两个实现类。 123456789101112131415161718192021package xyz.taotao.content.service;/** * Created with IntelliJ IDEA. * Jedis接口 * @Author: yu_zh * @DateTime: 2018/07/14 23:32 */public interface JedisClient { String set(String key, String value); String get(String key); Boolean exists(String key); Long expire(String key, int seconds); Long ttl(String key); Long incr(String key); Long hset(String key, String field, String value); String hget(String key, String field); Long hdel(String key, String... field); } 单机版实现类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package xyz.taotao.content.service.impl;import org.springframework.beans.factory.annotation.Autowired;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import xyz.taotao.content.service.JedisClient;/** * Created with IntelliJ IDEA. * 单机版实现 * @Author: yu_zh * @DateTime: 2018/07/14 23:35 */public class JedisClientPool implements JedisClient { @Autowired private JedisPool jedisPool; @Override public String set(String key, String value) { Jedis jedis = jedisPool.getResource(); String result = jedis.set(key, value); jedis.close(); return result; } @Override public String get(String key) { Jedis jedis = jedisPool.getResource(); String result = jedis.get(key); jedis.close(); return result; } @Override public Boolean exists(String key) { Jedis jedis = jedisPool.getResource(); Boolean result = jedis.exists(key); jedis.close(); return result; } @Override public Long expire(String key, int seconds) { Jedis jedis = jedisPool.getResource(); Long result = jedis.expire(key, seconds); jedis.close(); return result; } @Override public Long ttl(String key) { Jedis jedis = jedisPool.getResource(); Long result = jedis.ttl(key); jedis.close(); return result; } @Override public Long incr(String key) { Jedis jedis = jedisPool.getResource(); Long result = jedis.incr(key); jedis.close(); return result; } @Override public Long hset(String key, String field, String value) { Jedis jedis = jedisPool.getResource(); Long result = jedis.hset(key, field, value); jedis.close(); return result; } @Override public String hget(String key, String field) { Jedis jedis = jedisPool.getResource(); String result = jedis.hget(key, field); jedis.close(); return result; } @Override public Long hdel(String key, String... field) { Jedis jedis = jedisPool.getResource(); Long result = jedis.hdel(key, field); jedis.close(); return result; }} 集群版实现类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package xyz.taotao.content.service.impl;import org.springframework.beans.factory.annotation.Autowired;import redis.clients.jedis.JedisCluster;import xyz.taotao.content.service.JedisClient;/** * Created with IntelliJ IDEA. * 集群版实现类 * @Author: yu_zh * @DateTime: 2018/07/14 23:44 */public class JedisClientCluster implements JedisClient { @Autowired private JedisCluster jedisCluster; @Override public String set(String key, String value) { return jedisCluster.set(key, value); } @Override public String get(String key) { return jedisCluster.get(key); } @Override public Boolean exists(String key) { return jedisCluster.exists(key); } @Override public Long expire(String key, int seconds) { return jedisCluster.expire(key, seconds); } @Override public Long ttl(String key) { return jedisCluster.ttl(key); } @Override public Long incr(String key) { return jedisCluster.incr(key); } @Override public Long hset(String key, String field, String value) { return jedisCluster.hset(key, field, value); } @Override public String hget(String key, String field) { return jedisCluster.hget(key, field); } @Override public Long hdel(String key, String... field) { return jedisCluster.hdel(key, field); }} 配置：spring-redis.xml注意：单机版和集群版只能放开一个 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;!-- 用于激活已经注册的Bean --&gt; &lt;context:annotation-config&gt;&lt;/context:annotation-config&gt; &lt;!-- 配置单机版的连接 --&gt; &lt;bean id=\"jedisPool\" class=\"redis.clients.jedis.JedisPool\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"6379\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 创建单机版的实现类 --&gt; &lt;bean id=\"jedisClientPool\" class=\"xyz.taotao.content.service.impl.JedisClientPool\"/&gt; &lt;!--------------------------------------------------------&gt; &lt;!-- 配置集群版 --&gt; &lt;bean class=\"redis.clients.jedis.JedisCluster\"&gt; &lt;constructor-arg name=\"nodes\"&gt; &lt;set&gt; &lt;bean class=\"redis.clients.jedis.HostAndPort\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"7001\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=\"redis.clients.jedis.HostAndPort\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"7002\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=\"redis.clients.jedis.HostAndPort\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"7003\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=\"redis.clients.jedis.HostAndPort\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"7004\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=\"redis.clients.jedis.HostAndPort\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"7005\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=\"redis.clients.jedis.HostAndPort\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"7006\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 创建集群版的实现类 --&gt; &lt;bean class=\"xyz.taotao.content.service.impl.JedisClientCluster\"&gt;&lt;/bean&gt; 封装代码测试redis客户端Bean只在spring-redis.xml中注册，所以只需加载这个配置文件，注意：需要激活已经注册的Bean才能注入到属性。 12345678910@Testpublic void testJedisClient() throws Exception { //初始化Spring容器 ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"classpath:spring-redis.xml\"); //从容器中获得JedisClient对象（接口） JedisClient jedisClient = applicationContext.getBean(JedisClient.class); jedisClient.set(\"testJedis\", \"500\"); String result = jedisClient.get(\"testJedis\"); System.out.println(result);} 为查询添加缓存创建Json工具类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package xyz.taotao.utils;import java.util.List;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.JavaType;import com.fasterxml.jackson.databind.ObjectMapper;/** * 使用 jackson-databind 工具包封装Json */public class JsonUtils { // 定义jackson对象 private static final ObjectMapper MAPPER = new ObjectMapper(); /** * 将对象转换成json字符串。 * * @param data * @return */ public static String objectToJson(Object data) { try { String string = MAPPER.writeValueAsString(data); return string; } catch (JsonProcessingException e) { e.printStackTrace(); } return null; } /** * 将json结果集转化为对象 * * @param jsonData json数据 * @param beanType 对象中的object类型 * @return */ public static &lt;T&gt; T jsonToPojo(String jsonData, Class&lt;T&gt; beanType) { try { T t = MAPPER.readValue(jsonData, beanType); return t; } catch (Exception e) { e.printStackTrace(); } return null; } /** * 将json数据转换成pojo对象list * * @param jsonData * @param beanType * @return */ public static &lt;T&gt; List&lt;T&gt; jsonToList(String jsonData, Class&lt;T&gt; beanType) { JavaType javaType = MAPPER.getTypeFactory().constructParametricType(List.class, beanType); try { List&lt;T&gt; list = MAPPER.readValue(jsonData, javaType); return list; } catch (Exception e) { e.printStackTrace(); } return null; }} 添加缓存，不能影响业务。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package xyz.taotao.service.impl;import com.github.pagehelper.PageHelper;import com.github.pagehelper.PageInfo;import org.apache.commons.lang3.StringUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Service;import xyz.taotao.mapper.TbItemMapper;import xyz.taotao.pojo.EasyUIDataGridResult;import xyz.taotao.pojo.TbItem;import xyz.taotao.pojo.TbItemExample;import xyz.taotao.redis.JedisClient;import xyz.taotao.service.ItemService;import xyz.taotao.utils.JsonUtils;import java.util.List;/** * Created with IntelliJ IDEA. * * @Author: yu_zh * @DateTime: 2018/07/05 19:02 */@Servicepublic class ItemServiceImpl implements ItemService { @Autowired TbItemMapper tbItemMapper; @Autowired private JedisClient jedisClient; @Value(\"ITEM_LIST_KEY\") private String ITEM_LIST_KEY; /** * 为查询列表项添加缓存 * 结构：Hash * &lt;p&gt; * item_list_key * | * 1,50 —— EasyUIDataGridResult Json字符串 * 2,50 —— EasyUIDataGridResult Json字符串 * 3,50 —— EasyUIDataGridResult Json字符串 * &lt;p&gt; * 缓存不能影响业务流程，用try-catch起来。 * * @param page 查询页码 * @param rows 查询行数 * @return EasyUIDataGridResult */ @Override public EasyUIDataGridResult getItemList(int page, int rows) { //查询缓存 try { String json = jedisClient.hget(ITEM_LIST_KEY, page + \"-\" + rows); //判断json是否为空 if (StringUtils.isNotBlank(json)) { //把json转换成list System.out.println(\"获得缓存\"); return JsonUtils.jsonToPojo(json, EasyUIDataGridResult.class); } } catch (Exception e) { e.printStackTrace(); } //设置分页信息 PageHelper.startPage(page, rows); //查询数据，设置查询条件 TbItemExample example = new TbItemExample(); List&lt;TbItem&gt; tbItemList = tbItemMapper.selectByExample(example); //封装分页结果集 PageInfo&lt;TbItem&gt; pageInfo = new PageInfo&lt;&gt;(tbItemList); //创建分页对象 EasyUIDataGridResult result = new EasyUIDataGridResult((int) pageInfo.getTotal(), pageInfo.getList()); //向缓存中添加数据 try { jedisClient.hset(ITEM_LIST_KEY, page + \"-\" + rows, JsonUtils.objectToJson(result)); System.out.println(\"放入redis -&gt; \" + page + \"-\" + rows); System.out.println(JsonUtils.objectToJson(result)); } catch (Exception e) { e.printStackTrace(); } return result; }} 控制台打印：Redis数据库： 缓存同步对添加了缓存的数据进行更新（增、删、改）之后，需要同步最新的数据放入缓存。做法就是删除对应缓存的key，再次获取数据会先查询数据库，再放入缓存。","link":"/2018/07/14/分布式技术入坑指南（二）/"},{"title":"分布式技术入坑指南（四）","text":"12.Java消息队列学习与使用ActiveMQ官网：http://activemq.apache.org/ 安装 解压 cd到bin目录 ./activemq start 访问，默认端口：8161 默认用户名与密码：admin 使用两种模式 点对点 发布/订阅 需要包： 1234567891011121314151617&lt;!-- 消息队列整合包 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt;&lt;/dependency&gt;&lt;!-- activemq --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;${activemq.version}&lt;/version&gt;&lt;/dependency&gt; 点对点模式目的地实现类 —— Queue发送消息 12345678910111213141516171819202122232425262728293031323334353637383940414243package xyz.yuzh.activemq.queue;import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 12:31 * 消息发送端 * 点对点模式 */public class QueueProducer { public static void main(String[] args) throws Exception{ // 第一步：创建ConnectionFactory对象，需要指定服务端ip及端口号。 //brokerURL服务器的ip及端口号 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"tcp://192.168.184.130:61616\"); // 第二步：使用ConnectionFactory对象创建一个Connection对象。 Connection connection = connectionFactory.createConnection(); // 第三步：开启连接，调用Connection对象的start方法。 connection.start(); // 第四步：使用Connection对象创建一个Session对象。 //第一个参数：是否开启事务。true：开启事务，第二个参数忽略。 //第二个参数：当第一个参数为false时，才有意义。消息的应答模式。1、自动应答2、手动应答。一般是自动应答。 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); // 第五步：使用Session对象创建一个Destination对象（topic、queue），此处创建一个Queue对象。 //参数：队列的名称。 Queue queue = session.createQueue(\"queue-test\"); // 第六步：使用Session对象创建一个Producer对象。 MessageProducer producer = session.createProducer(queue); // 第七步：创建一个Message对象，创建一个TextMessage对象。 /*TextMessage message = new ActiveMQTextMessage(); message.setText(\"hello activeMq,this is my first test.\");*/ TextMessage textMessage = session.createTextMessage(\"hello activeMq,this is my first test.\"); // 第八步：使用Producer对象发送消息。 producer.send(textMessage); // 第九步：关闭资源。 producer.close(); session.close(); connection.close(); }} 接收消息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package xyz.yuzh.activemq.queue;import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 12:31 * 消息接收端 */public class QueueConsumer { public static void main(String[] args) throws Exception { // 1.创建一个连接工厂 （Activemq的连接工厂）参数：指定连接的activemq的服务 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"tcp://192.168.184.130:61616\"); // 2.获取连接 Connection connection = connectionFactory.createConnection(); // 3.开启连接 connection.start(); // 4.根据连接对象创建session // 第一个参数：表示是否使用分布式事务（JTA） // 第二个参数：如果第一个参数为false,第二个参数才有意义；表示使用的应答模式 ：自动应答，手动应答.这里选择自动应答。 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); // 5.根据session创建Destination(目的地，queue topic,这里使用的是queue) Queue queue = session.createQueue(\"queue-test\"); // 6.创建消费者 MessageConsumer consumer = session.createConsumer(queue); //7.接收消息 //第一种/* while(true){ //接收消息 （参数的值表示的是超过一定时间 以毫秒为单位就断开连接） Message message = consumer.receive(10000); //如果message为空，没有接收到消息了就跳出 if(message==null){ break; } if(message instanceof TextMessage){ TextMessage messaget = (TextMessage)message; System.out.println(\"&gt;&gt;&gt;获取的消息内容：\"+messaget.getText());//获取消息内容 } }*/ //第二种： //设置监听器,其实开启了一个新的线程。 consumer.setMessageListener((m) -&gt; { //接收消息，如果有消息才进入，如果没有消息就不会进入此方法 if (m instanceof TextMessage) { TextMessage message = (TextMessage) m; try { //获取消息内容 System.out.println(\"&gt;&gt;&gt;获取的消息内容：\" + message.getText()); } catch (JMSException e) { e.printStackTrace(); } } }); Thread.sleep(10000);//睡眠10秒钟。 // 9.关闭资源 consumer.close(); session.close(); connection.close(); }} 发布/订阅模式目的地实现类 —— Topic 发送消息 12345678910111213141516171819202122232425262728293031323334353637383940package xyz.yuzh.activemq.topic;import org.apache.activemq.ActiveMQConnectionFactory;import org.apache.activemq.command.ActiveMQTextMessage;import javax.jms.*;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 12:50 * 发布订阅模式 */public class TopicProducer { public static void main(String[] args) throws Exception { // 1.创建一个连接工厂 （Activemq的连接工厂）参数：指定连接的activemq的服务 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"tcp://192.168.184.130:61616\"); // 2.获取连接 Connection connection = connectionFactory.createConnection(); // 3.开启连接 connection.start(); // 4.根据连接对象创建session // 第一个参数：表示是否使用分布式事务（JTA） // 第二个参数：如果第一个参数为false,第二个参数才有意义；表示使用的应答模式 ：自动应答，手动应答.这里选择自动应答。 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); // 5.根据session创建Destination(目的地，queue topic,这里使用的是topic) Topic topic = session.createTopic(\"topic-test\"); // 6.创建生产者 MessageProducer producer = session.createProducer(topic); // 7.构建消息对象，（构建发送消息的内容） 字符串类型的消息格式（TEXTMessage） TextMessage textMessage = new ActiveMQTextMessage(); textMessage.setText(\"发送消息123\");// 消息的内容 // 8.发送消息 producer.send(textMessage); // 9.关闭资源 producer.close(); session.close(); connection.close(); }} 接收消息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package xyz.yuzh.activemq.topic;import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 12:50 */public class TopicConsumer { public static void main(String[] args) throws Exception { // 1.创建一个连接工厂 （Activemq的连接工厂）参数：指定连接的activemq的服务 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"tcp://192.168.184.130:61616\"); // 2.获取连接 Connection connection = connectionFactory.createConnection(); // 3.开启连接 connection.start(); // 4.根据连接对象创建session // 第一个参数：表示是否使用分布式事务（JTA） // 第二个参数：如果第一个参数为false,第二个参数才有意义；表示使用的应答模式 ：自动应答，手动应答.这里选择自动应答。 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); // 5.根据session创建Destination(目的地，queue topic,这里使用的是queue) Topic topic = session.createTopic(\"topic-test\"); // 6.创建消费者 MessageConsumer consumer = session.createConsumer(topic); // 7.接收消息 while (true) { //接收消息 （参数的值表示的是超过一定时间 以毫秒为单位就断开连接） Message message = consumer.receive(100000); //如果message为空，没有接收到消息了就跳出 if (message == null) { break; } if (message instanceof TextMessage) { TextMessage messaget = (TextMessage) message; System.out.println(\"&gt;&gt;&gt;获取的消息内容：\" + messaget.getText());//获取消息内容 } } // 第二种： // 设置监听器,其实开启了一个新的线程。 /* consumer.setMessageListener((m) -&gt; { // 接收消息，如果有消息才进入，如果没有消息就不会进入此方法 if (m instanceof TextMessage) { TextMessage messaget = (TextMessage) m; try { // 获取消息内容 System.out.println(\"&gt;&gt;&gt;获取的消息内容：\" + messaget.getText()); } catch (JMSException e) { e.printStackTrace(); } } }); Thread.sleep(10000);// 睡眠10秒钟。*/ // 9.关闭资源 consumer.close(); session.close(); connection.close(); }} 与Spring整合这里只做测试，发送与接收均在同一系统并在同一配置文件 mvc配置 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd\"&gt; &lt;!-- ActiveMQ的连接工厂 --&gt; &lt;bean id=\"targetConnection\" class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.184.130:61616\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- Spring通用的connectionfacotry 指定真正使用的连接工厂 --&gt; &lt;bean id=\"connectionFactory\" class=\"org.springframework.jms.connection.SingleConnectionFactory\"&gt; &lt;property name=\"targetConnectionFactory\" ref=\"targetConnection\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 接收和发送消息时使用的模板类 --&gt; &lt;bean class=\"org.springframework.jms.core.JmsTemplate\"&gt; &lt;property name=\"connectionFactory\" ref=\"connectionFactory\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 目的地实现类：Queue、Topic --&gt; &lt;bean id=\"queueDestination\" class=\"org.apache.activemq.command.ActiveMQQueue\"&gt; &lt;constructor-arg name=\"name\" value=\"item-change-queue\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- &lt;bean id=\"topicDestination\" class=\"org.apache.activemq.command.ActiveMQTopic\"&gt; &lt;constructor-arg name=\"name\" value=\"item-change-topic\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; --&gt; &lt;!-- 配置消息接收监听器 --&gt; &lt;bean id=\"myMessageListener\" class=\"xyz.yuzh.activemq.spring.SpringActiveMqReciveListener\"&gt;&lt;/bean&gt; &lt;bean class=\"org.springframework.jms.listener.DefaultMessageListenerContainer\"&gt; &lt;property name=\"connectionFactory\" ref=\"connectionFactory\"&gt;&lt;/property&gt; &lt;property name=\"destination\" ref=\"queueDestination\"&gt;&lt;/property&gt; &lt;property name=\"messageListener\" ref=\"myMessageListener\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 发送消息 123456789101112131415161718192021222324252627282930313233343536373839package xyz.yuzh.activemq.spring;import org.apache.xbean.spring.context.ClassPathXmlApplicationContext;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.jms.core.JmsTemplate;import org.springframework.jms.core.MessageCreator;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.Session;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 17:21 * 消息发送端 */public class SpringActiveMqSend { public static void main(String[] args) throws Exception{ //初始化容器 ApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:spring-activemq.xml\"); //获得JMS模板对象 JmsTemplate jmsTemplate = context.getBean(JmsTemplate.class); //获得消息队列目的地（注意是jms接口的包，不是activemq的包。） Destination queueDestination = context.getBean(Destination.class); //发送消息 jmsTemplate.send(queueDestination, (s) -&gt; { StringBuilder message = new StringBuilder(); for (int i = 1 ; i &lt;= 100;i++){ message.append(\"测试消息\"+i+\"\\n\"); } return s.createTextMessage(message.toString()); }); Thread.sleep(100000); }} 接收消息 123456789101112131415161718192021222324252627282930package xyz.yuzh.activemq.spring;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 18:06 * 消息接收监听器 */public class SpringActiveMqReciveListener implements MessageListener { @Override public void onMessage(Message message) { if(message instanceof TextMessage){ TextMessage textMessage = (TextMessage)message; String text; try { text = textMessage.getText(); System.out.println(\"SpringActiveMqReciveListener-&gt; \"+text); } catch (JMSException e) { e.printStackTrace(); } } }} 具体业务场景下使用manager-service工程更新一个商品（增删改查），search-service工程要在索引库中更新该商品。 manager-service系统（发送消息端）spring-activemq.xml 123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd\"&gt; &lt;!-- 系统间通信 —— 消息发送方 --&gt; &lt;bean id=\"targetConnection\" class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.184.130:61616\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 通用的connectionfacotry 指定真正使用的连接工厂 --&gt; &lt;bean id=\"connectionFactory\" class=\"org.springframework.jms.connection.SingleConnectionFactory\"&gt; &lt;property name=\"targetConnectionFactory\" ref=\"targetConnection\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 接收和发送消息时使用的类 --&gt; &lt;bean id=\"jmsTemplate\" class=\"org.springframework.jms.core.JmsTemplate\"&gt; &lt;property name=\"connectionFactory\" ref=\"connectionFactory\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 订阅通知模式 --&gt; &lt;bean id=\"topicDestination\" class=\"org.apache.activemq.command.ActiveMQTopic\"&gt; &lt;constructor-arg name=\"name\" value=\"item-change-topic\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt;&lt;/beans&gt; Service 1234567891011121314151617181920212223@Servicepublic class ItemServiceImpl implements ItemService { //...... @Resource private JmsTemplate jmsTemplate; @Resource private Destination topicDestination; //...... @Override public Object addItem() { //执行商品添加逻辑 //TODO... //发送一个消息通知搜索系统更新该商品到索引库 jmsTemplate.send(topicDestination, (s) -&gt;{ System.out.println(\"发送方-&gt; 添加操作，商品编号是123\"); return s.createTextMessage(\"addItem:123\"); }); return null; }} search-service系统（接收消息端）spring-activemq.xml 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd\"&gt; &lt;!-- 系统间通信 —— 消息接收方 --&gt; &lt;bean id=\"targetConnection\" class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.184.130:61616\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 通用的connectionfacotry 指定真正使用的连接工厂 --&gt; &lt;bean id=\"connectionFactory\" class=\"org.springframework.jms.connection.SingleConnectionFactory\"&gt; &lt;property name=\"targetConnectionFactory\" ref=\"targetConnection\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 接收和发送消息时使用的类 --&gt; &lt;bean id=\"jmsTemplate\" class=\"org.springframework.jms.core.JmsTemplate\"&gt; &lt;property name=\"connectionFactory\" ref=\"connectionFactory\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 订阅通知模式 --&gt; &lt;bean id=\"topicDestination\" class=\"org.apache.activemq.command.ActiveMQTopic\"&gt; &lt;!-- name不和发送端保持一致接收不到消息！ --&gt; &lt;constructor-arg name=\"name\" value=\"item-change-topic\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 接收消息的监听器 --&gt; &lt;bean class=\"org.springframework.jms.listener.DefaultMessageListenerContainer\"&gt; &lt;property name=\"connectionFactory\" ref=\"connectionFactory\"&gt;&lt;/property&gt; &lt;property name=\"destination\" ref=\"topicDestination\"&gt;&lt;/property&gt; &lt;property name=\"messageListener\" ref=\"itemChangeListener\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; Service 12345678910111213141516171819202122232425262728293031323334353637383940414243package xyz.taotao.search.activemq.recive;import org.apache.solr.client.solrj.SolrServer;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 23:22 * 商品改变后通知该方法更新索引库 */@Componentpublic class ItemChangeListener implements MessageListener { @Autowired private SolrServer solrserver; @Override public void onMessage(Message message) { if (message instanceof TextMessage) { TextMessage textMessage = (TextMessage) message; String text = \"\"; try { text = textMessage.getText(); if (text.contains(\"addItem\")) { String itemId = text.substring(text.lastIndexOf(\":\")+1); //通知索引库服务提供者更新商品 //TODO... System.out.println(\"接收方-&gt; 索引库更新产品:\"+itemId); } } catch (JMSException e) { e.printStackTrace(); } } }} 推荐博客：http://elim.iteye.com/blog/1893038","link":"/2018/07/25/分布式技术入坑指南（四）/"},{"title":"NIO","text":"Java Non blocking IO 学习笔记 Java NIO 简介 Java NIO（Non blocking IO）是从Java 1.4版本开始引入的一个新的IO API，可以替代标准的Java IO API。NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同，NIO支持面向缓冲区的、基于通道的IO操作。NIO将以更加高效的方式进行文件的读写操作。 Java NIO 与 IO 的主要区别 IO NIO 面向流(Stream Oriented) 面向缓冲区(Buffer Oriented) 阻塞IO(Blocking IO) 非阻塞IO(Non Blocking IO) (无) 选择器(Selectors) 缓冲区(Buffer)和通道(Channel) Java NIO系统的核心在于：通道(Channel)和缓冲区(Buffer)。通道表示打开到 IO 设备(例如：文件、套接字)的连接。若需要使用 NIO 系统，需要获取用于连接 IO 设备的通道以及用于容纳数据的缓冲区。然后操作缓冲区，对数据进行处理。简而言之，Channel 负责传输， Buffer 负责存储。 缓冲区缓冲区（Buffer）：一个用于特定基本数据类型的容器。由 java.nio 包定义的，所有缓冲区都是 Buffer 抽象类的子类。 Java NIO 中的 Buffer 主要用于与 NIO 通道进行交互，数据是从通道读入缓冲区，从缓冲区写入通道中的。 Buffer 就像一个数组，可以保存多个相同类型的数据。根据数据类型不同(boolean 除外) ，有以下 Buffer 常用子类： ByteBuffer / CharBuffer / ShortBuffer / IntBuffer / LongBuffer / FloatBuffer / DoubleBuffer 上述 Buffer 类 他们都采用相似的方法进行管理数据，只是各自管理的数据类型不同而已。都是通过如下方法获取一个 Buffer 对象： static XxxBuffer allocate(int capacity) : 创建一个容量为 capacity 的 XxxBuffer 对象 基本属性： 容量 (capacity) ：表示 Buffer 最大数据容量，缓冲区容量不能为负，并且创建后不能更改。 限制 (limit)：第一个不应该读取或写入的数据的索引，即位于 limit 后的数据不可读写。缓冲区的限制不能为负，并且不能大于其容量。 位置 (position)：下一个要读取或写入的数据的索引。缓冲区的位置不能为负，并且不能大于其限制 标记 (mark)与重置 (reset)：标记是一个索引，通过 Buffer 中的 mark() 方法指定 Buffer 中一个特定的position，之后可以通过调用 reset() 方法恢复到这个 position. 标记、位置、限制、容量遵守以下不变式： 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity 常用方法： 方 法 描 述 byte get() 读取单个字节 Buffer put(byte b) 写入单个字节到缓冲区 Buffer clear() 清空缓冲区并返回对缓冲区的引用 Buffer flip() 将缓冲区的界限设置为当前位置，并将当前位置充值为 0 int capacity() 返回 Buffer 的 capacity 大小 boolean hasRemaining() 判断缓冲区中是否还有元素 int limit() 返回 Buffer 的界限(limit) 的位置 Buffer limit(int n) 将设置缓冲区界限为 n, 并返回一个具有新 limit 的缓冲区对象 Buffer mark() 对缓冲区设置标记 int position() 返回缓冲区的当前位置 position Buffer position(int n) 将设置缓冲区的当前位置为 n , 并返回修改后的 Buffer 对象 int remaining() 返回 position 和 limit 之间的元素个数 Buffer reset() 将位置 position 转到以前设置的 mark 所在的位置 Buffer rewind() 将位置设为为 0， 取消设置的 mark 用例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class TestBuffer { @Test public void test() { // 分配一个指定容量的缓冲区 ByteBuffer buffer = ByteBuffer.allocate(1024); System.out.println(\"-----&lt; allocate &gt;-----\"); showAttribute(buffer); // position:0 - limit:1024 - capacity:1024 // 存数据到缓冲区 buffer.put(\"abcde\".getBytes()); // 存入了5个字节 System.out.println(\"-----&lt; put &gt;-----\"); showAttribute(buffer); // position:5 - limit:1024 - capacity:1024 // 切换到读取数据，将缓冲区的界限设置为当前位置（5），并将当前位置充值为 0（从0开始读取） buffer.flip(); System.out.println(\"-----&lt; flip &gt;-----\"); showAttribute(buffer); // position:从 0 开始读 - limit:5 - capacity:1024 // 这个时候如果存入数据会报错，因为指针在0，界限是5，而存入的数据长度10大于界限。// buffer.put(\"zhangyu123\".getBytes()); // 取数据 byte[] bytes = new byte[buffer.limit()]; buffer.get(bytes); System.out.println(new String(bytes, 0, bytes.length)); System.out.println(\"-----&lt; get &gt;-----\"); showAttribute(buffer); // position:5 - limit:5 - capacity:1024 // 重复读取 buffer.rewind(); System.out.println(\"-----&lt; rewind &gt;-----\"); showAttribute(buffer); // position:0 - limit:5 - capacity:1024 // 清空缓存区，缓存区的数据依旧存在，只是position到了0，limit和capacity变为最大容量数值，数据处于游离状态。 buffer.clear(); System.out.println(\"-----&lt; clear &gt;-----\"); showAttribute(buffer); // position:0 - limit:1024 - capacity:1024 } @Test public void testMark() { String s = \"abcde\"; ByteBuffer buffer = ByteBuffer.allocate(1024); buffer.put(s.getBytes()); buffer.flip(); byte[] bytes = new byte[buffer.limit()]; buffer.get(bytes, 0, 2); // 从缓冲区获取从0开始的两个字符 System.out.println(new String(bytes, 0, bytes.length)); // ab System.out.println(\"position:\" + buffer.position()); // 2 buffer.mark(); // 对位置 2 做标记，继续往下读。 buffer.get(bytes, 2, 2); System.out.println(new String(bytes, 0, bytes.length)); // abcd System.out.println(\"position:\" + buffer.position()); // 4 buffer.reset(); // position 重新恢复到了 2 System.out.println(\"position:\" + buffer.position()); // 2 System.out.println((char) buffer.get()); // 获取下一个字节 c if (buffer.hasRemaining()) System.out.println(buffer.remaining()); // 获得剩余字节数量 2 } @Test public void test3() { //分配直接缓冲区 ByteBuffer buf = ByteBuffer.allocateDirect(1024); System.out.println(buf.isDirect()); } public void showAttribute(ByteBuffer buffer) { System.out.println(\"position:\" + buffer.position()); System.out.println(\"limit:\" + buffer.limit()); System.out.println(\"capacity:\" + buffer.capacity()); }} 非直接缓冲区：通过 allocate() 方法分配缓冲区，将缓冲区建立在 JVM 的内存中。 直接缓冲区：通过 allocateDirect() 方法分配直接缓冲区，将缓冲区建立在物理内存中。可以提高效率。弊端：直接在系统内存中建立（分配、销毁）缓存比在JVM中建立缓存内存消耗要大,并且当我们的应用程序将数据写入到系统内存之后数据是不可控的（不归应用程序管了），缓存中的数据什么写入到磁盘由操作系统决定。使用直接缓冲区最好的场景是当我们需要长时间在缓存中操作数据或者大量的数据时，此时的效率会得到很大的提高。 通道 通道（Channel）：由 java.nio.channels 包定义的。Channel 表示 IO 源与目标打开的连接。Channel 类似于传统的“流”。只不过 Channel 本身不能直接访问数据，Channel 只能与Buffer 进行交互。 主要实现类： java.nio.channels.Channel 接口： |--FileChannel |--SocketChannel |--ServerSocketChannel |--DatagramChannel 获取通道的几种方式： Java 针对支持通道的类提供了 getChannel() 方法 本地 IO： FileInputStream/FileOutputStream RandomAccessFile 网络IO： Socket ServerSocket DatagramSocket 在 JDK 1.7 中的 NIO.2 针对各个通道提供了静态方法 open() 在 JDK 1.7 中的 NIO.2 的 Files 工具类的 newByteChannel() 文件通道(FileChannel)FileChannel 的常用方法： 方 法 描 述 int read(ByteBuffer dst) 从 Channel 中读取数据到 ByteBuffer long read(ByteBuffer[] dsts) 将 Channel 中的数据“分散”到 ByteBuffer[] int write(ByteBuffer src) 将 ByteBuffer 中的数据写入到 Channel long write(ByteBuffer[] srcs) 将 ByteBuffer[] 中的数据“聚集”到 Channel long position() 返回此通道的文件位置 FileChannel position(long p) 设置此通道的文件位置 long size() 返回此通道的文件的当前大小 FileChannel truncate(long s) 将此通道的文件截取为给定大小 void force(boolean metaData) 强制将所有对此通道的文件更新写入到存储设备中 以文件传输体验通道的数据传输： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class TestFileChannel { /** * 利用通道和非直接缓冲区传输文件 */ @Test public void test1() throws IOException { FileInputStream in = null; FileOutputStream out = null; FileChannel inChannel = null; FileChannel outChannel = null; try { in = new FileInputStream(\"img/mm.jpg\"); out = new FileOutputStream(\"img/mm2.jpg\"); // 通过输入输出流获得通道 inChannel = in.getChannel(); outChannel = out.getChannel(); // 构建缓冲区 ByteBuffer buffer = ByteBuffer.allocate(1024); while (inChannel.read(buffer) != -1) { // 从输入通道中读取内容到缓冲区 buffer.flip(); // 切换成读取数据模式 outChannel.write(buffer); // 写入缓冲区数据到输出通道 buffer.clear(); // 清空缓冲区，用于下一次存储 } } catch (IOException e) { e.printStackTrace(); } finally { outChannel.close(); inChannel.close(); out.close(); in.close(); } } /** * 利用通道和直接缓冲区传输文件（内存映射文件） */ @Test public void test2() throws IOException { /** * open() 方式打开通道 * * StandardOpenOption.READ : 以只读方式创建通道 * StandardOpenOption.CREATE: 若文件存在覆盖，不存在创建。 * StandardOpenOption.CREATE_NEW: 若文件不存在创建，存在报错。 */ FileChannel inChannel = FileChannel.open(Paths.get(\"img/mm.jpg\"), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(\"img/mm2.jpg\"), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE); // 构建内存映射文件（数据在物理内存中的映射，也是直接缓冲区） MappedByteBuffer inMappedBuf = inChannel.map(FileChannel.MapMode.READ_ONLY, 0, inChannel.size()); MappedByteBuffer outMappedBuf = outChannel.map(FileChannel.MapMode.READ_WRITE, 0, inChannel.size()); // 对直接缓冲区进行数据读取 System.out.println(\"byte:\" + inMappedBuf.limit() + \"k\"); byte[] dst = new byte[inMappedBuf.limit()]; inMappedBuf.get(dst); outMappedBuf.put(dst); inChannel.close(); outChannel.close(); } /** * 直接利用通道进行传输，将源通道中的数据传输到目标通道中去。 */ @Test public void test3() throws IOException { FileChannel inChannel = FileChannel.open(Paths.get(\"img/mm.jpg\"), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(\"img/mm2.jpg\"), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE); inChannel.transferTo(0, inChannel.size(), outChannel); // 把输入管道的数据传到输出管道中去// outChannel.transferFrom(inChannel,0,inChannel.size()); // 从输入管道中传输数据到输出管道中来 outChannel.close(); inChannel.close(); }} RandomAccessFile 类在某些应用场景，我们需要在一个数据流中的末尾插入数据，通常的方式是先把文件全部读取出来，再用插入的数据拼接到末尾，然后重新写入。但是当数据量特别大时，内存占用会特别的高甚至溢出。 RandomAccessFile是Java中输入，输出流体系中功能最丰富的文件内容访问类，它提供很多方法来操作文件，包括读写支持，与普通的IO流相比，它最大的特别之处就是支持任意访问的方式，程序可以直接跳到任意地方来读写数据。如果我们只希望访问文件的部分内容，而不是把文件从头读到尾，使用RandomAccessFile将会带来更简洁的代码以及更好的性能。 通过用例练习RandomAccessFile： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class TestRandomAccessFile { /** * 读取任意位置的文件内容 * &lt;p&gt; * r 代表以只读方式打开指定文件 * rw 以读写方式打开指定文件 * rws 读写方式打开，并对内容或元数据都同步写入底层存储设备 * rwd 读写方式打开，对文件内容的更新同步更新至底层存储设备 */ @Test public void randomReadFile() throws IOException { RandomAccessFile read = new RandomAccessFile(\"src/subject_1/TestBuffer.java\", \"r\"); System.out.println(\"文件指针初始位置：\" + read.getFilePointer()); read.seek(1000); // 将指针定位到某个位置 FileChannel readChannel = read.getChannel(); // 从指定位置开始读取，获得通道 ByteBuffer buffer = ByteBuffer.allocate(1024); // 创建缓冲区，可以将容量设为通道大小`(int) readChannel.size()`这样就不用循环读取 // 控制台打印的同时还将数据传输到输出通道 RandomAccessFile write = new RandomAccessFile(\"src/subject_1/TestBuffer.txt\", \"rw\"); FileChannel writeChannel = write.getChannel(); while (readChannel.read(buffer) != -1) { // 不断的将输入通道中的数据读取到缓冲区 buffer.flip(); // 开启读取模式，读取完毕之后 position 到了数据末尾，进行下一次读取。 System.out.println(new String(buffer.array(), 0, buffer.limit())); writeChannel.write(buffer); buffer.clear(); } } /** * 追加数据到文件的指定位置 */ @Test public void randomWriteFile() throws IOException { RandomAccessFile write = new RandomAccessFile(\"src/subject_1/TestBuffer.txt\", \"rw\"); write.seek(write.length()); // 将文件指针移动到末尾 write.write(\"---------&lt; this is append content &gt;--------\".getBytes()); } /** * 在任意处插入数据，如果不将插入点之后的数据备份的话，插入的数据会覆盖插入点之后的数据。 * &lt;p&gt; * - 将插入点之后的数据存入临时文件 * - 将数据插入到插入点 * - 将临时文件中的内容插入到旧文件 */ @Test public void randomReadWriteFile() throws IOException { File tempFile = File.createTempFile(\"src/subject_1/tmp\", \"txt\", null); tempFile.deleteOnExit(); // JVM退出时删除 // 建立临时文件的输入输出通道 FileChannel temInChannel = new FileInputStream(tempFile).getChannel(); FileChannel temOutChannel = new FileOutputStream(tempFile).getChannel(); RandomAccessFile target = new RandomAccessFile(\"src/subject_1/target.txt\", \"rw\"); int seekIndex = 1210; // 插入点 target.seek(seekIndex); FileChannel targetChannel = target.getChannel(); // 将目标文件插入点之后的数据创建通道传输到临时文件中的通道 temOutChannel.transferFrom(targetChannel, 0, targetChannel.size()); // 指针回到插入点，插入数据。 target.seek(seekIndex); target.write(\"[ this is append content ]\\n\".getBytes()); // 复制插入点之后的数据.读取临时文件通道中的数据，将临时文件通道数据传输到目标文件通道。如果能读取到说明数据传输成功 ByteBuffer buffer = ByteBuffer.allocate(2048); while (temInChannel.read(buffer) != -1) { buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.limit())); targetChannel.write(buffer); buffer.clear(); } }} 分散和聚集分散读取（Scattering Reads）是指从 Channel 中读取的数据“分散”到多个 Buffer 中（按照缓冲区的顺序，从 Channel 中读取的数据依次将 Buffer 填满）。 聚集写入（Gathering Writes）是指将多个 Buffer 中的数据“聚集”到 Channel（按照缓冲区的顺序，写入 position 和 limit 之间的数据到 Channel）。 12345678910111213141516171819202122232425public class ScatterAndGather { /** * 分散读取与聚集写入 */ @Test public void test1() throws IOException { RandomAccessFile file = new RandomAccessFile(\"src/subject_1/target.txt\", \"rw\"); FileChannel channel = file.getChannel(); // 分配两个缓冲区 ByteBuffer buf1 = ByteBuffer.allocate(100); ByteBuffer buf2 = ByteBuffer.allocate((int) channel.size() - 100); // 分散读取到缓冲区 ByteBuffer[] buffers = {buf1, buf2}; channel.read(buffers); // 将输入通道的中的数据依次分散读取到不同的缓冲区 for (ByteBuffer buffer : buffers) { buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.limit())); System.out.println(\"-----&lt; 分割 &gt;-----\"); } // 聚集写入到文件 FileChannel bakChannel = new RandomAccessFile(\"src/subject_1/target_bak.txt\", \"rw\").getChannel(); bakChannel.write(buffers); }} 字符集 Charset123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class TestCharset { /** * 查看支持的所有字符集 */ @Test public void test1() { SortedMap&lt;String, Charset&gt; map = Charset.availableCharsets(); Set&lt;Map.Entry&lt;String, Charset&gt;&gt; set = map.entrySet(); Iterator&lt;Map.Entry&lt;String, Charset&gt;&gt; iterator = set.iterator(); while (iterator.hasNext()) { Map.Entry&lt;String, Charset&gt; entry = iterator.next(); System.out.println(entry.getKey() + \" &lt;&gt; \" + entry.getValue()); } System.out.println(\"defaultCharset: \" + Charset.defaultCharset()); } /** * 编码：字符 -&gt; 字节数组 * 解码：字节数组 -&gt; 字符 */ @Test public void test2() throws CharacterCodingException { // 以指定编码加载字符集 Charset gbk = Charset.forName(\"GBK\"); Charset utf8 = Charset.forName(\"UTF-8\"); // 创建编码器 CharsetEncoder gbkEncoder = gbk.newEncoder(); CharsetEncoder utf8Encoder = utf8.newEncoder(); // 创建解码器 CharsetDecoder utf8Decoder = utf8.newDecoder(); CharsetDecoder gbkDecoder = gbk.newDecoder(); // 将数据放到缓冲区 CharBuffer buffer = CharBuffer.allocate(1024); buffer.put(\"测试编码解码\"); // 对字符使用 GBK 编码，切换到读模式，指针从0开始。 buffer.flip(); ByteBuffer byteBuffer = gbkEncoder.encode(buffer); // ByteBuffer byteBuffer = utf8Encoder.encode(buffer); // 使用 UTF8 编码 for (int i = 0; i &lt; byteBuffer.limit(); i++) { System.out.println(byteBuffer.get()); } // 使用 GBK 解码 byteBuffer.flip(); CharBuffer cb = gbkDecoder.decode(byteBuffer); System.out.println(new String(cb.array(), 0, cb.limit())); // 使用 UTF8 解码，失败 byteBuffer.flip(); CharBuffer cb1 = utf8Decoder.decode(byteBuffer); System.out.println(new String(cb1.array(), 0, cb1.limit())); }} NIO 的非阻塞式网络通信 传统的 IO 流都是阻塞式的。也就是说，当一个线程调用 read() 或 write() 时，该线程被阻塞，直到有一些数据被读取或写入，该线程在此期间不能执行其他任务。因此，在完成网络通信进行 IO 操作时，由于线程会阻塞，所以服务器端必须为每个客户端都提供一个独立的线程进行处理，当服务器端需要处理大量客户端时，性能急剧下降。Java NIO 是非阻塞模式的。当线程从某通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务。线程通常将非阻塞 IO 的空闲时间用于在其他通道上执行 IO 操作，所以单独的线程可以管理多个输入和输出通道。因此，NIO 可以让服务器端使用一个或有限几个线程来同时处理连接到服务器端的所有客户端。 通过用例代码验证阻塞式网络通信： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class BlockingNioTest { /** * 客户端：发送数据 */ @Test public void client() throws IOException, InterruptedException { // 打开网络IO通道 SocketChannel socketChannel = SocketChannel.open(new InetSocketAddress(\"localhost\", 1998)); // 读模式打开本地传输文件通道 FileChannel inChannel = FileChannel.open(Paths.get(\"img/mm.jpg\"), StandardOpenOption.READ); // 传输 ByteBuffer buffer = ByteBuffer.allocate(1024); while (inChannel.read(buffer) != -1) { buffer.flip(); socketChannel.write(buffer); buffer.clear(); } /** * 接收服务端反馈信息 * 调用 read()/write() 方法当前线程会进入阻塞状态，如果不强制停止write，不会进行下面的操作。 */ socketChannel.shutdownOutput(); while (socketChannel.read(buffer) != -1) { System.out.println(\"接收服务器反馈中...\"); buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.limit())); buffer.clear(); } inChannel.close(); socketChannel.close(); } /** * 服务器端：接收数据 */ @Test public void server() throws IOException { // 打开网络IO通道 ServerSocketChannel ssChannel = ServerSocketChannel.open(); // 绑定连接，进入阻塞状态 ssChannel.bind(new InetSocketAddress(\"localhost\", 1998)); // 获取客户端的连接通道 System.out.println(\"服务端等待获取客户端连接通道...\"); SocketChannel socketChannel = ssChannel.accept(); System.out.println(\"成功获取到客户端连接通道！\"); // 从客户端连接通道读取数据到本地 FileChannel outChannel = FileChannel.open(Paths.get(\"src/subject_2/mm.jpg\"), StandardOpenOption.WRITE, StandardOpenOption.CREATE); // 传输 ByteBuffer buffer = ByteBuffer.allocate(1024); while (socketChannel.read(buffer) != -1) { buffer.flip(); outChannel.write(buffer); buffer.clear(); } /*发送反馈信息给客户端*/ buffer.put(\"[服务端]：消息接收成功！\".getBytes()); buffer.flip(); socketChannel.write(buffer); outChannel.close(); socketChannel.close(); ssChannel.close(); }} 选择器(Selector)选择器（Selector） 是 SelectableChannle 对象的多路复用器，Selector 可以同时监控多个 SelectableChannel 的 IO 状况，也就是说，利用 Selector 可使一个单独的线程管理多个Channel。Selector 是非阻塞 IO 的核心。 java.nio.channels.Channel 接口： |--SelectableChannel |--SocketChannel |--ServerSocketChannel |--DatagramChannel |--Pipe.SinkChannel |--Pipe.SourceChannel 非阻塞式IO及选择器的用例说明： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class NonBlockingNioTest { @Test public void client() throws IOException { SocketChannel sChannel = SocketChannel.open(new InetSocketAddress(\"localhost\", 1998)); sChannel.configureBlocking(false); //切换非阻塞模式 ByteBuffer buf = ByteBuffer.allocate(1024); buf.put((new Date().toString()).getBytes()); buf.flip(); sChannel.write(buf); buf.clear(); sChannel.close(); } @Test public void server() throws IOException { ServerSocketChannel ssChannel = ServerSocketChannel.open(); ssChannel.configureBlocking(false); // 服务端通道切换非阻塞模式 ssChannel.bind(new InetSocketAddress(1998)); Selector selector = Selector.open(); // 获取选择器 /* * 将服务器通道注册到选择器上, 并且指定“监听接收事件”。 * - 读: SelectionKey.OP_READ * - 写: SelectionKey.OP_WRITE * - 连接: SelectionKey.OP_CONNECT * - 接收: SelectionKey.OP_ACCEPT */ ssChannel.register(selector, SelectionKey.OP_ACCEPT); // 轮询式的获取选择器上已经“准备就绪”的事件 while (selector.select() &gt; 0) { // 获取当前选择器中所有注册的“选择键(已就绪的监听事件)” Iterator&lt;SelectionKey&gt; it = selector.selectedKeys().iterator(); while (it.hasNext()) { SelectionKey sk = it.next(); // 获取准备“就绪”的事件 if (sk.isAcceptable()) { // 若事件是 “接收就绪”，获取客户端连接 SocketChannel sChannel = ssChannel.accept(); sChannel.configureBlocking(false); // 客户端切换非阻塞模式 sChannel.register(selector, SelectionKey.OP_READ); // 将客户端通道注册到选择器上 } else if (sk.isReadable()) { // 获取当前选择器上“读就绪”状态的通道 SocketChannel sChannel = (SocketChannel) sk.channel(); ByteBuffer buf = ByteBuffer.allocate(1024); int len = 0; while ((len = sChannel.read(buf)) &gt; 0) { buf.flip(); System.out.println(new String(buf.array(), 0, len)); buf.clear(); } } it.remove(); // 取消选择键 SelectionKey } } }} SocketChannel、ServerSocketChannel、DatagramChannelJava NIO中的SocketChannel是一个连接到TCP网络套接字的通道。操作步骤： 打开 SocketChannel 读写数据 关闭 SocketChannel Java NIO中的 ServerSocketChannel 是一个可以监听新进来的TCP连接的通道，就像标准IO中的ServerSocket一样。 Java NIO中的DatagramChannel是一个能收发UDP包的通道。操作步骤： 打开 DatagramChannel 接收/发送数据 管道(Pipe)Java NIO 管道是2个线程之间的单向数据连接。Pipe有一个source通道和一个sink通道。数据会被写到sink通道，从source通道读取。 1234567891011121314151617181920public class PipTest { @Test public void test1() throws IOException { Pipe pipe = Pipe.open(); // 获取管道 ByteBuffer buf = ByteBuffer.allocate(1024); // 将缓冲区中的数据写入管道 Pipe.SinkChannel sinkChannel = pipe.sink(); buf.put(\"通过单向管道发送数据\".getBytes()); buf.flip(); sinkChannel.write(buf); Pipe.SourceChannel sourceChannel = pipe.source(); // 读取缓冲区中的数据 buf.flip(); int len = sourceChannel.read(buf); System.out.println(new String(buf.array(), 0, len)); sourceChannel.close(); sinkChannel.close(); }} Java NIO2 (Path、Paths 与 Files )java.nio.file.Path 接口代表一个平台无关的平台路径，描述了目录结构中文件的位置。 Paths 提供的 get() 方法用来获取 Path 对象： Path get(String first, String … more) : 用于将多个字符串串连成路径。 方法 描述 boolean endsWith(String path) 判断是否以 path 路径结束 boolean startsWith(String path) 判断是否以 path 路径开始 boolean isAbsolute() 判断是否是绝对路径 Path getFileName() 返回与调用 Path 对象关联的文件名 Path getName(int idx) 返回的指定索引位置 idx 的路径名称 int getNameCount() 返回Path 根目录后面元素的数量 Path getParent() 返回Path对象包含整个路径，不包含 Path 对象指定的文件路径 Path getRoot() 返回调用 Path 对象的根路径 Path resolve(Path p) 将相对路径解析为绝对路径 Path toAbsolutePath() 作为绝对路径返回调用 Path 对象 String toString() 返回调用 Path 对象的字符串表示形式 java.nio.file.Files 用于操作文件或目录的工具类。 方法 描述 Path copy(Path src, Path dest, CopyOption … how) 文件的复制 Path createDirectory(Path path, FileAttribute&lt;?&gt; … attr) 创建一个目录 Path createFile(Path path, FileAttribute&lt;?&gt; … arr) 创建一个文件 void delete(Path path) 删除一个文件 Path move(Path src, Path dest, CopyOption…how) 将 src 移动到 dest 位置 long size(Path path) 返回 path 指定文件的大小 boolean exists(Path path, LinkOption … opts) 判断文件是否存在 boolean isDirectory(Path path, LinkOption … opts) 判断是否是目录 boolean isExecutable(Path path) 判断是否是可执行文件 boolean isHidden(Path path) 判断是否是隐藏文件 boolean isReadable(Path path) 判断文件是否可读 boolean isWritable(Path path) 判断文件是否可写 boolean notExists(Path path, LinkOption … opts) 判断文件是否不存在 SeekableByteChannel newByteChannel(Path path, OpenOption…how) 获取与指定文件的连接 DirectoryStream newDirectoryStream(Path path) 打开 path 指定的目录 InputStream newInputStream(Path path, OpenOption…how) 获取 InputStream 对象 OutputStream newOutputStream(Path path, OpenOption…how) 获取 OutputStream 对象 自动资源管理 Java 7 增加了一个新特性，该特性提供了另外一种管理资源的方式，这种方式能自动关闭文件。这个特性有时被称为自动资源管理(Automatic Resource Management, ARM)， 该特性以 try 语句的扩展版为基础。自动资源管理主要用于，当不再需要文件（或其他资源）时，可以防止无意中忘记释放它们。 语法： try( 需要关闭的资源声明 ){ //可能发生异常的语句 }catch( 异常类型 变量名 ){ //异常的处理语句 } …… finally{ //一定执行的语句 } 当 try 代码块结束时，自动释放资源。因此不需要显示的调用 close() 方法。该形式也称为“带资源的 try 语句”。注意： try 语句中声明的资源被隐式声明为 final ，资源的作用局限于带资源的 try 语句 可以在一条 try 语句中管理多个资源，每个资源以“;” 隔开即可。 需要关闭的资源，必须实现了 AutoCloseable 接口或其自接口 Closeable 12345678910111213public class TestNIO_2 { //自动资源管理：自动关闭实现 AutoCloseable 接口的资源 @Test public void test(){ try(FileChannel inChannel = FileChannel.open(Paths.get(\"1.jpg\"), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(\"2.jpg\"), StandardOpenOption.WRITE, StandardOpenOption.CREATE)){ ByteBuffer buf = ByteBuffer.allocate(1024); inChannel.read(buf); }catch(IOException e){} }}","link":"/2018/09/07/NIO/"},{"title":"20190603 spring-boot | part2(8~10)","text":"Spring Boot Reference Guide2.1.5.RELEASEhttps://docs.spring.io/spring-boot/docs/2.1.5.RELEASE/reference/htmlsingle/#getting-started Part II. Getting Started 8. Introducing Spring Boot 9. System Requirements 9.1 Servlet Containers 10. Installing Spring Boot 10.1 Installation Instructions for the Java Developer 10.1.1 Maven Installation 10.1.2 Gradle Installation 10.2 Installing the Spring Boot CLI 10.2.1 Manual Installation 10.2.2 Installation with SDKMAN! 10.2.3 OSX Homebrew Installation 10.2.4 MacPorts Installation 10.2.5 Command-line Completion 10.2.6 Windows Scoop Installation 10.2.7 Quick-start Spring CLI Example 10.3 Upgrading from an Earlier Version of Spring Boot 8. \bspring boot 介绍 9. 系统要求 9.1 \bServlet 容器 10. 安装 spring boot 10.1 java 开发者的安装介绍 10.1.1 Maven 安装 10.1.2 继承 Gradle 10.2 安装 Spring Boot CLI（命令行工具） 10.2.1 手动安装 10.2.2 SDKMAN 安装 10.2.3 OSX Homebrew 安装 10.2.4 MacPorts 安装 10.2.5 命令行编译 10.2.6 Windows Scoop 安装 10.2.7 Spring CLI 案例快速开始 10.3 从 SpringBoot 的早期（Earlier）版本升级 If you are getting started with Spring Boot, or “Spring” in general, start by reading this section. It answers the basic “what?”, “how?” and “why?” questions. It includes an introduction to Spring Boot, along with installation instructions. We then walk you through building your first Spring Boot application, discussing some core principles as we go. 8. Introducing Spring BootSpring Boot makes it easy to create stand-alone, production-grade Spring-based Applications that you can run. We take an opinionated view of the Spring platform and third-party libraries, so that you can get started with minimum fuss. Most Spring Boot applications need very little Spring configuration. You can use Spring Boot to create Java applications that can be started by using java -jar or more traditional war deployments. We also provide a command line tool that runs “spring scripts”. Our primary goals are: Provide a radically faster and widely accessible getting-started experience for all Spring development. Be opinionated out of the box but get out of the way quickly as requirements start to diverge from the defaults. Provide a range of non-functional features that are common to large classes of projects (such as embedded servers, security, metrics, health checks, and externalized configuration). Absolutely no code generation and no requirement for XML configuration. 9. System RequirementsSpring Boot 2.1.5.RELEASE requires Java 8 and is compatible up to Java 11 (included). Spring Framework 5.1.7.RELEASE or above is also required. Explicit build support is provided for the following build tools: Build Tool Version Maven 3.3+ Gradle 4.4+ 9.1 Servlet ContainersSpring Boot supports the following embedded servlet containers: Name Servlet Version Tomcat 9.0 4.0 Jetty 9.4 3.1 Undertow 2.0 4.0 You can also deploy Spring Boot applications to any Servlet 3.1+ compatible container. 10. Installing Spring BootSpring Boot can be used with “classic” Java development tools or installed as a command line tool. Either way, you need Java SDK v1.8 or higher. Before you begin, you should check your current Java installation by using the following command: 1$ java -version If you are new to Java development or if you want to experiment with Spring Boot, you might want to try the Spring Boot CLI (Command Line Interface) first. Otherwise, read on for “classic” installation instructions. 10.1 Installation Instructions for the Java DeveloperYou can use Spring Boot in the same way as any standard Java library. To do so, include the appropriate spring-boot-*.jar files on your classpath. Spring Boot does not require any special tools integration, so you can use any IDE or text editor. Also, there is nothing special about a Spring Boot application, so you can run and debug a Spring Boot application as you would any other Java program. Although you could copy Spring Boot jars, we generally recommend that you use a build tool that supports dependency management (such as Maven or Gradle). 10.1.1 Maven InstallationSpring Boot is compatible with Apache Maven 3.3 or above. If you do not already have Maven installed, you can follow the instructions at maven.apache.org. On many operating systems, Maven can be installed with a package manager. If you use OSX Homebrew, try brew install maven. Ubuntu users can run sudo apt-get install maven. Windows users with Chocolatey can run choco install mavenfrom an elevated (administrator) prompt. Spring Boot dependencies use the org.springframework.boot groupId. Typically, your Maven POM file inherits from the spring-boot-starter-parent project and declares dependencies to one or more [“Starters”]. Spring Boot also provides an optional [Maven plugin] to create executable jars. The following listing shows a typical pom.xml file: 1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;myproject&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!-- Inherit defaults from Spring Boot --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;!-- Add typical dependencies for a web application --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- Package as an executable jar --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; The spring-boot-starter-parent is a great way to use Spring Boot, but it might not be suitable all of the time. Sometimes you may need to inherit from a different parent POM, or you might not like our default settings. In those cases, see Section 13.2.2, [“Using Spring Boot without the Parent POM”] for an alternative solution that uses an import scope. 10.1.2 Gradle InstallationSpring Boot is compatible with Gradle 4.4 and later. If you do not already have Gradle installed, you can follow the instructions at gradle.org. Spring Boot dependencies can be declared by using the org.springframework.boot group. Typically, your project declares dependencies to one or more “Starters”. Spring Boot provides a useful Gradle plugin that can be used to simplify dependency declarations and to create executable jars. 123Gradle WrapperThe Gradle Wrapper provides a nice way of “obtaining” Gradle when you need to build a project. It is a small script and library that you commit alongside your code to bootstrap the build process. See docs.gradle.org/4.2.1/userguide/gradle_wrapper.html for details. More details on getting started with Spring Boot and Gradle can be found in the Getting Started section of the Gradle plugin’s reference guide. 10.2 Installing the Spring Boot CLIThe Spring Boot CLI (Command Line Interface) is a command line tool that you can use to quickly prototype with Spring. It lets you run [Groovy] scripts, which means that you have a familiar Java-like syntax without so much boilerplate code. You do not need to use the CLI to work with Spring Boot, but it is definitely the quickest way to get a Spring application off the ground. 10.2.1 Manual InstallationYou can download the Spring CLI distribution from the Spring software repository: spring-boot-cli-2.1.5.RELEASE-bin.zip spring-boot-cli-2.1.5.RELEASE-bin.tar.gz Cutting edge snapshot distributions are also available. Once downloaded, follow the INSTALL.txt instructions from the unpacked archive. In summary, there is a spring script (spring.bat for Windows) in a bin/ directory in the .zip file. Alternatively, you can use java -jar with the .jar file (the script helps you to be sure that the classpath is set correctly). 10.2.2 Installation with SDKMAN!SDKMAN! (The Software Development Kit Manager) can be used for managing multiple versions of various binary SDKs, including Groovy and the Spring Boot CLI. Get SDKMAN! from sdkman.io and install Spring Boot by using the following commands: 123$ sdk install springboot$ spring --versionSpring Boot v2.1.5.RELEASE If you develop features for the CLI and want easy access to the version you built, use the following commands: 1234$ sdk install springboot dev /path/to/spring-boot/spring-boot-cli/target/spring-boot-cli-2.1.5.RELEASE-bin/spring-2.1.5.RELEASE/$ sdk default springboot dev$ spring --versionSpring CLI v2.1.5.RELEASE The preceding instructions install a local instance of spring called the dev instance. It points at your target build location, so every time you rebuild Spring Boot, spring is up-to-date. You can see it by running the following command: 12345678910111213$ sdk ls springboot================================================================================Available Springboot Versions================================================================================&gt; + dev* 2.1.5.RELEASE================================================================================+ - local version* - installed&gt; - currently in use================================================================================ 10.2.3 OSX Homebrew InstallationIf you are on a Mac and use Homebrew, you can install the Spring Boot CLI by using the following commands: 12$ brew tap pivotal/tap$ brew install springboot Homebrew installs spring to /usr/local/bin. If you do not see the formula, your installation of brew might be out-of-date. In that case, run brew update and try again. 10.2.4 MacPorts InstallationIf you are on a Mac and use MacPorts, you can install the Spring Boot CLI by using the following command: 1$ sudo port install spring-boot-cli 10.2.5 Command-line CompletionThe Spring Boot CLI includes scripts that provide command completion for the BASH and zsh shells. You can source the script (also named spring) in any shell or put it in your personal or system-wide bash completion initialization. On a Debian system, the system-wide scripts are in /shell-completion/bash and all scripts in that directory are executed when a new shell starts. For example, to run the script manually if you have installed by using SDKMAN!, use the following commands: 123$ . ~/.sdkman/candidates/springboot/current/shell-completion/bash/spring$ spring &lt;HIT TAB HERE&gt; grab help jar run test version If you install the Spring Boot CLI by using Homebrew or MacPorts, the command-line completion scripts are automatically registered with your shell. 10.2.6 Windows Scoop InstallationIf you are on a Windows and use Scoop, you can install the Spring Boot CLI by using the following commands: 12&gt; scoop bucket add extras&gt; scoop install springboot Scoop installs spring to ~/scoop/apps/springboot/current/bin. If you do not see the app manifest, your installation of scoop might be out-of-date. In that case, run scoop update and try again. 10.2.7 Quick-start Spring CLI ExampleYou can use the following web application to test your installation. To start, create a file called app.groovy, as follows: 123456789@RestControllerclass ThisWillActuallyRun { @RequestMapping(\"/\") String home() { \"Hello World!\" }} Then run it from a shell, as follows: 1$ spring run app.groovy The first run of your application is slow, as dependencies are downloaded. Subsequent runs are much quicker. Open localhost:8080 in your favorite web browser. You should see the following output: 1Hello World! 10.3 Upgrading from an Earlier Version of Spring BootIf you are upgrading from an earlier release of Spring Boot, check the [“migration guide” on the project wiki] that provides detailed upgrade instructions. Check also the [“release notes”] for a list of “new and noteworthy” features for each release. When upgrading to a new feature release, some properties may have been renamed or removed. Spring Boot provides a way to analyze your application’s environment and print diagnostics at startup, but also temporarily migrate properties at runtime for you. To enable that feature, add the following dependency to your project: 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-properties-migrator&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; Properties that are added late to the environment, such as when using @PropertySource, will not be taken into account. Once you’re done with the migration, please make sure to remove this module from your project’s dependencies. To upgrade an existing CLI installation, use the appropriate package manager command (for example, brew upgrade) or, if you manually installed the CLI, follow the [standard instructions], remembering to update your PATH environment variable to remove any older references. 如果您通过 spring boot、通用的 spring 获得快速开始。阅读这个章节，它会回答你\b基于 “是什么？”，“怎么样？”，“为什么？”的问题。它\b包含了 Spring boot 的介绍，以及（along with）安装说明。然后我们（we then）引导你（walk you）通过构建你的第一个 spring \bboot 应用，讨论（discussing）一些核心原则（principles）。 8. \bspring boot 介绍spring boot 使得单体应用创建变得简单。你可以运行生产级别（\bgrage）基于 spring 的应用。我们对Spring平台和第三方库有自己的看法，所以你可以最小化的获得开始。大多数 spring boot 应用只需要\b\b很少的配置。 你可以使用 spring boot 创建 java \b应用，\b那样你可以使用 java -jar 或者 更多传统（traditional）的 war 包部署。我们同样提供命令行工具运行“\bspring 脚本”。 我们主要的目标是： 为所有的 spring 开发提供一种\b更加快速（pradically faster）和广泛访问（widly accessiblw）的快速开始体验。 开箱即用（Be opinionated out of the box），但随着需求（requirements）开始偏离（diverge）默认值而迅速摆脱困境。 提供一些（a range of）非功能性（non-functional）的特性，（这些特性）是大型项目通用的。例如\b嵌入式服务器、安全、测量、健康检查和外部化配置。 确实没有没有代码生成\b和 xml \b配置的要求。 9. 系统要求Spring Boot 2.1.5.RELEASE 需要 java 8，向上兼容（compatible up） java 11（\b包括）。Spring Framework 5.1.7.RELEASE 或\b更高版本同样是必须的。 为\b以下构建工具提供了显式（Explicit）构建支持： Build Tool Version Maven 3.3+ Gradle 4.4+ 9.1 \bServlet 容器spring boot 提供了以下\b嵌入式服务器： Name Servlet Version Tomcat 9.0 4.0 Jetty 9.4 3.1 Undertow 2.0 4.0 你可以同样部署 spring boot 应用到兼容 servlet 3.1+ 的容器。 10. 安装 spring bootspring boot 可以\b使用“经典的”的java部署工具或者安装命令行工具。无论哪种方式（either way），你需要 jdk 1.8 或更高的版本。在开始之前，你需要使用以下命令检查你当前的java安装。 1java -version 如果你是 java \b开发新手，或者你想尝试（experiment） spring boot。你可能首先想要尝试 Spring Boot CLI（命令行接口）。否则，请阅读经典的安装介绍。 10.1 java 开发者的安装介绍你可以像使用任意标准 java 类库同样的方式（in the same way as）一样使用 spring boot。这样做，包含一个合适的 spring-boot-*.jar 的文件在你的类路径下。spring boot 不需要与任何特定工具集成，所以你可以使用任一\b IDE 或文本编辑器。同样，Spring boot 也没有特定的应用。因此，你可以像\b使用其他java程序一样运行或调试 spring boot \b应用。 虽然（although）你可以拷贝 spring boot 的jar\b，我们通常建议（generally recommend）您使用支持依赖管理的构建工具。 10.1.1 Maven 安装Spring Boot \b兼容 Apache Maven 3.3 或更高版本。如果你还没有（not alreay）安装 Maven，你可以按照 maven.apache.org \b操作使用。 在一些操作系统上，maven 可以通过包管理安装。如果你使用 OSX Homebrew，尝试 brew install maven。Ubuntu 用户可以运行 sudo apt-get inst6all maven，巧克力 window 用户可以从管理员提示符运行 choco install maven 。 Spring Boot \b依赖使用 org.springframework.boot 的 groupId，通常（typically），你的 maven pom 文件继承 spring-boot-starter-parent 父项目，向一个\b或多个“启动器”声明\b依赖。Spring Boot 提供可选的 maven 插件创建可执行jar。 以下列表展示了一个典型的 pom.xml 文件： 12345678910111213141516171819202122232425262728293031323334&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;myproject&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!-- 默认继承 spring boot --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;!-- 添加 web 应用的典型依赖项 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 打包为可执行 jar --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; spring-boot-starters-parent 是使用 Spring Boot 的好的方式，但是它不可能\b适合（suitable）所有情况。有的时候你可能需要继承不同的父 pom，或者你\b可能不需要我们的默认设置。在那些情况下（in those cases），查看“13.2.2章，在没有 parent pom 下使用 spring boot，对于使用 import \b域的可代替（alternative）方案。 10.1.2 继承 GradleSpring Boot 兼容 Gradle 4.4 和更高版本，如果你还没有\b安装 Gradle，你可以在 gradle.org 找到使用\b说明。 spring boot 依赖项可以通过使用 org.springframework.boot 这一 group 来申明（declared），通常，你的项目声明\b依赖关系为一个或多个“启动器”。Spring boot 提供可用的 gradle 插件，它可以简化依赖声明和创建可执行jar。 Gradle Wrapper当你需要构建一个项目时 Gradle Wrapper 提供了一种好的方式“获得”Gradle。它是一个小脚本和库，您可以与代码一起（alongside）提交以引导（bootstrap）构建过程。更多详情请查看 https://docs.gradle.org/4.2.1/userguide/gradle_wrapper.html 更多获得 spring boot 和 Gradle 的信息可以在 Gradle 插件的参考指南的 \b“快速开始章节” 找到。 10.2 安装 Spring Boot CLI（命令行工具）Spring Boot 命令行接口是一个命令行工具，你可以\b使用 Spring 快速原型。它允许你\b运行 Groovy 脚本，这意味着你有一个熟悉的类似（familiar）Java的语法没有这么多的样板代码（boilerplate code）。 你不必非要使用 CLI 在 Spring Boot 中，但这绝对（difinitely）是获得 Spring 应用程序的最快方法。 10.2.1 手动安装你可以从spring软件仓库下载 Spring CLI 发行版： spring-boot-cli-2.1.5.RELEASE-bin.zip spring-boot-cli-2.1.5.RELEASE-bin.tar.gz 最新的（cutting edge）快照版本同样可用。 下载完成后，\b按照 INSTALL.txt 引导从解压缩归档。总之，.zip 文件中的 bin/ 目录下有一个 spring 脚本。或者（Alternatively），你可以在 jar 文件中使用 java -jar（脚本帮助您确保正确设置了类路径） 10.2.2 SDKMAN 安装SDKMAN!（一个软件开发工具包管理器）可以用来管理多个各种（various）版本的 SDK，包含 Groovy 和 \bSpring Boot CLI。从 sdkman.io 获得 SDKMAN 并从以下命令安装： 123$ sdk install springboot$ spring --versionSpring Boot v2.1.5.RELEASE 如果你通过 CLI 开发功能，并且想要快速访问你构建的版本，使用以下命令行： 1234$ sdk install springboot dev /path/to/spring-boot/spring-boot-cli/target/spring-boot-cli-2.1.5.RELEASE-bin/spring-2.1.5.RELEASE/$ sdk default springboot dev$ spring --versionSpring CLI v2.1.5.RELEASE 前面的指令（preceding instructions）安装了一个名为（called） dev 的本地 spring 实例。它\b指向了你的构建路径，所以每当你重新构建 Spring Boot，spring 都是最新的。 通过运行以下命令可以看到它：12345678910111213$ sdk ls springboot================================================================================Available Springboot Versions================================================================================&gt; + dev* 2.1.5.RELEASE================================================================================+ - local version* - installed&gt; - currently in use================================================================================ 10.2.3 OSX Homebrew 安装\b如果你在 Mac 上使用 Homebrew，你可以通过以下命令安装 Spring Boot CLI： 12$ brew tap pivotal/tap$ brew install springboot Homebrew 安装 spring 到了 /usr/local/bin. 如果你看不到公式（\bformula），您安装的 brew 可能过时。那样的话（in that case），再次运行 run update。 10.2.4 MacPorts 安装如果你在 mac 上使用 MacPorts，你可以使用以下命令安装 Spring Boot CLI： 1$ sudo port install spring-boot-cli 10.2.5 命令行编译Spring Boot CLI包含为 BASH 和 zsh shell 提供命令完成的脚本。你可以在任何 shell 中获得脚本（也称之为 spring），或者将其放入个人或系统范围的bash完成初始化。在 Debian 系统上，该系统范围内的脚本在 /shell-completion/bash，并且当新shell启动时，该目录中的所有脚本都将被执行。例如：如果你使用 SDKMAN 安装了脚本，可以通过以下命令手动运行该脚本： 123$ . ~/.sdkman/candidates/springboot/current/shell-completion/bash/spring$ spring &lt;HIT TAB HERE&gt; grab help jar run test version 如果你使用 Homebrew 或 MacPorts 安装的 Spring Boot CLI，该命令行编译脚本将自动注册到你的 shell。 10.2.6 Windows Scoop 安装如果你在 Windows 上面使用 Scoop，你可以通过以下命令安装 Spring Boot CLI： 12scoop bucket add extrasscoop install springboot Scoop 安装 spring 到了 ~/scoop/apps/springboot/current/bin. 如果您没有看到应用程序清单（app manifest），你安装的 scoop 可能不是最新版。这样的话，运行 scoop update \b然后重试。 10.2.7 Spring CLI 案例快速开始你可以使用以下 Web 应用测试你的安装，开始，创建一个名为 app.groovy 的文件，如下： 123456789@RestControllerclass ThisWillActuallyRun { @RequestMapping(\"/\") String home() { \"Hello World!\" }} 然后从脚本运行，如下： 1spring run app.groovy 在下载依赖项时首次运行会很慢，随后的运行会很快速。 \b在你喜爱的浏览器上打开 localhost:8080，你可以看到以下输出： 1Hello World! 10.3 从 SpringBoot 的早期（Earlier）版本升级如果你从\b早期的 spring boot 发行版升级，从项目的 wiki 上\b点击 “迁移指南”，它提供了更详细的说明。\b另请查看“发行说明”，了解每个版本的“新的和值得注意的（noteworthy）”功能列表。 当升级到了最新发行版，一些属性可能已经（have been）重命名\b或者删除。Spring Boot 提供一种方式分析的你的应用环境，和\b在启动时\b打印诊断（diagnostics），还可以（but also）在运行时（runtime）临时（temporarily）迁移（migrate）属性。\b要打开这个功能，添加以下依赖到你的项目： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-properties-migrator&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 晚加入到环境之后的属性，例如 @PropertySource，将不会被考虑在内。一旦你完成了迁移，请\b确保从项目中移除该模块。 要更新已存在的 CLI 安装，使用适当的包管理器命令（例如：brew update）或者，如果你手动安装CLI，从请遵守（follow）标准说明，记住更新PATH环境变量以删除任何旧的引用。","link":"/2019/06/03/[20190603] spring-boot | part2(8~10)/"},{"title":"20190608 spring-boot | part2(11~12)","text":"Spring Boot Reference Guide2.1.5.RELEASEhttps://docs.spring.io/spring-boot/docs/2.1.5.RELEASE/reference/htmlsingle/#getting-started-first-application Part II. Getting Started 11. Developing Your First Spring Boot Application 11.1 Creating the POM 11.2 Adding Classpath Dependencies 11.3 Writing the Code 11.3.1 The @RestController and @RequestMapping Annotations 11.3.2 The @EnableAutoConfiguration Annotation 11.3.3 The “main” Method 11.4 Running the Example 11.5 Creating an Executable Jar 12. What to Read Next 11 开发你的第一个 \bSpring Boot 应用 11.1 创建 pom 11.2 添加 ClassPath 依赖项 11.3 编写代码 11.3.1 @RestController 和 @RequestMapping 注解 11.3.2 @EnableAutoConfiguration 注解 11.3.3 main 方法 11.4 运行案例 11.5 创建可执行 jar 接下来要阅读的内容 11. Developing Your First Spring Boot ApplicationThis section describes how to develop a simple “Hello World!” web application that highlights some of Spring Boot’s key features. We use Maven to build this project, since most IDEs support it. The spring.io web site contains many “Getting Started” [guides] that use Spring Boot. If you need to solve a specific problem, check there first.\\You can shortcut the steps below by going to start.spring.io and choosing the “Web” starter from the dependencies searcher. Doing so generates a new project structure so that you can start coding right away. Check the Spring Initializr documentation for more details. Before we begin, open a terminal and run the following commands to ensure that you have valid versions of Java and Maven installed: 1234$ java -versionjava version \"1.8.0_102\"Java(TM) SE Runtime Environment (build 1.8.0_102-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.102-b14, mixed mode) 1234$ mvn -vApache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T14:33:14-04:00)Maven home: /usr/local/Cellar/maven/3.3.9/libexecJava version: 1.8.0_102, vendor: Oracle Corporation This sample needs to be created in its own folder. Subsequent instructions assume that you have created a suitable folder and that it is your current directory. 11.1 Creating the POMWe need to start by creating a Maven pom.xml file. The pom.xml is the recipe that is used to build your project. Open your favorite text editor and add the following: 123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;myproject&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;!-- Additional lines to be added here... --&gt;&lt;/project&gt; The preceding listing should give you a working build. You can test it by running mvn package (for now, you can ignore the “jar will be empty - no content was marked for inclusion!” warning). At this point, you could import the project into an IDE (most modern Java IDEs include built-in support for Maven). For simplicity, we continue to use a plain text editor for this example. 11.2 Adding Classpath DependenciesSpring Boot provides a number of “Starters” that let you add jars to your classpath. Our sample application has already used spring-boot-starter-parent in the parent section of the POM. The spring-boot-starter-parent is a special starter that provides useful Maven defaults. It also provides a [dependency-management] section so that you can omit version tags for “blessed” dependencies. Other “Starters” provide dependencies that you are likely to need when developing a specific type of application. Since we are developing a web application, we add a spring-boot-starter-web dependency. Before that, we can look at what we currently have by running the following command: 123$ mvn dependency:tree[INFO] com.example:myproject:jar:0.0.1-SNAPSHOT The mvn dependency:tree command prints a tree representation of your project dependencies. You can see that spring-boot-starter-parent provides no dependencies by itself. To add the necessary dependencies, edit your pom.xml and add the spring-boot-starter-web dependency immediately below the parent section: 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; If you run mvn dependency:tree again, you see that there are now a number of additional dependencies, including the Tomcat web server and Spring Boot itself. 11.3 Writing the CodeTo finish our application, we need to create a single Java file. By default, Maven compiles sources from src/main/java, so you need to create that folder structure and then add a file named src/main/java/Example.java to contain the following code: 123456789101112131415161718import org.springframework.boot.*;import org.springframework.boot.autoconfigure.*;import org.springframework.web.bind.annotation.*;@RestController@EnableAutoConfigurationpublic class Example { @RequestMapping(\"/\") String home() { return \"Hello World!\"; } public static void main(String[] args) { SpringApplication.run(Example.class, args); }} Although there is not much code here, quite a lot is going on. We step through the important parts in the next few sections. 11.3.1 The @RestController and @RequestMapping AnnotationsThe first annotation on our Example class is @RestController. This is known as a stereotype annotation. It provides hints for people reading the code and for Spring that the class plays a specific role. In this case, our class is a web @Controller, so Spring considers it when handling incoming web requests. The @RequestMapping annotation provides “routing” information. It tells Spring that any HTTP request with the / path should be mapped to the home method. The @RestController annotation tells Spring to render the resulting string directly back to the caller. The @RestController and @RequestMapping annotations are Spring MVC annotations. (They are not specific to Spring Boot.) See the MVC section in the Spring Reference Documentation for more details. 11.3.2 The @EnableAutoConfiguration AnnotationThe second class-level annotation is @EnableAutoConfiguration. This annotation tells Spring Boot to “guess” how you want to configure Spring, based on the jar dependencies that you have added. Since spring-boot-starter-web added Tomcat and Spring MVC, the auto-configuration assumes that you are developing a web application and sets up Spring accordingly. Starters and Auto-configuration\\Auto-configuration is designed to work well with “Starters”, but the two concepts are not directly tied. You are free to pick and choose jar dependencies outside of the starters. Spring Boot still does its best to auto-configure your application. 11.3.3 The “main” MethodThe final part of our application is the main method. This is just a standard method that follows the Java convention for an application entry point. Our main method delegates to Spring Boot’s SpringApplication class by calling run. SpringApplication bootstraps our application, starting Spring, which, in turn, starts the auto-configured Tomcat web server. We need to pass Example.class as an argument to the run method to tell SpringApplication which is the primary Spring component. The args array is also passed through to expose any command-line arguments. 11.4 Running the ExampleAt this point, your application should work. Since you used the spring-boot-starter-parent POM, you have a useful run goal that you can use to start the application. Type mvn spring-boot:run from the root project directory to start the application. You should see output similar to the following: 12345678910111213$ mvn spring-boot:run . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.1.5.RELEASE)....... . . ........ . . . (log output here)....... . . ......... Started Example in 2.222 seconds (JVM running for 6.514) If you open a web browser to localhost:8080, you should see the following output: 1Hello World! To gracefully exit the application, press ctrl-c. 11.5 Creating an Executable JarWe finish our example by creating a completely self-contained executable jar file that we could run in production. Executable jars (sometimes called “fat jars”) are archives containing your compiled classes along with all of the jar dependencies that your code needs to run. Executable jars and Java\\Java does not provide a standard way to load nested jar files (jar files that are themselves contained within a jar). This can be problematic if you are looking to distribute a self-contained application.\\To solve this problem, many developers use “uber” jars. An uber jar packages all the classes from all the application’s dependencies into a single archive. The problem with this approach is that it becomes hard to see which libraries are in your application. It can also be problematic if the same filename is used (but with different content) in multiple jars.\\Spring Boot takes a different approach and lets you actually nest jars directly. To create an executable jar, we need to add the spring-boot-maven-plugin to our pom.xml. To do so, insert the following lines just below the dependencies section: 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; The spring-boot-starter-parent POM includes &lt;executions&gt; configuration to bind the repackage goal. If you do not use the parent POM, you need to declare this configuration yourself. See the [plugin documentation] for details. Save your pom.xml and run mvn package from the command line, as follows: 123456789101112131415$ mvn package[INFO] Scanning for projects...[INFO][INFO] ------------------------------------------------------------------------[INFO] Building myproject 0.0.1-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO] .... ..[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ myproject ---[INFO] Building jar: /Users/developer/example/spring-boot-example/target/myproject-0.0.1-SNAPSHOT.jar[INFO][INFO] --- spring-boot-maven-plugin:2.1.5.RELEASE:repackage (default) @ myproject ---[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------ If you look in the target directory, you should see myproject-0.0.1-SNAPSHOT.jar. The file should be around 10 MB in size. If you want to peek inside, you can use jar tvf, as follows: 1$ jar tvf target/myproject-0.0.1-SNAPSHOT.jar You should also see a much smaller file named myproject-0.0.1-SNAPSHOT.jar.original in the target directory. This is the original jar file that Maven created before it was repackaged by Spring Boot. To run that application, use the java -jar command, as follows: 12345678910111213$ java -jar target/myproject-0.0.1-SNAPSHOT.jar . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.1.5.RELEASE)....... . . ........ . . . (log output here)....... . . ......... Started Example in 2.536 seconds (JVM running for 2.864) As before, to exit the application, press ctrl-c. 12. What to Read NextHopefully, this section provided some of the Spring Boot basics and got you on your way to writing your own applications. If you are a task-oriented type of developer, you might want to jump over to [spring.io] and check out some of the [getting started] guides that solve specific “How do I do that with Spring?” problems. We also have Spring Boot-specific “How-to” reference documentation. The [Spring Boot repository] also has a [bunch of samples] you can run. The samples are independent of the rest of the code (that is, you do not need to build the rest to run or use the samples). Otherwise, the next logical step is to read [Part III, “Using Spring Boot”]. If you are really impatient, you could also jump ahead and read about [Spring Boot features.] 11 开发你的第一个 \bSpring Boot 应用这一章节描述了如何开发一个简单的“hello world！”web应用，以重点介绍Spring Boot的一些主要功能。我们使用 Maven 构建这个项目，因为（since）大多数 IDE 都支持它。 这个 \bspring.io 站点包含了一些使用 Spring Boot 的“快速开始”指南。如果你要解决（solve）一个具体（specific）的问题，首先点击这里。您可以通过转到start.spring.io并从依赖关系搜索器中选择“Web”启动器来快捷执行（shortcut the steps）以下步骤。这样做会生成一个新的项目结构，以便（so that）您可以立即（right away）开始编码。点击 Spring \bInitializr 文档查看更多细节。 在开始之前，打开终端运行以下命令确保你安装的 Java 和 Maven 是有效的版本： 1234$ java -versionjava version \"1.8.0_102\"Java(TM) SE Runtime Environment (build 1.8.0_102-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.102-b14, mixed mode) 1234$ mvn -vApache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T14:33:14-04:00)Maven home: /usr/local/Cellar/maven/3.3.9/libexecJava version: 1.8.0_102, vendor: Oracle Corporation 这个案例需要在自己的\b目录中创建。随后（subsequent）的\b指南假定（assume）你已经创建了合适（suitable）的目录并且是你的当前\b文件夹。 11.1 创建 pom我们需要从创建 Maven 的 pom.xml 文件开始，这个 pom.xml 是用于（use to）构建你的项目的配方（recipe）。打开你喜欢的文本编辑器添加\b以下： 123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;myproject&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;!-- 这里还会额外添加其他行... --&gt;&lt;/project&gt; 前面的\b列表应该可以给你有效（a working）的构建。你可以通过 mvn package 测试它（现在，你可以\b忽略“jar will be empty - no content was marked for inclusion!”警告） 在此时（At this point），你可以导入这个项目到你的 IDE（大多数现代Java IDE都包含对Maven的内置支持）。为了简单（simplicy）起见，我们继续为此示例使用纯文本编辑器。 11.2 添加 ClassPath 依赖项Spring Boot 添加了许多（a number of）“启动器” 允许你添加 jars 到\b你的类路径下。我们的示例应用程序已经在POM的父节中使用了spring-boot-starter-parent。spring-boot-starters-parent 是一个特殊的启动器，它提供了可用的 maven 默认配置。它同样提供一个 dependency-management 节点\b以便（so that）你可以省略（omit）version “blessed”依赖项的版本标签。 其他\b“启动器”提供了你在开发\b特定类型应用时或许（likely）需要的依赖项。当（since）我们正在开发Web应用程序，我们添加 spring-boot-starter-web 依赖。在此之前，我们可以通过运行以下命令来查看（look at）当前的内容： 123$ mvn dependency:tree[INFO] com.example:myproject:jar:0.0.1-SNAPSHOT 该 mvn dependency:tree 命令打印\b输来表示（representation）你项目依赖。您可以看到 spring-boot-starter-parent 本身（itself）不提供依赖关系。要添加必要（\bnecessary）的依赖，编辑你的 pom.xml， 添加 spring-boot-starters-web 依赖紧接（immediately）与 parent \b节点之下（below）。 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 如果你再次运行 mvn dependency:tree，你会看到这里有\b多个额外的依赖项，包含来 Tomcat Web 服务器和 Spring Boot 本身。 11.3 编写代码为了完成我们的项目，我们需要创建一个单个java文件。默认情况下（\bby \bdefault），maven 编译的资源来源自 src/main/java，所以你需要创建这个\b目录结构然后添加名字为 src/main/java/Example.java 文件，包含以下代码： 123456789101112131415161718import org.springframework.boot.*;import org.springframework.boot.autoconfigure.*;import org.springframework.web.bind.annotation.*;@RestController@EnableAutoConfigurationpublic class Example { @RequestMapping(\"/\") String home() { return \"Hello World!\"; } public static void main(String[] args) { SpringApplication.run(Example.class, args); }} 虽然（Although）这里的代码并不多，但是\b很多（quite a lot）事情在发生（is going on）。我们将在接下来的（next few）几节中逐步介绍重要部分（important part）。 11.3.1 @RestController 和 @RequestMapping 注解在我们的 Example \b类上第一注解是 @RestController，这被称为（known as）构造型注解。它为阅读代码的人提供了提示（hints），而为Spring提供了特定角色的提示。在这个\b用例，我们的\b类是一个web @Controller，所以Spring在处理传入的Web请求时会考虑（considers）它。 这个 @RequestMapping 注解提供了 “路由” 信息，它告诉 Spring 任何的 / 路径的 Http 请求都将映射到 home 方法。该 @RestController 注解告诉 Spring 将结果字符串直接（directly）渲染回调用者。 @RequestMapping 和 @RestController 注解是 \bSpring MVC 注解。（他们不是 Spring Boot 特有的），更多详情\b请查看 Spring 参考文档的 MVC 章节 11.3.2 @EnableAutoConfiguration 注解第二个类级别的注解是 @EnableAutoConfiguration，该注解告诉 Spring Boot “猜测”你想如何配置 Spring，这都基于您添加的jar依赖项。由于 spring-boot-startes-web 添加了 Tomcat 和 Spring MVC，这个\b自动配置\b假定（assumes）你正在开发web应用，于是（accordingly）相应的设置好\bSpring。 启动器和自动配置自动配置被设计为让启动器更好的工作，但是这两个概念（concept）并没有联合在一起（directly tied）。你可以挑选（pick）和选择（\bchoose）启动器之外的 jar 依赖。Spring Boot \u001d仍然尽力最好的自动配置你的应用。 11.3.3 main 方法最后一个单元是我们应用的 main 方法，这是一个遵循 java \b惯例（convertion）的标准方法，是\b应用的入口点（entry point）。我们的主方法通过调用 run 来委托（delegates 代表、委托）spring boot 的 SpringApplication， SpringApplication \b引导我们的应用启动 S\bpring，自动配置 Tomcat web 服务器。我们需要传递（pass） Example.class 作为（as an）一个参数给 run 方法，以便告诉 SpringApplication 这是主要的Spring组件。该 args 参数数组同样被传递到暴露的任何命令行参数中。 11.4 运行案例在此时，你的应用可以\b工作。当你使用 spring-boot-starter-parent POM 文件时，你有一个可用的 run 目标 （goals），可用于启动应用。从\b项目根目录输入 mvn spring-boot:run 以启动该\b应用。你可以\b看到类似以下的输出： 1234567$ mvn spring-boot:run :: Spring Boot :: (v2.1.5.RELEASE)....... . . ........ . . . (log output here)....... . . ......... Started Example in 2.222 seconds (JVM running for 6.514) 如果你在浏览器打开 localhost:8080，你可以看到以下输出： 1Hello World! 要优雅的（gracefully）退出该应用，按下 ctrl - c 11.5 创建可执行 jar通过创建一个完全独立的可执行 jar 文件完成我们的案例，他们可以在生产环境下运行。可执行 jar 是一个包含你的\b所有编译后的类文件和所有代码运行所需要的 jar 依赖的归档。 可执行 jar 和 javajava 没有提供\b标准的方式去加载嵌套的 jar 文件（java 文件本身(themsevles)在 jar 里面(within)）。如果你要分发自包含的\b应用，将会造成一些问题（problematic）。\\要解决（solve）这个问题，大多数开发者使用“uber” jar。一个 uber jar 从所有应用的\b依赖项中的所有字节码文件打包到一个单独的归档中。这种方法（approach）的问题在于：查看哪一个类库在你的应用中变得困难（become hard）。如果在多个 jars 中使用相同的文件名（但是内容不同）同样也会造成问题。\\Spring Boot 用不同\b的方法，让你直接嵌套 jars \b\b要创建一个可执行 jar，我们需要添加 spring-boot-maven-plugin 到你的 pom.xml。这样做，插入以下行紧接着 denpendency 节点： 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 该 spring-boot-maven-plugin POM 包含了 &lt;excutions&gt; 配置绑定到 repackage 目标。如果你不使用父 POM，你需要定义你自己的这个配置项。查看 插件文档 获得更多详情。 保存你的 pom.xml 并从命令行运行 mvn package，如下： 123456789101112131415$ mvn package[INFO] Scanning for projects...[INFO][INFO] ------------------------------------------------------------------------[INFO] Building myproject 0.0.1-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO] .... ..[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ myproject ---[INFO] Building jar: /Users/developer/example/spring-boot-example/target/myproject-0.0.1-SNAPSHOT.jar[INFO][INFO] --- spring-boot-maven-plugin:2.1.5.RELEASE:repackage (default) @ myproject ---[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------ 如果你查看 target 目录，你会看到 myproject-0.0.1-SNAPSHOT.jar。该文件大小应该为 10M。如果你想要偷看里面（peek inside），你可以使用 jar tvf，如下： 1jar tvf target/myproject-0.0.1-SNAPSHOT.jar 你同样会在 target 目录下看到大量类似名字为 myproject-0.0.1-SNAPSHOT.jar.original 的文件。这是Maven在Spring Boot重新打包之前创建的原始jar文件。 要运行该应用，使用 java -jar 命令，如下： 1$ java -jar target/myproject-0.0.1-SNAPSHOT.jar 像上次一样，退出应用请按 ctrl - c。 接下来要阅读的内容希望，这个章节提供了一些 Spring Boot 的基础知识能让你开始\b编写自己的应用。如果您是面向任务的开发人员，你可能想要跳到（jump over） spring.io，查看（check out）一些入门指南，解决具体的“如何使用Spring？”问题。 我们同样有 Spring Boot具体的“如何使用”参考文档。 这个 spring boot 存储库同样有一堆（a bunch of）你可以运行的样本。这些样本独立\b于（independent of）其余（rest of）的\b代码。（你不需要构建其余的来运行或使用样本） 总之，下一个合乎逻辑的步骤（logical step）是阅读第III部分“使用Spring Boot”。如果你真的很不耐烦，你也可以跳过去阅读 Spring Boot功能。","link":"/2019/06/08/[20190608] spring-boot | part2(11~12)/"},{"title":"20190609 spring-boot | part3(13~16)","text":"Spring Boot Reference Guide2.1.5.RELEASEhttps://docs.spring.io/spring-boot/docs/2.1.5.RELEASE/reference/htmlsingle/#using-boot Part III. Using Spring Boot 13. 构建系统 13.1 依赖项管理 13.2 Maven 13.2.1 继承 Starter Parent 13.2.2 没有 Parent Pom 使用 Spring Boot 13.2.3 使用 Spring Boot Maven 插件 13.3 Gradle 13.4 Ant 13.5 启动器 14. 代码结构 14.1 使用“默认的”包 14.2 定位（Location）主应用类 15. 配置类 15.1 导入额外的配置类 15.2 \b导入 XML 配置 16. 自动配置 16.1 逐步（gradually）更换（replacing）自动配置 16.2 禁用特定的自动配置类 这个章节将详细介绍更多细节关于你如何使用Spring Boot。它涵盖了一些主题（covers topics），例如构建系统、自动配置、和如何运行你的应用。我们同样涵盖了一些 Spring Boot 最佳实战。虽然Spring Boot没有什么特别之处（它只是你可以使用的另一个类库而已。）这里\b有一些建议，如果遵循（when allowed），将会使你的应用开发进度相对容易\b一些（easier）。 如果你是从 Spring Boot 开始的（starting out），\b你可能（probably）需要阅读“快速开始”指南，在进入（diving into）这个章节之前。 13. 构建系统这里强烈建议你选择一个支持 依赖项管理 和可以使用 artifacts 发布到 Maven \b中央仓库的构建系统。我们将建议您使用 Maven 或 Gradle。有可能使（it is possible to）S\bpring Boot 与其他构建工具一起工作，但是他们并没有得到专门的支持。 13.1 依赖项管理每一个 Spring Boot 的\b发行版都对依赖项管理列表提供支持，在实践当中（in \bpractice），你不需要在你的构建配置中添加这些依赖的任何一个 version 节点，spring boot \b帮您管理。当你升级 spring boot 本身，这些依赖以同样的（consistent way）方式升级。 如果你需要这样做你可以一直指定（specify） version 节点以覆盖 spring boot 的建议。 该列表包含了所有你使用的 Spring Boot 的所有\b模块以及（as well as）精确（refind）的第三方类库列表。该列表可作为标准的物料清单(spring-boot-dependencies)提供，可与Maven和Gradle一起使用。 每一个 spring boot 的发行版版本与 Spring 框架的基本版本相关联。我们强烈建议你不要定制自己的版本号。 13.2 MavenMaven 用户可以继承自 spring-boot-starters-parent 项目获得（obain）合理（sensible）的默认值。该父项目提供以下功能： java8 作为默认\b的编辑级别 UTF-8 资源编码 一个依赖管理节点，继承自 spring-boot-dependencies pom文件，用来管理公共依赖项的 version。该依赖项管理允许你忽略（omit）version 标签为了依赖项当你在你自己的 pom 文件中。 使用 repackage 的执行 id 执行 repackge 目标 合理（sensible）\b的资源过滤 合理的插件配置（exec plugin、git commit ID 和 shade） 用于 application.xml 和 application.Properties 的合理过滤，包含特殊的配置文件（如：applicatino-dev.properties 和 application-dev.yml） 请注意（note that），从 application.properties 和 application.yml 文件支持 Spring 风格的占位符(${...})，Maven 过滤\b改变为使用@...@占位符。（你可以设置 maven 属性名为 resource.dilimiter 充血该属性） 13.2.1 继承 Starter Parent继承你的项目自 spring-boot-starter-parent，设置 parent 节点如下： 123456&lt;!-- Inherit defaults from Spring Boot --&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt;&lt;/parent&gt; 你只需要在这个依赖项中指定 Spring Boot 的特定版本号，如果你导入\b额外的启动器，你可以安全\b地（savely）省略该版本号。 通过该配置（with setup），你可以在你项目中通过覆盖\b属性来覆盖\b单个依赖项（individual dependencies ）。例如，升级另外的 Spring Data 发行版，你可以添加以下到你的 pom.xml: 123&lt;properties&gt; &lt;spring-data-releasetrain.version&gt;Fowler-SR2&lt;/spring-data-releasetrain.version&gt;&lt;/properties&gt; 点击这个 spring-boot-dependencies pom 插件支持的\b属性列表 13.2.2 没有 Parent Pom 使用 Spring Boot不是每个人都喜欢继承自 spring-boot-starters-parent pom，你可能有你自己的企业的（corporate）标准 parent 要使用，或者你想明确的（exlictily）定义所有你的 maven 配置。 如果你不想要使用 spring-boot-starters-parent，你可以通过使用一个 scope=import 依赖一直保持依赖管理器的好处(benefit)（但不是插件管理），如下： 123456789101112&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!-- Import dependency management from Spring Boot --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 上面的（preveding）示例设置不允许通过使用属性覆盖各个依赖项，如上所述（as explained above）。要达到（achieve）同样的效果，你需要在你的项目中，spring-boot-dependencies 之前，\b\b添加一个条目到 dependencyManagement。例如：要更新其他的 Spring data 发行版，你需要添加以下元素到你的 pom.xml: 1234567891011121314151617181920&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- Override Spring Data release train provided by Spring Boot --&gt; &lt;!-- 在 spring-boot-dependencies 之前指定\b这个 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-releasetrain&lt;/artifactId&gt; &lt;version&gt;Fowler-SR2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 如上面例子\b，我们\b指定一个 POM，但是但是\b任何的依赖项类型以相同的\b方式覆盖。 13.2.3 使用 Spring Boot Maven 插件Spring Boot 包含一个 Maven 插件，\b可以打包项目作为一个可执行 jar。如果\b你想使用它添加\b以下插件到你的 &lt;plugins&gt; 节点，如以下示例所示： 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 如果你使用 Spring Boot 父启动器 pom，你只需要添加插件。这里不需要配置除非你想要改变在 \bparent 中的设置定义。 13.3 Gradle要学习使用 Spring Boot 的 \bGradle，请参考（refer）Spring Boot 的 Gradle 插件文档： 参考（HTML 和 PDF） API 13.4 Ant可以使用 ApacheAnt + Ivy 构建 SpringBoot 项目。这个 spring-boot-antlib，“ant-lib”模块同样可用于（available to）帮助 Ant 创建可执行jar。 要定义这个依赖项，一个典型的（a typical）的 ivy.xml 文件\b看起来像下面的例子： 1234567891011&lt;ivy-module version=\"2.0\"&gt; &lt;info organisation=\"org.springframework.boot\" module=\"spring-boot-sample-ant\" /&gt; &lt;configurations&gt; &lt;conf name=\"compile\" description=\"everything needed to compile this module\" /&gt; &lt;conf name=\"runtime\" extends=\"compile\" description=\"everything needed to run this module\" /&gt; &lt;/configurations&gt; &lt;dependencies&gt; &lt;dependency org=\"org.springframework.boot\" name=\"spring-boot-starter\" rev=\"${spring-boot.version}\" conf=\"compile\" /&gt; &lt;/dependencies&gt;&lt;/ivy-module&gt; 一个典型的 build.xml 文件看起来像下面的实例： 123456789101112131415161718192021222324252627282930313233&lt;project xmlns:ivy=\"antlib:org.apache.ivy.ant\" xmlns:spring-boot=\"antlib:org.springframework.boot.ant\" name=\"myapp\" default=\"build\"&gt; &lt;property name=\"spring-boot.version\" value=\"2.1.5.RELEASE\" /&gt; &lt;target name=\"resolve\" description=\"--&gt; retrieve dependencies with ivy\"&gt; &lt;ivy:retrieve pattern=\"lib/[conf]/[artifact]-[type]-[revision].[ext]\" /&gt; &lt;/target&gt; &lt;target name=\"classpaths\" depends=\"resolve\"&gt; &lt;path id=\"compile.classpath\"&gt; &lt;fileset dir=\"lib/compile\" includes=\"*.jar\" /&gt; &lt;/path&gt; &lt;/target&gt; &lt;target name=\"init\" depends=\"classpaths\"&gt; &lt;mkdir dir=\"build/classes\" /&gt; &lt;/target&gt; &lt;target name=\"compile\" depends=\"init\" description=\"compile\"&gt; &lt;javac srcdir=\"src/main/java\" destdir=\"build/classes\" classpathref=\"compile.classpath\" /&gt; &lt;/target&gt; &lt;target name=\"build\" depends=\"compile\"&gt; &lt;spring-boot:exejar destfile=\"build/myapp.jar\" classes=\"build/classes\"&gt; &lt;spring-boot:lib&gt; &lt;fileset dir=\"lib/runtime\" /&gt; &lt;/spring-boot:lib&gt; &lt;/spring-boot:exejar&gt; &lt;/target&gt;&lt;/project&gt; 如果你不想使用 spring-boot-antlib 模块，查看章节 91.9：不使用 spring-boot-ant 从 Ant 构建可执行归档。 13.5 启动器启动器是一组（set of）方便的（convenient）\b依赖描述符（descriptors），可以包含在你的应用中。你获得所有 Spring 和与之关联的技术的一站式（one-stop）服务，你不需要（need without）寻找（hunt throught）相似代码和复制粘贴大量的依赖描述符。如：\b如果你想开始获得 Spring 和 JPA 访问数据库，包含 spring-data-jpa依赖到你的项目中。 该启动器包含了大量的依赖项，你需要这些才可以方便的获得项目一致性和快速运行。支持管理传递（transitive）依赖。 名字里有什么？所有官方的启动器遵循相似的命令规范；spring-boot-starters-*，其中 * 是特定（particular）类型的\b应用。这个命名结构是为了（intented to）帮助你寻找启动器。Maven 集成了许多 IDE \b允许你通过名字查找依赖项。例如：安装了适当的 Eclipse 或 STS 插件，你可以在 Pom 编辑器按下 ctrl + space 并输入 spring-boot-starter 一个完整\b\b清单。\b\\如 “创建你自己的启动器” \b章节解释（explained）的一样，第三方启动器不需要以 spring-boot 开头，\b因为它是为官方的 Spring \bBoot \b\b\b制品保留的。相反（Rather），一个第三方启动器\b典型\u001b的以项目名字开始，如：一个第三方应用叫做 thirdpartyproject 将\b会\b命名为 thirdpartyproject-spring-boot-starter 以下应用程序由 Spring\b Boot 在 org.springframework.boot 组下提供： Name Description Pom spring-boot-starter 核型启动器，包含自动配置支持，日志和 YAML Pom spring-boot-starter-activemq 使用 Apache ActiveMQ 的 JMS 消息启动器 Pom spring-boot-starter-amqp Starter for using Spring AMQP and Rabbit MQ Pom spring-boot-starter-aop 使用 Spring AOP 和 AspectJ 面向（oriented）切面编程的启动器 Pom spring-boot-starter-artemis 使用 Apache Artemis 的 JMS 消息启动器 Pom spring-boot-starter-batch Starter for using Spring Batch Pom spring-boot-starter-cache Starter for using Spring Framework’s caching support Pom spring-boot-starter-cloud-connectors 使用SpringCloud连接器，简化了与云平台中服务，如 Cloud Foundry and Heroku Pom spring-boot-starter-data-cassandra 使用 Cassandra 分布式数据库和 Spring Data Cassandra Pom spring-boot-starter-data-cassandra-reactive 使用 Cassandra 分布式数据库和 Spring Data Cassandra 反应 Pom spring-boot-starter-data-couchbase 使用 Couchbase 面向文档数据库和 Spring Data Couchbase Pom spring-boot-starter-data-couchbase-reactive 使用 Couchbase 面向文档数据库和 Spring Data Couchbase 反应 Pom spring-boot-starter-data-elasticsearch 使用 Elasticsearch 搜索和分词引擎 和 Spring Data Elasticsearch Pom spring-boot-starter-data-jdbc Starter for using Spring Data JDBC Pom spring-boot-starter-data-jpa Starter for using Spring Data JPA with Hibernate Pom spring-boot-starter-data-ldap Starter for using Spring Data LDAP Pom spring-boot-starter-data-mongodb 使用 MongoDB 面向文档数据库 和 Spring Data MongoDB Pom spring-boot-starter-data-mongodb-reactive 使用 MongoDB 面向文档数据库 和 Spring Data MongoDB 反应 Pom spring-boot-starter-data-neo4j 使用 Neo4j 图数据库 和 Spring Data Neo4j Pom spring-boot-starter-data-redis 使用 Redis 键值存储和 Spring Data Redis and the Lettuce client Pom spring-boot-starter-data-redis-reactive 使用 Redis 键值存储和 Spring Data Redis and the Lettuce client Pom spring-boot-starter-data-rest 使用 Spring Data REST 曝光 Spring Data 存储库为 rest Pom spring-boot-starter-data-solr 使用 Spring Data Solr 的 Apache Solr 搜索平台 Pom spring-boot-starter-freemarker 使用 FreeMarker 视图构建 MVC Web 应用 Pom spring-boot-starter-groovy-templates 使用 Groovy 模版构建 MVC Web 应用 Pom spring-boot-starter-hateoas 使用 Spring MVC 和 Spring HATEOAS 构建基于超媒体的 RestFul web 应用 Pom spring-boot-starter-integration 使用 Spring 整合 Pom spring-boot-starter-jdbc 使用 HikariCP 连接池的JDBC Pom spring-boot-starter-jersey 使用 JAX-RS 和 Jersey 构建 restfull web 应用. 另一种选择（An alternative to）是 spring-boot-starter-web Pom spring-boot-starter-jooq 使用 jOOQ 访问 SQL 数据库. 另一种选择是 spring-boot-starter-data-jpa 或 spring-boot-starter-jdbc Pom spring-boot-starter-json 读写 json Pom spring-boot-starter-jta-atomikos 使用 Atomikos 的 JTA 事务 Pom spring-boot-starter-jta-bitronix 使用 Bitronix 的 JTA 事务 Pom spring-boot-starter-mail 使用 Java Mail 和 Spring Framework’s 邮件发送支持 Pom spring-boot-starter-mustache 使用 Mustache views 构建 web 应用 Pom spring-boot-starter-oauth2-client 使用 Spring Security’s OAuth2/OpenID 连接客户端特性 Pom spring-boot-starter-oauth2-resource-server 使用 Spring Security’s OAuth2 资源服务器特性 Pom spring-boot-starter-quartz 使用 Quartz 任务调度 Pom spring-boot-starter-security 使用 Spring Security Pom spring-boot-starter-test 用库或者 Junit Hamcrest 和 Mockito 测试 Spring Boot 应用 Pom spring-boot-starter-thymeleaf 使用 Thymeleaf views 构建 web 应用 Pom spring-boot-starter-validation 在 Hibernate Validator 中使用 Java Bean 验证 Pom spring-boot-starter-web 使用 Spring MVC 构建 restfull web 应用. 使用 tomcat 作为默认内嵌容器 Pom spring-boot-starter-web-services 使用 Spring Web 服务 Pom spring-boot-starter-webflux 使用 Spring Framework’s 响应式 web 支持构建 WebFlux 应用 Pom spring-boot-starter-websocket 使用 Spring Framework’s WebSocket 支持构建 WebSocket 应用 Pom 除了（in addition to）应用启动器，以下启动器可用来添加到“生产可读”特性： Name Description POM spring-boot-starter-actuator 使用 Spring Boot 的监控提供生产可读的特性帮助你监视并管理你的应用 POM 最终，如果你想排除（exclude）或替换（swap）特定的技术方面，Spring Boot 同样包含以下启动器可以使用： name Description Pom spring-boot-starter-jetty 使用 Jetty 作为内嵌服务器，另一个可替代的（alternative）是：spring-boot-starter-tomcat Pom spring-boot-starter-log4j2 使用 Log4j2 作为日志记录，可替代的是：spring-boot-starter-logging Pom spring-boot-starter-logging 使用 Logback 作为日志记录，是默认的日志记录启动器 Pom spring-boot-starter-reactor-netty 使用 Reactor Netty 作为内嵌的响应式 HTTP 服务器 Pom spring-boot-starter-tomcat 使用 Tomcat 作为内嵌的 servlet 服务器，spring-boot-starter-web 使用的默认 servlet 服务器 Pom spring-boot-starter-undertow 使用 Undertow 作为内嵌服务器，一个可替代的是：spring-boot-starter-tomcat Pom 更多的社区贡献的启动器列表，请在 GITHUB 的 spring-boot-starters 模块中查看 README file 14. 代码结构Spring Boot 不要求你工作时的任意特定的代码结构布局。但是，这里有最佳实践可以帮助你。 14.1 使用“默认的”包当一个类没有包含 package 声明（declaration），它被认为是（it is considered to）在默认的包中。使用默认的包通常（generally）不被鼓励（discouraged）应该尽量避免（avoided）。在 Spring Boot 使用 @ComponentScan,@EntityScan,@SpringBootApplication 时这会导致一些特定的问题，因为每个类每个 jar 都是可读的。 我们建议你遵循 java 推荐的包命名约定（Convertions）并反转域名名字（例如：com.example.project） 14.2 定位（Location）主应用类我们通常建议你在其他类之上的根包中放置（Locate）您的主应用程序类，该 @SpringBootApplication 注解经常被放在（place）你的主类，它隐式（implicitly）定义某些（cartain）“查询包”。例如：如果你要写一个 JPA 应用，@SpringBootApplication 注解类的包用于搜索 @Entity 项。使用根包还允许注解只扫描你的应用。 如果你不想使用 @SpringBootApplication，@EnableAutoConfiguration 和 @ComponentScan 注解导入了定义的行为，所以你同样可以使用他们。 以下列表展示了典型的布局： 12345678910111213141516com +- example +- myapplication +- Application.java | +- customer | +- Customer.java | +- CustomerController.java | +- CustomerService.java | +- CustomerRepository.java | +- order +- Order.java +- OrderController.java +- OrderService.java +- OrderRepository.java 一个 Application.java 文件会定义一个 main 方法，连同基础的 @SpringBootApplication，如下： 12345678910111213package com.example.myapplication;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} 15. 配置类spring boot 支持（favors）基于 java 的配置，虽然能够使用基于 XML 资源的 SpringApplication，我们\b通常建议你主要资源是一个（be a）单个 @Configuration 类。通常定义 main 方法的类是 @Configuration 的主要候选者。 许多 Spring 配置样例使用 XML 配置在网络上发布。如果可能，永远尝试使用相等的基于 Java 的配置。搜索 Enable* \b注解是一个很好的\b开始。 15.1 导入额外的配置类你不需要把所有的 @\bConfiguration 都放在一个配置类中。@Import 注解可以被用来导入额外的配置类。另外（Alternatively），你可以使用 @CompomentScan 去动态的\b获取（pick up）所有的 Spring 组件，包含 @Configuration \b类。 15.2 \b导入 XML 配置如果你绝对（Absolutely）\b要用基于 XML 的配置，我们建议你仍然（still）从 @Configuration 类开始。你可以使用 @ImportResource 注解\b加载 XML 配置文件。 16. 自动配置Spring Boot 自动配置尝试（attempts）去动态的配置你的 Spring 应用基于在你添加的 jar 依赖项之上。例如：如果 HSQLDB 在你的类路径下，并且你没有手动（manually）配置任何数据库连接 bean，spring boot 会在内存中自动配置数据库。 你需要添加 @EnableAutoConfiguration 或者 @SpringBootApplication 其中一个注解到你的一个 @Configuration 配置类上来选择自动配置。 你应该只添加一个注解 @EnableAutoConfiguration 或者 @SpringBootApplication。我们通常建议你只添加一个或另外一个到您的 @Configuration 配置类上。 16.1 逐步（gradually）更换（replacing）自动配置自动配置是非侵入型的（non-invasive）。任何时候，你可以开始定义你自己的配置类来替换特定部分的自动配置。例如：如果你添加你自己的 DataSource bean，默认内嵌的数据库将不再\b支持（backs away）。 如果你想找出（find out）当前（currently）正在应用（being applied）的自动配置，和为什么，使用 --debug 开关（switch）开始你的应用。\b这样做使调试日志可以选择核心日志记录器，并将条件报告记录到控制台。 16.2 禁用特定的自动配置类如果你\b发现一些自动配置类并不想它被应用，你可以为 @\bEnableAutoConfiguration 使用 exclude 属性关闭他们，as shown in the following example: 12345678import org.springframework.boot.autoconfigure.*;import org.springframework.boot.autoconfigure.jdbc.*;import org.springframework.context.annotation.*;@Configuration@EnableAutoConfiguration(exclude={DataSourceAutoConfiguration.class})public class MyConfiguration {} 如果该 class 不在类路径下，你可以使用注解的 \bexcludeName 属性并指定完全限定名。最终，你同样可以控制要排除的自动配置列表通过 spring.autoconfigure.exclude\b 属性。 可以在注释级别和使用属性定义排除。","link":"/2019/06/09/[20190609] spring-boot | part3(13~16)/"},{"title":"20190622 spring-boot | part3(17~22)","text":"Spring Boot Reference Guide2.1.5.RELEASEhttps://docs.spring.io/spring-boot/docs/2.1.6.RELEASE/reference/html/using-boot-spring-beans-and-dependency-injection.html Part III. Using Spring Boot 17 Spring Bean 依赖注入 18. 使用 @SpringBootApplication 注解 19. 运行你的应用 19.1 从 IDE 运行 19.2 \b作为打包应用程序运行 19.3 使用 Maven 插件 19.4 使用 Gradle 插件 19.5 热部署 20. 开发者工具 20.1 默认属性 20.2 自动重启 20.2.1. 在状态评估（condition evaluation）中记录\b变化 20.2.2. 排除资源 20.2.3. 监视额外的路径 20.2.4. 禁用重启 20.2.5. 使用触发文件 20.2.6. 定制重启类加载器 20.2.7. 已知限制 20.3 热加载 20.4 全局设置 20.5 远程应用 20.5.1 运行远程应用客户端 20.5.2 远程更新 21. 为生产环境打包你的应用 22. \b下一步是什么 17 Spring Bean 依赖注入你可以免费使用任意标准的 Spring 框架技术来定义的你的 bean 和管理依赖注入。为了简单，我们经常发现使用 @ComponentScan （查找你的 bean）和使用 @Autowired （做依赖注入）效果很好（work well）。如果按照上面的建议构造你的代码（在根包中定位应用程序类），你可以\b无理由的（without arguments）添加 @ComponentScan。你应用的所有组件（@Component、@Service、@Repository、@Controller）都会自动注册到 Spring bean里。 \b以下实例展示了一个 @Service bean，它使用控制器注入以获得必要的 RiskAssessor bean： 123456789101112131415161718package com.example.service;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Servicepublic class DatabaseAccountService implements AccountService { private final RiskAssessor riskAssessor; @Autowired public DatabaseAccountService(RiskAssessor riskAssessor) { this.riskAssessor = riskAssessor; } // ...} 如果这个 bean 有一个控制器，你可以省略 @Autowired，如以下所示\b：123456789101112@Servicepublic class DatabaseAccountService implements AccountService { private final RiskAssessor riskAssessor; public DatabaseAccountService(RiskAssessor riskAssessor) { this.riskAssessor = riskAssessor; } // ...} 注意，如果使用控制器注入让 riskAssessor 字段标记为 final。这表明（indicating）它随后（subsequently）不能被修改。 18. 使用 @SpringBootApplication 注解许多 Spring Boot 的开发者喜欢\b他们的\b应用使用自动配置，组件扫描和能够（be able to）在他们的主类上定义额外的（extra）的配置。一个单一的 @SpringBootApplication 注解\b就可以被用于启用这些三个特性，他们是： @EnableAutoConfiguration：开启Spring Boot 的自动配置机制 @ComponentScan：对应用程序所在的包启用 @Component\b 扫描（最佳实战） @Configuration：允许在上下\b文注册额外的 bean 或者导入额外的配置类 这个 @SpringBootApplication 注解等价于（equivalent）使用 @Configuration，@EnableAutoConfiguration，和 @ComponentScan 他们的默认属性，如下所示： 12345678910111213package com.example.myapplication;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication // same as @Configuration @EnableAutoConfiguration @ComponentScanpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} @SpringBootApplication 同样提供别名定义 @EnableAutoConfiguration，和 @ComponentScan 的属性 这些\b功能都不是强制性的（mandatory），你可以选择通过打开任何的特性来替换这个单个注解。例如：\b你可能不想在你的\b应用中使用注解扫描： 1234567891011121314151617package com.example.myapplication;import org.springframework.boot.SpringApplication;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Import;@Configuration@EnableAutoConfiguration@Import({ MyConfig.class, MyAnotherConfig.class })public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} 在这个例子中，Application 就像其他的 Spring Boot 应用一样除了 @Component 注解类不会被监测到，用户定义的 bean 被显式的导入（见 @Import）。 19. 运行你的应用打包你的应用作为一个 jar 和使用内嵌的 HTTP 服务器的一个最大的优势是：你可以像其他应用程序一样运行你的应用。Spring Boot 的调试也同样简单，你不需要任何特定的 IDE 插件或拓展程序。 这个章节\b只涵盖基于包的 jar，如果你选择打包你的应用作为一个 war 包文件，你可以参考服务器和 IDE 文档。 19.1 从 IDE 运行你可以从你的 IDE 作为一个简单的 Java 应用运行 Spring Boot。然而，你首先需要导入你的项目。导入的步骤的不同（vary）依赖于（depending on）你的 IDE 和构建系统。大多数\b IDE 可以直接导入 maven 项目。例如：Eclipse 用户可以选择 import -&gt; existing maven projects \b从文件菜单。 如果你不想直接导入你的项目到你的 IDE，你可以通过使用构建插件生成 IDE 元数据。Maven 包含了 IDEA 和 Eclipse 插件。gradle 为各种（various） ide 提供插件。 如果你不小心（accidentally）运行了\b你的应用程序两次，\b你可以查看“端口已被使用”错误。STS 用户可以使用 Relaunch 按钮而不是（rather than）Run 按钮以确保（ensure）任何存在的实例是关闭的。 19.2 \b作为打包应用程序运行如果你使用 Spring Boot Maven 或 Gradle 插件\b创建一个可执行 jar，你可以运行你的应用使用 java -jar，如以下所示： 1java -jar target/myapplication-0.0.1-SNAPSHOT.jar 还可以在启用远程调试支持的情况下运行打包应用程序。这样\b做可以使你依附一个调试器到你的\b应用程序，如以下所示： 12java -Xdebug -Xrunjdwp:server=y,transport=dt_socket,address=8000,suspend=n \\ -jar target/myapplication-0.0.1-SNAPSHOT.jar 19.3 使用 Maven 插件Spring Boot Maven 插件包含一个 run 目标可以使用它\b快速启动编译和运行你的应用。应用程序以分解形式（exploded）运行，如在你的 IDE 一样。以下\b的一个例子展示了一个\b\b典型的 maven 命令运行你的 spring boot 应用： mvn spring-boot:run 你可能想要使用 MAVEN_OPTS 操作系统环境变量，如下所示： export MAVEN_OPTS=-Xmx1024m 19.4 使用 Gradle 插件Spring Boot Gradle 插件同样\b包含 bootRun 任务可以被使用来\b分解式的运行你的应用。每当你\b应用 org.springframework.boot 和 java 插件时都会添加 bootRun，如下所示： gradle bootRun 你可能想要使用 JAVA_OPTS 操作系统环境变量，如下所示： export JAVA_OPTS=-Xmx1024m 19.5 热部署由于 Spring Boot 应用只是一个普通的（\bplain）的 Java 应用，JVM 热部署可以开箱即用（work out of the box）。JVM 热部署有点受限于（\bsomewhat limited with）它可以替换的字节码。更多的编译解决方案，可以使用 JRebel spring-boot-devtools 模块同样包括了\b支持应用快速重启。查看\b本章节\b后面的（later in this chapter）20 章 —— 开发\b工具 和 \b如何使用热部署 \b\b获得更多细节。 20. 开发者工具Spring Boot 包含了额外的\b工具集，可以使你的\b应用开发体验稍微愉快（pleasant）一点。spring-boot-devtools 模块可以被添加到任意项目中\b以提供额外的开发时特性。要\b包含测试工具支持，添加模块依赖到你的\b构建中，如下展示了 Maven 和 Gradle 的\b清单： Maven：1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt; Gradle:123456789configurations { developmentOnly runtimeClasspath { extendsFrom developmentOnly }}dependencies { developmentOnly(\"org.springframework.boot:spring-boot-devtools\")} 开发者工具在你运行完整打包的应用时自动禁用。如果你的类从 java -jar 启动，或者如果你\b从特定的类加载器开始，那么认为（considered）它是一个生产应用。\b如果不是这种情况（如果你的应用是从容器运行），认为排除了开发者工具或者设置了系统属性：-Dspring.devtools.restart.enabled=false 在Maven中将依赖项标记为可选的，或者在Gradle中使用定制的“只开发”配置(如上面所示)是防止DevTools被临时应用到使用您的项目的其他模块的最佳实践。 默认情况下重新打包不会包含开发者工具。如果你想使用某些远程开发特性，你需要禁用 excludeDevtools 属性以包含它。这个属性同时支持 Maven 和 Gradle 插件。 20.1 默认属性一些类库通过支持使用 Spring Boot 使用缓存来提高性能（improve performance），例如：模版引擎缓存编译的模版以避免（avoid）重复（repeatedly）解析模版文件。同样，当服务静态资源时 Spring MVC 可以添加 HTTP 缓存头到响应信息中。 缓存在生产中是非常有益的（beneficial），然而它在开发环境则会适得其反（counter-productive），阻止（preventing）你看到你刚刚在应用程序中产生的更改。由于这个原因，spring-boot-devtools 默认禁用缓存选项。 缓存选项通常在你的 application.properties 文件里面设置。例如：Thymeleaf 提供了 spring.thymeleaf.cache 属性，而不用手动设置这些属性，spring-boot-devtools 模块自动合理应用开发时配置。 因为你需要更多信息关于 web 请求的信息在开发 spring mvc 和 spring WebFlux 应用时，开发者工具将会为 web 日志记录开启 debug 的日志记录。这将会给你进来的请求的信息，处理中程序，返回结果等。如果你希望记录所有请求的细节（可能包含敏感信息），你可以打开 spring-http.log-request-detail 配置属性。 如果你不想应用该默认属性你可以在你的 application.properties 中设置 spring-http.log-request-detail 为 false。 应用于 devtools 的所有的属性列表，查看 DevToolsPropertyDefaultsPostProcessor. 20.2 自动重启使用 spring-boot-devtools 的应用会自动重启，每当类路径下的文件改变。在 IDE 工作时，这是一个有用的特性，因为它为代码改变提供类快速的反馈循环。作为默认，指向（point to）类路径下的所有条目都会被监视为了更改。注意某些资源如：静态资源和视图模版，不需要重新启动应用。 触发重启当 DevTools 监视类路径下的资源，触发重启的唯一方式是更新其类路径。导致（cause）类路径更新的方式依赖于你使用的 IDE。在 Eclipse 中，保存和修改文件导致类路径更新和出发重启。在 IDEA，编译项目有同样的效果。 只要此分叉被打开，你可以同样启动你的应用通过使用支持的构建插件，因为 DevTools 需要一个独立的应用程序加载器来正确操作。作为默认，Gradle 和 Maven 在类路径上检测到 DevTools 时会这样做。 与 LiveReload 工作时自动重启工作良好，查看 LiveReload 章节获得更多细节。如果你使用 JReble，自动重启会禁用，有利于（in favor of）类的动态加载。其他 devtools 的特性如：LiveReload 和 属性覆盖可以一直使用。 DevTools 依赖于应用程序上下文的 shutdown 钩子来在重启期间关闭它。 如果禁用了 shutdown 挂钩，则无法正常工作。 当决定在类路径上的条目是否应该在更改时触发重新启动时，Devztools 自动忽略名为 spring-boot, spring-boot-devtools, spring-boot-autoconfigure, spring-boot-actuator, spring-boot-starter 的项目。 DevTools 需要通过 ApplicationContext 来定制 ResourceLoader。如果您的应用已经提供来一个，它将被包裹起来。不支持直接覆盖 ApplicationContext 上的 getResource 方法。 重启和重新加载Spring Boot 程序提供的重新启动技术使用了两个类加载器。不会改变的类（例如：第三方jar）被加载到（loaded into）基类加载器中。你正在积极开发的类被加载到重启类加载器。当应用程序重启，该重启类加载器会被丢掉（thrown away）并重新创建一个新的。这种方法意味着应用程序重启通常比“冷启动”快得多，因为基类装入器已经可用并已填充。 如果发现重新启动对应用程序来说不够快，或者遇到类加载问题。你可以考虑重新选择技术如\b从 ZeroTurnaround 获得 JReble。这些工作是通过在加载类时重写类来完成的，以使它们更易于重新加载。 20.2.1. 在状态评估（condition evaluation）中记录\b变化作为默认，每当你的应用重启，将记录显示状态评估增量的报表。该报告展示了你的应用的\b自动配置的改变如增加或删除bean，设置配置属性。 要禁用日志记录报告，设置以下属性： spring.devtools.restart.log-condition-evaluation-delta=false 20.2.2. 排除资源某些资源\b当他们改变时没有必要触发重启。如：Thymeleaf 模版可以就地（in-place）编辑，默认情况下，改变 /META-INF/maven, /META-INF/resources, /resources, /static, /public, or /templates 中的资源不会触发重启但会触发 live reload。 如果你想定制这些排除项，你可以使用 spring.devtools.restart.exclude 属性。如：要仅仅排除 /static 和 /public 你需要设置以下命令： spring.devtools.restart.exclude=static/**,public/** 如果你要保持默认值并添加额外的排除项，使用 spring.devtools.restart.additional-exclude 作为替换。 20.2.3. 监视额外的路径你可能想要你的应用程序重启或重加载当你\b不在类路径下改变文件。要这样做，使用 spring.devtools.restart.additional-paths 属性配置额外的路径并监视。前面描述的是控制在额外路径下的更改是否会触发完全重新启动或重新加载。 20.2.4. 禁用重启如果你不想使用重启特性，你可以通过 spring.devtools.restart.enabled 属性禁用它。大多数情况下，你可以在你的 application.properties 设置这个属性。（这样做仍然初始化时重启类加载器，但是他不会监视文件更改） 如果你想要完全禁用重启支持（例如：他在特定的类库中不能工作），你需要在调用 SpringApplication.run(…​), 之前设置 spring.devtools.restart.enabled 系统属性为 false，如下所示： 1234public static void main(String[] args) { System.setProperty(\"spring.devtools.restart.enabled\", \"false\"); SpringApplication.run(MyApp.class, args);} 20.2.5. 使用触发文件如果你工作的\b IDE 不断的（continuouslt）编译改变文件，你可能希望仅在特定时间内触发重启。要这样做，你可以使用“触发文件”，这是一个特殊的文件，当您想要实际触发重新启动检查时，必须修改该文件。更改文件只会触发检查，只有在 Devtools 检测到必须执行某些操作时才会重新启动。 使用触发文件，设置 spring.devtools.restart.trigger-file 属性为触发文件的路径。 你可能想要设置 spring.devtools.restart.trigger-file 作为一个全局设置，这样所有的项目都以同样的方式运作。 20.2.6. 定制重启类加载器如在前面的“重启和重加载”章节所\b述，重启功能是使用两个\b类加载器实现的。对于更多的应用，这种方法（approack）工作良好。然而，它有时会导致一些类加载问题。 \b作为默认，你\b的 IDE 中任何打开的项目都\b加载类“重启”类加载器，任何普通的（regular）的 jar 文件都带有“基础”类加载器。如果你在\b多模块项目中工作，并且不是\b每个项目都导入到了 IDE，你可能需要定制一些东西。要这样做的话，你可以创建一个 META-INF/spring-devtools.properties 文件。 该 spring-devtools.properties 文件可以包含有 restart.exclude 和 restart.include 前缀的属性。include 元素下的项都会被拉取（pulled up）到 “重启” 类加载器，exclude 元素下的项都被推进到（pushed down）\b“基础”类加载器。该属性值是应用在类路径下的正则模式，如下所示： 12restart.exclude.companycommonlibs=/mycorp-common-[\\\\w\\\\d-\\.]+\\.jarrestart.include.projectcommon=/mycorp-myproj-[\\\\w\\\\d-\\.]+\\.jar 所有的属性关键字都是必须的。只要（as long as）属性以 restart.include 或 resatrt.exclude 开头都被考虑进去。 加载类路径中的所有 META-INF/Spring-devtools.properties。您可以在项目中或项目所消耗的库中打包文件。 20.2.7. 已知限制重启功能（functionality）不适用使用标准 ObjectInputStream 反序列化的对象。如果你需要反序列化对象，你可能需要\b使用 Spring 的 ConfigurableObjectInputStream 结合于（\bin combination with）Thread.currentThread().getContextClassLoader()。\b不幸的是（Unfortunately），一些第三方类库在不考虑类加载器\b上下文的情况下反序列化。如果你发现一些问题，你需要请求原作者解决。 20.3 热加载Spring Boot Devtools 模块包括一个内嵌的 LiverLoad 服务器，当资源被改变时，它可以用来触发浏览器刷新。livereload.com 免费提供 LiveReload 浏览器插件\b Chrome、Firefox，Safari版。 如果你想当你的应用启动时启动 LiveReload，你可以设置 spring.devtools.livereload.enabled 属性为 false。 一次（at \ba time）只能运行一个LiveReload服务器。在你的应用启动之前，确保没有其他的 LiveReload 服务器在运行。如果\b你从你的 IDE 启动了多个应用程序，只有第一个 LiveReload 会提供支持。 20.4 全局设置\b你可以通过在你的 $HOME 文件夹下添加一个名为 .spring-boot-devtools.properties 的文件来配置开发工具的全局设置（注意文件名从 . 开始）。\b添加到这个文件的所有属性会应用到所有的 Spring Boot 应用程序，在你的机器上使用开发工具。如：要配置永远使用 触发文件 重启，你需要添加以下属性： ~/.spring-boot-devtools.properties. spring.devtools.reload.trigger-file=.reloadtrigger 在.spring-boot-devtools.properties中激活的配置文件不会影响（affect）特定于配置文件的加载。 20.5 远程应用Spring Boot 开发者工具没有限制于本地开发，你同样可以在\b运行的远程应用上使用一些特性功能。远程支持是可选的，要开启它，你需要确保 devtools \b包含在重新打包后的归档文件中，如下列表所示： 1234567891011&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;excludeDevtools&gt;false&lt;/excludeDevtools&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 如果你需要设置 spring.devtools.remote.secret 属性，如下所示： spring.devtools.remote.secret=mysecret 在远程应用开启 spring-boot-devtools 是有安全风险的（risk）。你应该永远都不开启\b对生产环境的支持。 远程开发工具提供以下两个单元的支持：一个服务器断点，接受在你的 IDE 中运行的应用和连接。当 spring.devtools.remote.secret 属性被设置了\b该服务组件会自动开启。客户端组件必须手动运行。 20.5.1 运行远程应用客户端该远程客户端应用被设计为在你的 IDE 中运行。你需要运行 org.springframework.boot.devtools.RemoteSpringApplication 使用和你连接的远程个项目相同的类路径。该应用程序所需的唯一参数是需要连接到的远程服务器的 URL。 如，如果你使用 Eclipse 或 STS，并且你有一个名为 my-app 的项目被\b部署到了云服务器，你可\b这样做： 从 Run 菜单构建 Run Configurations… 创建一个新的 Java Application\b 启动配置 浏览 my-app 应用 使用 org.springframework.boot.devtools.RemoteSpringApplication 作为主类 添加 https://myapp.cfapps.io 到 程序参数。（或者不管您的远程URL是什么） 正在运行的远程客户端可能类似于下列列表： . ____ _ __ _ _ /\\\\ / ___&apos;_ __ _ _(_)_ __ __ _ ___ _ \\ \\ \\ \\ ( ( )\\___ | &apos;_ | &apos;_| | &apos;_ \\/ _` | | _ \\___ _ __ ___| |_ ___ \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| []::::::[] / -_) &apos; \\/ _ \\ _/ -_) ) ) ) ) &apos; |____| .__|_| |_|_| |_\\__, | |_|_\\___|_|_|_\\___/\\__\\___|/ / / / =========|_|==============|___/===================================/_/_/_/ :: Spring Boot Remote :: 2.1.6.RELEASE 2015-06-10 18:25:06.632 INFO 14938 --- [ main] o.s.b.devtools.RemoteSpringApplication : Starting RemoteSpringApplication on pwmbp with PID 14938 (/Users/pwebb/projects/spring-boot/code/spring-boot-devtools/target/classes started by pwebb in /Users/pwebb/projects/spring-boot/code/spring-boot-samples/spring-boot-sample-devtools) 2015-06-10 18:25:06.671 INFO 14938 --- [ main] s.c.a.AnnotationConfigApplicationContext : Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@2a17b7b6: startup date [Wed Jun 10 18:25:06 PDT 2015]; root of context hierarchy 2015-06-10 18:25:07.043 WARN 14938 --- [ main] o.s.b.d.r.c.RemoteClientConfiguration : The connection to http://localhost:8080 is insecure. You should use a URL starting with &apos;https://&apos;. 2015-06-10 18:25:07.074 INFO 14938 --- [ main] o.s.b.d.a.OptionalLiveReloadServer : LiveReload server is running on port 35729 2015-06-10 18:25:07.130 INFO 14938 --- [ main] o.s.b.devtools.RemoteSpringApplication : Started RemoteSpringApplication in 0.74 seconds (JVM running for 1.105) 因为远程客户端使用与实际应用程序相同的类路径，\b所以它可以直接的读取你的应用配置 。这是Spring.devtools.remote.secret属性的读取和传递到服务器进行身份验证的方式。 总是建议使用 https:// 作为连接协议，因此，通信是加密的（traffic is encrypted），密码不能被截获（intercepted）。 如果你使用\b代理\b访问远程应用，配置 spring.devtools.remote.proxy.host 和 spring.devtools.remote.proxy.port 属性。 20.5.2 远程更新远程客户端以与本地重新启动相同的方式监视应用程序类路径以进行更改。任何更新的资源被推到远程应用程序，（如果需要的话）触发重新启动。如果你需要迭代本地没有的云服务功能，这样十分有用。远程更新和重新启动要比完整的（full）重建和部署周期快得多（quicker than）。 只有当\b远程客户端在运行时才会监视文件，如果你在远程客户端其中之前改变文件，它不会推送到远程服务器。 21. 为生产环境打包你的应用可执行 jar 可用于生产部署，因为他们是独立的（self-contained），它们也非常适合（ideally \bsuited）基于云的部署。 如需要额外的“生产准备”特性，例如健康，升级，和度量 Rest 或者 JMX 端点，考虑添加 spring-boot-actuator。查看 第四章 Spring Boot 监控：\b生产可读的特性 获得更多细节。 22. \b下一步是什么你现在应该理解如何使用 Spring Boot 和一些遵循的最佳实践。现在可以深入学习特定的 Spring Boot 特性，或者你可以跳过前面（ahead），阅读关于 “生产可读” 各方面的 Spring Boot。\b\b","link":"/2019/06/22/[20190622] spring-boot | part3(17~22)/"},{"title":"算法第一章 基础","text":"第一章 基础基础编程模型格式化输出从标准输出流中打印随机生成的数值，“%.2f\\n”表示输出两位小数精度的浮点型数值并换行。 cmd运行需要注意的几个地方： 我们的工程一般使用utf-8编码，但是windows系统默认gbk编码，所以编译javac会出现“找不到gbk编码的字符映射”。解决办法：编译时指定参数 -encoding utf-8 “找不到某个类”，程序中引用了非当前目录的jar文件，在本路径编译会找不到jar包，需要执行参数：-Djava.ext.dirs=jar包作为路径。 “无法运行主类”，检查是否配置了classpath环境变量，CLASSPATH=&quot;.;%JAVA_HOME%\\lib;%JAVA_HOME%\\lib\\tools.jar;&quot; 如果被编译类有包，需要在该包下执行编译和运行，最终该类的编译和运行命令： javac -Djava.ext.dirs=D:\\IdeaProjects\\Algorithms\\lib -encoding utf-8 chapter_1/programming_model/RandomSeq.java java -Djava.ext.dirs=D:\\IdeaProjects\\Algorithms\\lib chapter_1/programming_model/RandomSeq 10 1 100 12345678910111213public class RandomSeq { public static void main(String[] args) { // 打印n个(lo,hi)之间的随机值 int N = Integer.parseInt(args[0]); double lo = Double.parseDouble(args[1]); double hi = Double.parseDouble(args[2]); for (int i = 0; i &lt; N; i++) { // 返回随机实数 double x = StdRandom.uniform(lo, hi); StdOut.printf(\"%.2f\\n\", x); } }} 注意：java要求参数的数据类型和转换代码表示的数据类型必须相同，printf()的第一个String字符串也可以包含其他字符。所有非格式的字符串会被传递到输出之中，而格式化的字符串则会被参数的值所代替。例如： 1Std.printf(\"PI is %.2f\\n\",Math.PI); 会打印出：PI is 3.14 标准输入特点标准输入流最重要的特点就是这些值会在程序读取之后消失，程序读取了就不能回退再次读取。 重定向与管道使输出重定向到一个文件中，而不是终端打印：java RandomSeq 1000 100.0 200.0 &gt; data.txt，每次打印都会向文件追加内容。 从文件读取输入流而不是等待用户输入，“&lt;”是一个操作符，它告诉系统从文件中作为输入流而不是等终端用户输入。java Average &lt; data.txt 将一个程序的输出重定向为一个程序的输入叫做管道。java RandomSeq 1000 100.0 200.0 | Java Average，该命令将RandomSeq的标准输出和Average的标准输入指定为了同一个流。看起来的效果就是Average运行时从RandomSeq的输出作为了自己的输入。这种写法的好处在于它能够突破输入输出流长度的限制，有效的利用了系统资源。RandomSeq调用了printf()时，向输入流末尾添加了一条字符串；Average调用readDouble()时，就从输入流开头删除了一个字符串。 二分查找读取终端输入流中的值，如果该值在指定文件中不存在则返回这个值，否则不返回。 1234567891011121314151617181920212223242526272829303132333435363738public class BinarySearch { public static int rank(int key, int[] arr) { // 使用lo和hi变量保证key一定在arr[lo...hi]中 int lo = 0; int hi = arr.length - 1; for (int i = 0; i &lt; hi; i++) { // 取中间值索引，当查找的范围在左边，lo始终为0，当查找的范围在右边，中间值索引就是起始值索引+前后折半的值 int mid = lo + (hi - lo) / 2; // 小于中间值，查找范围缩小到左边 if (key &lt; arr[i]) { hi = mid - 1; } // 大于中间值，查找范围缩小到右边 if (key &gt; arr[i]) { lo = mid + 1; } else { return i; } } return -1; } public static void main(String[] args) { long start = System.currentTimeMillis(); // Reads all integers from a file and returns them as an array of integers. argument：filename int[] whitelist = In.readInts(args[0]); Arrays.sort(whitelist); while (!StdIn.isEmpty()) { // Reads the next token from standard input, parses it as an integer, int key = StdIn.readInt(); if (rank(key, whitelist) &lt; 0) { StdOut.println(key); } } long end = System.currentTimeMillis(); StdOut.println(\"time-&gt;:\" + (end - start)); }} 命令行参数： 编译忽略过期警告： javac -Djava.ext.dirs=D:\\IdeaProjects\\Algorithms\\lib -Xlint:deprecation -encoding utf-8 chapter_1/programming_model/BinarySearch.java 运行：传入一个文件路径，等待用户输入，比较输入的值是否在文件中存在 java -Djava.ext.dirs=D:\\IdeaProjects\\Algorithms\\lib chapter_1/programming_model/BinarySearch D:\\IdeaProjects\\Algorithms\\algs4-data\\tinyW.txt 运行：传入一个文件路径，指定输入流来源于文件，从tinyT.txt中作为输入流，比较tinyT.txt里的每个值是否在tinyW.txt中存在 java -Djava.ext.dirs=D:\\IdeaProjects\\Algorithms\\lib chapter_1/programming_model/BinarySearch D:\\IdeaProjects\\Algorithms\\algs4-data\\tinyW.txt &lt; D:\\IdeaProjects\\Algorithms\\algs4-data\\tinyT.txt 数据抽象背包、队列和栈背包（Bag）是一种不支持从中删除元素的数据类型，其主要目的用来帮助用例（应用程序）收集元素并迭代遍历搜集到的所有元素（检查背包是否为空，或获取背包中元素的数量）。使用背包说明元素的处理是无序的。 典型用例：计算标准输入中所有double值的平均值和标准差 1234567891011121314151617181920212223public class Stats { public static void main(String[] args) { Bag&lt;Double&gt; numbers = new Bag&lt;Double&gt;(); while (!StdIn.isEmpty()) { numbers.add(StdIn.readDouble()); } int N = numbers.size(); double sum = 0.0; for (double x : numbers) { sum += x; } double mean = sum / N; sum = 0.0; for (double x : numbers) { sum += (x - mean) * (x - mean); } double std = Math.sqrt(sum / N - 1); StdOut.printf(\"Mean: %.2f\\n\", mean); StdOut.printf(\"Std dec: %.2f\\n\", std); }} 队列（Queue）是一种基于先进先出（FIFO）策略的集合类型。队列是许多日常现象的模型，也是无数应用程序的核心。 典型用例：读取文件中的所有数字并放入数组中，使用队列和好处在于用例无需知道文件中的数字的大小即可将文件中的所有数字放入数组中，首先将文件中的所有数字按顺序放入队列中，再从队列中按顺序一个一个取出放入数组，队列中元素的顺序就是文件中数字的顺序。 1234567891011121314151617181920public class QueueDemo { public static int[] readInts(String name) { In in = new In(name); Queue&lt;Integer&gt; q = new Queue&lt;&gt;(); while (!in.isEmpty()) { q.enqueue(in.readInt()); } int N = q.size(); int[] a = new int[N]; for (int i = 0; i &lt; N; i++) { a[i] = q.dequeue(); } return a; } public static void main(String[] args) { readInts(args[0]); }} 下压栈（栈、Stack）是一种基于后进先出（LIFO）策略的集合类型。生活中常见的后进先出策略的例子比如：桌面上放成一叠的邮件，当收信时将邮件压入（push）最顶端，取信时从最顶端将其弹出（pop）。这种策略好处在于我们能够及时的看到最新的邮件，坏处就是当没有清理栈时，某些较早的邮件永远不会被阅读。 典型用例：用元素保存集合的同时颠倒他们的顺序，Reverse会把标准输入中的所有整数逆序排列。 123456789101112public class Reverse { public static void main(String[] args) { Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); while (!StdIn.isEmpty()) { stack.push(StdIn.readInt()); } for (int i : stack) { StdOut.println(i); } }} 栈的典型用例：双栈算术表达式求值算法编写一个算法来模拟系统运算算术表达式： ( 1 + ( ( 2 + 3 ) * ( 4 * 5 ) ) ) ，输入一个表达式字符串，为了简化问题，我们假设表达式只由运算符+、-、*、/，小括号，和数字组成，并且每个元素之间都用一个空格隔开。 双栈算术表达式求值算法核心利用了用两个栈：一个保存运算符、一个保存操作数。处理逻辑如下： 当遇到操作数将操作数压入操作数栈 当遇到运算符将运算符压入运算符栈 忽略左括号 当遇到右括号时，弹出一个运算符，弹出所需数量的操作数，并将操作数和运算符的运算结果压入操作数栈 123456789101112131415161718192021222324252627282930313233343536373839404142public class Evaluate { public static void main(String[] args) { Stack&lt;String&gt; ops = new Stack&lt;&gt;(); Stack&lt;Double&gt; vals = new Stack&lt;&gt;(); while (!StdIn.isEmpty()) { // 循环读取每一个操作符，如果是运算符则压入运算符栈 String s = StdIn.readString(); if (s.equals(\"(\")) { } else if (s.equals(\"+\")) { ops.push(s); } else if (s.equals(\"-\")) { ops.push(s); } else if (s.equals(\"*\")) { ops.push(s); } else if (s.equals(\"/\")) { ops.push(s); } else if (s.equals(\"sqrt\")) { ops.push(s); } else if (s.equals(\")\")) { // 如果运算符为 ） ，弹出运算符和操作数，计算结果并压入操作数栈 String op = ops.pop(); double v = vals.pop(); // 弹出栈顶的操作数。弹出栈元素是在栈中删除了的 if (op.equals(\"+\")) { v = vals.pop() + v; // 再弹出一个栈顶操作数，与前面弹出的栈顶操作数（v）做运算并重新赋值给变量v } else if (op.equals(\"-\")) { v = vals.pop() - v; // 第二次弹出的操作数在前，第一次弹出的操作数在后。因为先进栈的操作数后弹出，后进栈的元素先弹出 } else if (op.equals(\"*\")) { v = vals.pop() * v; } else if (op.equals(\"/\")) { v = vals.pop() / v; } else if (op.equals(\"sqrt\")) { v = Math.sqrt(v); } vals.push(v); // 运算后的值入栈，进行运算的两个操作数被弹出（删除）了。 } else { // 如果既不是运算符也不是括号，则就是数字，将其压入数值栈。 vals.push(Double.parseDouble(s)); } } StdOut.println(vals.pop()); }} 求值算法轨迹图： 集合类数据类型的实现基于顺序存储结构的集合类型实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class ResizingArrayStack&lt;Item&gt; implements Iterable&lt;Item&gt; { private Item[] a; private int N; public ResizingArrayStack(int cap) { a = (Item[]) new Object[cap]; } public void push(Item item) { if (N == a.length) { resize(a.length * 2); } a[N++] = item; } public Item pop() { Item item = a[--N]; a[N] = null; if (N &gt; 0 &amp;&amp; N == a.length / 4) { resize(a.length / 2); } return item; } public boolean isEmpty() { return N == 0; } public int size() { return N; } public void resize(int max) { Item[] temp = (Item[]) new Object[max]; for (int i = 0; i &lt; N; i++) { temp[i] = a[i]; } a = temp; } @Override public Iterator&lt;Item&gt; iterator() { return new ReverseArrayStack&lt;&gt;(); } private class ReverseArrayStack&lt;Item&gt; implements Iterator&lt;Item&gt; { private int i = N; @Override public boolean hasNext() { return i == 0; } @Override public Item next() { return (Item) a[--i]; } }} 基于链式存储结构的集合类型实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class LinkedStack&lt;Item&gt; implements Iterable&lt;Item&gt; { private Node first; private int N; private class Node&lt;Item&gt; { private Item item; private Node next; } private class listIterator&lt;Item&gt; implements Iterator&lt;Item&gt; { private Node currentNode = first; @Override public boolean hasNext() { return currentNode != null; } @Override public Item next() { Item item = (Item) currentNode.item; currentNode = currentNode.next; return item; } } public void push(Item item) { Node oldFirst = first; first = new Node&lt;&gt;(); first.item = item; first.next = oldFirst; N++; } public Item pop() { Node&lt;Item&gt; oldFirst = first; first = first.next; N--; return oldFirst.item; } public boolean isEmpty() { return first == null; } public int size() { return N; } @Override public Iterator&lt;Item&gt; iterator() { return new listIterator&lt;&gt;(); }} 123456789101112131415161718192021222324public class LinkedQueue&lt;Item&gt; implements Iterable { // ...... public void enqueue(Item item) { Node&lt;Item&gt; oldLast = last; last = new Node(); last.item = item; if (isEmpty()) { first = last; } else { oldLast.next = last; } N++; } public Item dequeue() { Node&lt;Item&gt; oldFirst = first; first = first.next; if (isEmpty()) { last = null; } N--; return oldFirst.item; }} 更多拓展在练习题： 下压栈： 补全表达式转为中序表达式 中序表达式转后序表达式 后序表达式求值实现简单计算器 队列： 读取倒数第K个字符串 链表： LinkedStackExercise.java 双向链式存储结构集合数据类型实现： Ex31_DoubleLinkedStack.java 随机背包： Ex34_RandomBag.java Josephus生存游戏： Ex37_Josephus.java 可连接队列、栈： Ex47.java 算法分析案例研究：并查集（union-find）算法问题由来 —— 动态连通性问题： 程序从输入中每次读取一对整数 P 和 Q ，如果已知的所有整数对不能证明他们是“相连”的，那么把他们“连起来”，并打印；如果能证明他们是相连的则不处理，继续读取下一对整数对。当两个对象（整数点）相连时称为属于一个等价类。 概念：如果两个对象“相连”是一种等价关系，那么它具有以下特性： 自反性：P和P是相连的（就是一个点和自己本身是相连的，em…）； 对称性：若P和Q是相连的，那么Q和P也是相连的； 传递性：若P和Q相连且Q和R相连，那么P和R是相连的 理解并查集以上问题其实就是并查集的一个具体案例，关于并查集，解释如下： 并查集，在一些有N个元素的集合应用问题中，我们通常是在开始时让每个元素构成一个单元素的集合，然后按一定顺序将属于同一组的元素所在的集合合并，其间要反复查找一个元素在哪个集合中。 “并查集”是一种不相交集合的数据类型，初始时并查集中的元素是不相交的，经过一系列的基本操作(Union)，最终合并成一个大的集合。 API 初始化触点 连接触点 某个触点所在的连通分量 判断两个触点是否在同一个连通分量之中 返回连通分量的数量 123456789101112131415161718192021public interface UF { /** * 连接P和Q */ void union(int p, int q); /** * p所在分量（相等整数对）的标识符 */ int find(int p); /** * p和q存在同一分量返回true */ boolean connected(int p, int q); /** * 分量的个数 */ int count();} 实现一：quick-find 算法数据结构：数组 用数组 id[] 表示每一个触点的值，数组索引表示触点，触点的值就是分量的值，触点值相同表明分量相同。 初始化时每个触点的值都是该触点的索引。 比如：触点0 = id[0] = 0; 触点1 = id[1] = 1; 触点3 = id[3] = 3; 多个触点属于同一个连通分量时，其中某个触点的值“代表”该连通分量的值，把其他触点的值统一成所属分量的代表值，比如： 要把id[4] (值为4) 和 id[8] (值为8) 相连为同一分量，可以把id[4]的值改成id[8]的值，那么把 id[8] 值称为该连通分量的代表（或标识符或值）；也可以把id[8]的值改成id[4]的值，连通分量的值就是id[4]了。 要把id[5] (值为5) 和 id[4] (假设所属分量值为8) 相连为同一分量，连通分量的值以id[5]为代表，那么所有值为 8 的分量的值都改成了 5。 连通分量中的所有触点的值是统一的。 算法分析可以快速进行 find 操作，即可以快速判断两个节点是否连通。 同一连通分量的所有节点的 id 值相等。 但是 union 操作代价却很高，需要将其中一个连通分量中的所有节点 id 值都修改为另一个节点的 id 值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class QuickFind implements UF { private int[] id; // 连通分量标识符集合 private int count; // 连通分量数量 /** * 初始化所有连通分量 */ QuickFind(int N) { count = N; id = new int[N]; for (int i = 0; i &lt; count; i++) { id[i] = i; } } @Override public void union(int p, int q) { int pID = find(p); int qID = find(q); if (pID == qID) { // 已经在同一个分量中不做处理 return; } for (int i = 0; i &lt; count; i++) { if (id[i] == pID) { id[i] = qID; } count--; } } @Override public int find(int p) { return id[p]; } @Override public boolean connected(int p, int q) { return id[p] == id[q]; } @Override public int count() { return count; }} 实现二：quick-union 算法数据结构：树 同样以 id[] 表示每一个节点（触点）的值，但节点的值不是分量的值，每一个节点值是以其父节点的索引号的id[]值，该节点最终的值是根节点的值（父节点指向父节点，直到指向根节点）。 比如节点4（id[4]=9） 是 节点8 的父节点，那么节点8id[8]的值就是id[4]，即：id[8] = id[4] = 9 初始化时每个触点的值都是该触点的索引，并且都是根节点。 属于同一个连通分量的所有节点都属于同一颗数，判断是否属于同一分量需要判断是否属于同一棵树，我们可以把根节点代表分量的标识符。 两个节点的联合操作，操作的是两个节点的根节点，只需要将一个根节点的父节点设为另外一个根节点，这样两个节点（分量）联合成了一个节点（分量）。 比如：初始化时，每个节点都是根节点。 id[0] = 0; id[1] = 1; id[3] = 3; id[7] = 7 … 联合节点 0 和 1，将id[0]的父节点设为id[1]，即：id[0] = id[1] = 1 联合节点 3 和 0，将id[3]的父节点设为id[0]，即：id[3] = id[0] = id[1] = 1 联合节点 1 和 7，将id[1]的父节点设为id[7]，即：id[1] = id [7] = 7（此时id[3] = id[0] = id[1] = id [7] = 7） 算法分析可以快速进行 union 操作，只需要修改一个节点的 id 值即可。 union操作，固定的将左边的树链接到右边的树，导致树的深度很深，进行find()操作时效率变低。 但是 find 操作开销很大，因为同一个连通分量的节点 id 值不同，id 值只是用来指向另一个节点。因此需要一直向上查找操作，直到找到最上层的节点。 这种方法可以快速进行 union 操作，但是 find 操作和树高成正比，最坏的情况下树的高度为触点的数目。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class QuickUnion implements UF { private int[] id; // 树的每一个节点（触点） private int count; // 连通分量（根节点）的数量 QuickUnion(int N) { count = N; id = new int[N]; for (int i = 0; i &lt; count; i++) { id[i] = i; } } @Override public void union(int p, int q) { // 获取两个节点所属分量（根节点） int pRoot = find(p); int qRoot = find(q); if (pRoot == qRoot) { return; } // 把p的根节点的爸爸设为q的根节点，这样p和q就有了共同的爸爸。 id[pRoot] = qRoot; count--; } @Override public int find(int p) { // 当id[p]的值是本身，说明它是根节点（分量名）；若不是，向上循环找到根节点。 while (p != id[p]) { p = id[p]; } return p; // 所在分量就是根节点 } @Override public boolean connected(int p, int q) { return id[p] == id[q]; } @Override public int count() { return count; }} 轨迹图： 实现三：加权 quick-union 算法算法分析加权 quick-union 算法的出现是为了解决 quick-union 中find()操作随着树的深度加深成本变得越来越昂贵的问题。 不再固定的将左边的树链接到右边的树，而是根据树的深度（节点的个数）决定将深度小的树链接在深度大的树，由此降低find()操作次数。 数据结构 和 quick-union 结构相同，仅仅添加了一个用于记录每个分量个数的数组 不再是把p的根节点的爸爸设为q的根节点了，而是比较p的分量个数和q的分量个数，分量个数小的认分量个数大的当爸爸 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class WeightQuickUnion implements UF { private int[] id; // 每个触点的值是父链接 private int count; // 连通分量个数 private int[] sz; // 各个根节点对应的分量大小（节点个数） WeightQuickUnion(int N) { count = N; id = new int[N]; for (int i = 0; i &lt; count; i++) { id[i] = i; } // 初始化每个根节点对应分量的大小都是1 sz = new int[N]; for (int i = 0; i &lt; count; i++) { sz[i] = 1; } } @Override public void union(int p, int q) { int pRoot = find(p); int qRoot = find(q); if (pRoot == qRoot) { return; } // 不再是把p的根节点的爸爸设为q的根节点了，而是比较p的分量个数和q的分量个数，分量个数小的认分量个数大的当爸爸 if (sz[pRoot] &gt; sz[qRoot]) { id[qRoot] = pRoot; sz[pRoot] += sz[qRoot]; } else { // 当p分量大小 &lt;= q分量大小时，默认q的根节点认q的根节点当爸爸 id[pRoot] = qRoot; sz[qRoot] += sz[pRoot]; } count--; } @Override public int find(int p) { while (p != id[p]) { p = id[p]; } return p; } @Override public boolean connected(int p, int q) { return find(p) == find(q); } @Override public int count() { return count; }} 轨迹图： 实现四：路径压缩的加权 quick-union 算法算法分析路径压缩的加权 quick-union 算法是为了优化find()操作，减少查找父节点的次数，从而提升查找的效率； 使用路径压缩的加权 quick-union 算法是解决动态连通性问题的最优解； 它将每一个子节点都挂在根节点形成一个近似扁平的树状结构； 每次查找指定节点的根元素（分量）时，都将路径上（该节点的所有父节点）遇到所有节点挂在根节点之下； 压缩加权后的算法find()效率与 quick-find 的效率非常接近。 12345678910111213141516171819202122232425262728293031323334public class WeightQuickUnion implements UF { public int pathCompressionFind(int p) { // 先向上循环找到根节点 int root = p; while (root != id[root]) { root = id[root]; } // 再次循环，如果当前节点不是根节点，把当前节点挂在根节点上成为根节点的一级节点。 while (p != id[p]) { int tem = p; p = id[p]; id[tem] = root; } return root; } public void union(int p, int q) { int pRoot = pathCompressionFind(p); int qRoot = pathCompressionFind(q); if (pRoot == qRoot) { return; } // 不再是把p的根节点的爸爸设为q的根节点了，而是比较p的分量个数和q的分量个数，分量个数小的认分量个数大的当爸爸 if (sz[pRoot] &gt; sz[qRoot]) { id[qRoot] = pRoot; sz[pRoot] += sz[qRoot]; } else { // 当p分量大小 &lt;= q分量大小时，默认q的根节点认q的根节点当爸爸 id[pRoot] = qRoot; sz[qRoot] += sz[pRoot]; } count--; }}","link":"/2018/08/05/算法第一章 基础/"},{"title":"算法第二章 排序","text":"第二章 排序待排序的元素需要实现 Java 的 Comparable 接口，该接口有 compareTo() 方法，可以用它来判断两个元素的大小关系。 定义算法模板类API 1234567891011121314151617181920212223242526272829303132333435363738394041424344public abstract class Example { /** * 具体排序算法实现 */ public abstract void sort(Comparable[] a); /** * 对元素进行比较 * @return first &lt; second ? true : false */ public static boolean less(Comparable first, Comparable second) { return first.compareTo(second) &lt; 0; } /** * 把两个元素交换位置 */ public static void exch(Comparable[] a, int i, int j) { Comparable tem = a[i]; a[i] = a[j]; a[j] = tem; } /** * 返回序列是否有序（asc） */ public static boolean isSorted(Comparable[] a) { for (int i = 1; i &lt; a.length; i++) { if (less(a[i], a[i - 1])) { // 后面的元素 &lt; 前面的元素 不是升序排列 返回false return false; } } return true; } public static void show(Comparable[] a) { for (int i = 0; i &lt; a.length; i++) { StdOut.print(a[i] + \" \"); } StdOut.println(); }} 选择排序首先在数组中找到最小的元素，将其和第一个元素交换；然后继续在第一个元素之后的元素中寻找最小元素，将其和第二个元素交换… 循环往复直到将整个数组排序。 外循环遍历数组的每个当前元素 内循环遍历当前元素之后的所有元素寻找最小值 算法分析优点：数据移动次数最少，选择排序的交换次数和数组长度N成线性关系，其他排序算法不具备该特征。 缺点：运行时间与输入（整个序列的值）无关，一个值相同的或有序的序列和一个随机无序的序列进行排序的时间一样长。 123456789101112131415161718192021public class Selection extends Example { @Override public void sort(Comparable[] a) { int N = a.length; for (int i = 0; i &lt; N; i++) { int minIndex = i; for (int j = i + 1; j &lt; N; j++) { if (less(a[j], a[minIndex])) { minIndex = j; // 如果后续元素小于最小元素，把后续元素索引赋给最小元素索引。 } exch(a, i, minIndex); // 交换原最小元素与新最小元素位置 } } } public static void main(String[] args) { String[] a = new In().readAllStrings(); new Selection().sort(a); assert isSorted(a); // 验证：确认排序后的算法是有序的，当序列元素相同时无法通过验证。 show(a); }} 插入排序将当前元素插入到当前元素之前的合适位置 首先从数组的第二个元素（目标元素）开始，当目标元素小于前面的元素，交换两者位置（否则不变）；然后目标元素变为第三个元素，将其与第二个元素比较，若小则交换位置（此时目标元素索引为1），再将其与第一个元素对比，循环往复… 外循环遍历每一个需要插入的目标元素 内循环将目标元素与其左边的每一个元素对比、交换位置，直至目标元素被插入到了合适的位置。 目标元素（a[i]）从左到右移动时，其左侧的元素始终时有序的，当其移动到了最右边，数组也完成了排序。 算法分析插入排序所需的时间取决于数组中元素的初始位置。因为当元素有序时不会进行交换，对于一个元素很大的且元素有序（或接近有序）的序列进行排序会比随机顺序的序列进行排序要快得多。 12345678910111213public class Insertion extends Example { @Override public void sort(Comparable[] a) { int N = a.length; for (int i = 1; i &lt; N; i++) { // 将当前元素 a[i] 与 其左边的所有元素对比、交换位置 for (int j = i; j &gt; 0 &amp;&amp; less(a[j], a[j - 1]); j--) { // 后面的元素比前面的元素小才进行排序 exch(a, j, j - 1); } } }} 大幅度提高插入排序的速度，只需要在内循环中将较大的元素向右移动而不总是交换两个元素（这样访问数组的次数会减半），实现见 练习。 12345678910111213public class Ex25 extends Example { public void sort(Comparable[] a) { int n = a.length; for (int i = 1; i &lt; n; i++) { Comparable target = a[i]; // 保存目标元素的值 int j; // 保存目标元素应该插入的位置 for (j = i; j &gt; 0 &amp;&amp; less(target, a[j - 1]); j--) { a[j] = a[j - 1]; // 前驱元素后移 } a[j] = target; } }} 选择排序与插入排序比较从直观上来说： 选择排序不会访问索引左侧的元素（每次都是从目标元素的索引右边遍历所有元素取最小值进而与目标元素交换位置） 插入排序不会访问索引右侧的元素（每次都是目标元素与其左边的每一个元素做对比进而交换位置） 首先规定输入模型：数组中的元素随机排序，且主键值不重复。 速度对比： 1000条数据排序100次，选择排序花费0.4s，插入排序花费0.1s； 10000条数据排序100次，选择排序花费43.6s，插入排序花费10.2s； 结论： 对于随机排序的无重复主键，插入排序和选择排序的运行时间都是平方级别的。 123456789101112131415161718192021222324252627282930313233343536public class SortCompare { public static double time(String alg, Comparable[] a) { StopWatch watch = new StopWatch(); if (alg.equals(\"Insertion\")) { new Insertion().sort(a); } if (alg.equals(\"Selection\")) { new Selection().sort(a); } return watch.elapsedTime(); } //使用alg算法将长度为N的数组排序T次 public static double timeRandomInput(String alg, int N, int T) { double total = 0.0; Double[] a = new Double[N]; // 目标数组 for (int t = 0; t &lt; T; t++) { for (int i = 0; i &lt; N; i++) { a[i] = StdRandom.uniform(); // 生成随机值 } total += time(alg, a); // 计算T次时间总和 } return total; } public static void main(String[] args) { String alg1 = args[0]; String alg2 = args[1]; int N = Integer.parseInt(args[2]); int T = Integer.parseInt(args[3]); double t1 = timeRandomInput(alg1, N, T); // 算法1的总时间 double t2 = timeRandomInput(alg2, N, T); // 算法2的总时间 StdOut.printf(\"the %s algorithm takes %.1f seconds.\\n\", alg2, t2); StdOut.printf(\"the %s algorithm takes %.1f seconds.\\n\", alg1, t1); }} 希尔排序希尔排序是插入排序的增强版，是为了改进插入排序对于处理大规模乱序数组排序速度过慢的问题。实质上是分组插入排序，该方法又称缩小增量排序。 该方法的基本思想是：先将整个待排元素序列分割成若干个子序列（由相隔某个“增量”的元素组成的）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序。因为直接插入排序在元素基本有序的情况下（接近最好情况），效率是很高的，因此希尔排序在时间效率上比前两种方法有较大提高。 序列分组轨迹图： 参考：https://blog.csdn.net/IWantToHitRen/article/details/51583047 对于希尔排序和插入排序速度的对比： 10000条数据排序100次，插入排序用时12.3s，希尔排序用时0.3s!； 50000条数据排序100次，插入排序用时380.7s，希尔排序用时1.8s!； 以下是结合网上对希尔排序的理解实现的算法以及《算法 第四版》原文中的算法。 12345678910111213141516171819202122232425262728293031323334353637383940public class Shell extends Example { /** * 根据网上总结自己实现的算法 */ @Override public void sort(Comparable[] a) { int N = a.length; for (int gap = N / 2; gap &gt; 0; gap /= 2) { // gap：增量（步数），每次循环增量减少一倍，直至增量为1（此时对全部元素进行插入排序）完成排序。 for (int i = 0; i &lt; gap; i++) { // 把整体序列分为若干子序列。a[i]是每一组的第一个元素 for (int j = i + gap; j &lt; N; j += gap) { // 每间隔一个增量，获得一个该组的元素。 int tarIndex = j; // 目标元素索引，当前元素索引。 for (int k = tarIndex; k &gt; i &amp;&amp; less(a[k], a[k - gap]); k -= gap) { // 对子序列进行插入排序，将该元素与本组左边所有元素进行比较。 exch(a, k, k - gap); } } } } } /** * 原文的算法，增量使用了递增序列，有时间再来理解。 */ public void sort3(Comparable[] a) { int N = a.length; int h = 1; while (h &lt; N / 3) { h = 3 * h + 1; } while (h &gt;= 1) { // 子数组插入排序 for (int i = h; i &lt; N; i++) { for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j - h]); j -= h) { exch(a, j, j - h); } } h = h / 3; } }} 归并排序归并排序的核心是归并操作，归并排序每次将数组 递归的 拆分成两半分别排序，再将两半的结果 合并 起来最终实现整个数组的排序。 归并操作归并操作的前提是数组的两边是分别 有序 的，将一个“两边有序的数组”合并成一个“整体有序的数组”。 1234567891011121314151617181920212223242526public class Merge extends Example { private static Comparable aux[]; // 辅助数组，用于合并操作。 //TODO sort() public static void merge(Comparable[] a, Comparable[] aux, int lo, int mid, int hi) { int le = lo; int ri = mid + 1; for (int k = lo; k &lt;= hi; k++) { aux[k] = a[k]; } for (int k = lo; k &lt;= hi; k++) { if (le &gt; mid) { a[k] = aux[ri++]; // 左边元素用尽，将右边元素一个一个放入a[] } else if (ri &gt; hi) { a[k] = aux[le++]; // 右边元素用尽，将左边元素一个一个放入a[] } else if (less(aux[ri], aux[le])) { a[k] = aux[ri++]; // 右边元素小于左边元素，右边元素放入a[]，右边元素索引+1 } else { a[k] = aux[le++]; // 左边元素小于右边元素，左边元素放入a[]，左边元素索引+1 } } }} 自顶向下归并排序归并排序不断（递归）的将大数组插拆分为两半，直到不可再拆（小数组仅剩“左右”两个元素），再将两边的数组合并成一个整体有序的大数组。 1234567891011121314151617public class Merge extends Example { private static Comparable aux[]; // 辅助数组，用于合并操作。 @Override public void sort(Comparable[] a) { aux = new Comparable[a.length]; sort(a, 0, a.length - 1); } private void sort(Comparable[] a, int lo, int hi) { if (hi &lt;= lo) return; int mid = lo + (hi - lo) / 2; sort(a, lo, mid); // 左半边排序 sort(a, mid + 1, hi); // 右半边排序 merge(a, aux, lo, mid, hi); // 合并子数组 }} 每一个节点都是 merge() 操作形成的子数组。当数组不可再分（递归到了最小情况），merge()通过交换前后元素实现排序。 改进对于小规模数组使用插入排序 测试数组是否有序 有参考价值博客：图解排序算法(四)之归并排序 自底向上归并排序先归并微型数组，再成对归并得到的子数组，直到归并形成一个大数组，排序结束。 第一轮：将大数组的每一个元素当作一个子数组（最小的子数组），两两归并 子数组（将大小为1的子数组归并成大小为2的子数组）。 第二轮：一轮归并之后每个子数组存在 2 个元素，再 四四归并 子数组（将大小为2的子数组归并为大小为4的子数组）。 第三轮：二轮归并之后每个子数组存在 4 个元素，再 八八归并 子数组（将大小为4的子数组归并为大小为8的子数组）。 …… 如此往复，直到子数组大小 &gt;= 待排序的大数组，完成了排序。 123456789101112131415161718192021222324public class MergeBU extends Example { private static Comparable aux[]; @Override public void sort(Comparable[] a) { int N = a.length; aux = new Comparable[N]; for (int sz = 1; sz &lt; N; sz = sz + sz) { // 控制子数组大小呈倍数递增 /** * 遍历每个子数组 * lo 每个子数组的第一个元素 * lo &lt; N - sz 控制最后一个子数组的开头 * lo = lo + sz + sz 跳到下一个子数组开头 * Math.min(lo + sz + sz - 1, N - 1) 最后一个子数组的大小有可能不是sz的整数倍，lo + sz + sz - 1可能会出现数组越界。 */ for (int lo = 0; lo &lt; N - sz; lo = lo + sz + sz) { int mid = lo + sz - 1; int hi = Math.min(lo + sz + sz - 1, N - 1); merge(a, aux, lo, mid, hi); } } assert isSorted(a); }} 可视图： 快速排序快速排序同归并排序一样是一种分治的排序算法。它通过 切分 递归的将数组分为两个部分，对两个部分分别排序，并保证左边的元素都 &lt;= 切点，右边的元素都 &gt;= 切点。 每次切分都能保证子数组左边的元素小于切点，右边的元素大于切点。通过递归，对左半边和右半边数组再次切分，最终达到整个数组的有序。 切分算法： 切点定为子数组的第一个元素（可以是任意元素） 指针 i 从左往右扫描 大于 切点的值，找到即退出扫描；指针 j 从右往左扫描 小于 切点的值，找到即退出扫描。 交换 a[i] 与 a[j] 的位置，小的值放在左边，大的值放在右边。 若 i 扫描完毕找不到最大值，说明 切点 就是最大值；若 j 扫描完毕找不到最小值，说明 切点 就是最小值 为什么指针相遇(i &gt;= j)切分结束？因为相遇了代表所有元素都已遍历完毕。 指针相遇（双向扫描完毕）之后，交换 切点(v) 与 a[j] 的值，此时a[j]是最后一个小于 v 的值，而切点到了数组中间，最后返回切点索引。 博客参考，对于理解很有帮助：坐在马桶上看算法：快速排序 12345678910111213141516171819202122232425262728293031public class Quick extends Example { @Override public void sort(Comparable[] a) { StdRandom.shuffle(a); sort(a, 0, a.length - 1); } private void sort(Comparable[] a, int lo, int hi) { if (hi &lt;= lo) return; int j = partition(a, lo, hi); // 切分 sort(a, lo, j - 1); // 左半边排序 sort(a, j + 1, hi); // 右半边排序 } private int partition(Comparable[] a, int lo, int hi) { int i = lo, j = hi + 1; // 左右扫描的指针 Comparable v = a[lo]; // 切分的元素 while (true) { while (less(a[++i], v)) { // 指针 i 从左往右扫描大于v的值 if (i == hi) break; } while (less(v, a[--j])) { // 指针 j 从右往左扫描小于v的值 if (j == lo) break; } if (i &gt;= j) break; // 为什么 i &gt;= j 退出外循环？ exch(a, i, j); // 小值放左边，大值放右边。 } exch(a, lo, j); return j; }} 快速排序最好的情况下是每次都正好能将数组对半分，这样递归调用次数才是最少的。 最坏的情况下，第一次从最小的元素切分，第二次从第二小的元素切分，如此这般。为了防止数组最开始就是有序的，在进行快速排序时需要随机打乱数组。 改进 对于小数组，使用插入排序。只需将递归结束条件从 if (hi &lt;= lo) return; 改为：if (hi &lt;= lo + 15) { new Insertion().sort(a); return; } 三取样切分：选取较优的切点元素来提高性能。将子数组的一小部分元素中的中位数作为切点来切分数组效果为好，一般取3个元素。参考：图解排序算法(五)之快速排序——三数取中法 对于含有大量重复元素的数组，该算法还是会继续切分数组，增加不必要的性能开销。解决方案：三向切分算法：Quick3way.java 以上改进 均未！实现！太搞脑子了😣~~~ 优先队列在某些拥有大量输入N（数十亿甚至无限）的用例中，需要在大量输入中取最大（或最小）的前M个值。解决这种需求，数组排序的代价特别高昂，原因有2点：1. 数据量特别大，不可能将十亿个数放进数组排序，有可能内存都装不下；2. 只需要取前M的有序的值，并不需要将所有数据排序，甚至都无法获取全部的数据。 优先队列可以解决这类问题，有了优先队列，只需要创建一个大小为M的队列即可代替创建大小为总数据量N的数组。 API 方法 描述 MaxPQ() 创建一个优先队列 MaxPQ(int max) 创建一个初始容量的优先队列 MaxPQ(Key[] arr) 用arr[]中的元素创建一个优先队列 void insert(Key v) 向优先队列插入一个元素 Key max() 返回最大元素 Key delMax() 删除最大元素 boolean isEmpty() 判断是否为空 int size() 查看队列大小 初级实现基于无序数组的优先队列：MaxPQ4DisArray.java 基于有序数组的优先队列：MaxPQ4Array.java 基于无序链表栈的优先队列：MaxPQ4Linked.java 基于堆的优先队列二叉堆的定义与表示法 二叉堆（完全二叉树，之不过在这叫做堆）是一种基于数组的数据结构。既然是树形结构，必然有一个根节点，根节点下面挂着（一个或）两个子节点，每个子节点作为父节点又挂着两个子节点。同级节点之间无关顺序，父节点大于等于子节点。当一个二叉树的每个节点都大于等于它的两个子节点时，被称之为“堆有序”。 如何用数组存储具有层级顺序关系的二叉堆呢？ 首先，二叉堆在数组中按索引位置 1 开始存储（不使用数组的第一个元素） 在一个堆中位置 k 的节点的父节点的位置为 k/2，而它的两个子节点的位置分别为 k*2, K*2+1，这样就可以通过计算索引在树中上下移动。 二叉堆表示： 二叉堆在数组中的存储结构： 用长度为 N+1 的数组 pq[] 来表示一个大小为 N 的堆，因为堆元素存放与 pq[1]到pq[N]之中，所以实际数组的长度要是堆的元素大小+1。 由下至上的堆有序化（上浮）当堆的有序化因为某个节点变得比其父节点更大而被打破，我们需要交换该节点和其父节点来修复堆。交换后该节点比它的两个子节点（一个是交换之前的父节点，另一个比它更小，因为是旧父节点的子节点）都要大了，但该节点仍然有可能比现在的父节点要大，所以需要再一次交换，使得该节点不断上浮直到遇到了更大的节点或到达堆顶。 123456789public class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt; implements IMaxPQ&lt;Key&gt; { //...... public void swim(int k) { while (k &gt; 1 &amp;&amp; less(k / 2, k)) { exch(k / 2, k); k = k / 2; } } } 由上至下的堆有序化（下沉）下沉与上浮相反，当有序状态因为某个节点变得比它的两个（或其中之一）子节点要小被打破，那么需要交换该节点与其较大的一个子节点来保持平衡。倘若交换之后该节点仍比现在的子节点之一要大，继续交换，直至向下交换到该节点的子节点都比它小或到达堆的底部。 疑问：“父节点怎么会变得比子节点要小呢？添加一个元素在数组末尾时会通过上浮移动到合适的位置的啊。” — 这跟删除最大元素的算法有关，移除堆顶元素时，会用数组的最后一个元素替补最大元素，所以此时存在元素下沉的必要。 123456789101112public class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt; implements IMaxPQ&lt;Key&gt; { //...... public void sink(int k) { while (2 * k &lt;= N) { int j = 2 * k; if (j &lt; N &amp;&amp; less(j, j + 1)) j++; if (!less(k, j)) break; exch(k, j); k = j; } } } 堆的上浮与下沉： 优先队列实现理解了上浮和下沉，优先队列核心的两个api就能实现了，对于 插入元素，只需将元素添加到数组末尾，增加堆的大小并让新元素上浮到合适的位置；对于 删除最大元素，我们从数组顶端去除最大元素，并将数组最后一个元素放到顶端，减少堆的大小并让元素下沉到合适的位置即可。 12345678910111213141516171819202122232425262728293031323334353637public class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt; implements IMaxPQ&lt;Key&gt; { private Key[] pq; // 基于堆的完全二叉树 private int N; // 堆元素数量 @Override public void insert(Key v) { if (N == pq.length - 1) resize(pq.length * 2); pq[++N] = v; swim(N); } @Override public Key delMax() { if (isEmpty()) throw new NoSuchElementException(\"Priority queue underflow\"); Key max = pq[1]; exch(1, N--); pq[N + 1] = null; // 防止对象游离 sink(1); if (N &gt; 0 &amp;&amp; (pq.length - 1) / 4 == N) resize(pq.length / 2); return max; } @Override public Key max() { if (isEmpty()) throw new NoSuchElementException(\"Priority queue underflow\"); return pq[1]; } private void resize(int max) { assert max &gt; N; Key[] temp = (Key[]) new Comparable[max]; for (int i = 1; i &lt; N + 1; i++) { temp[i] = pq[i]; } pq = temp; }} 基于堆的优先队列API能够保证插入元素和删除最大元素的用时和队列的大小仅成对数关系。 索引优先队列二叉树存储的不是元素值，而是元素值的key；通过这个 key 在元素数组 element[] 中找到元素值；用keyIndex[]存储key的索引。 先补点智商，干了这碗鸡汤：索引优先队列的工作原理与简易实现 提醒：前方高能！！！传送门 堆排序以优先队列实现的排序算法，将原始数组元素放入一个优先队列中，由于在队列中可以轻易的获得最大值，每次获取的最大值可以组成一个递减序列。如果获取的最大值不删除，而是将其和队列的最后一个元素交换，第二次将新的最大值与数组的倒数第二个值交换，循环往复，直至数组元素遍历完，排序完成。 堆的构建将原始数组元素组成一个完全二叉树结构，一个简单的方式就是将数组 从左至右 执行 上浮 操作，直至每个元素放到了合适的位置。 上浮操作生成堆会扫描数组的每一个元素，更好的方式是 从右至左 执行 下沉 操作，它只需要扫描数组一半的元素，因为不需要比较叶子节点。 排序交换堆顶元素和最后一个元素，每次交换之后重新下沉以维持堆的有序状态。 由于在堆结构中不使用数组的第一个位置的元素，导致原始数组的第一个元素值必须为null，要以正常存储的方式使用堆排序，只需要在 less() 和 exch() 中将传入的索引-1即可。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class Heap { public void sort(Comparable[] a) { int n = a.length - 1; // 构造堆 sinkGenerationHead(a, n);// swimGenerationHead(a, n); // 堆排序 while (n &gt; 1) { exch(a, 1, n--); sink(a, 1, n); } } //下沉生成大顶堆（最优） public void sinkGenerationHead(Comparable[] a, int n) { for (int i = n / 2; i &gt;= 1; i--) { // 从右到左 sink(a, i, n); } } // 上浮生成大顶堆 public void swimGenerationHead(Comparable[] a, int n) { for (int k = 0; k &lt; n; k++) { // 必须是从左到右 swim(a, k, n); } } public void sink(Comparable[] a, int k, int n) { while (2 * k &lt;= n) { int j = 2 * k; if (j &lt; n &amp;&amp; less(a, j, j + 1)) j++; if (!less(a, k, j)) break; exch(a, k, j); k = j; } } public void swim(Comparable[] a, int k, int n) { while (k &gt; 1 &amp;&amp; less(a, k / 2, k)) { exch(a, k / 2, k); k = k / 2; } } private boolean less(Comparable[] a, int i, int j) { return a[i].compareTo(a[j]) &lt; 0; } private void exch(Comparable[] a, int i, int j) { Comparable tem = a[i]; a[i] = a[j]; a[j] = tem; } public static void main(String[] args) { Comparable[] a = new Comparable[]{null, 2, 0, 5, 7, 9, 8, 3, 1, 4, 6}; Heap heap = new Heap(); heap.sort(a); for (int i = 0; i &lt; a.length; i++) { StdOut.print(a[i] + \" \"); } }} 总结在java中的排序都是基于指针的，除了原始数据类型以外，我们操作的都是数据的引用（指针），而非数据本身。指针排序增加了一层间接性，因为数组保存的是待排序对象的引用，而非对象本身。 在一些情况下，对于排序之后的数据要求不可改变键值，如果能修改，那么数组将不再有序。类似的，优先队列在能改变键值的情况下也不太可能正常工作（索引优先队列能改变键值并维持有序是每次改变之后都进行上浮下沉操作）。限定排序元素不可变可以使用java的不可变数据类型，如八大封装类型和String，以及自定义的不可变数据类型（不可变类型：实例变量以private、final修饰；不提供setter方法；提供带参构造器以初始化实例变量）。 在java中实现任意数据类型排序的方法就是实现Comparable接口，重写其compareTo方法。但当我们对该数据类型的排序方法有多个时，我们可以创建一个比较器对象，使其实现Comparator接口，重写compare方法，进行比较时根据需求传入不同Comparator接口的实现即可。 如果一个排序算法能够保留数组中重复元素的相对位置则可以被称之为 稳定的，对于排序算法稳定性的要求在某些场景尤为重要。 对于前面学习过的各种排序算法的性能特点如下： 算 法 是否稳定 是否为原地排序 时间复杂度 空间复杂度 备 注 选择排序 否 是 N^2 1 插入排序 是 是 介于N和N^2之间 1 取决于输入元素的排列情况 希尔排序 否 是 NlogN? N^(6/5)? 1 快速排序 否 是 NlogN lgN 运行效率由概率提供保证 三向快速排序 否 是 介于N和NlogN之间 lgN 运行效率由概率保证，同时也取决于输入元素的分布情况 归并排序 是 否 NlogN N 堆排序 否 是 NlogN 1 大多数情况下，快速排序是最好的选择。但是如果稳定性很重要而空间不是问题的情况下，归并排序可能是最好的。 java 函数库中对原始数据类型使用三向切分快速排序，对于引用类型使用归并排序。这么做也印证着用速度和空间（对于原始数据类型）来换取稳定性（对于引用类型）。","link":"/2018/08/14/算法第二章 排序/"},{"title":"高性能 MySql —— 学习笔记","text":"读《高性能 MYSQL》笔记，仅用回顾复习作用，不能具备参考价值。 Table Of Contens 第一章 架构与历史 Mysql 逻辑架构： 并发控制 读写锁 锁粒度 事务 隔离级别 第四章 Schema 与 数据类型优化 整数类型 \b实数类型 字符串类型 时间类型 位类型 特殊类型 \b\bSchema 设计的\b陷阱 范式与反范式 第五章 创建高性能的索引 索引的类型 B-Tree 索引 哈希索引 空间数据索引（R-Tree） 全文索引 索引的优点 正确的创建和利用索引 独立的列 前缀索引和索引选择性 选择合适的索引列的顺序 聚簇索引 覆盖索引 第六章 \b查询性能优化 查询慢的因素 优化数据访问 是否请求了不需要的数据 Mysql 是否在扫描额外的记录 重构查询方式 一个复杂查询还是多个简单查询 切分查询 分解关联查询 查询执行的基础（查询\b的内部机制） Mysql 客户端 / 服务端通信协议 查询缓存 \b查询优化处理 第一章 架构与历史Mysql 逻辑架构： 第一层是连接处理，\b并非是 Mysql 独有，大多数应用都有类似的架构。比如连接、授权、安全等。 第二层是 Mysql 核心功能\b层，包括解析、分析、优化、缓存以及内置函数（日期、时间、数学、加密）等。所有跨存储引擎的功能也在这一层实现如：触发器、视图、存储过程等。 第三层包含存储\b引擎，负责 Mysql 中数据的存储与提取。每一种\b存储引擎都有各自的优势与劣势，\bmysql 服务器通过 API 与存储引擎通信，这些 API 屏蔽了不同存储引擎之间的差异，使得这些差异对上层的查询透明。存储引擎不会去解析 SQL，不同存储引擎之间也不会互相通信，只是响应上层 mysql 服务器的请求。 并发控制只要有多个查询在同一时刻操作数据，就有会有\b并发问题。Mysql 可以从服务层和存储引擎层控制并发。 读写锁读写锁也称为共享锁和排它锁，读锁是共享的（互不阻塞的），多个连接可以同时读取同一份资源而不产生并发问题；写锁是排它的（一个写锁会阻塞其他写锁和\b读锁），这有这样才会保证给定时间内只有一个用户可以\b执行操作，并防止其他用户读取正在写入的数据。 锁粒度加锁操作（如：加锁、检查锁是否释放、释放锁等\b）都是会消耗系统资源的，如果花费大量的时间来管理锁而不是存储数据，那么系统性能也会受到影响。 因此一种提高并发性能\b的方案是让锁定对象更有选择性，尽量锁定部分数据而不是全部资源。\b锁定的资源越少，并发控制的性能越高。 锁策略是指在锁的开销和数据安全之间\b寻求\b平衡。Mysql 提供多种选择，每一个存储引擎都\b实现了自己的锁策略和锁粒度。 表锁Mysql 最基本的锁策略，也是锁开销最小的策略，对数据的写操作（插入、更新、删除）会锁定整张表。当拥有一个写锁时，将阻塞其他连接对数据的读写操作，直至写锁释放。读锁是互不阻塞的。 行锁行锁可以最大程序的支持并发，同时也带来了锁的开销。行级锁只在存储引擎中实现，mysql 服务器层没有实现，服务器层不了解存储引擎的锁实现。 事务事务是一组原子性的 SQL 查询，是一个独立的工作单元。事务中的 SQL 语句要么全部成功，要么全部失败。 一个良好的事务处理系统必须具备 ACID 标准，不基于 ACID 标准谈事务的概念是没有意义的。 ACID 即：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。 「原子性」 一个事务被视为一个独立的工作单元，事务中的操作要么提交成功，要么全部失败回滚，不可能只执行其中一部分操作。 「一致性」 数据库总是从一个状态到另一个状态的变化。若事务提交成功，A 状态到了 B 状态；若事务执行失败，回到 A 状态；不存在第三种状态 C。 「隔离型」 通常来说，一个事务所做的修改在提交成功之前，对其他事务是不可见的。隔离性是四个性质中最复杂的一个，其中细分了许多 「隔离级别」。 「持久性」 一旦事务提交了，所做的修改将永久保存到数据库中，即使系统崩溃，修改的数据也不会丢失。当然这是理想的情况，很多时候不能够保证 100% 的持久性。 隔离级别SQL 标准定义了四种隔离级别，每一种级别中都规定了一个事务所做的修改，哪些在事务内和事务见是可见的，哪些是不可见的。较低的隔离通常可以执行更高 的并发，系统开销也会更低。 「READ UNCOMMIT 未提交读」事务中的修改，即使没有提交，对其他事务也是可见的。这也叫做脏读（drity read），这个级别会导致很多问题，很少使用这个级别。并且从性能上来说，read \buncommit 不会比其他\b级别高出多少，但是缺少了其他级别的很多\b优势。 「READ COMMIT 提交读」大多数数据库隔离级别都是 read commit，但 Mysql 不是。 read commit 满足事务隔离性的基本定义，一个事务\b开始时只能看到已经提交的\b事务所做的修改。 read commit 也叫做「不可重复读」，两次执行相同的查询，可能得到不同的结果。 「REPEATABLE READ 可重复读」Mysql 的默认隔离级别。 该级别解决的脏读并且支持可重复读（同个事务中多次读取同样的记录的结果是一致的）。不过无法解决「幻读」问题，即当一个事务读取某个范围的记录时，另一个事务插入了新的记录，\b该事务再次读取会出现幻行。 不过 InnDB \b存储引擎通过多版本并发控制（MVVC）解决了幻读。 「SERIALIZABLE 可串行化」最高的隔离级别，强制事务\b\b串行执行。serializable 会给每一行数据加锁，所以可能导致大量超时和锁占用。除非非常需要确保数据一致性并且不需要并发情况，否则不考虑使用该级别。 各个隔离级别\b比较： 隔离级别 脏读可能性 不可重复读可能性 幻读可能性 加锁读 READ UNCOMMIT yes yes yes no READ COMMIT no yes yes no PEREATABLE READ no no yes no SERIALIZABLE no no no yes 第四章 Schema 与 数据类型优化选择数据类型的几种原则： 1）更小的通常更好更小的数据类型\b\b速度越快，占用更少的磁盘、内存和 CPU 缓存。但最好\b确保数据类型将不会扩充，因为扩大\b\b数据类型的范围是十分耗时和消耗资源的操作。 2）简单就好简单的数据类型通常需要更少的 CPU 周期。\b整型比字符型的操作代价要低，这是由于字符型的校对和排序规则比整型更复杂导致的。 能用 Mysql 内置的时间类型就不用字符串，用整型存储 IP 地址不要用字符串。 3）避免使用 \bNULL可为 NULL 的列会使得索引、索引统计、比较变得复杂，Mysql 需要\b更多的空间对 NUll 列做\b特殊处理。 NULL 列不要\b用作索引。 整数类型数字类型分为整数和实数，整数的几种 MYSQL 类型如下： 类型 占用位数 字节 TINYINT 8 1 SMALLINT 16 2 MEDIUMINT 24 3 INT 32 4 BIGINT 64 8 整数类型分为有符号和无符号（UNSIGNED），无符号表示不支持负数。使用无符号大约可以使存储空间提高一倍。 有符号和无符号使用相同的存储空间，具有相同的性能，可以根据实际情况选择。 Mysql 中可以给整数指定宽度，如 INT(11)，但对大多数应用来说是没有意义的。它没有限制数的存储范围，而只是规定在一些 MYSQL 客户端工具中显示的字符的宽度。对于存储和计算来收，INT(1) 和 INT(11) 是没有区别的。 \b实数类型实数是带有小数的数字。MYSQL 中支持的类型有 「浮点类型（float / double）」 和 「Decimal 类型」。 类型 字节数 \b位数 float 4 32 double 8 64 decimal 16 128 浮点类型是不精确类型，不支持精确计算，存储同样范围的值占用空间较 decimal 少； decimal 类型是精确类型，可存储精确小数，支持精确计算（Mysql 5.0 开始），但计算代价较高。 decimal(a,b) a 指定小数点左边和右边可以存储的十进制数字的最大个数，最大精度38。 b 指定小数点右边可以存储的十进制数字的最大个数。小数位数必须是从 0 到 a 之间的值。默认小数位数是 0。 建议： 1. 只指定\b数值类型，不指定精度。 2. 尽量在\b只对小数计算时才使用 Decimal，数据量\b大情况下最好是使用 BIGINT 代替 DECIMAL。\b 小数按倍数相乘之后存入\b数据库，取出时按倍数相除即可。 字符串类型VARCHAR &amp; CHARvarchar 比 char 更节省空间，一定程度上也提高了性能，因为仅使用必要的空间。但由于行是变长的，做更新操作可能时会比 vhar 多做一些额外操作。 char 是变长的，根据定义的字符串的长度分配固定的空间，当存储的\b值少于固定长度时以空格填充。char 类型适合用于存储\b长度短、值的长度固定的如 MD5 加密后的密码，因为\b是定长的，不易产生碎片，特定类型的数值存储效率比 varchar 要高。 BINARY &amp; VARBINARYbinary 和 varbinary 与 char 和 varchar 类似，只不过 binary、varbinary 存储的是二进制字符\b串。二进制字符串与普通字符串类似，不过存储的\b是\b字节码而不是字符。 BLOB &amp; TEXT存储大数据量的字符串类型，分别存储二进制大字符串和普通文本大字符串。 BLOB 类型有：TINYBLOB、SMALLBLOB、BLOB、MEDIUMBLOB、BIGBLOB。 TEXT 类型有：TINYTEXT、SMALLTEXT、TEXT、MEDIUMTEXT、BIGTEXT。 时间类型DATETIME能保存较大范围的值，从 1001 年到 9999 年，精度为秒。与时区无关，\b使用 8 个字节存储。 TIMESTAMP该类型保存了从 1970 \b年 1 月 1 日午夜以来\b的描述，表示的范围为 1970 年到 2038 年。只占用 4 个字节。与时区相关。 除了特殊情况之外，尽量使用 TIMESTAMP，因为它比 DATETIME 空间利用效率更高。 位类型Mysql 5.0 之前，BIT 与 TINYINT 没有区别，\bMYSQL 5.0 之后这两者是不同的\b数据类型。 BIT 最大支持 64 \b个位，Mysql 将 BIT 视为字符串类型，当检索 bit(1) 时，返回的是二进制 的 0 或 1 的字符串，而不是数字。 注意：在数字上下文中检索时，会将\b字符串转为数字。如：存储值为 b’00111001’（二进制等于57）的列检索时会得到 57 的字符串，然后根据 57 \b在 ASCII 码中的位置得出数字 9。这通常不是我们需要的。因此应尽量避免使用这个类型。 特殊类型如 IP 地址，应该用无符号整数来存储。IP 之间的小数点只是为了让人们利于区分，MYSQL 提供 INET_ATON() 和 INET_NTOA() 函数在这两者之间转换。 \b\bSchema 设计的\b陷阱 避免设计\b太多的列 避免滥用枚举 避免太多的关联 尽量避免设计可为 NULL 的列，但有时必须这样做。 范式与反范式范式的优点： 范式化的更新操作通常比反范式化要快。 范式化很少有重复数据。 范式化的表通常更小，可以更好的放在内存里，执行会更快。 有很少的数据意味着检索列时需要更少的 DISTINCT 或者 GROUP BY 语句。 范式的缺点：通常需要关联，代价\b昂贵 ，可能使得索引策略无效。 最佳的设计是混合范式化与反范式化 第五章 创建高性能的索引索引是存储引擎用于快速找到记录的一种数据结构，设计良好的索引比不好的索引可能要好几个量级。在 Mysql 中，存储引擎先在索引中搜索对应的值，再根据匹配的索引记录找到对应的数据行。 索引可以包含一个或多个列，如果包含多个列，那么列的顺序十分重要，因为 Mysql 只能高效的使用索引最左前缀的列。创建一个包含多列的索引和创建多个只包含一个列的索引是大不相同的。 索引的类型索引有很多类型，不同的类型可以为不同的场景提供更好的性能。在 Mysql 中，索引是存储在存储引擎层而不是在服务层实现的，所以没有统一的索引标准。 B-Tree 索引B-TREE 索引是大多数 MYSQL 存储引擎使用的索引类型，InnoDB 使用就是 B-TREE。这类索引适用于「全键值」「键值范围」「键前缀」查找，键前缀查找只适用于根据最左前缀查找。B-Tree 是最常见的索引，支持按顺序存储数据，所以可以用来做 GROUP BY 和 ORDER BY 操作。以下查询类型使用 B-Tree 会十分有效： 1）全值匹配利用索引中所有的列进行匹配的查询。 2）匹配最左前缀对于多个列组成的索引，匹配最左列的查询使用 b-tree 效率很高。 3）匹配列前缀匹配某个列的值的开头部分，如 first_name 是最左列，查找姓从 J 开头的人的查询会走索引。这里的匹配列前缀是在最左前缀前提下的。 4）精确匹配某一列并范围匹配另外一列这些必须都是索引列的一部分。 5）只访问索引的查询查询只访问索引，不访问其他数据行。 因为索引数的节点都是有序的，所以除了按值查找之外，还可以用来查询之中的 ORDER BY 操作。如果 ORDER BY 字句满足上述查询要求，那么索引也可以满足对应的排序需求。 B-Tree 的限制： 不是按最左列的查询不会走索引。 不是列前缀的查询也不会走索引，如查找名字以 J 结尾的用户。 不能跳过索引中的列查询。即如果查询条件中只包含索引的第一列和最后一列，那么索引只会利用第一列。 如果查询中有某个列的范围查找，则右边的所有列都无法利用索引优化查找。 B-Tree 索引中，索引列的顺序对索引的查询效率十分重要，有时需要用相同的列但不同的顺序建立索引来满足不同的查询要求。 哈希索引基于哈希表实现，只有精确匹配所有列的查询才会有效。对于每一行数据，存储引擎都会对其中所有的索引列计算一个哈希码。哈希索引将所有的哈希吗存储在索引中，同时在哈希表中保存指向每个数据行的指针。 在 Mysql 中，只有 Memory 引擎显式支持哈希索引。 空间数据索引（R-Tree）MyISAM 引擎支持 R-Tree，可用作地理位置数据存储。这种索引无需前缀查询，可以从所有纬度来检索数据，但必须使用 Mysql 的 GIS 相关函数的支持，Mysql 对此支持并不完善，大部人很少使用这个特性。 全文索引全文索引是一种特殊类型的索引，它查找的是文本中的关键字而不是比较索引中的值。 索引的优点索引可以让服务器快速定位到表的指定位置，并且根据索引的数据结构的不同，也存在一些附加作用。 其优点有： 大大减少服务器需要扫描的数据量 可以帮助服务器避免排序和临时表 可以将随机 I/O 变为顺序 I/O 正确的创建和利用索引独立的列如果查询的列不是独立的，则 Mysql 不会使用索引。“独立的列”是指索引列不能是表达式的一部分，也不能是函数的参数 。 前缀索引和索引选择性有时候索引列是很长的字符串，这会让索引变得大而慢，虽然 MYSQL 可能会隐式的转换成哈希索引，但有时候不足够，另一种方案是采用「前缀索引」。 顾名思义，前缀索引是指 索引只索引列的前面部分值。创建前缀索引需要注意的地方是分配合理的前缀大小，前缀大小决定着索引选择性。 索引选择性是指通过该前缀索引能够过滤掉的行数，选择性越高，过滤的行数越多。例如：唯一索引的选择性是 1，因为通过唯一索引能够精确定位到某一条数据。这是最好的索引选择性，性能也是最好的。 对 BLOB、TEXT、很长的 varchar 必须使用前缀索引，长文本创建前缀索引关键点在于分配多少大小的前缀以保证足够高的选择性，但同时又不能太长（以便节约空间）。 创建前缀索引的语法： 123- column 是列名- n 是前缀索引字符宽度create table ...... add key(column(n)); 选择合适的索引列的顺序当不考虑排序和分组的时候，可以将选择性最高的列放在索引最前列。 聚簇索引覆盖索引如果一个索引\b包含查询中所有的列，称之为「覆盖索引」。 …… 第六章 \b查询性能优化数据库性能的优化是个大工程，库表结构优化、索引优化、查询优化 \b需要一个不漏。 查询慢的因素如果把查询看作一个任务，那么一个查询实际上是由\b许多个子任务组成。每个子任务都会消耗一定的时间。优化查询时间，实际上是\b优化子任务的查询，要么消除其中一些没有必要的子任务，要么减少子任务的查询时间\b\b，要么让子任务运行的更快。 \b除了一个查询含有多个子任务会导致慢之外，网络、CPU计算、数据\b统计、执行分析、锁等待 等因素也是导致查询慢的重要\b原因。 优化数据访问查询性能低下最基本的原因是访问的\b数据太多，大部分的性能低下的查询都可以通过减少\b访问的数据量来优化，以下两个步骤很有效： 确认\b应用程序是否\b在 检索\b 大量超过\b需要的数据。这通常意味着访问了\b大量不需要的行，有时候也可能是访问了太多的列。 确认 Mysql 服务器\b层是否在 分析 大量超过\b需要的数据行。 是否请求了不需要的数据有些查询会请求超过实际需要的数据，然后这些多余的数据会被应用程序丢弃。这会给 Mysql 服务器带来额外的负担，并增加网络开销，也会消耗应用服务器 CPU 和内存的资源。在设计查询中需要注意以下几点： 避免查询不需要的数据。 推荐使用 LIMIT。 多表关联查询时返回全部列。 应该只取需要的数据。 总是取出全部列。 这样做不仅会让优化器无法使用「覆盖索引」扫描优化，\b还会为服务器带来额外的 I/O、\b内存和 CPU消耗。 重复性的查询\b相同的数据 这类情况下考虑使用应用层缓存。 Mysql 是否在扫描额外的记录确定查询只返回需要的数据以后，\b下一个应该注意的是看查询\b为了返回结果是否扫描了\b过多的数据。对于 Mysql，有以下\b几个简单\b的衡量指标： 响应时间 扫描的行数 返回的行数 响应时间响应时间是服务时间和排队时间的总和。服务时间是指数据库真正处理这个查询花费的时间，排队时间是指服务器因为等待某些资源而没有真正执行查询的时间，可能是等 I/O 操作完成，\b也可能是等行锁释放等等。 扫描的行数返回的行数理想情况下扫描的行数和返回的行数应该是相同的，但实际情况是很少的。一般扫描的行数与返回的行数的比率很小，通常在 1:1 和 10:1 之间。 扫描的行数和访问类型Mysql 有好几种方式可以查找并返回同一行结果，不同的方式扫描的行数不经相同，有的不需要扫描。 EXPAIN 语句中的 type 列表示访问类型。访问类型有：全表扫描、索引扫描、范围扫描、唯一索引扫描、常数引用等。这些访问方式速度从慢到快，扫描的行数从小到大。 如果发现查询需要扫描大量的数据但只返回少数的行，通常可以尝试采用以下技巧去优化： 使用索引覆盖扫描，把需要用到的列都放到索引中，这样存储引擎无需回表获取对应的行就可以返回结果了。 改变库表结构。如使用单独的「汇总表」 重写这个复杂查询，让 Mysql 优化器以更优化的方式执行查询。 重构查询方式优化有问题的查询，并不是说一定需要从 Mysql 获取一摸一样的结果集，而是找到一个更优的方式获得结果。比如将查询转换另外一种写法使得性能更好，或者修改应用程序代码换一种方式获得同样的结果。 一个复杂查询还是多个简单查询尽量使用少的查询是好的，但是有时候将一个大的查询分解为多个小查询也是很有必要的。 切分查询将一个大的查询分解成多个查询功能一样、只完成一小部分的小查询，每次只返回一小部分的查询结果。 比如删除旧数据：定期删除大量数据时如果用一个大的语句一次性完成的化，可能需要锁住很多数据、沾满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。因此将一个大的删除语句切分成多个小的删除语句可以尽可能小的影响 Mysql 的性能，同时还可以减少 Mysql 复制的延迟。 分解关联查询将一个关联查询分解，对每一个表进行一次单表查询，然后将结果在应用程序中做关联。使用分解关联查询有很多好处，如： 让缓存效率更高。 很多应用程序可以方便的缓存单表查询对应的结果对象（对多表关联查询的结果做缓存是不切实际的，因为往往多表查询的条件是不断变化的。而对单表做缓存可以最大程序上利用缓存）。而对于 Mysql 本身的查询缓存来说，如果关联的某个表发生变化就无法使用查询缓存了。 将查询拆解后，执行单个查询可以减少锁的竞争。 在应用层做关联，可以更容易的对数据库进行拆分，更容易做到高性能和可拓展。 查询本身效率也会提高。 可以减少冗余记录的查询。 在应用层做关联查询，意味着对于某条记录应用只需要查询一次。而在数据库中做关联查询，则可能需要重复地访问一部分数据。从这点看，这样重构还可能会减少网络和内存的消耗。 更深一步，这样做相当于在应用中实现了哈希关联，而不是使用 Mysql 的嵌套循环关联。某些场景哈希关联效率要高很多。 查询执行的基础（查询\b的内部机制）要想 MYSQL 能够以更高的性能运行查询，弄清楚 MYSQL 是如何\b优化和执行查询是很有必要的。 客户端发送一条查询语句给服务端 \b服务端先\b检查缓存，如果命中了缓存，则\b立即返回存储在缓存中的结果。否则进行下一阶段。 服务端进行 SQL 解析、预处理、再由优化器生成\b\b对应的执行计划。 Mysql 根据优化器生成的执行计划，调用存储引擎的 API 执行查询。 将结果返回给客户端。 每一步都比想象的要复杂，其中查询优化器是最复杂最难理解的部分。 Mysql 客户端 / 服务端通信协议mysql 客户端和\b服务端之间的通信协议是「半双工」的，这意味着：\b\b任一时刻，要么是服务端向客户端发送数据，要么是客户端向服务端发送数据，两个动作不会同时发生。 这种方式有一个限制\b就是没法对流量进行控制，当客户端向服务端请求一个大的数据量，就必须一直等待接收完服务端的响应，\b不可能说接收一半就断开\b连接。这也是为什么推荐使用 LIMIT 的原因之一了。 查询缓存这是查询的第一阶段。在解析一个语句之前，如果查询缓存是打开的，那么 Mysql 会优先检查这个\b查询是否命中查询缓存中的数据。该检查是通过一个对大小写敏感的哈希查找来实现的，即使查询和\b缓存中的查询有\b一个字节不同，也不会匹配缓存结果，这种情况会进入一个阶段的处理。 如果查询命中了缓存，Mysql 在返回结果之前则会检查\b该用户的权限。权限没有问题就会直接\b返回结果跳过其他阶段。 \b查询优化处理这是查询缓存之后的下一个阶段，","link":"/2019/07/01/high-performance-mysql-note/"},{"title":"Git 实用指南","text":"版本控制系统（VCS） 版本控制 / 主动提交 / 中央仓库 构成了一个最核心的版本控制系统。 版本控制：最基本的功能 版本控制系统最基本的功能是版本控制。版本控制，简单的理解就是在文件中的修改历程中保存修改历史，我们可以方便的撤销之前对文件的修改。 在普通文本编辑器中，我们可以使用 Undo 操作回退到上一次的操作；在程序编码，我们可以通过 VCS 回退到指定的一次操作，而不仅仅是上一次操作。 主动提交机制：VCS 与普通文本编辑器的区别 使用普通文本编辑器的时候，一次保存就是一次改动，对版本的 控制 仅仅是回退到上一次操作。而正常情况下，我们的程序代码修改的生命周期十分长，一次代码的修改，在几天后、几个月后、甚至几年后都可能被翻出来。此时像普通编辑器的“自动保存提交”的功能在对历史代码审查、回退中会变得非常繁琐和无章可循。所以和普通文本编辑器的“撤销”功能不同，VCS 保存修改历史，使用 主动提交改动 的机制。 所谓 主动提交改动 ，是指每次代码的修改和保存不会自动提交，需要手动提交（commit）到仓库，VCS 会把这次提交记录到版本历史中，当往后需要回退到这个版本，可以在 VCS 的历史提交纪录中找到这条记录。中央仓库：多人合作的同步需求 中央仓库作为代码的存储中心，所有人的改动都上传到这里，所有人都可以看到并下载别人上传的改动。 版本控制 / 主动提交 / 中央仓库 这三个要素，共同构成了版本控制系统 VCS 的核心：开发团队中的每个人向中央仓库中主动提交自己的改动和同步别人的改动，并在需要的时候查看和操作历史的版本，这就是版本控制系统。 中央式版本控制系统 最基本的模型是：在一台服务器中初始化一个中央仓库，每个人从中央仓库下载初始版本开始并行开发，提交各自的代码到中央仓库并更新其他人的代码同步到自己的机器上。 团队中的每个人需要做的就是：1. 第一次加入团队，从中央仓库取代码到本地； 2. 写好的新功能提交到中央仓库； 3. 同事有新的代码提交，及时同步到本地。实际开发中当然还会经常需要处理代码冲突、查看代码历史、回退代码版本等。 分布式版本控制系统（DVCS）分布式 VCS 和中央式 VCS 的区别在于：分布式 VCS 除了有中央仓库之外，还有本地仓库，团队中的每个人的机器上都有一个本地仓库，这个仓库中保存着版本的所有历史，每个人都可以在自己的机器的本地仓库中提交代码、查看历史而无需联网与中央仓库交互，取而代之的，只需要和本地仓库交互。 中央式 VCS 的中央仓库有两个主要功能：保存版本历史 / 同步代码 。而在分布式的 VCS 中，保存版本历史转移到了每个人的本地仓库，中央仓库只剩下同步代码这一个主要任务。当然中央仓库也会保存版本历史，不过这个历史只是作为团队同步代码的中转站。 快速上手 在 github 上新建一个仓库： git-practical-guide 在指定路径克隆该远程仓库到本地： git clone https://github.com/yuzh233/git-practical-guide.git 查看日志： git log ，若日志信息太长，按 q 退出。 12345678$ git logcommit 0a00230727018a14d481fe482e8e85f7b312e39c (HEAD -&gt; master, origin/master, origin/HEAD)Author: yu_zh &lt;yuzh233@163.com&gt;Date: Wed Oct 3 00:23:27 2018 +0800 Initial commit -- github 默认创建了一次提交 新建一个文件，自己创建一个提交：但先查看一下状态 git status 12345678910111213$ git statusOn branch masterYour branch is up to date with 'origin/master'.Untracked files: (use \"git add &lt;file&gt;...\" to include in what will be committed) README.mdnothing added to commit but untracked files present (use \"git add\" to track)-- 当前分支是主分支，并且当前分支是最新的（相对于中央仓库）-- 有一个未追踪的文件 “README.md” ,可以使用 git add 追踪文件（提交） 追踪文件： git add README.md，再次 git status。 添加全部文件到暂存区：git add . / git add -A 12345678910$ git statusOn branch masterYour branch is up to date with 'origin/master'.Changes to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) new file: README.md-- 当前分支是最新的，已暂存一个新文件：README.md，该文件由“未追踪”变成了“已暂存”，表明这个文件被改动的部分已进入“暂存区” 提交文件：git commit 。进入 vim 填写提交的描述信息保存退出即可。也可以 git commit -m &quot;描述信息&quot; 123456789101112131415161718192021222324252627$ git commit*** Please tell me who you are.Run git config --global user.email \"you@example.com\" git config --global user.name \"Your Name\"to set your account's default identity.Omit --global to set the identity only in this repository.fatal: unable to auto-detect email address (got 'Administrator@YU-ZH.(none)')-- 首次提交需要指明身份（额外一点：github的贡献值是以邮箱地址作为提交的记录标识，如果 setting 里面没有添加该邮箱，那么贡献值会不存在。）Administrator@YU-ZH MINGW64 /d/IdeaProjects/git-practical-guide (master)$ git config --global user.email \"yuzh233@gmail.com\"Administrator@YU-ZH MINGW64 /d/IdeaProjects/git-practical-guide (master)$ git config --global user.name \"yu.zh\"Administrator@YU-ZH MINGW64 /d/IdeaProjects/git-practical-guide (master)$ git commit[master 967f40b] add README.md 1 file changed, 76 insertions(+) create mode 100644 README.md 再查看一次日志吧：git log 123456789101112131415$ git logcommit 967f40b3fd29f102fc84f62ac9d20243db2a99b4 (HEAD -&gt; master)Author: yu.zh &lt;yuzh233@gmail.com&gt;Date: Wed Oct 3 21:50:03 2018 +0800 add README.mdcommit 0a00230727018a14d481fe482e8e85f7b312e39c (origin/master, origin/HEAD)Author: yu_zh &lt;yuzh233@163.com&gt;Date: Wed Oct 3 00:23:27 2018 +0800 Initial commit-- 可以看到，一共有两次提交记录，最近的一次提交在最前面。-- origin/master, origin/HEAD 是对远端仓库的 master 和 HEAD 的本地镜像。 当我们的文件有修改时，需要更新到本地仓库。先看一下状态是个好习惯： git status 123456789101112131415$ git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use \"git push\" to publish your local commits)Changes not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: README.mdno changes added to commit (use \"git add\" and/or \"git commit -a\")-- 当前位于主分支，当前分支“领先于”远程仓库主分支一个提交-- 未提交的一个更改 README.md ，git 认识这个文件，但它不是一个新文件了，我们把它同步为最新的。 依然是： git add README.md 查看状态： git status 1234567891011$ git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use \"git push\" to publish your local commits)Changes to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) modified: README.md-- 一个文件被改动了 提交： git commit 此时查看下日志：git log 123456789101112131415161718$ git logcommit 7ba78ab8cef21de0174884ef13fb6210f9552fe3 (HEAD -&gt; master)Author: yu.zh &lt;yuzh233@gmail.com&gt;Date: Wed Oct 3 22:10:13 2018 +0800 update README.mdcommit 967f40b3fd29f102fc84f62ac9d20243db2a99b4Author: yu.zh &lt;yuzh233@gmail.com&gt;Date: Wed Oct 3 21:50:03 2018 +0800 add README.mdcommit 0a00230727018a14d481fe482e8e85f7b312e39c (origin/master, origin/HEAD)Author: yu_zh &lt;yuzh233@163.com&gt;Date: Wed Oct 3 00:23:27 2018 +0800 Initial commit 此时本地仓库已经领先于中央仓库，把本地仓库推送到中央仓库：git push / git push origin master 小结 git clone url git log git status git add 文件 / git add . / git add -A git commit / git commit -m “info” git push / git push origin master 本地初始化仓库并推送到 GitHub 某个项目文件夹执行 git init git log / git add / git commit / git status 啥的都来一遍 在 github 创建与本地同名的仓库，如果本地有 README.md 远程就不要勾选创建这个文件，否则会冲突。 关联远程库: git remote add origin git@github.com:yuzh233/demo.git or git remote add origin https://github.com/yuzh233/demo.git 推送到远程库：git push -u origin master ，需要先关联 GitHub 与本机的 SSH Key. 关联 GitHub 与本机的 SSH Key 先确保已经在 git 中保存了全局用户名和邮箱 git config –global user.name “yourname” git config –global user.email“your@email.com“ 删除 C:\\Users\\Administrator.ssh\\known_hosts 文件 bash 输入 ssh-keygen -t rsa -C &quot;yuzh233@gmail.com&quot;，出现提示信息，一路回车，然后系统会自动在.ssh文件夹下生成两个文件，id_rsa 和 id_rsa.pub。 打开 id_rsa.pub 将全部内容复制到 Github-&gt;setting-&gt;SSH and GPG keys-&gt;New SSH key-&gt;key ssh -T git@github.com git pullpull 指令用于从中央仓库更新代码到本地仓库。当多人协作开发时，同事 A 先于同事 B push 自己的本地仓库代码到中央仓库后，同事 B 再 push 自己的本地仓库时会报错，原因是远程仓库含有本地没有的 commit 而导致 push 失败。此时同事 B 需要使用 git pull 将同事 A push 到远程仓库的内容更新下来，这样同事 B 的本地仓库就含有远程仓库的commit了，然后同事 B 才能执行自己的 push。 一种场景：同事A commit了一条记录并 push 到远程仓库。同事B 也在自己的本地仓库中 commit 了一条记录后试图 push。此时 git 会发现远程仓库含有本地未有的提交 push 失败。于是同事B 执行 git pull ，此时的 pull 并不会和往常一样结束，而是会进入一个 vim 的信息提示界面，需要输入提交信息（git默认填写了信息），原因是git不仅发现远程仓库含有本地仓库没有的提交，本地仓库也含有远程仓库没有的提交，git会将远程仓库的 commit 和本地仓库的 commit 合并（git mage）产生一条新的提交并添加默认描述信息。 退出保存信息提示界面之后，pull就完成了，然后执行 push，此时本地仓库含有远程仓库所有的提交不会失败。 HEAD / master / branch 理解指向 commit 的快捷方式：引用 括号里的 HEAD -&gt; master, origin/master, origin/HEAD ，都是指向这个 commit 的引用。commit 后面一大串的字符是当前提交的唯一标识符（SHA-1 校验和），提供引用机制是为了简化标识符，方便记忆。 HEAD 指向当前最新的 commit ，当前 commit 在哪里，HEAD 就在哪里，这是一个永远指向当前 commit 的引用。 HEAD 除了可以指向 commit，还可以指向一个 branch，当它指向某个 branch 的时候，会通过这个 branch 来间接地指向某个 commit；另外，当 HEAD 在提交时自动向前移动的时候，它会像一个拖钩一样带着它所指向的 branch 一起移动。 我们创建一个 commit 之后查看 log： 最新的 commit 被创建后，HEAD 和 master 这两个引用都指向了它，而在上面第一张图中的后两个引用 origin/master 和 origin/HEAD 则依然停留在原先的位置。 branch 可以理解为从初始 commit 到 branch 所指向的 commit 之间的所有 commit 集合的一个串。 所有的 branch 之间都是平等的 branch 包含了从初始 commit 到它的所有路径，而不是一条路径。并且，这些路径之间也是彼此平等的。 master 是一个特殊的 branch ,是git默认的分支（主分支）。新创建一个 repository 的第一个 commit 时，会把 master 指向它，并把 HEAD 指向 master。 新建的仓库中的第一个 commit 会被 master 自动指向 在 git clone 时，会自动 checkout 出 master branch xx / checkout branch xx / checkout -d xx / branch -d xx / branch -a创建一个分支：git branch feature1 切换到这个分支：git checkout feature1，此时 HEAD 指向了 feature1 这和分支了。 创建一个分支并切换过去：git checkout -b feature1 我们在 feature1 分支中创建一个提交：添加 feature1.txt。此时 HEAD指向了 feature1，feature1 指向当前提交。 又切换回 master 分支：git checkout master，在 master 创建一个提交：添加 master.txt，此时出现了分叉（两个分支有不同的提交）。 删除刚刚创建的分支：git branch -d feature1 HEAD 指向的 branch 不能删除。如果要删除 HEAD 指向的 branch，需要先用 checkout 把 HEAD 指向其他地方。 branch 只是一个引用，删除引用并不会删除该引用路径上的所有 commit 集合（不过一个 commit 不在任何一个 branch 路径上，就是个野生 commit 了，会被 git 垃圾回收掉） 没有被合并到 master 过的 branch 在删除时会失败。强制删除将 -d 改为 -D 删除远程的分支：git push origin -d feature1 查看所有分支：git branch -a push 的本质push 是把当前的分支上传到远程仓库，并把这个 branch 的路径上的所有 commits 也一并上传。 push 的时候，如果当前分支是一个本地创建的分支，需要指定远程仓库名和分支名，用 git push origin 分支名 的格式，而不能只用 git push；或者可以通过 git config 修改 push.default 来改变 push 时的行为逻辑。 push 之后上传当前分支，并不会上传 HEAD；远程仓库的 HEAD 是永远指向默认分支（即 master）的。 git merge &lt;被合并分支&gt;merge(合并) 从目标 commit（被合并分支的最新commit） 和当前 commit （即 HEAD 所指向的最新 commit）分叉的位置起，把目标 commit 的路径上的所有 commit 的内容一并应用到当前 commit，然后自动生成一个新的 commit。 HEAD 指向 master，说明当前在主分支，执行 git merge branch1之后 git 会 在 commit 2 （交叉位置），将commit 5 和commit 6 合并到 commit 4，然后生成一个新的提交。 首先创建一个分支 branch1，开始并行开发： git branch branch1 ------------------------------------- 在 master 分支创建两个文件： touch a.txt touch b.txt 添加并提交这两个文件： git add a.txt b.txt git commit -m &quot;add a.txt b.txt&quot; 此时 master 分支有这两个文件 ------------------------------------- 切换到 branch1 分支： git chekout branch1 创建一个文件 c.txt 添加并提交： touch c.txt git add c.txt git commit -m &quot;add c.txt&quot; 此时 branch1 分支含有 c.txt 这个文件 -------------------------------------- master 有自己的新提交：“a.txt / b.txt”，branch1有自己的新提交：“c.txt”，此时想将 branch1 的提交合并到 master 主分支上： git checkout master 先切换到主分支 git merge branch1 于是 master 就含有 a.txt / b.txt / c.txt 这三个文件了。 冲突（conflict） merge 在做合并的时候，是有一定的自动合并能力的：如果一个分支改了 A 文件，另一个分支改了 B 文件，那么合并后就是既改 A 也改 B，这个动作会自动完成；如果两个分支都改了同一个文件，但一个改的是第 1 行，另一个改的是第 2 行，那么合并后就是第 1 行和第 2 行都改，也是自动完成。但如果两个分支修改了同一部分内容，merge 的自动算法就搞不定了。这种情况 Git 称之为：冲突（Conflict）。 例如：git仓库中有一个文件 shopping-list.txt，内容如下： 移动硬盘 女装 我们用两个分支分别修改文件的同一个地方，先创建一个分支 feature1： 1git branch feature1 在 master 中修改内容并提交： 12345 移动硬盘 女装（已买）git add shopping-list.txtgit commit -m \"购买女装\" 切换到 feature1 修改并提交： 1234567git checkout feature1 移动硬盘 女装（没买）git add shopping-list.txtgit commit -m \"没买女装\" 此时切换回 master ，执行 git merge feature1，git 傻了 在 shopping-list.txt 中出现了 “merge conflict”，自动合并失败，要求 “fix conflicts and then commit the result”（把冲突解决掉后提交） 第一步：解决冲突，打开冲突的文件： 移动硬盘 &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD 女装（已买） ======= 女装（没买） &gt;&gt;&gt;&gt;&gt;&gt;&gt; feature1 发现内容有些变化，Git 虽然没有帮你完成自动 merge，但它对文件还是做了一些工作：它把两个分支冲突的内容放在了一起，并用符号标记出了它们的边界以及它们的出处。 我们要保留主分支的更改，即：“购买女装”，只要删除掉 feature1 的修改，再把 Git 添加的那三行 &lt;&lt;&lt; === &gt;&gt;&gt; 辅助文字也删掉，保存文件退出，冲突就解决了。 第二步：手动提交，提交解决冲突之后的文件： 12git add shopping-list.txt # 这里 commit 前也需要先 add 一下git commit 如果要放弃这次 merge ，可以执行： 1git merge --abort HEAD 领先于目标 commit如果 merge 时的目标 commit 和 HEAD 处的 commit 并不存在分叉，而是 HEAD 领先于目标 commit。 那么 merge 就没必要再创建一个新的 commit 来进行合并操作，因为并没有什么需要合并的。在这种情况下， Git 什么也不会做，merge 是一个空操作。 HEAD 落后于目标 commit如果 HEAD 和目标 commit 不存在分叉，但 HEAD 落后于目标 commit。那么 Git 会直接把 HEAD（以及它所指向的 branch，如果有的话）移动到目标 commit。这也叫做：“fast-forward”。 fast-forward 这种场景在 pull 中经常遇到：本地的 master 没有新提交，而远端仓库中有同事提交了新内容到 master，此时的 HEAD 落后于目标 commit（远程的 HEAD），而造成 “fast-forward”。 Feature Branching 工作流 之前的工作模型是：所有人都在 master 分支上工作，commit 了代码通过 push 推送到远程仓库，获取别人的 commit 通过 pull。这种模型的局限性在于：每一个人的代码在被大家看到的时候，是它正式进入生产环境的时候。所有人的代码都直接 push 到远程的 master，这就导致了每个人的代码在正式启用（投入生产环境）前无法被别人看到。 这样就让代码在正式启用前的讨论和审阅极不方便。 feature branching 工作流解决了这种问题，该工作流的核心特点如下： 任何一个新功能（feature）和 bug 的修复都用一个新的 branch 来写； branch 写完之后，合并到 master，再删除这个 branch。 这种工作流为团队协作间的 代码审阅 / 一人多任务 提供解决方案。 代码审阅（branch / commit / push / review / merge）假如要开发一个新的功能，我们创建一个分支 books ，开始开发： git checkout -b books # 创建分支并切换过去 十几个 commit 过后，功能开发完毕，告诉同事功能开发完毕，有时间帮我 review 一下呗，分支名是 books，然后把这个分支 push 上去： # 确保当前在 books 分支，将当前分支 push 到远程仓库的 books 分支。 git push origin books [ 模拟同事：review 刚刚上传的 books 分支：] # 克隆同事的仓库到桌面（如果同事有这个仓库就是 git pull ） git clone https://github.com/yuzh233/git-practical-guide.git cd git-practical-guide git checkout books # 切换到同事刚刚开发新功能的分支：books 开始 review ... [ review 完毕，同事：我觉得很 OK 啊~ 可以合并了！] 于是我一顿操作： git checkout master git pull # 保持更新，是个好习惯 git merge books -- 此时 books 分支的内容合并到了 master 工作目录 -- 紧接着，把合并后的 master push 上去，并删除本地和远程的 books 分支： git push git branch -d books # 删除本地 books 分支 git push origin -d books # 删除远程 books 分支 一切都是这么的完美，然而此时一个同事发现不对，说：“嘿！你的代码缩进怎么是 tab ，快改成空格，不然砍死你哦~”，我一看情况不对，立马重复上面的操作：新建分支、改代码、推送上去、同事审阅、合并、再推送、删除分支，ok，空格党觉得很ok，乎~ perfect。[ 然而，发现事情没有这么简单… ] 12345678910git branch booksgit checkout books--- tab 改为 空格 git add / git commit ---git push origin books--- review... ok ---git checkout mastergit merge books # 这里会出现 Fast-forward，原因是当前commit（HEAD）落后于目标commit（books 的 commit 比 master 的 HEAD 领先）git pushgit branch -d booksgit push origin -d books pull request 在上一主题，同事取到我的新功能审阅代码，都是在自己本地中打开，觉得有问题一般都是通过短信电话，发邮件等。这样的审阅是很不方便的，而 pull request 就是对前面代码审阅过程的简化。 pull request 不是 git 的内容，而是 git 服务提供商（如 GitHub）提供的一种便捷功能，可以让团队方便的讨论一个 branch，并在讨论结束后一件合并这个 branch 到 master。 如：现在创建一个分支修改购物清单：“购买SSD”，并推送到远程仓库，github 会自动提示是否 pull request: 创建一个 pull request： 创建之后，其他同事就可以在 github 上看到我们的拉请求。他们可以在这个页面查看我们的所有 commit 并提建议，我们就可以根据同事们的建议提交新的 commit 并 push 到这个分支，这个页面会随着 push 展示最新的 commit。 我们在 feature1 分支又决定不买SSD了，于是更新后重新 push，此时该界面也同步更新了一条 commit： 就这样，根据同事的意见不断的 push 新 commit 之后，最终一致决定没问题可以合并到 master 了，点击 Merge pull request ，GitHub 会自动在中央仓库中将 feature1 合并到 master。 一人多任务利用 feature branching 工作流，一个多任务并行开发变得简单多了。当一个新任务下发时，我们仅需要将当前任务的分支简单收尾一下，回到主分支再开辟一个新任务的分支就可以开发新的任务了。 关于 addadd 指令除了 git add 文件名 这种用法外，还可以使用 add . 来直接把工作目录下的所有改动全部放进暂存区 add 添加的是文件改动，而不是文件名。也就是说,对文件修改之后通过 add 放入暂存区，再修改一次该文件，然后执行 commit，第二次的修改并没有提交，原因是第二次改动了内容没有重新 add。 add 也支持匹配表达式，如 add *.java add 文件进暂存区，又不想 add 了，使用：git reset HEAD filename 看看我改了什么 查看历史记录 git log 查看详细历史记录 git log -p 查看概要历史记录 git log --stat 查看当前（HEAD指向的） commit 的信息 git show 查看指定 commit 的信息：git show &lt;commit的引用&gt; 查看指定 commit 中的某个文件的改动：git show 2edc shopping-list.txt 查看工作区和暂存区的区别：git diff 查看暂存区和上一条提交的区别：git diff --staged 查看工作目录和上一条 commit 的区别：git diff HEAD 不喜欢 merge 的分叉？用 rebase 把 rebase —— 给当前 commit 序列重新设置基础点（也就是父 commit）。就是说，把指定的 commit 以及所在的 commit 串，以指定的目标 commit 为基础（头），重新作为一次提交。 例如：下面是一个 merge 操作: git merge branch1 如果把 merge 换成 rebase： git checkout branch1 git rebase master 可以看到，通过 rebase，将 commit 5 和 commit 6 这个 commit 串，从原有的父节点 commit 2 移到现在的父节点 commit 4。通过这样，让原本分叉的提交历史重新回到了一条线。这种 [ 重新设置基础点 ] 的操作，就是 rebase 的含义。 在 branch1 分支 rebase master 之后，branch1 跑到 master 前面变成了同一条线，但是实际上还是两个彼此独立的分支，只不过 branch1 现在是以 master 的 HEAD（即：commit 4） 作为 基础点（commit 串的头）。master 的 HEAD 是 commit 4，branch1 的 HEAD 是 commit 8，并且 branch1 的 commits 领先于 master 的 commits。 我们希望用 rebase 之后能实现和 merge 一样的合并两条分支的效果，那么怎么做呢？其实还是需要用到 merge 操作，当前分支（master）与目标分支（branch1）没有分叉，并且当前 HEAD 落后于目标分支的 commit，使用 merge，将 HEAD 移到目标的 commit，这就是前面学到过的 Fast-Forward。 git checkout master # 还需先切换回 master git merge branch1 [ 蒙圈了怎么办，演示一把： ] -----------&lt; 新建一个分支 &gt;----------- git branch branch1 -----------&lt; 在 master 创建一个提交 &gt;----------- touch a.txt git add a.txt git commit -m &quot;add a.txt&quot; -----------&lt; 在 branch1 创建一个提交 &gt;----------- git checkout branch1 touch b.txt / touch c.txt git add b.txt c.txt git commit -m &quot;add b.txt c.txt&quot; -----------&lt; 想把 branch1 合并到 master 但是不想有分叉 &gt;----------- # 注意：必须先切换到被合并的分支！ git checkout branch1 git rebase master [ 此时，branch1 和 master 属于同一条线，但是 branch1 领先于 master：] [ branch1 的新提交是 a.txt / b.txt ，master 的新提交是 a.txt，此时合并到 master：git checkout master / git merge branch1] [ 可以看出是一个快速前移操作，此时的日志：master 已经移到了最新的 commit] 注意事项 merge 操作是在合并分支上进行的； rebase 操作是在 被合并 分支上进行的，这点很重要。 rebase 是带着当前 commit 移到别的 commit 上「去」，而 merge 则是把别的 commit 合并过「来」 “ 为什么要在被合并分支 branch1 上执行 rebase，在合并分支 master上执行 merge，而不是直接在 master上执行 rebase 呢？” —— 简单的理解就是：这两种 rebase 本身就是两种不同的情况，如果在 master 上 rebase：git checkout master / git rebase branch1 ，master 就会带着它的 commit 串内容作为新的 commit 跑到 branch1 的 HEAD 前面去啦！ master 跑到了 branch1 这条线上，master 的 commit 的内容还是以前的内容，但是却不是同一个 commit 了，只不过是内容相同的另外一个 commit罢了。而如果远程仓库有之前 master 的 commit，但是在本地仓库中找不到远程库对应的这个 commit，会因为远程库含有本地没有的 commit 导致 push 失败！ 应用场景 你自己开发分支一直在做，然后某一天，你想把主线的修改合到你的分支上，做一次集成，这种情况就用 rebase 比较好。把你的提交都放在主线修改的头上。 参考：git rebase 还是 merge的使用场景最通俗的解释 修正 commit用 commit --amend 修复当前提交的错误。在 commit 一条提交之后发现写错了，我要买：“机械键盘”，可以使用 commit --amend 指令来修正本次提交的错误。git 不会在当前 commit 上增加 commit ，而是把当前 commit 里的内容和暂存区的内容合并起来形成一个新的 commit，用新的 commit 把当前的 commit 替换掉。 [ 我们在购物清单中添加一个：“薄膜键盘”，提交之后发现写错了… 于是将内容重新修改，并重新 add 到暂存区，使用 commit –amend 指令覆盖当前提交：] 修正之后可以发现只有一条 commit 记录。 修正指定 commit 交互式 rebase：git rebase -i &lt;指定 commit 链的头&gt; 所谓交互式 rebase，就是在 rebase 的操作执行之前，指定要 rebase 的 commit 链中的每一个 commit 是否需要进一步修改。 -------&lt; 第一次提交 &gt;------- 我们在文件 rebase-i.txt 中添加一行 aaaaa 后执行提交：git add rebase-i.txt / git commit -m &quot;aaaaa&quot; -------&lt; 第二次提交 &gt;------- 在文件 rebase-i.txt 中又添加一行 bbbbb 后执行提交：git add rebase-i.txt / git commit -m &quot;bbbbb&quot; 查看日志： 但是发现 “aaaaa” 这个提交的内容写错了，想要修改这次提交。由于不是最新的提交，不能使用 commit –amend 来修正。 可以使用 rabse，不过此时的 rebase 是在同一条基线上，也叫 [原地 rebase]，通过原地变基，指定一个 commit ，将其所在的 commits 串从父基础点断开。然后对该 commits 串中的每一个 commit 修改后重新挂在原来的父基础点。 使用 git rebase -i HEAD^^ or git rebase -i HEAD~2 来指定从哪个 commit 开始变基。（rebase 之前需要将工作空间新的修改放入暂存区，所以现在有了三条提交。） 我们要修正指定的 commit，将需要被修正的 commit 对应的操作由 pick 改为 edit（应用当前的提交，但是停下来修正）： 根据提示信息：rebase 已经停到了 “aaaaa” 这个提交，现在可以修正这个提交： 12修改 aaaaa 为 aaaaa_amendgit commit --amend # 应用这个修复 修复了第一个之后，执行：git rebase --continue 继续执行第二个：第二个也是修复，对文件修改 amend 之后继续 continue ，第三个 commit 是默认操作是 pick（应用当前的提交），不执行任何操作，至此rebase完毕。 撤销 commit —— resetgit add 后撤销： 撤销所有add文件 git reset HEAD . 撤销单个add文件 git reset HEAD -filename git commit 后撤销： 只回退 commit 的信息，保留修改代码：git reset --soft head 回退到上次 commit 版本，不保留修改代码：git reset --hard head^ HEAD：回退到当前版本（啥也没干） HEAD^ ：回退到上一个版本 reset 本质上不是撤销提交，而是移动 HEAD ，并且「捎带」上 HEAD 所指向的 branch（如果有的话），用来重置 HEAD 以及它所指向的 branch 的位置。 reset --hard HEAD^ 之所以起到了撤销前一个 commit 的效果，是因为它把 HEAD 和它所指向的 branch 一起移动到了当前 commit 的父 commit 上，从而起到了「撤销」的效果： 注意： --hard： 添加这个参数会抛弃当前工作区的修改 --soft： 添加这个参数会回退到之前的版本，但是保留当前工作区的修改，可以重新提交 撤销指定 commit —— rebase -i现有三条提交，要撤销第二条提交： git rebase -i HEAD~3 操作当前 commit 所在 commits 链中三条 commit： 撤销某个 commit ，将这一行删除即可。此时第二条 commit 被删掉了： 撤销已 push 的 commit —— revertgit revert 撤销某次操作，此次操作之前和之后的 commit 和 history 都会保留，并且把这次撤销作为一次最新的提交。 比如我们我们对文件rebase-i.txt添加两次修改并提交两次后 push 到远程库： 我们要撤销前一次提交:”bbb”，也就是删除文件中的“bbb”这一行：git revert HEAD 可以看到执行完之后增加了一条新的 commit，它的内容和最新的 commit 是相反的，从而和最新的 commit 相互抵消，达到撤销的效果。 把新的 commit 再 push 上去，这个 commit 的内容就被撤销了。它和前面所介绍的撤销方式 reset 相比，最主要的区别是，这次改动只是被「反转」了，并没有在历史中消失掉，你的历史中会存在两条 commit ：一个原始 commit ，一个对它的反转 commit。 checkout —— 不止可以签出分支前面学习过，使用：git checkout &lt;branch-name&gt; 可以切换到指定分支，即：把 HEAD 指向指定的 branch，然后签出这个 branch 所对应的 commit 的工作目录。 实际上 checkout 的本质是签出指定的 commit，不止可以切换 branch，也可以直接指定 commit 作为参数，来把 HEAD 移动到指定的 commit。 对于签出（checkout）的概念，简单的理解就是切换分支并在本地仓库中取出指定分支的内容到工作目录。 [ 演示：] 创建一个文件abc.txt并作为一个提交 使用 reset 撤回提交（不保留修改代码）： git reset --hard HEAD^ 可以看到刚刚的提交被撤销了，HEAD 带着 master 一起指向了上一条 commit： 如果用 checkout 来撤销提交：git checkout HEAD^ 可以看到，HEAD 已经和刚刚它指向的 branch -&gt; master 脱离了，此时如果继续提交更改，HEAD 就会跟着新的 commit 跑，而 master 依旧停到原地。当我们切换 master 之后，HEAD会因为没有所属分支而提示：“你有n个提交没有连接到分支,可以通过：git branch &lt;new-branch-name&gt; commitID 将新提交放到新创建的分支上去。然后可以将该分支合并到 master。” stash 临时存放工作目录的改动 保存工作目录的修改（不包含未 add 过的文件）并清空工作目录：git stash 恢复保存过的修改：git stash pop 包含未 add 过的文件使用：git stash -u 切换分支之前提交当前分支的修改，免去了不必要的麻烦，也没必要使用 stash 了。 恢复误删的 branch reflog 是 “reference log” 的缩写，使用它可以查看 Git 仓库中的引用的移动记录。如果不指定引用，它会显示 HEAD 的移动记录。 恢复指定 branch ，只需要查看 branch 最后一次移动的记录，那么其之前的一个 commit 就是删除之前的数据，使用 checkout 签出这个 commit 的内容到新的分支。实际上不会恢复分支，而是恢复分支里的内容并放到新的分支。使用这个方法，不仅可以恢复分支，还可以执行其他操作，比如恢复 reset 的数据。 假如误删了 branch1，那么可以查看一下 HEAD 的移动历史： git reflog HEAD 的最后一次移动行为是「从 branch1 移动到 master」。而在这之后，branch1 就被删除了。所以它之前的那个 commit 就是 branch1 被删除之前的位置了，也就是第二行的 c08de9a。 现在就可以切换回 c08de9a，然后重新创建 branch1: git checkout c08de9a git checkout -b branch1 这样分支里的内容就已经恢复到新建的同名分支里面了。","link":"/2018/10/07/Git 实用指南/"},{"title":"分布式技术入坑指南（一）","text":"知识点:1.SOA分布式架构2.Maven-多模块搭建3.初识dubbo、zookepper4.多工程之间的整合5.学习MyBatis逆向工程6.学习PageHelper7.了解SEO：搜索引擎优化，以及使用伪静态化尽可能的提高推广度8.内容管理系统 — 统一表字段抽取9.mapper中使用“主键返回” SOA(Service Oriented Architecture)面向服务的架构&nbsp;&nbsp;也就是把工程都拆分成服务层工程、表现层工程。服务层中包含业务逻辑，只需要对外提供服务即可。表现层只需要处理和页面的交互，业务逻辑都是调用服务层的服务来实现。工程都可以独立部署。 Maven-多模块搭建&nbsp;&nbsp;Maven的常见打包方式：jar、war、pom。Pom工程一般都是父工程，管理jar包的版本、maven插件的版本、统一的依赖管理。聚合工程。 本项目工程结构：taotao-parent：父工程，打包方式pom，管理jar包的版本号。项目中所有工程都应该继承父工程。&nbsp;&nbsp;|–taotao-common：通用的工具类通用的pojo,util。打包方式jar&nbsp;&nbsp;|–taotao-manager：服务层工程。聚合工程。Pom工程&nbsp;&nbsp;|–taotao-manager-dao：打包方式jar&nbsp;&nbsp;|–taotao-manager-pojo：打包方式jar&nbsp;&nbsp;|–taotao-manager-interface：打包方式jar&nbsp;&nbsp;|–taotao-manager-service：打包方式：war (为了发布服务的方便)&nbsp;&nbsp;|–taotao-manager-web：表现层工程。打包方式war taotao-parentpom123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 父工程，打包方式pom，管理jar包的版本号。项目中所有工程都应该继承父工程. --&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;artifactId&gt;taotao-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!-- 所有子工程 --&gt; &lt;modules&gt; &lt;module&gt;taotao-common&lt;/module&gt; &lt;module&gt;taotao-manager&lt;/module&gt; &lt;module&gt;taotao-manager-web&lt;/module&gt; &lt;module&gt;MybatisGenerator&lt;/module&gt; &lt;module&gt;taotao-protal-web&lt;/module&gt; &lt;module&gt;taotao-content&lt;/module&gt; &lt;/modules&gt; &lt;!-- 集中定义依赖版本号 --&gt; &lt;properties&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;spring.version&gt;4.2.4.RELEASE&lt;/spring.version&gt; &lt;mybatis.version&gt;3.2.8&lt;/mybatis.version&gt; &lt;mybatis.spring.version&gt;1.2.2&lt;/mybatis.spring.version&gt; &lt;mybatis.paginator.version&gt;1.2.15&lt;/mybatis.paginator.version&gt; &lt;mysql.version&gt;5.1.32&lt;/mysql.version&gt; &lt;slf4j.version&gt;1.6.4&lt;/slf4j.version&gt; &lt;jackson.version&gt;2.4.2&lt;/jackson.version&gt; &lt;druid.version&gt;1.0.9&lt;/druid.version&gt; &lt;httpclient.version&gt;4.3.5&lt;/httpclient.version&gt; &lt;jstl.version&gt;1.2&lt;/jstl.version&gt; &lt;servlet-api.version&gt;2.5&lt;/servlet-api.version&gt; &lt;jsp-api.version&gt;2.0&lt;/jsp-api.version&gt; &lt;joda-time.version&gt;2.5&lt;/joda-time.version&gt; &lt;commons-lang3.version&gt;3.3.2&lt;/commons-lang3.version&gt; &lt;commons-io.version&gt;1.3.2&lt;/commons-io.version&gt; &lt;commons-net.version&gt;3.3&lt;/commons-net.version&gt; &lt;!-- 3.4.2-fix是从官方的3.4.2版本添加修改之后形成的自己的工程 --&gt; &lt;!--&lt;pagehelper.version&gt;3.4.2-fix&lt;/pagehelper.version&gt;--&gt; &lt;!--&lt;pagehelper.version&gt;3.4.2&lt;/pagehelper.version&gt;--&gt; &lt;!--该版本已经修复了使用逆向工程导致pageHelper无效的问题 --&gt; &lt;pagehelper.version&gt;4.1.0&lt;/pagehelper.version&gt; &lt;jsqlparser.version&gt;0.9.1&lt;/jsqlparser.version&gt; &lt;commons-fileupload.version&gt;1.3.1&lt;/commons-fileupload.version&gt; &lt;jedis.version&gt;2.7.2&lt;/jedis.version&gt; &lt;solrj.version&gt;4.10.3&lt;/solrj.version&gt; &lt;dubbo.version&gt;2.5.4&lt;/dubbo.version&gt; &lt;zookeeper.version&gt;3.4.7&lt;/zookeeper.version&gt; &lt;zkclient.version&gt;0.1&lt;/zkclient.version&gt; &lt;activemq.version&gt;5.13.0&lt;/activemq.version&gt; &lt;freemarker.version&gt;2.3.23&lt;/freemarker.version&gt; &lt;quartz.version&gt;2.2.2&lt;/quartz.version&gt; &lt;/properties&gt; &lt;!-- 父工程统一项目的所有依赖，该依赖对子工程无效，只起到版本控制的效果，子工程根据需要复制部分的依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 时间操作组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;${joda-time.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Apache工具组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;${commons-lang3.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;${commons-io.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-net&lt;/groupId&gt; &lt;artifactId&gt;commons-net&lt;/artifactId&gt; &lt;version&gt;${commons-net.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Jackson Json处理工具包 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;${jackson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- httpclient --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;${httpclient.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- quartz任务调度框架 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;${quartz.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 单元测试 --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 日志处理 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;${mybatis.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;${mybatis.spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 分页相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.miemiedev&lt;/groupId&gt; &lt;artifactId&gt;mybatis-paginator&lt;/artifactId&gt; &lt;version&gt;${mybatis.paginator.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;${pagehelper.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySql --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 最牛逼的连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- JSP相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;${jstl.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;${servlet-api.version}&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;${jsp-api.version}&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 文件上传组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;${commons-fileupload.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Redis客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;${jedis.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- solr客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.solr&lt;/groupId&gt; &lt;artifactId&gt;solr-solrj&lt;/artifactId&gt; &lt;version&gt;${solrj.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- dubbo相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;${dubbo.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;${zookeeper.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;${zkclient.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;${activemq.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;${freemarker.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;finalName&gt;${project.artifactId}&lt;/finalName&gt; &lt;plugins&gt; &lt;!-- 资源文件拷贝插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;2.7&lt;/version&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- java编译插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;!-- 插件版本的管理 --&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- 配置Tomcat插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;8080&lt;/port&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 配置打包时跳过测试 ，首次配置使用的时候会自动联网进行下载 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.12.4&lt;/version&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!-- 子工程需要覆写这个配置，该配置并不会继承到子工程。 --&gt; &lt;resources&gt; &lt;!-- 解决安装后java目录下的资源文件不发布的问题（默认maven是在resources下找资源文件） --&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;!-- 如果配置文件resources中也有，还需要配置这个 --&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources &lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; 举例：taotao-manager的pom123456789101112131415161718192021222324252627282930&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 服务层工程。聚合工程。Pom工程 --&gt; &lt;artifactId&gt;taotao-manager&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;taotao-manager-dao&lt;/module&gt; &lt;module&gt;taotao-manager-pojo&lt;/module&gt; &lt;module&gt;taotao-manager-interface&lt;/module&gt; &lt;module&gt;taotao-manager-service&lt;/module&gt; &lt;/modules&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;artifactId&gt;taotao-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!-- 依赖通用工程 --&gt; &lt;dependency&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;artifactId&gt;taotao-common&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; taotao-manager-service 的 pom12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;taotao-manager&lt;/artifactId&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;taotao-manager-service&lt;/artifactId&gt; &lt;!-- service是以服务模块单独跑服务器的，需要打成war应用包。 --&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;!-- 需要依赖dao模块 --&gt; &lt;dependency&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;artifactId&gt;taotao-manager-dao&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 需要依赖接口模块 --&gt; &lt;dependency&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;artifactId&gt;taotao-manager-interface&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;!-- 版本已经在parent控制了，这里添加也无效！ --&gt; &lt;/dependency&gt; ...... &lt;!-- 添加dubbo依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;!-- 排除依赖 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.jboss.netty&lt;/groupId&gt; &lt;artifactId&gt;netty&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; ...... &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;8081&lt;/port&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 使用tomcat的Maven插件启动123456789101112&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;8081&lt;/port&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; &nbsp;&nbsp;注：启动之前需要编译+安装模块到本地仓库，并且注意根据模块的层级关系确保安装的顺序！ 不想安装过程测试、资源文件拷贝不上等配置参考parent pom dubbo、zookepper SOA架构，表现层和服务层是不同的工程。某些需求的实现需要两个系统之间进行通信。Dubbo便是这类框架之一 DUBBO是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，是阿里巴巴SOA服务化治理方案的核心框架。 Dubbo是资源调度和治理中心的管理工具。 Dubbo 是类似于webservice的关于系统之间通信的框架，并可以统计和管理服务之间的调用情况（包括服务被谁调用了，调用的次数是如何，以及服务的使用状况）。 dubbo的架构 Provider: 暴露服务的服务提供方。 Consumer: 调用远程服务的服务消费方。 Registry: 服务注册与发现的注册中心。 Monitor: 统计服务的调用次调和调用时间的监控中心。 Container: 服务运行容器。 接入spring提供服务： 1234567891011121314151617181920212223242526&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd\"&gt; &lt;context:component-scan base-package=\"xyz.taotao.service\"&gt;&lt;/context:component-scan&gt; &lt;!-- 使用 dubbo 发布服务 --&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=\"taotao-manager\"/&gt; &lt;dubbo:registry protocol=\"zookeeper\" address=\"192.168.184.130:2181\"/&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\"/&gt; &lt;!-- 声明需要暴露的服务接口 --&gt; &lt;dubbo:service interface=\"xyz.taotao.service.TestService\" ref=\"testServiceImpl\"&gt;&lt;/dubbo:service&gt; &lt;dubbo:service interface=\"xyz.taotao.service.ItemService\" ref=\"itemServiceImpl\"&gt;&lt;/dubbo:service&gt;&lt;/beans&gt; 引入服务： 12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.2.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd\"&gt; &lt;!-- 引用dubbo服务 --&gt; &lt;dubbo:application name=\"taotao-manager-web\"/&gt; &lt;dubbo:registry protocol=\"zookeeper\" address=\"192.168.184.130:2181\"/&gt; &lt;!-- 引用指定的服务接口 --&gt; &lt;dubbo:reference interface=\"xyz.taotao.service.TestService\" id=\"testService\"&gt;&lt;/dubbo:reference&gt; &lt;dubbo:reference interface=\"xyz.taotao.service.ItemService\" id=\"itemService\"&gt;&lt;/dubbo:reference&gt; &lt;dubbo:reference interface=\"xyz.taotao.content.service.ContentService\" id=\"contentService\"&gt;&lt;/dubbo:reference&gt; &lt;dubbo:reference interface=\"xyz.taotao.content.service.ContentCategoryService\" id=\"contentCategoryService\"&gt;&lt;/dubbo:reference&gt;&lt;/beans&gt; 注意模块之间的依赖关系！ 注册中心 zookepper&nbsp;&nbsp;注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。使用dubbo-2.3.3以上版本，官方建议使用zookeeper作为注册中心。 在linux中安装zookepper第一步：安装jdk 第二步：解压缩zookeeper压缩包 第三步：将conf文件夹下zoo_sample.cfg复制一份，改名为zoo.cfg 第四步：修改配置dataDir属性，指定一个真实目录（进入zookeeper解压目录，创建data目录：mkdir data) 第五步： 启动zookeeper：bin/zkServer.sh start 关闭zookeeper：bin/zkServer.sh stop 查看zookeeper状态：bin/zkServer.sh status 注意开放防火墙的端口： 查看防火墙：service iptables status 添加规则：vim /etc/sysconfig/iptables 添加之后刷新配置：scource /etc/sysconfig/iptables 监控中心安装&nbsp;&nbsp;参考上一篇：https://www.yuzh.xyz/2018/07/06/dubbo%E7%9B%91%E6%8E%A7%E4%B8%AD%E5%BF%83-dubbo-admin-war%E7%9A%84%E6%89%93%E5%8C%85%E5%92%8C%E9%83%A8%E7%BD%B2/ 多工程之间的整合 dao模块管理dao层，放映射文件。 interface（分为dao-interface、service-interface）模块管理接口，放接口。 service模块管理service层，放SqlMapConfig.xml、连接池、sessionFactory、事务、dobbo服务等等… web模块管理controller层，放web.xml、spring、mvc、dubbo相关… MyBatis逆向工程就是导入一个工程，配置一下，生成数据库中对应的pojo和mapper pom 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;taotao-parent&lt;/artifactId&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;MybatisGenerator&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.6&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- 生成插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;configuration&gt; &lt;!--配置文件的位置--&gt; &lt;configurationFile&gt;src/main/resources/generatorConfig.xml&lt;/configurationFile&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Generate MyBatis Artifacts&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 配置生成规则： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt;&lt;generatorConfiguration&gt; &lt;!--mysql 连接数据库jar 这里选择自己本地位置--&gt; &lt;classPathEntry location=\"H:/[ 包 ] Lib/Other/mysql-connector-java-5.1.7-bin.jar\"/&gt; &lt;context id=\"testTables\" targetRuntime=\"MyBatis3\"&gt; &lt;commentGenerator&gt; &lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt; &lt;property name=\"suppressAllComments\" value=\"true\"/&gt; &lt;/commentGenerator&gt; &lt;!--数据库连接的信息：驱动类、连接地址、用户名、密码 --&gt; &lt;jdbcConnection driverClass=\"com.mysql.jdbc.Driver\" connectionURL=\"jdbc:mysql://localhost:3306/taotao\" userId=\"root\" password=\"admin\"&gt; &lt;/jdbcConnection&gt; &lt;!-- 默认false，把JDBC DECIMAL 和 NUMERIC 类型解析为 Integer，为 true时把JDBC DECIMAL 和 NUMERIC 类型解析为java.math.BigDecimal --&gt; &lt;javaTypeResolver&gt; &lt;property name=\"forceBigDecimals\" value=\"false\"/&gt; &lt;/javaTypeResolver&gt; &lt;!-- targetProject:生成PO类的位置 --&gt; &lt;javaModelGenerator targetPackage=\"xyz.yuzh.pojo\" targetProject=\"src/main/java\"&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name=\"enableSubPackages\" value=\"false\"/&gt; &lt;!-- 从数据库返回的值被清理前后的空格 --&gt; &lt;property name=\"trimStrings\" value=\"true\"/&gt; &lt;/javaModelGenerator&gt; &lt;!-- targetProject:mapper映射文件生成的位置 如果maven工程只是单独的一个工程，targetProject=\"src/main/java\" 若果maven工程是分模块的工程，targetProject=\"所属模块的名称\"，例如： targetProject=\"ecps-manager-mapper\"，下同--&gt; &lt;sqlMapGenerator targetPackage=\"xyz.yuzh.mapper\" targetProject=\"src/main/java\"&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name=\"enableSubPackages\" value=\"false\"/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- targetPackage：mapper接口生成的位置 --&gt; &lt;javaClientGenerator type=\"XMLMAPPER\" targetPackage=\"xyz.yuzh.mapper\" targetProject=\"src/main/java\"&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name=\"enableSubPackages\" value=\"false\"/&gt; &lt;/javaClientGenerator&gt; &lt;!-- 指定数据库表 --&gt; &lt;table schema=\"\" tableName=\"tb_content\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_content_category\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_item\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_item_cat\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_item_desc\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_item_param\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_item_param_item\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_order\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_order_item\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_order_shipping\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_user\"&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 点击插件运行-&gt;自动生成pojo和mapper在指定位置。然后复制到自己需要的工程里面，注意：没有自动实现序列化。 参考地址：https://blog.csdn.net/liudongdong0909/article/details/51534735 PageHelper导包之后在Mybatis的全局文件中配置SqlMapConfig.xml中配置拦截器插件 123456&lt;plugins&gt; &lt;plugin interceptor=\"com.github.pagehelper.PageHelper\"&gt; &lt;!-- 设置数据库类型 Oracle,Mysql,MariaDB,SQLite,Hsqldb,PostgreSQL六种数据库--&gt; &lt;property name=\"dialect\" value=\"mysql\"/&gt; &lt;/plugin&gt;&lt;/plugins&gt; 测试代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package xyz.taotao.pagehelper;import com.github.pagehelper.PageHelper;import com.github.pagehelper.PageInfo;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import xyz.taotao.mapper.TbItemMapper;import xyz.taotao.pojo.TbItem;import xyz.taotao.pojo.TbItemExample;import java.util.List;/** * Created with IntelliJ IDEA. * * @Author: yu_zh * @DateTime: 2018/07/05 14:36 */public class TestPageHelper { @Test public void testPageHelper() { //初始化spring容器 ApplicationContext ac = new ClassPathXmlApplicationContext(\"spring-dao.xml\"); //获取mapper代理对象 TbItemMapper tbItemMapper = ac.getBean(TbItemMapper.class); //设置分页信息 PageHelper.startPage(3, 100); //调用mapper方法查询数据 //查询条件对象 TbItemExample tbItemExample = new TbItemExample(); TbItemExample.Criteria criteria = tbItemExample.createCriteria(); //创建时间不为空才查询，免去了mapper中编辑sql criteria.andCreatedIsNotNull(); //第一个查询列表被分页 List&lt;TbItem&gt; tbItemList = tbItemMapper.selectByExample(tbItemExample); //第二个不会被分页 List&lt;TbItem&gt; tbItemList2 = tbItemMapper.selectByExample(tbItemExample); //获取分页信息 PageInfo&lt;TbItem&gt; tbItemPageInfo = new PageInfo&lt;&gt;(tbItemList); //遍历信息列表 tbItemPageInfo.getList(); System.out.println(\"被分页后条数：\"+tbItemPageInfo.getEndRow()); System.out.println(\"总记录数\"+tbItemPageInfo.getTotal()); System.out.println(\"页数\"+tbItemPageInfo.getPages()); System.out.println(\"当前页\"+tbItemPageInfo.getPageNum()); System.out.println(\"页大小\"+tbItemPageInfo.getPageSize()); int i = 1; for (TbItem item : tbItemList2) { i++; } System.out.println(\"全部条数：\"+i); }} 了解SEO &nbsp;&nbsp;百度这样的搜索引擎对于.html后缀的网页的搜索排名优先级是高于jsp的，我们可以在不改变网页是jsp格式的前提下，通过控制springmvc拦截.html请求达到浏览器始终都是.html后缀显示的效果。 比如： 12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:web=\"http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\" id=\"WebApp_ID\" version=\"2.5\"&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;/index.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!-- spring-mvc --&gt; &lt;servlet&gt; ...... &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;....&lt;/servlet-name&gt; &lt;!-- 伪静态化：SEO 搜索引擎优化--&gt; &lt;url-pattern&gt;*.html&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 12345页面控制器：@RequestMapping(value = \"/index\",method = RequestMethod.GET)public String index(){ return \"index\";} 访问一个站点的主页，用户一般都是 http://www.yuzh.xyz/ 或者有经验一点的会这样 http://www.yuzh.xyz/index.html 通常情况下，mvc的拦截形式是 / ，表示拦截所有非 jsp\\html的资源访问请求，这时/和/index.html两者的效果可能不一样。 如果主页在/WEB-INF/下，/index.html是会报404的，只有以/形式通过控制器跳转到主页。 回到伪静态化的话题，既然要实现伪静态化，就必须把拦截形式设为*.html，那么当用户输入两种不同的url是怎么跳转到主页的呢？ 1）当输入地址/，mvc没有拦截到，转而找欢迎页&lt;welcome-file&gt;/index.html&lt;/welcome-file&gt;，于是找/index.html，如果webapps下有页面就直接返回，如果没有就进入到mvc（此时已经被mvc拦截到了），前面mvc配置了@RequestMapping(value =&quot;/index&quot;)，于是进入了控制器方法，最终在控制器中跳转页面。 2）当输入地址/index.html，直接被mvc所拦截，不需要进欢迎页，直接到了控制器跳转页面。 3）注意：配置伪静态化后，url地址必须以.html才能访问资源。访问控制器的方法需要”映射路径+.html“，比如：@RequestMapping(value = “/getList”)，访问这个方法需要”getList.html“的形式，很奇怪哦~ 不然无法被拦截到啊！ 内容管理系统 — 抽取抽象表违反了数据库范式，但以便于开发 1) 随着硬件水平的迅猛发展，硬件成本的降低，数据库范式和开发效率上大多数情况下选择后者，现代企业开发中，通常会为了简单有效的管理数据和应用系统的效率，违反三大范式的要求，以空间换时间。1) 内容管理系统（content management system，CMS）是一种位于WEB 前端（Web 服务器）和后端办公系统或流程（内容创作、编辑）之间的软件系统。内容的创作人员、编辑人员、发布人员使用内容管理系统来提交、修改、审批、发布内容。这里指的“内容”可能包括文件、表格、图片、数据库中的数据甚至视频等一切你想要发布到Internet网站的信息。2) 就是后台管理维护前台的页面和页面中的内容可以动态展示。 栗子：本商城的门户系统首页中存在多个小板块，比如大广告位、淘淘快报、商品展示位…如果对于每一个小板块都创建一张表进行维护将会十分的麻烦，前台一个页面调整（增加删除修改），后台对应将会是pojo、mapper、dao、service、controller都要改动，于是试着把这些所有板块抽取一张统一的分类表。 把首页的每个展示功能（大广告位，淘淘快报等），看作是一个分类，每个展示功能里面展示的多条信息，看作是分类下的内容。 例如：首页大广告，对应的是大广告分类，而大广告位展示的多张图片，就是大广告分类下的内容，前台需要获取大广告的图片，只需要根据大广告的id查询对应的内容即可。 内容分类表：tb_content_category，需要存储树形结构的数据。（大分类下有小分类） 内容表：tb_content，将所有信息统一到一张表。 比如有些板块不需要`price`这个字段，当字段不足时，就用该字段存点其他的。 mapper中使用“主键返回”在自动生成的sql中添加 &lt;selectKey/&gt; 节点： 1234567891011&lt;insert id=\"insert\" parameterType=\"xyz.taotao.pojo.TbContentCategory\" &gt; &lt;selectKey keyProperty=\"id\" resultType=\"long\" order=\"AFTER\"&gt; select last_insert_id(); &lt;/selectKey&gt; insert into tb_content_category (id, parent_id, name, status, sort_order, is_parent, created, updated) values (#{id,jdbcType=BIGINT}, #{parentId,jdbcType=BIGINT}, #{name,jdbcType=VARCHAR}, #{status,jdbcType=INTEGER}, #{sortOrder,jdbcType=INTEGER}, #{isParent,jdbcType=BIT}, #{created,jdbcType=TIMESTAMP}, #{updated,jdbcType=TIMESTAMP}) &lt;/insert&gt;","link":"/2018/07/08/分布式技术入坑指南（一）/"},{"title":"线程高级","text":"Java并发编程包 java.util.concurrent 的学习笔记 简介 在 Java 5.0 提供了 java.util.concurrent （简称JUC ）包，在此包中增加了在并发编程中很常用的实用工具类，用于定义类似于线程的自定义子系统，包括线程池、异步 IO 和轻量级任务框架。提供可调的、灵活的线程池。还提供了设计用于多线程上下文中的 Collection 实现等。 volatile 关键字-内存可见性 内存可见性（Memory Visibility）是指当某个线程正在使用对象状态而另一个线程在同时修改该状态，需要确保当一个线程修改了对象状态后，其他线程能够看到发生的状态变化。 通过一个用例验证可见性：子线程修改共享资源的状态（写操作），主线程访问共享资源（读操作），如果为true打印一段符号并退出循环。 1234567891011121314151617181920212223242526272829public class TestVolatile { public static void main(String[] args) { // 线程1 ThreadDemo td = new ThreadDemo(); new Thread(td).start(); // 主线程循环的访问共享资源 while(true){ if(td.isFlag()){ System.out.println(\"------------------\"); break; } } }}class ThreadDemo implements Runnable { private boolean flag = false; // 共享资源 @Override public void run() { try { Thread.sleep(200); } catch (InterruptedException e) { } flag = true; System.out.println(\"flag=\" + isFlag()); }} 运行结果： 可以看到，子线程将资源状态改为true之后，而主线程一直处在循环状态，并未打印一段符号，说明此时共享资源状态还是false，而子线程明明将状态改为true来着的，这是什么原因呢？ 计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。 程序运行时，JVM为每一个线程分配一个独立的缓存来提高效率。共享资源存放在主存（堆内存、物理内存）中，“每个线程操作共享资源时，先从主存中读取共享资源放入自己的缓存区，在自己的缓存区中对资源进行修改，然后将修改更新到主存中去。” 从用例可以看出，子线程睡了2s，所以主线程先执行，获得了资源状态为false。然后子线程将状态改为true并将修改更新到主存中，但是主线程一直处在循环状态，这是因为while的运行调用了底层的代码处理非常之快，快到都没有来得及更新主存中的共享资源数据。 现在知道是因为子线程更新缓存中的值到主存去了而另外一个线程没有来得及刷新缓存来更新主存中的数据，所以导致的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。 Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。 子线程对主存进行了修改，主线程没有立即看到，所以出现了概念中的可见性问题。 解决方案： 方式一：使用synchronized和Lock（后面学）保证可见性。它能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。 12345678while (true) { synchronized (td) { if (td.isFlag()) { System.out.println(\"------------------\"); break; } }} 每次访问加锁数据都会从主存中刷新数据，所以主线程正常退出。 但是由于 synchronized 关键字会极低的影响运行效率，所以还有一种方式：使用 volatile 关键字保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 volatile 和 synchronized 的区别： volatile 不保证互斥性。一个线程对共享资源访问另外一个线程也能访问，不具备互斥性。 volatile 不保证原子性。见下一节 synchronized 保证原子性是因为对共享资源加锁，每次只能一个线程访问，一个线程在同步代码块中执行操作之后另一个线程才会进入。 引用：Java并发编程：volatile关键字解析 原子变量-CAS算法首先明白 i++ 操作是不具备原子性的，i++分为三个步骤：首先线程从主存中获取变量i的值，然后执行 i + 1，再将 i+1 赋值给i，然后写入到线程自己的工作内存，最后写入到主存。 假如线程1获取了volatile修饰的共享变量i还未来得及操作，但此时被线程2抢夺了时间片进行了 +1 操作并写入到主存，此时主存的 i 的值已被更改。 由于线程1只是对共享变量进行读取操作并没有对变量进行修改，所以不会导致线程2的工作内存中缓存变量i的缓存无效，所以线程2会直接去主存读取i的值。然后线程1对线程2修改之前的i进行+1之后写入到主存，此次的线程2更新的值被线程1给覆盖掉了。 原子变量原子变量是保证了变量具有原子性的特征，对该变量的操作要么全部成功，要么全部失败。原子变量通过以下两点保证变量的原子性。 使用 volatile 修饰符保证变量的内存可见性 使用 CAS 算法通过内存值和预估值的比对实现原子性 java.util.concurrent 包中常见原子变量及API： 类 对应类型 AtomicBoolean boolean AtomicInteger int AtomicLong long AtomicReference 参数化类型 T AtomicIntegerArray int[] AtomicLongArray long[] AtomicMarkableReference Pair AtomicReferenceArray T[] AtomicStampedReference Pair 核心方法：boolean compareAndSet(expectedValue, updateValue) CAS算法CAS (Compare-And-Swap) 是一种硬件对并发的支持，针对多处理器操作而设计的处理器中的一种特殊指令，用于管理对共享数据的并访问。 CAS 是一种无锁的非阻塞算法的实现。 CAS 包含了 3 个操作数： 需要读写的内存值 V 进行比较的值 A 拟写入的新值 B 当且仅当 V 的值等于 A 时，CAS 通过原子方式用新值 B 来更新 V 的值，否则不会执行任何操作。 重现i++操作：初始化时 i=0, 线程2从主存中获取到共享变量i，内存值V=0；此时线程1抢夺到了时间片也从主存中获取到共享变量i，内存值V=0；并且进行+1操作，+1时CAS算法再次读取主存的值发现i没变，所以比较值A=0，对比V == A为true 则以B=1更新V，写入到线程1的工作内存，再写入到主存。 此时主存中的值i=1，但是线程2在线程1修改之前就读取到了 i 的值，V=0，然后进行+1操作，CAS算法再次从主存获取i值发现已经变化了：A=1，此时 V == A 为false，则取消更新。 ConcurrentHashMap 锁分段机制 Java 5.0 在 java.util.concurrent 包中提供了多种并发容器类来改进同步容器的性能。ConcurrentHashMap 同步容器类是Java 5 增加的一个线程安全的哈希表。对与多线程的操作，介于 HashMap 与 Hashtable 之间。内部采用“锁分段”机制替代 Hashtable 的独占锁。进而提高性能。 多线程环境下，使用 HashMap 是线程不安全的。为了保证线程安全，我们可以通过使用Collectinos集合工具类中的synchronized方法来将非线程安全的容器类转为对应线程安全的容器类。其内部就是给每个方法加了一把synchronized锁。另外一种方式就是使用 HashMap 的线程安全类 Hashtable。 Hashtable 采用了表锁机制，任何一个线程对容器访问其他线程会进入阻塞或轮询状态。由于Hashtable 为每个方法使用了同一把锁（每一个被synchronized修饰的方法都是使用的java内置锁，锁的是方法所属对象本身），一个线程获得了锁进入某个同步方法，其他线程都不能进入被该锁修饰的其他同步方法，除非锁被释放抢到了锁。在并发编程中，极低的降低了效率。 另外 Hashtable 这种表锁机制（每个同步方法使用同一把锁）在并发的复合操作中会产生异常。例如：在迭代操作中，线程1调用了同步的 hashNext() 方法发现有下一个元素准备调用同步的 next() 方法获取元素时，时间片被线程2抢夺过去将某个元素修改了，此时会抛出并发异常ConcurrentModificationException。多个同步方法组成的操作不是同步操作了。 为了解决这种问题于是有了锁分段机制，这个机制将容器中的数据分为一段一段存储，为每一段加一把锁，不同的锁之间互不干扰，当一个线程占用其中一段数据的时候另一个线程可以访问另一段的数据。以此提高了并发效率。 以下是常用并发容器类对应的未加同步的容器类： 并发容器类 非同步容器类 ConcurrentHashMap HashMap ConcurrentSkipListMap TreeMap ConcurrentSkipListSet TreeSet CopyOnWriteArrayList ArrayList CopyOnWriteArraySet Set 当希望许多线程访问一个容器类的时候，ConcurrentHashMap 通常优于同步的 HashMap。ConcurrentSkipListMap 通常优于同步的TreeMap。当期望的读数和遍历远远大于列表的更新数时，CopyOnWriteArrayList 优于同步的 ArrayList。 CountDownLatch 闭锁CountDownLatch 一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 闭锁可以延迟线程的进度直到其到达终止状态，闭锁可以用来确保某些活动直到其他活动都完成才继续执行： 确保某个计算在其需要的所有资源都被初始化之后才继续执行; 确保某个服务在其依赖的所有其他服务都已经启动之后才启动; 等待直到某个操作所有参与者都准备就绪再继续执行 一个简单的用例，统计所有线程执行某个同步操作的总计时间。主线程需要在其他线程执行完毕之前等待，直至闭锁计数器为0解除等待状态。 12345678910111213141516171819202122232425262728293031323334353637public class TestCountDownLatch { public static void main(String[] args) { final CountDownLatch latch = new CountDownLatch(50); // 创建一个闭锁对象 LatchDemo ld = new LatchDemo(latch); long start = System.currentTimeMillis(); for (int i = 0; i &lt; 50; i++) { new Thread(ld).start(); // 每一个线程执行一次运算 } try { latch.await(); // 主线程进入等待，直至闭锁计算器为0，解除等待状态。 } catch (InterruptedException e) { } long end = System.currentTimeMillis(); System.out.println(\"耗费时间为：\" + (end - start)); // 其他线程都执行完毕统计所有线程执行的总时间 }}class LatchDemo implements Runnable { private CountDownLatch latch; // 维护一个闭锁对象 public LatchDemo(CountDownLatch latch) { this.latch = latch; } @Override public void run() { try { for (int i = 0; i &lt; 50000; i++) { if (i % 2 == 0) { System.out.println(i); } } } finally { latch.countDown(); // 每个线程执行完毕计数器-1 } }} 实现 Callable 接口创建线程的第三种方式：实现 Callable 接口，这是一个带泛型的接口，实现这个接口的线程可以返回泛型参数的值并可以抛出异常。 12345678910111213141516171819202122232425public class TestCallable { public static void main(String[] args) { ThreadDemo td = new ThreadDemo(); // 线程对象 FutureTask&lt;Integer&gt; result = new FutureTask&lt;&gt;(td); // 用于接收线程结果的对象 new Thread(result).start(); // 启动 try { Integer sum = result.get(); //FutureTask没有获取到结果之前，线程进入阻塞状态，因此也可用于闭锁。 System.out.println(sum); System.out.println(\"------------------------------------\"); } catch (InterruptedException | ExecutionException e) { e.printStackTrace(); } }}class ThreadDemo implements Callable&lt;Integer&gt; { @Override public Integer call() throws Exception { int sum = 0; for (int i = 0; i &lt;= 100000; i++) { sum += i; } return sum; }} Lock 同步锁 在 Java 5.0 之前，协调共享对象的访问时可以使用的机制只有 synchronized 和 volatile 。Java 5.0 后增加了一些新的机制，但并不是一种替代内置锁的方法，而是当内置锁不适用时，作为一种可选择的高级功能。ReentrantLock 实现了 Lock 接口，并提供了与synchronized 相同的互斥性和内存可见性。但相较于synchronized 提供了更高的处理锁的灵活性。 解决多线程安全问题，加锁的第二种方式。相对于 synchronized 上锁使用 lock 可更具有灵活性，并且是显式锁，上锁和释放锁需要手动完成。需要注意的是当同步代码出现异常必须保证 unlock 操作一定会执行，否则由于没释放锁其他线程会一直处于阻塞状态。 12345678910111213141516171819202122232425262728293031public class TestLock { public static void main(String[] args) { Ticket ticket = new Ticket(); new Thread(ticket, \"1号窗口\").start(); new Thread(ticket, \"2号窗口\").start(); new Thread(ticket, \"3号窗口\").start(); }}class Ticket implements Runnable { private int tick = 100; private Lock lock = new ReentrantLock(); @Override public void run() { while (true) { lock.lock(); //上锁 try { if (tick &gt; 0) { try { Thread.sleep(200); } catch (InterruptedException e) { } System.out.println(Thread.currentThread().getName() + \" 完成售票，余票为：\" + --tick); } } finally { lock.unlock(); //释放锁 } } }} Condition 控制线程通信首先回顾一下生产者消费者模型，直接上代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class TestProducerAndConsumer { public static void main(String[] args) { Clerk clerk = new Clerk(); Producer producer = new Producer(); producer.setClerk(clerk); Consumer consumer = new Consumer(); consumer.setClerk(clerk); new Thread(producer,\"生产者A：\").start(); new Thread(consumer,\"消费者B：\").start(); }}// 店员（维护共享资源——产品，生产和消费）@Dataclass Clerk { private int product; public synchronized void production(){ if (product &gt;= 10) { System.out.println(\"已满！\"); try { this.wait(); } catch (InterruptedException e) { } } else { System.out.println(Thread.currentThread().getName()+\"生产了：\" + ++product); this.notifyAll(); } } public synchronized void consumption(){ if (product &lt;= 0) { System.out.println(\"缺货！\"); try { this.wait(); } catch (InterruptedException e) { } } else { System.out.println(Thread.currentThread().getName()+\"消费了：\" + product--); this.notifyAll(); } }}// 生产者@Dataclass Producer implements Runnable{ private Clerk clerk; @Override public void run() { for (int i = 0; i &lt; 20; i++){ clerk.production(); } }}// 消费者@Dataclass Consumer implements Runnable{ private Clerk clerk; @Override public void run() { for (int i = 0; i &lt; 20; i++){ clerk.consumption(); } }} 运行结果部分截图： 以上结果看似交替有序的执行，但是存在一个潜在的问题。当我们将仓库容量设为1，库存有了一个产品就满了，生产者挂起，通知消费者运行。 if (product &gt;= 1) { System.out.println(&quot;已满！&quot;); try { this.wait(); } catch (InterruptedException e) { } } else { System.out.println(Thread.currentThread().getName()+&quot;生产了：&quot; + ++product); this.notifyAll(); } 再让生产者每次生产之前睡一秒： for (int i = 0; i &lt; 20; i++){ try { Thread.sleep(200); } catch (InterruptedException e) { } clerk.production(); } 看看运行情况… 发现程序没有正常停止 为什么会出现这种情况呢？首先：生产者每次生产之前都会睡上一秒，这就意味着时间片总是被消费者先抢去了，每次都是消费者没货了进入阻塞状态之后生产者才慢吞吞的抢到了时间片进行生产。 再看一次消费者的代码： public synchronized void consumption() { if (product &lt;= 0) { System.out.println(&quot;缺货！&quot;); try { this.wait(); } catch (InterruptedException e) { } } else { System.out.println(Thread.currentThread().getName() + &quot;消费了：&quot; + product--); this.notifyAll(); } } 注意：这个 else 是问题的关键点。 生产者消费者同时开抢，由于生产者0要睡上一会，于是毫不意外的被消费者0抢到时间片，进入缺货分支里面陷入了等待状态，此时生产者0 睡完1秒生产了一个产品，唤醒所有线程。消费者0由于已经在消费的同步代码块里面所以继续执行退出了本次循环，该消费者0没有消费产品。 接着，生产者1和消费者1抢时间片，生产者每次都要睡觉怎么抢的过消费者，于是消费者1抢到了，发现有货！通知所有线程，消费者2又抢到了时间，发现没货，此时生产1才“被迫”拿到时间片生产一个产品，通知所有线程。由于生产者每次都要等待所以每次都被消费者抢到时间，消费者2执行完毕。消费者2没有消费就结束。 生产者2与消费者3开抢，消费者3胜。有货！消费完毕通知所有线程，消费者4又抢到了，没货。此时生产者2又“被迫”生产了一个，通知所有线程… 好吧，消费者5抢到了，消费完美滋滋。消费者6又来了，缺货！生产者3“被迫”生产…… 每次都是消费者抢到CPU时间片执行权，而生产者每次都是在消费者没货时等待状态下才有机会执行，而由于存在else分支导致有些消费者并没有消费产品就结束了。 最后的结果是消费者早早的遍历完20次，而生产者迟迟没有遍历完20次，慢慢吞吞的… 最关键的： 由于消费者早就消费完了，生产者生产了一个唤醒所有，只有自己被唤醒没人和它抢，就又进入了生产者方法，发现库存满了！于是乎，等待其他线程唤醒自己，然而没有其他线程了，就没人唤醒自己了… 解决办法：去掉else分支 public synchronized void production() { if (product &gt;= 1) { System.out.println(&quot;已满！&quot;); try { this.wait(); } catch (InterruptedException e) { } } System.out.println(Thread.currentThread().getName() + &quot;生产了：&quot; + ++product); this.notifyAll(); } public synchronized void consumption() { if (product &lt;= 0) { System.out.println(&quot;缺货！&quot;); try { this.wait(); } catch (InterruptedException e) { } } System.out.println(Thread.currentThread().getName() + &quot;消费了：&quot; + product--); this.notifyAll(); } 这样保证了每次消费者都能消费到产品，然而只有一个消费者和一个生产者的情况下是没问题的，当分别有两个呢？ 乱套了… 这个稍微想想很好理解，比如刚开始第一个消费者线程抢到了时间进入缺货分支陷入等待，于是生产者生产了一个，开始抢夺时间，假如此时被第二个消费者线程抢到时间进入了消费代码块，但是第一个消费线程已经进入了它就会继续执行完毕，于是乎两个消费者线程消费了同一份产品。 这就是 虚假唤醒 ，那么怎么解决呢？真是令人头大… 其实也很简单，将生产消费的同步代码块中由 if 改为 while就行了。 public synchronized void production() { while (product &gt;= 1) { System.out.println(&quot;已满！&quot;); try { this.wait(); } catch (InterruptedException e) { } } System.out.println(Thread.currentThread().getName() + &quot;生产了：&quot; + ++product); this.notifyAll(); } public synchronized void consumption() { while (product &lt;= 0) { System.out.println(&quot;缺货！&quot;); try { this.wait(); } catch (InterruptedException e) { } } System.out.println(Thread.currentThread().getName() + &quot;消费了：&quot; + product--); this.notifyAll(); } 一次等待之后，当要继续执行下面的代码，再次判断一次是否有货，有才消费，没有就继续等待。 至此，线程间通信的潜在问题及虚假唤醒问题完美解决了。 接下来就是通过使用Lock锁取代Synchronized锁，而Condiction则是对线程通信进行控制的条件变量的对象。 Condition 接口描述了可能会与锁有关联的条件变量。这些变量在用法上与使用 Object.wait 访问的隐式监视器类似，但提供了更强大的功能。需要特别指出的是，单个 Lock 可能与多个 Condition 对象关联。为了避免兼容性问题，Condition 方法的名称与对应的 Object 版本中的不同。在 Condition 对象中，与 wait、notify和notifyAll 方法对应的分别是await、signal 和 signalAll。Condition 实例实质上被绑定到一个锁上。要为特定 Lock 实例获得Condition 实例，请使用其 newCondition() 方法。 123456789101112131415161718192021222324252627282930313233343536373839class Clerk1 { private int product; private Lock lock = new ReentrantLock(); // 加 Lock 锁 Condition condition = lock.newCondition(); // 通过 lock 获得锁关联变量对象 public void production() { lock.lock(); try { while (product &gt;= 1) { System.out.println(\"已满！\"); try { condition.await(); } catch (InterruptedException e) { } } System.out.println(Thread.currentThread().getName() + \"生产了：\" + ++product); condition.signalAll(); } finally { lock.unlock(); } } public void consumption() { lock.lock(); try { while (product &lt;= 0) { System.out.println(\"缺货！\"); try { condition.await(); } catch (InterruptedException e) { } } System.out.println(Thread.currentThread().getName() + \"消费了：\" + product--); condition.signalAll(); } finally { lock.unlock(); } }} 线程按序交替 编写一个程序，开启 3 个线程，这三个线程的 ID 分别为A、B、C，每个线程将自己的 ID 在屏幕上打印 10 遍，要求输出的结果必须按顺序显示。如：ABCABCABC…… 依次递归 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class TestABCAlternate { public static void main(String[] args) { ABCAlternate alternate = new ABCAlternate(); new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; 10; i++) { alternate.printA(); } } },\"A\").start(); new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; 10; i++) { alternate.printB(); } } },\"B\").start(); new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; 10; i++) { alternate.printC(); } } },\"C\").start(); }}class ABCAlternate { private int num = 1; Lock lock = new ReentrantLock(); Condition con1 = lock.newCondition(); Condition con2 = lock.newCondition(); Condition con3 = lock.newCondition(); public void printA() { lock.lock(); try { if (num != 1) { try { con1.await(); } catch (InterruptedException e) { } } System.out.print(Thread.currentThread().getName()); num = 2; con2.signal(); } finally { lock.unlock(); } } public void printB() { lock.lock(); try { if (num != 2) { try { con2.await(); } catch (InterruptedException e) { } } System.out.print(Thread.currentThread().getName()); num = 3; con3.signal(); } finally { lock.unlock(); } } public void printC() { lock.lock(); try { if (num != 3) { try { con3.await(); } catch (InterruptedException e) { } } System.out.print(Thread.currentThread().getName()); num = 1; con1.signal(); } finally { lock.unlock(); } }} ReadWriteLock 读写锁ReadWriteLock 维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。只要没有 writer，读取锁可以由多个 reader 线程同时保持。写入锁是独占的。 ReadWriteLock 读取操作通常不会改变共享资源，但执行写入操作时，必须独占方式来获取锁。对于读取操作占多数的数据结构。 ReadWriteLock 能提供比独占锁更高的并发性。而对于只读的数据结构，其中包含的不变性可以完全不需要考虑加锁操作 用例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class TestReadWriterLock { public static void main(String[] args) { ReadWriterLock rwLock = new ReadWriterLock(); new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; 100; i++) { rwLock.read(); } } }, \"ReadLock:\").start(); new Thread(new Runnable() { @Override public void run() { rwLock.writer(233); } }, \"WriterLock:\").start(); }}class ReadWriterLock { private int resource; private ReadWriteLock rwLock = new ReentrantReadWriteLock(); public void read() { try { rwLock.readLock().lock(); System.out.println(Thread.currentThread().getName() + resource); } finally { rwLock.readLock().unlock(); } } public void writer(int n) { try { rwLock.writeLock().lock(); resource = n; System.out.println(Thread.currentThread().getName() + resource); } finally { rwLock.writeLock().unlock(); } }} 运行结果部分截图： 线程八锁线程八锁，实际上是多线程编程中经常遇到的八种情况。通过八种场景学习总结线程锁的特性。 场景一：两个普通同步方法，两个线程，是同一把锁（this锁），存在互斥关系。 123456789101112131415161718192021222324252627282930public class TestThread8Monitor { public static void main(String[] args) { Number number = new Number(); new Thread(new Runnable() { @Override public void run() { number.one(); } }).start(); new Thread(new Runnable() { @Override public void run() { number.two(); } }).start(); }}class Number { public synchronized void one() { System.out.println(\"one\"); } public synchronized void two() { System.out.println(\"two\"); }} 运行结果： one two 场景二：让同步方法 one() 睡3秒，观察结果。同一把锁，存在互斥关系，一个同步方法没有释放锁其他所有同步方法阻塞。 public synchronized void one() { try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;one&quot;); } 运行结果： one two 场景三：新增一个同步方法 three()，三个同步方法，三个线程，一个线程对象，竞争打印。 public synchronized void one() { System.out.println(&quot;one&quot;); } public synchronized void two() { System.out.println(&quot;two&quot;); } public synchronized void three() { System.out.println(&quot;three&quot;); } 运行结果： one three two 场景四：新增一个 Number 对象。两个线程对象，两个同步方法。不同锁之间（两个this不是同一个this）的同步方法不存在互斥。 public static void main(String[] args) { Number number = new Number(); Number number2 = new Number(); new Thread(new Runnable() { @Override public void run() { number.one(); } }).start(); new Thread(new Runnable() { @Override public void run() { number2.two(); } }).start(); } 两个同步方法： public synchronized void one() { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;one&quot;); } public synchronized void two() { System.out.println(&quot;two&quot;); } 运行结果： two one 场景五：同一个线程对象，一个静态同步方法，一个非静态同步方法。不同锁之间的同步方法不存在互斥。 public static synchronized void one() { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;one&quot;); } public synchronized void two() { System.out.println(&quot;two&quot;); } 运行结果： two one 场景六：同一个线程对象，两个静态同步方法，是相同的锁（Class锁），存在互斥。 public static synchronized void one() { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;one&quot;); } public static synchronized void two() { System.out.println(&quot;two&quot;); } 运行结果： one two 场景七：新增一个线程对象。两个线程对象，两个静态同步方法。同一把锁存在互斥性。 public static void main(String[] args) { Number number = new Number(); Number number2 = new Number(); new Thread(new Runnable() { @Override public void run() { number.one(); } }).start(); new Thread(new Runnable() { @Override public void run() { number2.two(); } }).start(); } 静态同步方法： public static synchronized void one() { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;one&quot;); } public static synchronized void two() { System.out.println(&quot;two&quot;); } 运行结果： one two 场景八：新增一个线程对象。两个线程对象，一个静态同步方法，一个非静态同步方法。非同一把锁不存在竞争 public static synchronized void one() { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;one&quot;); } public synchronized void two() { System.out.println(&quot;two&quot;); } 运行结果： two one 结论： 静态同步方法的锁是 Class 锁，非静态同步方法的锁是 this 锁，不同的对象是不同的 this 锁。 某一个时刻内，只能有一个线程持有锁，无论几个方法。相同的锁，一个线程获得锁，其他线程都得等待。 线程池创建线程的第四种方式，线程池：提供了一个线程队列，队列中保存着所有等待状态的线程。避免了创建与销毁额外开销，提高了响应的速度。 线程池的体系结构： java.util.concurrent.Executor : 负责线程的使用与调度的根接口 |--**ExecutorService 子接口: 线程池的主要接口 |--ThreadPoolExecutor 线程池的实现类 |--ScheduledExecutorService 子接口：负责线程的调度 |--ScheduledThreadPoolExecutor ：继承ThreadPoolExecutor，实现ScheduledExecutorService ThreadPoolExecutor和ScheduledThreadPoolExecutor可以创建连接池对象，但是使用工厂获得对象是最好的方式。工具类 Executors 的常用API及描述： 方法 描述 ExecutorService newFixedThreadPool() 创建固定大小的线程池 ExecutorService newCachedThreadPool() 缓存线程池，线程池的数量不固定，可以根据需求自动的更改数量，可以自动进行线程回收 ExecutorService newSingleThreadExecutor() 创建单个线程池。线程池中只有一个线程 ScheduledExecutorService newScheduledThreadPool() 创建固定大小的线程，可以延迟或定时的执行任务 用例说明： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class TestThreadPool { public static void main(String[] args) throws Exception { //创建线程池 ExecutorService pool = Executors.newFixedThreadPool(5); ThreadPoolDemo tpd = new ThreadPoolDemo(); //5个线程执行10个任务，某些线程会被回收 for (int i = 0; i &lt; 10; i++) { pool.submit(tpd); // 可传 Callable 和 Runnable接口作为任务对象 } //关闭线程池 pool.shutdown(); /** 以 Callable 作为任务 **/ List&lt;Future&lt;Integer&gt;&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) { Future&lt;Integer&gt; future = pool.submit(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { int sum = 0; for (int i = 0; i &lt;= 100; i++) { sum += i; } return sum; } }); list.add(future); } pool.shutdown(); for (Future&lt;Integer&gt; future : list) { System.out.println(future.get()); } }}class ThreadPoolDemo implements Runnable { private int i = 0; @Override public void run() { while (i &lt;= 100) { System.out.println(Thread.currentThread().getName() + \" : \" + i++); } }} 线程调度一个 ExecutorService，可安排在给定的延迟后运行或定期执行的命令。 123456789101112131415161718192021222324public class TestScheduledThreadPool { public static void main(String[] args) throws ExecutionException, InterruptedException { // 线程池的任务调度 ScheduledExecutorService pool = Executors.newScheduledThreadPool(5); // 十个任务 for (int i = 0; i &lt; 5; i++) { /** * 参数一：任务 * 参数二：延迟时间 * 参数一：时间单位 */ ScheduledFuture&lt;Integer&gt; future = pool.schedule(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { int num = new Random().nextInt(100); return num; } }, 1, TimeUnit.SECONDS); System.out.println(future.get()); } // 关闭线程池 pool.shutdown(); }} ForkJoinPool 分支/合并框架 工作窃取Fork/Join 框架：就是在必要的情况下，将一个大任务，进行拆分(fork)成若干个小任务（拆到不可再拆时），再将一个个的小任务运算的结果进行 join 汇总。 前面学过 归并排序，实际上这种思想和归并排序是一样的。 采用 “工作窃取”模式（work-stealing）：当执行新的任务时它可以将其拆分分成更小的任务执行，并将小任务加到线程队列中，然后再从一个随机线程的队列中偷一个并把它放在自己的队列中。 相对于一般的线程池实现，fork/join框架的优势体现在对其中包含的任务的处理方式上.在一般的线程池中，如果一个线程正在执行的任务由于某些原因无法继续运行，那么该线程会处于等待状态。而在fork/join框架实现中，如果某个子问题由于等待另外一个子问题的完成而无法继续运行。那么处理该子问题的线程会主动寻找其他尚未运行的子问题来执行.这种方式减少了线程的等待时间，提高了性能。 模拟拆分： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class TestForkJoinPool { public static void main(String[] args) { // 创建fork/join对象 ForkJoinPool pool = new ForkJoinPool(); // 创建任务对象 ForkJoinTask&lt;Long&gt; task = new ForkJoinSumCalculate(0L, 100000000L); // 执行任务 Long sum = pool.invoke(task); System.out.println(sum); }}// 创建自己的fork/join任务，计算从start开始end个数的和。需要继承递归任务类。class ForkJoinSumCalculate extends RecursiveTask&lt;Long&gt; { private long start; private long end; /** * 拆分临界值：定义子任务（子线程队列）到多大时不再拆分，开始计算每个子任务的值。 * - 如果临界值 = 任务总大小，就不会拆分，直接循环计算所有值。 * - 如果临界值 = 1L，就拆到每个子线程队列大小为1时停止拆分 */ private static final long THURSHOLD = 10000L; public ForkJoinSumCalculate(long start, long end) { this.start = start; this.end = end; } @Override protected Long compute() { long len = end - start; if (len &lt;= THURSHOLD) { long sum = 0L; for (long i = start; i &lt;= end; i++) { sum += i; } return sum; } else { long mid = (end + start) / 2; ForkJoinSumCalculate left = new ForkJoinSumCalculate(start, mid); left.fork(); ForkJoinSumCalculate right = new ForkJoinSumCalculate(mid + 1, end); right.fork(); return left.join() + right.join(); } }}","link":"/2018/09/01/线程高级/"},{"title":"基于 Spring Boot 技术栈构建企业级博客系统的开发记录","text":"基于 Spring Boot 技术栈构建企业级博客系统的开发记录- 该项目构建基于 Gradle，目的在于通过博客系统的开发了解企业级开发的完整流程，学习掌握 Spring Boot 及其周边前沿技术。- preview：http://blog.yuzh.xyz 前端 BootStrap 样式框架 Thymeleaf 模板引擎 JQuery js 函数库 HTML5 页面结构 JavaScript 脚本 CSS 样式 后端 Spring 解耦合 Spring MVC 控制层框架 Spring Boot 快捷开发，整合 Spring 全家桶 Spring Data 持久层框架，简化数据库操作 Spring Security 安全权限控制 Hibernate 遵循 JPA 规范的持久层实现 数据存储 MySql 关系型数据库 H2 内存数据库 MongoDB 文件存储 其他 Elastic Search 全文检索 Gradle 项目构建 插件 catalog-generator.js 博客目录生成插件 tether.js 下拉框插件 thinker-md.vendor.js markdown 编辑器 toastr.min.js 提示框 cropbox.js 图片裁剪 … … 一、 使用 Gradle / Spring Initializer 搭建 Spring Boot 运行环境1.1 安装 Gradle 环境下载 gradle 二进制文件，解压到指定目录； 配置 GRADLE_HOME 环境变量，值为解压路径； 添加 %GRADLE_HOME%/bin 到 Path 变量。 命令行 gradle -v 查看版本： 1.2 使用 Spring Initializer 快速生成 Spring Boot 应用使用 Spring 快速开始向导，创建一个项目并下载到本地。 使用 gradle 编译项目，进入根目录执行： 1gradle build 编译完成之后会在目录生成一个 build 文件夹，里面存放着编译后的文件以及安装的jar。 运行这个 jar ： 1java -jar spring-boot-blog-0.0.1-SNAPSHOT.jar 一个简单的 spring boot 应用启动起来了，接下来可以正常访问。 1.3 项目结构 .gradle gradle 运行时相关配置文件，不用多说了。 文件夹 build 项目编译后路径 文件夹 gradle 文件夹 wrapper 统一管理 gradle 版本，优点是即使没有装 gradle 环境可以运行里面的 jar 直接构建项目。 build.gradle gradle的用户配置文件（构建脚本），相当于 maven 的 pom.xml. gradlew gradle 环境搭建的脚本（linux） gradlew.bat gradle 环境搭建的脚本（windows） settings.gradle 其他用户配置 1.4 自定义存储仓库更改 build.gradle 配置文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// buildscript 代码块中脚本优先执行buildscript { // ext 用于定义动态属性 ext { springBootVersion = '1.5.17.BUILD-SNAPSHOT' } // 使用了 Maven 的中央仓库（也可以指定其他仓库） repositories { mavenCentral() maven { url \"https://repo.spring.io/snapshot\" } maven { url \"https://repo.spring.io/milestone\" } // 使用 aliyun 镜像仓库// maven { url 'http://maven.aliyun.com/nexus/content/groups/public/' } } // 依赖关系 dependencies { // classpath 声明说明了在执行其余的脚本时，ClassLoader 可以使用这些依赖项 classpath(\"org.springframework.boot:spring-boot-gradle-plugin:${springBootVersion}\") }}// 使用插件apply plugin: 'java'apply plugin: 'eclipse'apply plugin: 'org.springframework.boot'group = 'xyz.yuzh.spring.boot.blog'// 打包的类型为 jar，并指定了生成的打包的文件名称和版本jar { baseName = 'hello-world' version = '0.0.1-SNAPSHOT'}version = '0.0.1-SNAPSHOT'// 指定编译 .java 文件的 JDK 版本sourceCompatibility = 1.8// 默认使用了 Maven 的中央仓库。repositories { mavenCentral() maven { url \"https://repo.spring.io/snapshot\" } maven { url \"https://repo.spring.io/milestone\" }// maven { url 'http://maven.aliyun.com/nexus/content/groups/public/' }}// 依赖关系dependencies { // 该依赖对于编译发行是必须的 compile('org.springframework.boot:spring-boot-starter-web') // 该依赖对于编译测试是必须的，默认包含编译产品依赖和编译时依 testCompile('org.springframework.boot:spring-boot-starter-test')} 1.5 编写程序代码及测试用例控制层： 1234567@RestControllerpublic class HelloController { @RequestMapping(value = \"/hello\") public String hello(){ return \"hello gradle!\"; }} 用例代码：使用了 Spring Mvc 单元测试类 MockMVC，详解参考 123456789101112131415161718@RunWith(SpringRunner.class)@SpringBootTest@AutoConfigureMockMvcpublic class SpringBootBlogApplicationTests { @Autowired private MockMvc mockMvc; @Test public void testHello() throws Exception { ResultActions actions = mockMvc.perform(MockMvcRequestBuilders.get(\"/hello\"). accept(MediaType.APPLICATION_JSON)); // 指定客户端能够接收的内容类型 actions.andExpect(status().isOk()); // 添加断言, 添加ResultMatcher验证规则，验证控制器执行完成后结果是否正确. actions.andExpect(content().string(equalTo(\"hello gradle!\"))); // 添加断言,返回结果内容是否是指定的. actions.andDo(MockMvcResultHandlers.print()); // 添加一个结果处理器，输出整个响应结果信息. actions.andReturn(); // 执行完毕返回相应的结果 }} 1.6 以 Gradle / Wrapper 编译项目当本地没有装 gradle 环境时，可以通过 wrapper 构建项目，只需在根目录执行即可打包： 1gradlew build 运行： 1.7 Gradle 项目运行的三种方式1). 使用 java -jar 2). 通过 SpringApplication.run() 3). 使用 Spring Boot Gradle 插件 1gradle bootRun / gradlew bootRun (wrapper 方式) 二、 Thymeleaf 模板引擎2.1 Thymeleaf官方文档 Java 模板引擎。能够处理 Html / XML / JavaScript / CSS / 甚至纯文本 。类似于 JSP / FreeMarker 自然模板。原型即页面 语法优雅易懂。支持 OGNL / SpringEL 遵从 Web 标准。支持 HTML5 2.2 标准方言（语法）名称空间 &lt;span th:text=&quot;…&quot;&gt; 需要引入命名空间: &lt;html xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; 或 &lt;span data-th-text=&quot;…&quot;&gt; 符合html5标准，不需要引入命名空间 变量表达式 - ${…} &lt;span th:text=&quot;${book.author.name}&quot;&gt; 消息表达式（i8n / 国际化）- #{…} &lt;th th:text=&quot;#{header.address.city}&quot;&gt;…&lt;/th&gt; &lt;th th:text=&quot;#{header.address.country}&quot;&gt;…&lt;/th&gt; 选择表达式 - *{…} &lt;div th:object=&quot;${book}&quot;&gt; ... &lt;span th:text=&quot;*{title}&quot;&gt;...&lt;/span&gt; ... &lt;/div&gt; 与变量表达式的区别：它是在当前选择的对象而不是整个上下文变量映射上执行。${book} 取的是整个上下文中的变量，而 *{title} 是在当前 ${book} 里边的变量。因此变量表达式一定程度上提高了效率。 链接表达式 - @{…} 链接表达式可以是相对的，在这种情况下，应用程序上下文将不会作为 URL 的前缀 &lt;a th:href=&quot;@{../documents/report}&quot;&gt;…&lt;/a&gt; 也可以是服务器相对的，同样也没有应用程序上下文前缀 &lt;a th:href=&quot;@{~/contents/main}&quot;&gt;…&lt;/a&gt; 协议相对的（类似绝对 URL，但浏览器将使用在显示的页面中使用的相同的 HTTP 或 HTTPS 协议） &lt;a th:href=&quot;@{//static.mycompany.com/res/initial}&quot;&gt;…&lt;/a&gt; 也可以是绝对的 &lt;a th:href=&quot;@{http://static.mycompany.com/main}&quot;&gt;…&lt;/a&gt; 模板布局 th:insert 将公共片段整个插入到声明引入的元素中 th:replace 将声明引入的元素替换为公共片段 th:include 将被引入的片段的内容包含进这个标签 &lt;footer th:fragment=&quot;copy&quot;&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/footer&gt; 引入方式 &lt;div th:insert=&quot;footer :: copy&quot;&gt;&lt;/div&gt; &lt;div th:replace=&quot;footer :: copy&quot;&gt;&lt;/div&gt; &lt;div th:include=&quot;footer :: copy&quot;&gt;&lt;/div&gt; 效果 &lt;div&gt; &lt;footer&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/footer&gt; &lt;/div&gt; &lt;footer&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/footer&gt; &lt;div&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/div&gt; 也可以使用指定的 id 来替代 th:fragment=&quot;copy&quot; 引用时指定 #id 字面量 文本 &lt;span th:text=&quot;'web application'&quot;&gt; 单引号包裹 数字 &lt;span th:text=&quot;2015&quot;&gt; or &lt;span th:text=&quot;2980 + 3&quot;&gt; 布尔：&lt;span th:if=&quot;${user.isAdmin()} == false&quot;&gt; or &lt;span th:if=&quot;${user.name} == null 算术操作 (+ 、-、*、/、%)：&lt;span th:with=&quot;isEven=(${prodStat.count} % 2 == 0)&quot;&gt; 比较和等价：&gt; 、&lt; 、&gt;= 、 &lt;= （gt、lt、ge、le） 等价： == 、 != (eq、ne) 条件运算 &lt;span th:class=&quot;${row.even} ? ‘even&apos; : ‘odd&apos; &quot;&gt;&lt;/span&gt; 无操作 - __ &lt;span th:text=&quot;${user.name} ? : __&quot;&gt;no user authenticated&lt;/span&gt; 用户名不存在取无操作运算符，保留原始文本值。 设置属性值 设置任意属性值 th:attr th:attr=&quot;action=@{/subsctibe}&quot; 设置action属性值 设置指定属性值，比如: th:action / th:value / th:text 固定布尔属性， th:checked=&quot;${user.active}&quot; 如果结果为 true 设置为选中状态 迭代器 基本迭代 th:each &lt;li th:each=“book : ${books}” th:text=“${book.title}”&gt;En las Orillas del Sar&lt;/li&gt; 状态变量：index（0开始）、count（1开始）、size、current、even/odd、first、last 条件语句 th:if / th:unless （成立时 / 不成立时） th:switch &lt;div th:switch=&quot;${user.role}&quot;&gt; &lt;p th:case=&quot;&apos;admin&apos;&quot;&gt;user is an administrator&lt;/p&gt; &lt;p th:case=&quot;${roles.manager}&quot;&gt;user is an manager&lt;/p&gt; &lt;p th:case=&quot;*&quot;&gt;user is some other thing&lt;/p&gt; &lt;/div&gt; 注释 1). 标准的 html 注释 &lt;!-- --&gt; 2). thymeleaf 解析器注释块 &lt;!--/* */--&gt; 删除 &lt;!--/* 和 */--&gt; 之间的所有内容 &lt;!--/*--&gt; &lt;div&gt;you can see me only before thymeleaf processes me!&lt;/div&gt; &lt;!--*/--&gt; 3). 原型注释块：当模板静态打开时（比如原型设计），原型注释块所注释的代码将被注释，而在模板执行时，这些注释的代码，会被显示出来。 原型设计代码： &lt;span&gt;hello&lt;/span&gt; &lt;!--/*/ &lt;div th:th:text=&quot;${...}&quot;&gt; ... &lt;/div&gt; /*/--&gt; &lt;span&gt;goodbye!&lt;/span&gt; 模板渲染执行后： &lt;span&gt;hello&lt;/span&gt; &lt;div th:th:text=&quot;${...}&quot;&gt; ... &lt;/div&gt; &lt;span&gt;goodbye!&lt;/span&gt; 内联表达式 [[…]] 或 [(…)] 分别对应于 th:text（会转译特殊字符） 和 th:utext（不会转译特殊字符） 禁用内联：th:inline=&quot;none&quot; Javascript 内联：th:inline=&quot;JavaScript&quot; CSS 内联：th:inline=&quot;css&quot; 2.3 表达式基本对象#ctx：上下文对象。是 org.thymeleaf.context.IContext 或者 org.thymeleaf.context.IWebContext 的实现。 #locale： 直接访问与 java.util.Locale 关联的当前的请求。 ${#ctx.locale} ${#ctx.bariableNames} ${#ctx.request} ${#ctx.response} ${#ctx.session} ${#ctx.servletContext} ${#locale} Request/session 等属性 param：用于检索请求参数 session：用于检索session属性 application：用于检索application/servlet上下文属性 ${#param.foo} ${#param.size()} ${#param.isEmpty()} ${#param.containsKey(&apos;foo&apos;)} ${#session.foo} ${#session.size()} ${#session.isEmpty()} ${#session.containsKey(&apos;foo&apos;)} ${#application.foo} ${#application.size()} ${#application.isEmpty()} ${#application.containsKey(&apos;foo&apos;)} Web上下文对象 #request：直接访问与当前请求关联的 HttpServletRequest 对象 #session：直接访问与当前请求关联的 HttpSession 对象 #servletContext：直接访问与当前请求关联的 servletContext 对象 ${#request.getAttribute(&apos;foo&apos;)} ${#request.getParameter(&apos;foo&apos;)} ${#request.getContextPath()} ${#request.getRequestName())} ${#session.getAttribute(&apos;foo&apos;)} ${#session.id} ${#session.lastAccessedTime} ${#servletContext.getAttribute(&apos;foo&apos;)} ${#servletContext.contextPath} 2.4 集成 Spring Boot修改 buid.gradle。添加对 Thymeleaf 的依赖，自定义 Thymeleaf 和 Thyme leaf Layout Dialect 的版本。 123456789101112131415161718buildscript { // ext 用于定义动态属性（统一管理版本） ext { springBootVersion = '1.5.17.BUILD-SNAPSHOT' } // 指定 Thymeleaf 和 Thymeleaf Layout Dialect 的版本 ext['thymeleaf.version'] = '3.0.3.RELEASE' ext['thymeleaf-layout-dialect.version'] = '2.2.0' ......}......// 依赖关系dependencies { ...... // 添加 Thymeleaf 依赖 testCompile('org.springframework.boot:spring-boot-starter-thymeleaf')} 修改 Spring Boot 的 application.properties（或 application.yml ） 123456spring: thymeleaf: encoding: UTF-8 cache: false # 使用 HTML5 标准 mode: HTML5 2.5 Thymeleaf 实战接口设计 接口 描述 GET /users 返回用于展示用户列表的 list.html GET /users/{id} 返回用于展示用户的 view.html GET /users/form 返回用于新增或者修改用户的 form.html POST /users 新增或修改用户，成功后重定向到 list.html GET /users/delete/{id} 根据 id 删除相应的用户数据，成功后重定向到 list.html GET /users/modify/{id} 根据 id 获取相应的用户数据，并返回 form.html 用来执行修改 后台编码 1234567891011121314151617181920212223242526272829303132333435363738@Repositorypublic class UserRepositoryImpl implements UserRepository { /** * 累加器 */ private static AtomicLong counter = new AtomicLong(); /** * 暂存数据 */ ConcurrentMap&lt;Long, User&gt; userMap = new ConcurrentHashMap&lt;&gt;(); @Override public User saveOrUpdateUser(User user) { Long id = user.getId(); if (id &lt;= 0) { id = counter.incrementAndGet(); user.setId(id); } userMap.put(id, user); return null; } @Override public void deleteUser(Long id) { userMap.remove(id); } @Override public User getUserById(Long id) { return userMap.get(id); } @Override public List&lt;User&gt; listUser() { return new ArrayList&lt;&gt;(userMap.values()); }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475@RestController@RequestMapping(value = \"/users\")public class UserController { @Autowired private UserRepository userRepository; public List&lt;User&gt; getUserList() { return userRepository.listUser(); } /** * 查询所有用户 [ GET /users ] * */ @GetMapping public ModelAndView list(ModelMap map) { map.addAttribute(\"users\", getUserList()); map.addAttribute(\"title\", \"用户管理\"); return new ModelAndView(\"users/list\", \"userModel\", map); } /** * 根据 id 查询用户 [ GET /users/{id} ] */ @GetMapping(value = \"/{id}\") public ModelAndView getUserById(@PathVariable(\"id\") Long id, ModelMap map) { User user = userRepository.getUserById(id); System.out.println(user); map.addAttribute(\"user\", user); map.addAttribute(\"title\", \"查看用户\"); return new ModelAndView(\"users/view\", \"userModel\", map); } /** * 跳转到新建用户 [ GET /users/form ] */ @GetMapping(value = \"/form\") public ModelAndView createForm(ModelMap map) { map.addAttribute(\"user\", new User()); map.addAttribute(\"title\", \"创建用户\"); return new ModelAndView(\"users/form\", \"userModel\", map); } /** * 新建及修改 [ POST /users ] */ @PostMapping public ModelAndView create(User user) { userRepository.saveOrUpdateUser(user); return new ModelAndView(\"redirect:/users\"); } /** * 删除用户 [ GET /users/delete/{id} ] */ @GetMapping(value = \"delete/{id}\") public ModelAndView delete(@PathVariable(\"id\") Long id, ModelMap map) { userRepository.deleteUser(id); map.addAttribute(\"users\", getUserList()); return new ModelAndView(\"redirect:/users\"); } /** * 跳转修改页面 [ GET /users/modify/{id} ] */ @GetMapping(value = \"modify/{id}\") public ModelAndView update(@PathVariable(\"id\") Long id, ModelMap map) { User user = userRepository.getUserById(id); map.addAttribute(\"user\", user); map.addAttribute(\"title\", \"修改用户\"); return new ModelAndView(\"users/form\", \"userModel\", map); }} 前台设计 fragment/header.html：共用的头部页面 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\" xmlns:layout=\"http://www.ultraq.net.nz/thymeleaf/layout\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Thymeleaf in action&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div th:fragment=\"header\"&gt; &lt;h1&gt;Thymeleaf in action&lt;/h1&gt; &lt;a th:href=\"@{~/users}\"&gt;首页&lt;/a&gt; &lt;a th:href=\"@{~/users/form}\"&gt;新增&lt;/a&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; fragment/footer.html：共用的底部页面 123&lt;div th:fragment=\"footer\"&gt; &lt;a th:href=\"@{http://blog.yuzh.xyz}\"&gt;welcome to blog.yuzh.xyz&lt;/a&gt;&lt;/div&gt; users/form.html 新增/修改 12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\" xmlns:layout=\"http://www.ultraq.net.nz/thymeleaf/layout\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Thymeleaf in action&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div th:replace=\"~{fragments/header::header}\"&gt;&lt;/div&gt;&lt;h3 th:text=\"${userModel.title}\"&gt;&lt;/h3&gt;&lt;form th:action=\"@{~/users}\" method=\"post\"&gt; &lt;input type=\"text\" name=\"name\" th:value=\"${userModel!=null}?${userModel.user.name}\" placeholder=\"name\"&gt; &lt;input type=\"email\" name=\"email\" th:value=\"${userModel!=null}?${userModel.user.email}\" placeholder=\"email\"&gt; &lt;input type=\"text\" name=\"age\" th:value=\"${userModel!=null}?${userModel.user.age}\" placeholder=\"age\"&gt; &lt;input type=\"submit\" th:value=\"${userModel.title=='创建用户'} ? 'register' : 'modify'\"&gt; &lt;input type=\"hidden\" name=\"id\" th:if=\"${userModel.title=='修改用户'}\" th:value=\"${userModel.user.id}\"&gt;&lt;/form&gt;&lt;div th:replace=\"~{fragments/footer::footer}\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; users/list.html 列表展示 1234567891011121314151617181920212223242526272829303132333435363738&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\" xmlns:layout=\"http://www.ultraq.net.nz/thymeleaf/layout\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Thymeleaf in action&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div th:replace=\"~{fragments/header :: header}\"&gt;&lt;/div&gt;&lt;h3 th:text=\"${userModel!=null}?${userModel.title}\"&gt;yuzh&lt;/h3&gt;&lt;table border=\"1\"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;Email&lt;/th&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Age&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr th:if=\"${userModel.users.size()}==0\"&gt; &lt;td colspan=\"5\"&gt;没有用户信息！&lt;/td&gt; &lt;/tr&gt; &lt;tr th:each=\"user:${userModel.users}\"&gt; &lt;td th:text=\"${user.id}\"&gt;&lt;/td&gt; &lt;td th:text=\"${user.email}\"&gt;&lt;/td&gt; &lt;td th:text=\"${user.name}\"&gt;&lt;/td&gt; &lt;td th:text=\"${user.age}\"&gt;&lt;/td&gt; &lt;td&gt; &lt;a href=\"\" th:href=\"@{~/users/}+${user.id}\"&gt;修改&lt;/a&gt; &lt;a href=\"\" th:href=\"@{~/users/delete/}+${user.id}\"&gt;删除&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt;&lt;div th:replace=\"~{fragments/footer::footer}\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; users/view 查看用户 1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\" xmlns:layout=\"http://www.ultraq.net.nz/thymeleaf/layout\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Thymeleaf in action&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div th:replace=\"~{fragments/header :: header}\"&gt;&lt;/div&gt;&lt;h3&gt;[[${userModel.title}]]&lt;/h3&gt;&lt;a th:href=\"@{~/users/modify/}+${userModel.user.id}\"&gt;修改信息&lt;/a&gt;&lt;p&gt;ID：[[${userModel.user.id}]]&lt;/p&gt;&lt;p&gt;Name：[[${userModel.user.name}]]&lt;/p&gt;&lt;p&gt;Email：[[${userModel.user.email}]]&lt;/p&gt;&lt;p&gt;Age：[[${userModel.user.age}]]&lt;/p&gt;&lt;div th:replace=\"~{fragments/footer :: footer}\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 三、 Spring Data JPA 数据持久化3.1 JPA 简介JPA (Java Persistence API) 是用于管理 JavaEE 和 JavaSE环境中的持久化，以及对象/关系映射的 Java API。 JPA 是用于处理数据持久化的接口（规范），基于 JPA 规范的实现有 EclipiseLink、Hibernate、Apache OpenJPA 3.2 JPA 核心概念理解 jpa 的核心概念，才能更好的使用 jpa 持久化。没有符合任意一项都不能成功完成持久化！ 实体 实体表示关系型数据库中表 每个实体实例对应于表中的行 类必须使用 javax.persistence.Entity 注解 类必须有一个 public 或 protected 的无参数构造器 实体实例被当作以分离对象方式进行传递（例如通过会话 bean 的远程业务接口），则该类必须实现 Serializable 接口 必须要有唯一的对象标识符：简单主键（javax.persistence.Id）、复合主键（javax.persistence.Embeddedld 和 javax.persistence.IdClass） 关系 一对一：@OneToOne 一对多：@OneToMany 多对一：@ManyToOne 多对多：@ManyToMany EntityManager (管理实体的接口 管理实体的接口 定义用于与持久化上下文进行交互的方法 创建和删除持久实体实例，通过实体的主键查找实体 允许在实体上运行查询 获取 EntityManager 实例 12345678910111213141516@PersistenceUnit EntityManagerFactory emf; // 用于创建 EntityManager 的工厂类EntityManager em;@ResourceUserTransaction utx; // 事务...em = emf.createEmtityManager(); // 创建 EntityManager try{ utx.begin(); // 事务开始 em.persist(SomeEntity); // 通过实体管理器持久化一个实体对象 em.merge(AnotherEntity); // 通过实体管理器合并一个实体对象 em.remove(ThirdEntity); // 通过实体管理器移除一个实体对象 utx.commit(); // 事务提交} catch (Exception e){ utx.rollback(); // 回滚} 查找实体 1234567@PersistenceContextEntityManager em;public void enterOrder(int custID, CustomerOrder newOrder){ Customer cust = em.find(Customer.class, custID); // 通过实体管理器查找指定类型的实体 cust.getOrders().add(newOrder); newOrder.setCustomer(cust);} 3.3 Spring Data JPA 使用概括什么是 Spring Data JPA： Spring Data 家族的一部分 对基于 JPA 的数据访问层的增强支持 更容易构建基于使用 Spring 的数据访问技术栈的应用程序 常用接口： CrudRepository 定义了一些增删改查的通用接口 PagingAndSortingRepository 用于分页和排序的接口，扩展于 CrudRepository 自定义接口：继承 Repository 及子类 3.4. Spring Data JPA / Hibernate / Spring Boot 集成修改 build.gradle 12345678910111213141516171819buildscript { ...... // 自定义 Hibernate 的版本 ext['hibernate.version'] = '5.2.8.Final' ......}// 依赖关系dependencies { ...... // 添加 Spring Data JPA 的依赖 compile('org.springframework.boot:spring-boot-starter-data-jpa') // 添加 MySQL连接驱动 的依赖 compile('mysql:mysql-connector-java:6.0.5') // 添加 H2 的依赖 内存数据库 runtime('com.h2database:h2:1.4.193') ......} 3.5 数据持久化实战3.5.1 H2 内存数据库后台编码 实体 User 资源库 UserRepository 控制器 UserController 修改实体：实现 Serializable 接口、添加 @Entity 、设置主键 @Id 和自增策略 @GeneratedValue 123456789101112131415161718192021222324252627282930@Entity // 实体public class User implements Serializable { @Id // 主键 @GeneratedValue(strategy = GenerationType.IDENTITY) // 自增策略 private long id; private String name; private String email; private int age; protected User() { // JPA 的规范要求无参构造函数；设为 protected 防止直接使用 } public User(long id, String name, String email, int age) { this.id = id; this.name = name; this.email = email; this.age = age; } @Override public String toString() { return \"User{\" + \"id=\" + id + \", name='\" + name + '\\'' + \", email='\" + email + '\\'' + \", age=\" + age + '}'; }} 修改资源库：删除自己的实现、继承 JPA 的 @Repository 接口 1234567/** * @author yu.zh [yuzh233@gmail.com] 2018/09/25 21:57 * &lt;p&gt; * CrudRepository 提供了常用接口，自己无需编写接口。 */public interface UserRepository extends CrudRepository&lt;User, Long&gt; {} 修改控制器：将自己的实现方法的调用改为 JPA 的常用 api，如：findAll() / findOne(id) / save(user) / delete(id) 访问与验证数据 能正常访问与操作，数据存储在了 内存数据库 H2 ,使用 h2 的 控制台 访问数据。 设置显示 h2 控制台： 123spring: # 使用 H2 控制台 h2.console.enabled: true 访问控制台： http://localhost:8080/h2-console/ 注意：JDBC URL 需要手动更改为 jdbc:h2:mem:testdb 才能正常访问，否则看不到保存的表。接着点击 connect 可以看到 JPA 在内存型数据中自动保存了一张 USER 表，就是 User 实体所映射的表，并且根据主键关系与实体属性映射了添加的数据，我们可以与使用关系型数据库一样的方式对内存型数据库执行 SQL 操作。 3.5.2 MySql 物理数据库修改配置文件： 1234567891011121314151617181920212223spring: # 模板引擎 thymeleaf: encoding: UTF-8 cache: false mode: HTML5 # 使用 H2 控制台 h2.console.enabled: true # 数据源 datasource: url: jdbc:mysql://localhost/blog?characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=UTC username: root password: admin driver-class-name: com.mysql.cj.jdbc.Driver # JPA jpa: show-sql: true hibernate: # 每次启动都会删除之前的表结构和数据并重新生成新的表结构 ddl-auto: create-drop 启动项目，可以看到 hibernate 自动创建了表结构，字段和实体属性一一对应。 浏览器存入了两条数据之后，查看数据库： 数据成功存入，并且 h2 数据库没有存入，说明指定了 mysql 作为数据源， h2 的配置可有可无了。 在实际场景中使用 MySql 这种大型数据库，在开发测试过程中建议使用 H2 这种内存数据库，提高开发效率。 四、Elastic Search 全文搜索概念：全文搜索是一种将文件中所有文本与搜索项匹配的文字资料检索方法 实现原理： 建立文本库：搜索的数据源 建立索引：提取规律，以便快速查找。 执行搜索：用户请求 过滤结果：对搜索结果处理 Elastic Search 是什么： 高度可扩展的开源全文搜索和分析引擎 快速、近实时地对大数据进行存储、搜索和分析 用来支持又复杂的数据搜索需求的企业级应用 Elastic Search 特点： 分布式 高可用 多 API 面向文档 异步写入 近实时 基于 Lucene 搜索引擎 遵循 Apache 协议 Elastic Search 核心概念： 近实时：根据刷新策略定期刷新索引到索引库，在存入索引库和读取索引库数据效率之间折中。 集群：一个或多个的节点的集合，用于保存应用的全部数据并提供基于全部节点的集成式搜索功能。 节点：集群中的单台服务器，用来保存数据并参与集群保存和搜索数据的操作。 索引：用于加快搜索速度，在 ES 中，索引是相似文档的集合。 类型：对索引中包含文档的细分，区分不同类型的索引。 文档：进行索引的基本单位，与索引中的类型是相对应的。每一个具体的索引有一个文档与之对应，使用 json 格式表示。文档的实例就是对应关系型数据中的实体（具体的数据）。 分片：当索引超出单个节点所能承受的范围，可以使用分片来存储索引的部分数据，ES 会自动处理索引的分片与聚合。 副本：分片的副本，有利于提高搜索效率和吞吐量。默认 ES 为每个索引分配 5 个分片和一个副本。 4.1 集成 Spring Boot环境： Elastic Search 2.4.4 Spring Data Elastic Search 2.1.4.RELEASE – Spring Boot 对 ES 的支持模块 JNA 4.3.0 – ES 依赖模块 依赖： 123456dependencies { // 添加 Spring Data Elasticsearch 的依赖 compile('org.springframework.boot:spring-boot-starter-data-elasticsearch') // 添加 JNA 的依赖 compile('net.java.dev.jna:jna:4.3.0')} 配置： 1234567891011spring: data: elasticsearch: # 服务地址 cluster-nodes: localhost:9300 # 连接超时时间 properties: transport: tcp: connect_timeout：120 开启 Elastic Search： 下载二进制文件：官网 解压到指定目录 进入 bin，根据系统平台执行 elasticsearch 命令 后台编码： 索引库实体：EsBlog 资源库：EsBlogRepository 测试用例：EsBlogRepositoryTest 控制器：BlogController 文档库实体：123456789101112131415@Document(indexName = \"blog\", type = \"blog\") // 标注为文档实体类public class EsBlog implements Serializable { @Id private String id; private String title; private String summary; // 关键字 private String content; // 遵循 JPA 规范 protected EsBlog() { } ......} 资源库：123456789101112public interface EsBlogRepository extends ElasticsearchRepository&lt;EsBlog, String&gt; { /** * 分页查询博客（去重） * JPA 自动根据方法名执行查询 */ Page&lt;EsBlog&gt; findDistinctEsBlogByTitleContainingOrSummaryContainingOrContentContaining( String title, String summary, String content, Pageable pageable);} 测试用例：1234567891011121314151617181920212223242526272829303132333435363738@RunWith(SpringRunner.class)@SpringBootTestpublic class TestEsBlogRepository { @Autowired private EsBlogRepository esBlogRepository; /** * 测试文档库之前存入数据 */ @Before public void initEsBlogRepository() { esBlogRepository.deleteAll(); esBlogRepository.save(new EsBlog(\"登鹤雀楼\", \"王之涣的登鹤雀楼\", \"白日依山尽，黄河入海流。欲穷千里目，更上一层楼。\")); esBlogRepository.save(new EsBlog(\"相思\", \"王维的相思\", \"红豆生南国，春来发几枝。愿君多采颉，此物最相思。\")); esBlogRepository.save(new EsBlog(\"静夜思\", \"李白的静夜思\", \"床前明月光，疑是地上霜。举头望明月，低头思故乡。\")); } @Test public void testFindDistinctEsBlogByTitleContainingOrSummaryContainingOrContentContaining() { Pageable pageRequest = new PageRequest(0, 20); // 搜索条件 String title = \"思\"; String summary = \"思\"; String content = \"相思\"; Page&lt;EsBlog&gt; page = esBlogRepository.findDistinctEsBlogByTitleContainingOrSummaryContainingOrContentContaining( title, summary, content, pageRequest); // 断言根据指定的 title、summary、content 来搜索 记录有两条 assertThat(page.getTotalElements()).isEqualTo(2); // 打印结果 for (EsBlog blog : page.getContent()){ System.out.println(blog); } }} 控制器：123456789101112131415161718192021@RestController@RequestMapping(\"/\")public class BlogController { @Autowired private EsBlogRepository esBlogRepository; @RequestMapping(value = \"/blogs\") public List&lt;EsBlog&gt; list(@RequestParam(value = \"title\") String title, @RequestParam(value = \"summary\") String summary, @RequestParam(value = \"content\") String content, @RequestParam(value = \"pageIndex\", defaultValue = \"0\") int pageIndex, @RequestParam(value = \"pageSize\", defaultValue = \"10\") int pageSize ) { Pageable pageable = new PageRequest(0, 10); Page&lt;EsBlog&gt; page = esBlogRepository.findDistinctEsBlogByTitleContainingOrSummaryContainingOrContentContaining( title, summary, content, pageable); return page.getContent(); }} 访问： 五、集成 BootStrap是什么： 基于 HTML、CSS、JavaScript 响应式布局 移动设备优先 如何实现： 文档必须是 HTML5 设置响应式的 meta 标签 &lt;meta bane=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;&gt; 通过 Normalize.css 达到浏览器一致性适配 使用 Normalize 建立跨浏览器的一致性 额外支持的 Reboot 核心概念： 移动设备优先策略 基础的 CSS 是移动优先。优先设计更小的宽度 媒体查询。针对平板电脑、台式电脑再做宽屏适配 渐进增强。随着屏幕大小的增加而添加元素 网格系统 响应式：viewport 尺寸的增加，系统会自动分为最多 12 格： 实例：12345678910111213141516171819202122&lt;!-- 此为一行，该行中有两列 --&gt;&lt;div class=\"row\"&gt; &lt;!-- 此为一列：移动设备下占满 12 格，中型PC下占 8 格 --&gt; &lt;div class=\"col-xs-12 col-md-8\"&gt;.col-xs-12 col-md-8 .col-xs-12 col-md-8&lt;/div&gt; &lt;div class=\"col-xs-6 col-md-4\"&gt;.col-xs-6 .col-md-4&lt;/div&gt;&lt;/div&gt;&lt;!-- 一行中有三列 --&gt;&lt;div class=\"row\"&gt; &lt;!-- 三列各占网格的 4 格刚好占满一行 --&gt; &lt;div class=\"col-xs-6 col-md-4\"&gt;.col-xs-6 .col-md-4&lt;/div&gt; &lt;div class=\"col-xs-6 col-md-4\"&gt;.col-xs-6 .col-md-4&lt;/div&gt; &lt;div class=\"col-xs-6 col-md-4\"&gt;.col-xs-6 .col-md-4&lt;/div&gt;&lt;/div&gt;&lt;!-- 一行中有两列 --&gt;&lt;div class=\"row\"&gt; &lt;!-- 该行中有两列，每列占 6 格刚好占满一行 --&gt; &lt;div class=\"col-xs-6\"&gt;.col-xs-6&lt;/div&gt; &lt;div class=\"col-xs-6\"&gt;.col-xs-6&lt;/div&gt;&lt;/div&gt;&lt;!-- --&gt; 效果： 常用组件、样式 Typography 处理印刷 Table Form Button Dropdown 下拉框 ButtonGroup InputGroup Bavbar Pagination 分页 Tag Alert 提示框 Modal Dialog 模态框 Progress Bar 进度条 List Group 列表 Card 卡片 Tooltip 提示 六、Spring Security 安全权限框架角色 代表一系列行为或责任的实体 限定能做什么、不能做什么 用户账号往往与角色相关联 RBAC 基于角色的访问控制（Role-Base Access Control） 隐式访问控制：与角色关联的访问控制 显式访问控制：与权限关联的访问控制（更灵活） 安全领域核心概念 认证（authentication）：“认证”是建立主体（principal）的过程。“主体”通常是指可以在您的应用程序中执行操作的用户、设备或其他系统。 授权（authorization）：或称为：“访问控制（access-control）”，“授权”是指决定是否允许主体在应用程序中执行操作。 支持的身份验证功能 HTTP BASIC HTTP Digest HTTP X.509 LDAP 基于表单的认证 OpenID 单点登陆 Remmenber-Me 匿名身份验证 Run-ad JAAS JavaEE 容器认证 提供的模块 Core - Spring-security-core.jar —— 核心模块 Remoting - spring-security-remoting.jar —— 与 Spring Remoting 整合包 Web - spring-security-web.jar —— web 支持 Config - spring-security-config.jar —— 安全配置 LDAP - spring-security-idap.jar —— 用于 LDAP 认证及配置 ACL - spring-secutiry-acl.jar —— 访问控制列表的实现，对特定对象的实例进行安全配置 CAS - spring-secutiry-cas.jar —— 可作为单点登陆服务器 OpenID - spring-secutiry-openid.jar Test - spring-secutiry-test.jar 与 Spring Boot 集成 环境： Spring Secutiry 4.2.2.RELEASE Thymeleaf Spring Secutiry 3.0.2.RELEASE 依赖： 123456dependencies { // 添加 Spring Security 依赖 compile('org.springframework.boot:spring-boot-starter-security') // 添加 Thymeleaf Spring Security 依赖，与 Thymeleaf 版本一致都是 3.x compile('org.thymeleaf.extras:thymeleaf-extras-springsecurity4:3.0.2.RELEASE')} 后台编码： 安全配置类 控制器 前台编码： index.html header.html login.html 123456789101112131415161718192021222324252627282930@EnableWebSecuritypublic class SpringSecurityConfig extends WebSecurityConfigurerAdapter { /** * 自定义配置 */ @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(\"/css/**\", \"/js/**\", \"/fonts/**\", \"/index\").permitAll() // 都可以访问 .antMatchers(\"/users/**\").hasRole(\"ADMIN\") // 需要相应的角色才能访问 .and() .formLogin() // 基于 Form 表单登录验证 .loginPage(\"/login\") // 跳转到登陆地址 .failureUrl(\"/login-error\"); // 登陆失败跳转地址 } /** * 认证信息管理 * * @param auth * @throws Exception */ @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception { auth.inMemoryAuthentication() // 认证信息存储内存中 .withUser(\"yuzh\").password(\"admin\").roles(\"ADMIN\"); // 硬编码测试 }} 七、用户管理需求/核心功能 需求分析 注册 /register：[GET] 获取注册页面 /register：[POST] 注册成功，跳转登陆页面 User 用户对象 登陆: /login: [get] 获取登陆页面 /login: [post] 登陆 username password remember-me 是否记住我 用户管理 /users: [get] 用户列表 async pageIndex pageSize name 用户名称关键字 /users/add: [get] 获取添加用户页面 /users/add: [post] 保存添加的用户 User authorityId 角色ID /users/{id}: [delete] 删除用户 id /users/edit/{id}: [get] 获取某个具体用户编辑页面 id 流程图 首页用户注册： 后台管理-修改用户： 后台实现 原有基础上添加依赖： // 添加 Apache Commons Lang 依赖 compile(&apos;org.apache.commons:commons-lang3:3.5&apos;) 对 User 实体添加持久化和校验注解： 123456789101112131415161718192021222324252627282930313233343536@Data@Entitypublic class User implements Serializable { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private long id; @NotEmpty(message = \"姓名不能为空\") @Size(min=2, max=20) @Column(nullable = false, length = 20) // 映射为字段，值不能为空 private String name; @NotEmpty(message = \"邮箱不能为空\") @Size(max=50) @Email(message= \"邮箱格式不对\" ) @Column(nullable = false, length = 50, unique = true) private String email; @NotEmpty(message = \"账号不能为空\") @Size(min=3, max=20) @Column(nullable = false, length = 20, unique = true) private String username; // 用户账号，用户登录时的唯一标识 @NotEmpty(message = \"密码不能为空\") @Size(max=100) @Column(length = 100) private String password; // 登录时密码 @Column(length = 200) private String avatar; // 头像图片地址 private int age; protected User() { }} 实现 JpaRepository 接口，根据规范的方法名执行查询： 123456789101112131415161718192021222324252627282930public interface UserRepository extends JpaRepository&lt;User, Long&gt; { /** * 根据用户名分页查询列表 * * @param name * @param pageable * @return */ Page&lt;User&gt; findByNameLike(String name, Pageable pageable); /** * 根据用户账号查询用户 * * @param username * @return */ User findByUsername(String username); /** * 查找用户名是否被占用 */ boolean existsByUsername(String primaryKey); /** * 查找邮箱是否被占用 */ boolean existsByEmail(String primaryKey);} UserService 接口及实现 xyz.yuzh.spring.boot.blog.vo.Response 全局响应结果对象 AdminController 后台管理控制器 —— 跳转后台管理页面 UserController 后台管理用户管理控制器 —— 增删改查 UserOperationExcption 用户操作异常类 GlobalExceptionHandler 全局异常处理类 前台实现 login.html register.html /users/*.html /admins/*.html js/admins/*.js js/users/*.js 问题解决 如何给通过脚本添加的元素注册事件 解决使用 bootstrap 更新操作时 —— 模态框回显传值问题 八、角色权限管理需求分析 User 对象实现 UserDetails 接口 实现 getAuthorities 方法，返回权限实体集合（需要自定义的 Authority 转为 SimpleGrantedAuthority） UserServiceImpl 实现 UserDetailsService 实现 security 默认方法 loadUserByUsername，返回数据库查到的用户实体 SecurityConfig 123456789101112131415161718192021222324252627282930313233343536373839404142434445@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true)public class SecurityConfig extends WebSecurityConfigurerAdapter { private static final String KEY = \"yuzh.xyz\"; @Autowired private UserDetailsService userDetailsService; @Bean public AuthenticationProvider authenticationProvider() { DaoAuthenticationProvider authenticationProvider = new DaoAuthenticationProvider(); authenticationProvider.setUserDetailsService(userDetailsService); return authenticationProvider; } @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(\"/css/**\", \"/js/**\", \"/fonts/**\", \"/\", \"/index\").permitAll() .antMatchers(\"/h2-console/**\").permitAll() // 数据库中的字段因该是 ROLE_ADMIN ，这里不需要写 ROLE_ 前缀。 .antMatchers(\" /admins/**\").hasRole(\"ADMIN\") .and() .formLogin() .loginPage(\"/login\") .failureUrl(\"/login-error\") .and() .rememberMe().key(KEY) .and() .exceptionHandling().accessDeniedPage(\"/403\"); http.csrf().ignoringAntMatchers(\"/h2-console/**\"); http.headers().frameOptions().sameOrigin(); } @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(userDetailsService); auth.authenticationProvider(authenticationProvider()); }} 数据库的权限存入的格式例如 ROLE_ADMIN / ROLE_USER 给需要授权才能访问的方法授权 给类授权：@PreAuthorize(&quot;hasAuthority('ROLE_ADMIN')&quot;) // 指定角色权限才能操作方法 给方法授权：如当请求参数中的 username 被查询到已认证才允许进入方法 12@PostMapping(\"/{username}/blogs/edit\")@PreAuthorize(\"authentication.name.equals(#username)\") 当表单发起 /login 的 post 请求并携带固定名称的 username、password 参数，security 会自动处理登陆，若登陆失败，跳到配置好的登陆失败页面。 九、博客管理需求分析 用户主页实现 个人资料设置 个人头像更换 user space API：用户主页空间接口 /blogs: [get] order：排序类型，new/hot，默认是 new keyword：搜索关键字。博客的标签，即为关键字。 async：是否为异步请求页面 pageIndex pageSize /u/{username}: [get] 具体某个用户的主页 username 用户账号 /u/{username}/profile: [get] 获取个人设置页面 username 用户账号 /u/{username}/profile: [post] 保存个人设置页面 username 用户账号 User 待保存的对象 /u/{username}/avatar: [get] 获取个人头像 username 用户账号 /u/{username}/avatar: [post] 保存个人头像 username 用户账号 /u/{username}/blogs: [get] 查询用户博客 order：排序类型，new/hot，默认是 new catalog：博客分类 ID，默认为空 keyword：搜索关键字。博客的标签，即为关键字。 async：是否为异步请求页面 pageIndex pageSize /u/{username}/blogs/edits: [get] 获取新增博客页面 username 用户账号 /u/{username}/blogs/edit/{id}: [get] 获取编辑博客的页面 username 用户账号 id 博客ID /u/{username}/blogs/edit: [post] 保存博客 username 用户账号 Blog 待保存的博客对象 /u/{username}/blogs/delete/{id}: [delete] 删除博客 username 用户账号 id 博客ID /u/{username}/blogs/{id}: [get] 获取博客展示页面 username 用户账号 id 博客ID 后台实现 添加 markdown 解析器的依赖： 1compile('es.nitaur.markdown:txtmark:0.16') MongoDB File Server 文件服务器 https://github.com/waylau/mongodb-file-server 用户个人设置 十、评论管理需求分析 comments API：评论管理接口 /comments: [get] 获取评论列表 blogid 博客id /comments: [post] 保存评论 blogid 博客idcommentContent 评论内容 /comments/{id}: [delete] 删除评论 blogid 博客id id 评论id 十一、点赞管理需求分析 votes API：点赞管理接口 /votes: [post] 保存点赞 blogid 博客id /votes/{id}: [delete] 删除点赞 blogid 博客id id 点赞id 十二、分类管理需求分析 catalogs API：分类管理接口 /catalogs: [get] 获取用户博客的分类列表 username 用户账号 /catalogs: [post] 保存用户博客的分类 username 用户账号 CatalogVO 包含 username、Catalog /catalogs/edit: [get] 获取编辑分类界面 /catalogs/edit/{id}: [get] 获取某ID分类编辑的分类界面 /catalogs/{id}: [delete] 删除分类 id 分类ID username 用户账号 十三、标签管理需求分析 使用插件：Jquery Tags Input 1.3.6 http://xoxco.com/projects/code/tagsinput 十四、首页搜索需求分析 index API：包含最新、最热文章、最热标签、最热用户等 /blogs: [get] order：排序类型，new/hot keyword：搜索关键字（包含博客标签） async：是否异步 pageIndex pageSize 环境： Elastic Search 2.4.4 Spring Data Elastic Search 2.1.4.RELEASE – Spring Boot 对 ES 的支持模块 JNA 4.3.0 – ES 依赖模块 十五、部署相关15.1 使用外部 MongoDB 存储文件服务器数据之前使用的是文件服务器内嵌的 mongoDB，项目停止之后图片数据不会保存。更换外部 mongoDB： window 下 下载 mongoDB https://www.mongodb.com/download-center#community 选择 msi 文件下载安装 MongoDB将数据目录存储在 db 目录下。但是这个数据目录不会主动创建，需要手动创建。（如：d:/mongoData/db） 修改文件服务器 build.gradle 文件，取消使用内嵌 mongoDB 12// 添加 Embedded MongoDB 的依赖用于测试// compile('de.flapdoodle.embed:de.flapdoodle.embed.mongo') 修改文件服务器 application.yml 文件，连接独立的 MongoDB 12# independent MongoDB serverspring.data.mongodb.uri=mongodb://localhost:27017/test 从 MongoDB 目录的 bin 目录中执行 mongod.exe 文件 1如：C:\\mongodb\\bin\\mongod --dbpath d:\\mongoData\\db 运行 mongo.exe 命令即可连接 MongoDB 更多细节见：http://www.runoob.com/mongodb/mongodb-window-install.html linux 下 1234567891011121314curl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.0.6.tgz # 下载tar -zxvf mongodb-linux-x86_64-3.0.6.tgz # 解压mv mongodb-linux-x86_64-3.0.6.tgz mongodb # 重命名vim /etc/profile # 配置环境变量---------------------export PATH=/opt/mongodb/bin:${PATH}---------------------resource /etc/profile # 刷新环境变量cd /opt/mongodbmkdir data &amp; cd data &amp; mkdir db # 创建文件存放目录mongod --dbpath=/opt/mongodb/data/db # 启动 mongodb 15.2 应用启动后台运行：nohup cmd &amp; 启动 mongoDB 启动文件服务器（gradlew bootRun） 进入 elastic search，删除 data 文件（测试环境下），执行 ./elasticsearch 启动 blog-full （gradlew bootRun）","link":"/2018/10/28/基于 Spring Boot 技术栈构建企业级博客系统的开发记录/"},{"title":"Docker 补救指南（一）—— 基础使用","text":"配置阿里云镜像加速阿里云主页搜索 容器镜像服务，进入「镜像仓库管理控制台」，根据说明文档操作即可。 学会使用帮助命令查看版本： 1docker version 查看docker安装信息： 1docker info 查看命令说明： 1docker --help 使用方式：docker COMMAND --help 如：docker logs --help 12345678910111213Usage: docker logs [OPTIONS] CONTAINERFetch the logs of a containerOptions: --details Show extra details provided to logs -f, --follow Follow log output --since string Show logs since timestamp (e.g. 2013-01-02T13:23:37) or relative (e.g. 42m for 42 minutes) --tail string Number of lines to show from the end of the logs (default \"all\") -t, --timestamps Show timestamps --until string Show logs before a timestamp (e.g. 2013-01-02T13:23:37) or relative (e.g. 42m for 42 minutes) 镜像查看本地镜像docker images / docker image ls 参数： -a 列出本地所有的镜像（包含所有中间层镜像） -q 只显示镜像ID –digests 显示镜像的摘要信息（会多一个GUGEST展示字段，相当于一个镜像的备注信息，有些镜像没有。） –no-trunc 显示完整的镜像信息 从 Docker Hub 查询镜像docker search 镜像名 如：docker search tomcat 1234567891011121314151617181920212223242526NAME DESCRIPTION STARS OFFICIAL AUTOMATEDtomcat Apache Tomcat is an open source implementati… 2345 [OK]tomee Apache TomEE is an all-Apache Java EE certif… 64 [OK]dordoka/tomcat Ubuntu 14.04, Oracle JDK 8 and Tomcat 8 base… 53 [OK]davidcaste/alpine-tomcat Apache Tomcat 7/8 using Oracle Java 7/8 with… 34 [OK]bitnami/tomcat Bitnami Tomcat Docker Image 28 [OK]cloudesire/tomcat Tomcat server, 6/7/8 14 [OK]meirwa/spring-boot-tomcat-mysql-app a sample spring-boot app using tomcat and My… 12 [OK]tutum/tomcat Base docker image to run a Tomcat applicatio… 11aallam/tomcat-mysql Debian, Oracle JDK, Tomcat &amp; MySQL 11 [OK]jeanblanchard/tomcat Minimal Docker image with Apache Tomcat 8arm32v7/tomcat Apache Tomcat is an open source implementati… 6rightctrl/tomcat CentOS , Oracle Java, tomcat application ssl… 4 [OK]maluuba/tomcat7-java8 Tomcat7 with java8. 3amd64/tomcat Apache Tomcat is an open source implementati… 2arm64v8/tomcat Apache Tomcat is an open source implementati… 2fabric8/tomcat-8 Fabric8 Tomcat 8 Image 2 [OK]camptocamp/tomcat-logback Docker image for tomcat with logback integra… 1 [OK]99taxis/tomcat7 Tomcat7 1 [OK]s390x/tomcat Apache Tomcat is an open source implementati… 0picoded/tomcat7 tomcat7 with jre8 and MANAGER_USER / MANAGER… 0 [OK]oobsri/tomcat8 Testing CI Jobs with different names. 0cfje/tomcat-resource Tomcat Concourse Resource 01and1internet/debian-9-java-8-tomcat-8.5 Our tomcat 8.5 image 0 [OK]jelastic/tomcat An image of the Tomcat Java application serv… 0swisstopo/service-print-tomcat backend tomcat for service-print the true, … 0 参数： -s [数字]： 列出 star 不小于指定数值的镜像 1234# 查询星星数不小于 30 个的 tomcat 镜像docker search -s 30 tomcat# -s 参数已废弃，可用 --filter 替代docker search --filter=stars=30 tomcat –no-trunc： 显示完整的镜像描述信息 –automated：只列出 automated build 类型的镜像 拉取镜像docker pull 镜像名:版本号 不加版本号默认 :latest 删除本地镜像docker rmi 镜像名字或ID 参数：-f 删除中间层镜像 删除单个 1docker rmi -f 镜像ID 删除多个 1docker rmi -f 镜像1:TAG 镜像2:TAG 删除全部 12# 命令的组合使用，将 $(docker image ls -qa) 的结果作为 前一个命令的参数。 `docker image ls -qa` 的结果就是一串镜像ID数组 docker rmi -f $(docker image ls -qa) 有容器正在使用此镜像，不能删除怎么办？ docker rmi -f XXX 删除镜像的高级用法（过滤）场景：工作和自己学习时产生了大量镜像，为了方便学习。需要将工作中的镜像删除，先看一下列表： 我需要把工作中的镜像删除，一个个复制镜像ID删除不免有些麻烦。这个时候就需要抽取共性，合理运用命令了。 1）先过滤掉学习镜像，只展示工作镜像。 12# 仔细观察，发现工作镜像上传的镜像服务地址都是上海的区域，可以以此作为条件过滤一次。docker image ls | grep 'shanghai' 2）过滤了不需要删除的镜像，接下来就是提取其中的 image id作为删除镜像的参数了 12# awk '{print $n}'处理文本、表格数据的强大linux命令 通过这个命令，将列表的镜像ID提取：docker image ls | grep ‘shanghai’ | awk ‘{print $3}’ 3）删除 docker rmi -f $(docker image ls | grep ‘shanghai’ | awk ‘{print $3}’) 保存镜像docker save -o 文件名.tar 镜像ID 123456Usage: docker save [OPTIONS] IMAGE [IMAGE...]Save one or more images to a tar archive (streamed to STDOUT by default)Options: -o, --output string Write to a file, instead of STDOUT 「演示」 将 izhiliu/centos:v2 这个镜像保存并重新加载 12345# mkdir image &amp;&amp; cd images# docker save -o centos2.tar cf18ff34c415~/Learning/docker-note/images(master*) » ll harry@192total 964608-rw------- 1 harry staff 458M May 12 16:47 centos2.tar 删除这个镜像： 1docker rmi cf18ff34c415 加载镜像docker load -i 文件.tar 1234567Usage: docker load [OPTIONS]Load an image from a tar archive or STDINOptions: -i, --input string Read from tar archive file, instead of STDIN -q, --quiet Suppress the load output 「加载刚刚删除的镜像」 123# docker load -i centos2.tar6e7dbd1f6260: Loading layer [==================================================&gt;] 55.3kB/55.3kBLoaded image ID: sha256:cf18ff34c415b8ca05494a3d6faa276a0b1229cffb5563cffbb8f0af533b6f47 容器以 CentOS 容器为例 新建并启动容器docker run [options] image [command] [ags…] options: –name=”容器名”：为容器指定一个名称 -d：后台运行容器，并返回容器ID，也即：启动守护式容器 -i：以交互式模式运行容器，通常与 -t 同时使用 -t：为容器重新分配一个伪输入终端，通常与 -i 同时使用 -P：随机端口分配 -p：指定端口映射，有一下四种格式： ip:hostPort:containerPort ip::containerPort hostPort:containerPort containerPort 简单启动： 1docker run -it centos 带容器名启动： 1docker run -it --name=\"my-centos\" centos 查看当前所有正在运行的容器docker ps [options] options: -a：列出当前所有正在运行的容器 + 历史上运行过的 -l：显示最近创建的容器 -n：显示最近 n 个创建的容器 -q：静默模式，只显示容器编号（不加其他参数默认显示当前运行的所有容器的ID） –no-trunc：不截断输出 结合 -a/-q 参数，可以实现删除所有容器： 123456# 删除最近的一个容器docker rm $(docker ps -lq)# 强制删除最近的一个容器（若最近的一个容器正在运行）docker rm -f $(docker ps -lq)# 删除历史所有的容器，包含正在运行的docker rm -f $(docker ps -aq) 退出容器一）exit：退出并停止 使用 docker run -it --name=&quot;my-centos&quot; centos 的方式启动容器会以一个交互式终端形式进入到容器内部，当执行 exit 时容器就自动停止了。 123# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES037deff7ded9 centos \"/bin/bash\" 14 seconds ago **Exited (0) 5 seconds ago** my-centos 二）Control + P + Q：退出不停止 重新运行容器，并在重启内执行快捷键之后： 123# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf654ef93ea3f centos \"/bin/bash\" About a minute ago **Up About a minute** practical_sinoussi 当不停止退出了，如何重新进去呢？ 查看下面的「进入正在运行的容器」章节 启动容器docker start 容器ID/容器名 重启容器docker restart 容器ID/容器名 停止容器docker stop 容器ID/容器名 强制停止容器docker kill 容器ID/容器名 删除已停止的容器docker rm 容器ID 一次性删除多个容器？前面已经使用了一种方式：docker rm -f $(docker ps -aq) 还有一种方式：12# 利用 linux 的管道符可变参数 xargs，将 | 前面的命令结果作为参数作为 | 后面命令的入参docker ps -aq | xargs docker rm -f 容器重要知识点启动守护式容器docker run -d 容器名/容器ID 以守护式方式启动容器后查看容器进程： 1234# docker run -d centos4de40688015eaec0a015f5d408117d938459828e2379dec4268ae88a298a7704# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 发现并没有显示正在运行的容器进程，为啥？再看一下容器历史运行记录试试。。。 123# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4de40688015e centos \"/bin/bash\" 4 minutes ago Exited (0) 4 minutes ago pedantic_benz 发现刚刚以 守护式方式 启动的容器，启动之后就立马停止了！ Docker 容器后台运行，就必须要有一个前台进程。\\什么意思呢？如果容器运行的命令不是那些 一直挂起 的命令（如：top、tail），容器是会自动退出的。\\这是由于 docker的机制问题，例如使用 nginx，启动 nginx 服务的命令是：service nginx start，这是一个后台命令，在 linux 中会一直在后台运行着。但是在 docker 中，nginx容器为后台模式运行模式，导致 docker 的 nginx 容器前台没有运行的应用。所以容器启动后会立即自动停止，因为这个容器觉得自己没有事情可做！😅\\最佳解决方案是：将要运行的程序以前台的方式运行！ 那么怎么让容器以守护式容器启动，但是避免前台没事可做导致容器自动关闭呢？简单的方式有：让后台运行的容器前台一直打印日志，这样就避免了前台没事可做导致容器退出😂。 12345# docker run -d centos /bin/bash -c \"while true; do echo hello harry!; sleep 1; done\"2b8e4a0014ab7cb435ecc19f171daf027c1291fa24b77ae52132ba9c225962d8# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES2b8e4a0014ab centos \"/bin/bash -c 'while…\" 3 seconds ago Up 3 seconds angry_aryabhata 可以看到此时容器正在以后台运行，但是没有关闭。解释一下 /bin/bash， 1如果 -c 选项存在，命令就从字符串中读取。如果字符串后有参数，他们将会被分配到参数的位置上，从$0开始。 查看容器日志docker logs -f -t –tail 容器ID optins： -t：加入时间戳 -f：跟随最新日志打印 –tail 数字：显示最后多少条 查看刚刚以守护容器运行的进程： 1234567891011121314151617# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES04b01b87b990 centos \"/bin/bash -c 'while…\" 5 seconds ago Up 4 seconds modest_chaplygin# docker logs -t -f --tail 10 04b01b87b990 从倒数第 10 条日志开始查看，不停的追加，并且显示日志打印的时间。2019-04-14T10:56:11.635841663Z hello harry!2019-04-14T10:56:12.638348360Z hello harry!2019-04-14T10:56:13.645537151Z hello harry!2019-04-14T10:56:14.651628446Z hello harry!2019-04-14T10:56:15.654658791Z hello harry!2019-04-14T10:56:16.658972279Z hello harry!2019-04-14T10:56:17.664596508Z hello harry!2019-04-14T10:56:18.668527236Z hello harry!2019-04-14T10:56:19.671418530Z hello harry!2019-04-14T10:56:20.676871204Z hello harry!2019-04-14T10:56:21.682418501Z hello harry!2019-04-14T10:56:22.683835449Z hello harry!2019-04-14T10:56:23.688968112Z hello harry! 查看容器内运行的进程docker top 容器ID 查看刚刚守护式运行的容器的内部进程： 1234# docker top 04b01b87b990PID USER TIME COMMAND8568 root 0:00 /bin/bash -c while true; do echo hello harry!; sleep 1; done8921 root 0:00 sleep 1 查看容器内部细节docker inspect 容器ID 进入正在运行的容器并以命令行交互前面学到过 不关闭容器并退出 的快捷键是：contrl + p + q，那么退出之后怎么重新进入呢？有以下两种方式。 docker attach 容器ID「演示」 12345678910111213141516171819202122232425262728# docker rm -f $(docker ps -aq) 先把所有容器杀死# docker run -it --name='my-centos' centos 以交互式终端启动容器[root@b7324d8b56b9 /]# pwd/[root@b7324d8b56b9 /]# lltotal 56-rw-r--r-- 1 root root 12082 Mar 5 17:36 anaconda-post.loglrwxrwxrwx 1 root root 7 Mar 5 17:34 bin -&gt; usr/bindrwxr-xr-x 5 root root 360 Apr 14 11:24 devdrwxr-xr-x 1 root root 4096 Apr 14 11:24 etcdrwxr-xr-x 2 root root 4096 Apr 11 2018 homelrwxrwxrwx 1 root root 7 Mar 5 17:34 lib -&gt; usr/liblrwxrwxrwx 1 root root 9 Mar 5 17:34 lib64 -&gt; usr/lib64drwxr-xr-x 2 root root 4096 Apr 11 2018 media......# 使用快捷键 control + p + q 不关闭容器并退出[root@b7324d8b56b9 /]# %# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb7324d8b56b9 centos \"/bin/bash\" About a minute ago Up About a minute my-centos# 可以看到容器依然在运行，执行命令 docker attach b7324d8b56b9 重新进入。[root@b7324d8b56b9 /]# pwd/[root@b7324d8b56b9 /]# lsanaconda-post.log bin dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var docker exec -it 容器ID bashShell「演示」 进入容器内部执行命令：123456789101112131415161718# 先不关闭退出容器 control + p + q# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb7324d8b56b9 centos \"/bin/bash\" 7 minutes ago Up 7 minutes my-centos# docker exec -it b7324d8b56b9 /bin/bash 一样进入了容器[root@60711933f7dd /]# pwd/[root@60711933f7dd /]# lsanaconda-post.log bin dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var# 执行 exit 命令退出容器，PS：这里容器会关闭吗？[root@60711933f7dd /]# exitexit# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES60711933f7dd centos \"/bin/bash\" 2 minutes ago Up 2 minutes my-centos# 可以看到，以 exec 方式进入的容器执行 exit 并不会关闭容器。 不进入容器，在宿主机执行容器内部命令：12345678910111213141516# docker exec -it 60711933f7dd ls -l /usrtotal 68dr-xr-xr-x 2 root root 16384 Mar 5 17:36 bindrwxr-xr-x 2 root root 4096 Apr 11 2018 etcdrwxr-xr-x 2 root root 4096 Apr 11 2018 gamesdrwxr-xr-x 3 root root 4096 Mar 5 17:35 includedr-xr-xr-x 19 root root 4096 Mar 5 17:36 libdr-xr-xr-x 24 root root 16384 Mar 5 17:36 lib64drwxr-xr-x 11 root root 4096 Mar 5 17:36 libexecdrwxr-xr-x 12 root root 4096 Mar 5 17:34 localdr-xr-xr-x 2 root root 4096 Mar 5 17:36 sbindrwxr-xr-x 52 root root 4096 Mar 5 17:36 sharedrwxr-xr-x 4 root root 4096 Mar 5 17:34 srclrwxrwxrwx 1 root root 10 Mar 5 17:34 tmp -&gt; ../var/tmpharry@192 ~/Learning/docker-note# 这里以 linux 中的 `ls -l /usr` 命令代替上面的 `/bin/bash` 命令查看了容器 centos 中的 /usr 下的所有文件，并且将返回的结果直接展示到了宿主机上（即：本机MacOS） 两者的区别： attach：直接进入容器启动命令的终端，不会启动新的进程。 exec：是在容器中打开新的终端，并且可以启动新的进程。 从容器内拷贝文件到主机上docker cp 容器ID:容器内路径 宿主机路径 容器关闭其运行过程中产生的数据文件都会丢失，所以需要把容器中的数据文件拷贝到宿主机上。 123456789101112131415# docker attach 60711933f7dd 进入容器[root@60711933f7dd /]# lltotal 56-rw-r--r-- 1 root root 12082 Mar 5 17:36 anaconda-post.log# 看到有一个日志文件，将其复制到宿主机，先宿主机当前文件：harry@192 ~/Learning/docker-note lltotal 40-rw-r--r--@ 1 harry staff 17K 4 14 19:56 Docker笔记.md# 可以看到当前宿主句只有一个文件。将容器中的 anaconda-post.log 复制到当前文件夹 ~/Learning/docker-note# control + p + q 需要先退出容器# docker cp 60711933f7dd:/anaconda-post.log ./ 复制到当前目录下# ll 查看当前宿主机文件total 64-rw-r--r--@ 1 harry staff 17K 4 14 20:01 Docker笔记.md-rw-r--r-- 1 harry staff 12K 3 6 01:36 anaconda-post.log 镜像原理是什么 镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件。它包含运行某个软件所需的所有内容，包括代码、库、环境、环境变量和配置文件。 UnionFS（联合文件系统） unionFS 是一种分层、轻量级并且高性能的文件系统，它支持 对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一虚拟文件系统下。\\联合文件系统是 Docker 镜像的基础。镜像可以通过分层来继承，基于基础镜像（没有父镜像），可以制作各种具体的镜像。 特性：一次同时加载多个文件系统，但从外面看来，只能看到一个文件系统。联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。 Docker 镜像加载原理为什么 Docker 镜像要采用分层的结构共享资源。如：有多个镜像都是从相同的 base 镜像构建而来，那么宿主机只需要在磁盘上保存一份 base 镜像。同时内存中也祝需要加载一份 base 镜像，就可以为所有的容器服务了。而且镜像的每一层都可以共享。 特点Docker 镜像都是只读的。当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称为「容器层」，容器层之下的都叫做「镜像层」。 镜像的 commit 操作docker commit 提交容器副本使之成为一个新的镜像 docker commit -m=”提交的描述信息” -a=”作者” 容器ID 要创建的镜像名[:标签名] 「演示」 1. 从 DockerHub 上下载 tomcat 镜像到本地并成功运行 1234567891011121314151617181920212223# docker pull tomcatUsing default tag: latestlatest: Pulling from library/tomcate79bb959ec00: Pull completed4b7902036fe: Pull complete1b2a72d4e030: Pull completede423484a946: Pull completeceaac3b844f7: Pull complete88f01b722a52: Pull completec23be56a9ac1: Pull completed852ffd6d31f: Pull complete11775a3d792d: Pull complete13fdd17462ac: Pull complete2092995a1e54: Pull completeDigest: sha256:409501d73062ab508930eab827fcb19d7d3f7e9bbe63bc6d587114c6af4bee12Status: Downloaded newer image for tomcat:latest# 以交互式终端并「映射容器端口到宿主机指定端口」运行 tomcat# docker run -it -p 8888:8080 --name='my-tomcat' tomcat# 日志太多不展示了，执行「退出不关闭容器 control + p + q」。# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc492f4bbce3e tomcat \"catalina.sh run\" About a minute ago Up About a minute 0.0.0.0:8888-&gt;8080/tcp my-tomcat# 可以看到容器中的 8080 端口已经映射到了宿主机上的 8888 端口，访问 http://localhost:8888 可以正常访问。 PS：运行 tomcat 不以交互式终端 -it 也可以，因为其有前台进程运行（日志打印），所以容器不会退出。 123456789# docker rm -f $(docker ps -aq) 先删除原有容器# docker run -d -p 8888:8080 --name='my-tomcat' tomcat96dad0f6272538e8a1c3359a42d0a6493814f1972c8adf86087dbd322d1033e6# docker logs -f -t --tail 10 96dad0f62725 查看日志：逐条追加，显示日期，从倒数第 10 条开始。......org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/manager] has finished in [18] ms2019-04-14T16:44:25.733314600Z 14-Apr-2019 16:44:25.732 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [\"http-nio-8080\"]2019-04-14T16:44:25.749280600Z 14-Apr-2019 16:44:25.748 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [\"ajp-nio-8009\"]2019-04-14T16:44:25.754519300Z 14-Apr-2019 16:44:25.754 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 889 ms 使用 -P 参数将会随机分配宿主机端口映射给容器。 2. 故意删除上一步镜像生产 tomcat 容器的文档 先访问 http://localhost:8888 查看 document 页面： 点击 Documentation，可以正常看到页面: 1234567# 重新进入上面启动的 tomcat 容器# docker exec -it 96dad0f62725 /bin/bashroot@96dad0f62725:/usr/local/tomcat# pwd/usr/local/tomcat# 删除当前 tomcat 应用的 document 文档页面root@96dad0f62725:/usr/local/tomcat# rm -rf webapps/docs/root@96dad0f62725:/usr/local/tomcat# 刷新文档页面再次查看： PS：这只是修改了当前容器的 tomcat，并没有 commit 作为一个新容器。所以当当前容器被删除之后修改的内容也随着被删除了，如需要保存修改后的内容，可以 commit 这个容器作为一个新的镜像。 3. 也即当前的 tomcat 运行实例是一个没有文档内容的容器。以它为模版 commit 一个没有 doc 的 tommcat 新镜像 my-tomcat 12345678910111213# docker exec -it 1b498158b4ee7fc71d80d9da9ba30d890fa5cddcffb7d1edbffbbfe21b4d2317 /bin/bashroot@1b498158b4ee:/usr/local/tomcat# pwd/usr/local/tomcatroot@1b498158b4ee:/usr/local/tomcat# rm -rf webapps/docs/root@1b498158b4ee:/usr/local/tomcat# exitexit # 这里只是退出新开的终端进程，实际上没有退出 tomcat 的进程。# 执行 docker commit -m=\"del tomcat documentation\" -a=\"harry\" 1b498158b izhiliu/tomcat2:v2# 镜像名规范：组织名/镜像名:TAGsha256:cf18ff34c415b8ca05494a3d6faa276a0b1229cffb5563cffbb8f0af533b6f47# 可以看到执行成功之后返回了新的镜像的唯一标识，再查看一下镜像：docker image ls | grep tomcatizhiliu/tomcat2 v2 cf18ff34c415 About a minute ago 465MBtomcat latest 5a069ba3df4d 41 hours ago 465MB# 刚刚新建的镜像已经存在了，启动一下看看：docker run -d -p 8080:8080 izhiliu/tomcat2:v2 可以看到新的容器已经没有 documentation 页面了。 4. 启动我们 commit 后的新景象并和原来的对比 官方的 tomcat:latest 有 Documentation 页面 自定义的 izhiliu/tomcat:v2 没有 Documentation 页面 容器数据卷 Docker 的理念 将应用与运行的环境打包形成容器运行，运行可以伴随着容器，但是我们对数据的要求是持久化的。 容器之间希望有可能共享数据 Docker 容器运行时产生的数据，如果不通过 docker commit 生成新的镜像，使得数据作为镜像的一部分保存下来，那么当容器删除后，数据自然也就没有了。 之前学到过一个命令「从容器拷贝数据到宿主机」：docker cp 容器ID:容器路径 宿主机路径 但是这只能实现将数据手动保存，并不能实现容器之间的数据共享。解决这种需求，可以使用 docker 的数据卷 作用一）容器持久化 二）容器间继承 + 数据共享 概念 卷就是目录或文件，存在于一个或多个容器中，由 Docker 挂载到容器，但不属于联合文件系统，因此可以能够绕过 UnionFS 提供的一些用于持久存储或共享数据的特性。\\卷设计的目的就是数据的持久化，完全独立于容器的生命周期，因此 Docker 不会在删除容器时删除其挂载的数据卷。 特点： 数据卷可在容器之间共享或重用数据 卷中的更改可以直接生效 数据卷中的更改不会包含在镜像的更新中 数据卷的生命周期一直持续大没有容器使用它为止 使用一：命令方式挂载数据卷docker run -it -v /宿主机文件绝对路径:/容器内路径 镜像名 「演示：查看数据卷挂载是否成功」 12345678910111213141516171819202122232425262728# 以数据卷挂载方式重新启动容器# -----------------------------------------------------------------# docker run -it -v ~/Learning/docker-note/host-data-volumes:/container-data-volumes centos# PS：一定要使用绝对路径，宿主机目录和容器目录若不存在会自动创建# 查看宿主机文件# -----------------------------------------------------------------# pwd/Users/harry/Learning/docker-note# lltotal 80-rw-r--r--@ 1 harry staff 26K 4 15 21:12 README.md-rw-r--r-- 1 harry staff 12K 3 6 01:36 anaconda-post.logdrwxr-xr-x 2 harry staff 64B 4 15 21:11 host-data-volumes # 被新创建的文件夹drwxr-xr-x 5 harry staff 160B 4 15 01:14 img# 查看容器文件# -----------------------------------------------------------------# pwd/# lltotal 56-rw-r--r-- 1 root root 12082 Mar 5 17:36 anaconda-post.loglrwxrwxrwx 1 root root 7 Mar 5 17:34 bin -&gt; usr/bindrwxr-xr-x 2 root root 64 Apr 15 13:11 container-data-volumes # 被创建的文件夹drwxr-xr-x 5 root root 360 Apr 15 13:11 devdrwxr-xr-x 1 root root 4096 Apr 15 13:11 etc...... 1使用 「docker inspect 容器ID」 查看容器是否挂载成功 「演示：容器与宿主机之间共享数据」 1234567891011121314151617181920212223242526# 查看宿主机数据卷绑定文件路径下的所有文件# pwd/Users/harry/Learning/docker-note/host-data-volumes# lltotal 0# -----------------------------------------------------# 查看容器中数据卷绑定文件路径下的所有文件# pwd/container-data-volumes# lltotal 0# -----------------------------------------------------# 分别在宿主机和容器数据卷绑定的目录中创建不同的文件，观察文件是否同步过去了# 在宿主机创建文件 touch host.txt &amp;&amp; ll-rw-r--r-- 1 harry staff 0B 4 15 21:25 host.txt# 在容器中创建文件 touch contianer.txt &amp;&amp; ll-rw-r--r-- 1 root root 0 Apr 15 13:26 contianer.txt # 容器创建的-rw-r--r-- 1 root root 0 Apr 15 13:25 host.txt # 前面宿主机创建的# 可以看到，文件创建成功了并且刚刚在宿主机创建的文件已经同步到了容器中。# 再观察宿主机有没有同步容器的文件过来 ll-rw-r--r-- 1 harry staff 0B 4 15 21:26 contianer.txt-rw-r--r-- 1 harry staff 0B 4 15 21:25 host.txt 「演示：容器停止后，主机修改后的数据是否会同步到容器中」 123456789101112# 停止容器 / 或者删除容器重新建立数据卷（宿主机的目录不变）# exit# 宿主机修改文件： echo 'host update' &gt;&gt; host.txt &amp;&amp; cat host.txthost update# 启动容器，查看文件内容# docker start 30a574c0dbe1# docker attach 30a574c0dbe1# cd container-data-volumes/ &amp;&amp; cat host.txthost update# 可以看到内容修改成功同步过来，重新创建的容器文件也是一样的会被同步过来。 「演示：使用带权限的挂载命令」 docker run -it -v /宿主机文件绝对路径:/容器内路径:ro 镜像名 :ro read only 123456789101112# 删除刚刚创建的容器# docker rm -f $(docker ps -aq)# 带权限的挂载数据卷# docker run -it -v ~/Learning/docker-note/host-data-volumes/:/container-data-volumes:ro centos# 依旧查看宿主机文件是否同步到位# cd container-data-volumes/ &amp;&amp; ll-rw-r--r-- 1 root root 0 Apr 15 13:26 contianer.txt-rw-r--r-- 1 root root 12 Apr 15 13:32 host.txt# 重点来了，容器修改共享文件夹（数据卷）的数据# touch modify.txttouch: cannot touch 'modify.txt': Read-only file system :vo 限制了容器对数据卷的写权限，使得容器只能够读数据。查看 docker inspect 75b1409b8a9e: 使用二： DockerFile 挂载数据卷DockerFile 的概念先不讨论，重点在于怎么使用 DockerFile 实现宿主机与容器之间的目录挂载。 「步骤」 1）创建 DockerFile 所属目录 1234567mkdir dockerfile-volumes &amp;&amp; lltotal 88-rw-r--r--@ 1 harry staff 29K 4 17 23:46 README.md-rw-r--r-- 1 harry staff 12K 3 6 01:36 anaconda-post.logdrwxr-xr-x 2 harry staff 64B 4 17 23:48 dockerfile-volumes # 存放 DockerFile 的文件夹drwxr-xr-x 4 harry staff 128B 4 17 23:22 host-data-volumesdrwxr-xr-x 7 harry staff 224B 4 15 21:47 img 2） 编写 Dockerfile 文件，在 DockerFile 中通过 VOLUME 指令给镜像添加「一个或多个」数据卷。 1PS: 以命令方式只能挂载一个数据卷 cd dockerfile-volumes &amp;&amp; touch Dockerfile 添加以下内容123456# Volume Dockerfile 方式挂载数据卷测试FROM centos# 挂载命令VOLUME [\"/data-volumes-container1\",\"/data-volumes-container2\"]CMD echo \"image is building...\"CMD /bin/bash PS：VOLUME命令指定了分别在容器上挂载两个目录：/data-volumes-container1 / /data-volumes-container2，但是没有指定宿主机目录。这是因为一个镜像会被不同的宿主机运行，但是宿主机路径不是每个执行镜像的宿主机都是相同的。通过 DockerFile 挂载的数据卷宿主机目录会被默认分配。 3）执行构建命令 docker build -f /Dockerfile名（路径） -t 镜像名:TAG . -f：指定 Dockerfile 名（路径），如果就在当前目录执行可以不加。 -t：指定镜像名 12345678910111213141516171819202122232425262728# docker build -f ~/Learning/docker-note/dockerfile-volumes/Dockerfile -t yuzh/centos:v1 .Sending build context to Docker daemon 2.048kBStep 1/4 : FROM centos ---&gt; 9f38484d220fStep 2/4 : VOLUME ['/data-volumes-container1','data-volumes-container2'] # 挂载命令 ---&gt; Running in 0ad66b7ad4f9Removing intermediate container 0ad66b7ad4f9 ---&gt; 1fad13e698d5Step 3/4 : CMD echo \"image is building...\" ---&gt; Running in 2a90e6187e24Removing intermediate container 2a90e6187e24 ---&gt; fc3713190c97Step 4/4 : CMD /bin/bash ---&gt; Running in 2a361cb58947Removing intermediate container 2a361cb58947 ---&gt; 31f766043abfSuccessfully built 31f766043abfSuccessfully tagged yuzh/centos:v1# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEyuzh/centos v1 31f766043abf 33 seconds ago 202MBizhiliu/tomcat2 v2 cf18ff34c415 2 days ago 465MB# docker run -it yuzh/centos:v1 运行构建的镜像查看数据卷是否存在# lldrwxr-xr-x 2 root root 4096 Apr 17 16:24 data-volumes-container1drwxr-xr-x 2 root root 4096 Apr 17 16:24 data-volumes-container2 4）docker inspect 容器ID 查看宿主机位置，验证数据共享 使用三：使用数据卷容器实现数据共享实现容器间数据共享的第三种方式，使用命令： docker run -it –volumes-from 父容器ID 镜像ID 「演示」 沿用之前通过 Dockerfile 创建的镜像 一）继承与被继承容器之间的数据共享： 1234567891011121314151617181920# 启动第一个容器，作为父容器# docker run -it --name container01 yuzh/centos:v1# ll 自然而然的可以看到有两个数据卷文件drwxr-xr-x 2 root root 4096 Apr 18 16:19 data-volumes-container1drwxr-xr-x 2 root root 4096 Apr 18 16:19 data-volumes-container2# 进去 data-volumes-container1，创建一个文件# touch container01.txt &amp;&amp; ll-rw-r--r-- 1 root root 0 Apr 18 16:21 container01.txt# 不停止退出，创建第二个容器，继承第一个容器作为数据卷容器# docker run -it --name container02 --volumes-from container01 yuzh/centos:v1# cd data-volumes-container1 &amp;&amp; ll-rw-r--r-- 1 root root 0 Apr 18 16:21 container01.txt# 可以看到容器1创建的文件同步过来了，在容器2创建一个文件，观察容器1是否同步：# touch container01.txt# docker attach container01# cd data-volumes-container1 &amp;&amp; ll-rw-r--r-- 1 root root 0 Apr 18 16:27 container01.txt-rw-r--r-- 1 root root 0 Apr 18 16:27 container02.txt 二）相同父容器的不同子容器之间的数据共享 12345678910111213141516171819202122# 创建第三个容器，继承容器1，操作容器3，观察容器1、2是否都有数据# docker run -it --name container03 --volumes-from container01 yuzh/centos:v1# cd data-volumes-container1 &amp;&amp; ll-rw-r--r-- 1 root root 0 Apr 18 16:27 container01.txt-rw-r--r-- 1 root root 0 Apr 18 16:27 container02.txt# 自然的看到了容器1、2之间共享的数据，在容器3创建文件：# touch container03.txt# 容器1肯定是有此文件的，因为容器3是挂载在容器1之上的。# docker attach container01# cd data-volumes-container1 &amp;&amp; ll-rw-r--r-- 1 root root 0 Apr 18 16:27 container01.txt-rw-r--r-- 1 root root 0 Apr 18 16:27 container02.txt-rw-r--r-- 1 root root 0 Apr 18 16:34 container03.txt# 问题来了：容器2会有 container03.txt 吗？# docker attach container02# cd data-volumes-container1 &amp;&amp; ll-rw-r--r-- 1 root root 0 Apr 18 16:27 container01.txt-rw-r--r-- 1 root root 0 Apr 18 16:27 container02.txt-rw-r--r-- 1 root root 0 Apr 18 16:34 container03.txt# 也是有的 三）删除父容器，两个子容器之间的数据还会共享吗？ 1234567891011121314151617181920212223242526# docker ps0bce4751cdf2 yuzh/centos:v1 \"/bin/sh -c /bin/bash\" 7 minutes ago Up 7 minutes container0398d3db76ca2c yuzh/centos:v1 \"/bin/sh -c /bin/bash\" 16 minutes ago Up 16 minutes container02fb12544f689b yuzh/centos:v1 \"/bin/sh -c /bin/bash\" 21 minutes ago Up 21 minutes container0# docker rm -f 0bce4751cdf20bce4751cdf2# 进入容器2，修改文件。# docker attach container02# touch container02-update.txt &amp;&amp; ll-rw-r--r-- 1 root root 0 Apr 18 16:27 container01.txt-rw-r--r-- 1 root root 0 Apr 18 16:42 container02-update.txt-rw-r--r-- 1 root root 0 Apr 18 16:27 container02.txt-rw-r--r-- 1 root root 0 Apr 18 16:34 container03.txt# ok，进入容器3，观察是否有 container02-update.txt# [control + p + q]# docker exec -it fb12544f689b /bin/bash# cd data-volumes-container1 &amp;&amp; ll-rw-r--r-- 1 root root 0 Apr 18 16:27 container01.txt-rw-r--r-- 1 root root 0 Apr 18 16:42 container02-update.txt # 容器2创建的-rw-r--r-- 1 root root 0 Apr 18 16:27 container02.txt-rw-r--r-- 1 root root 0 Apr 18 16:34 container03.txt# 嗯，有点东西～# 容器3修改文件进去容器2查看，也是一样的会被同步，不重复了。。。 结论：容器之间配置信息的传递，数据卷的生命周期一直持续到没有容器使用它为止。 DockerFile DockerFile 是用来构建 Docker 镜像的构建文件，是由一系列参数和命令构成的脚本。 DockerFile 规则 每条保留字指令都必须为大写字母且后面要至少包含一个参数 指令按照从上往下，顺序执行。 每条指令都会创建一个新的镜像层，并对镜像进行提交。 DockerFile 执行流程 docker 从基础镜像运行一个容器 执行一条指令并对容器作出修改 执行类似于 docker commit 的操作提交一个新镜像层 docker 再基于刚提交的镜像运行一个新容器 执行 dockerfile 中的下一条指令直到所有指令都执行完成 从应用软件的角度来看，DockerFile、Docker 镜像、Docker 容器分别代表软件的三个不同阶段 DockerFile 是软件的原材料 Docker 镜像时软件的交付品 Docker 容器则可以认为是软件的运行态 DockerFile 面向开发，Docker 镜像成为交付标准，Docker 容器设计部署与运维。三者缺一不可，合力充当 Docker 体系的基石。 DockerFile 指令FROM 基础镜像，当前新镜像是基于哪个镜像的。 LABLE 用于为镜像添加原数据 LABLE key1=value1 key2=value2 … MAINTAINER 镜像维护者的姓名和邮箱地址 已过时，建议使用 LABLE 形式：LABLE maintainer=&quot;harry&quot; RUN 容器构建时需要执行的命令 EXPOSE 当前容器对外暴露的端口号，随机端口映射将会自动映射此端口。 WORKDIR 指定在容器创建后，终端登陆进来后默认的工作目录，一个落脚点。 ENV 在构建时设置环境变量 12345ENV MY_PATH /usr/mytest这个环境变量可以在后续的任何 RUN 指令中使用，如同在命令前面指定了环境变量前缀一样。也可以在其他指令中直接使用这些环境变量，如：WORKDIR ${MY_PATH} ADD 将宿主机下的文件拷贝进镜像且 ADD 命令会自动处理 URL 和解压 tar 压缩包 COPY 类似于 ADD，拷贝文件和目录到镜像中。 将从「构建上下文」目录中的文件/目录，复制到新的一层镜像的目录中 12COPY source target # shell 格式COPY ['source','target'] # exec 格式 VOLUME 容器数据卷，用于数据保存和持久化。 CMD 指定一个容器「启动」时要运行的命令 12CMD &lt;命令&gt; # shellCMD ['可执行文件','参数1','参数2'...] # exec DockerFile 中可以有多个 CMD 命令，但只有最后一个生效。CMD 会被 docker run 之后的参数替换。 ENTERPOINT 指定一个容器启动时要运行的命令，ENTRYPOINT 的目的和 CMD 一样，都是指定容器启动命令和参数。 ENTRYPOINT 与 CMD 的区别在于：若存在多个 CMD 指令，docker build 时只会以最后一条 CMD 为准，而 ENTRYPOINT 则是追加。 ONBUILD 如果当前镜像是一个父镜像，并且 DockerFile 中存在 ONBUILD 指令，那么子镜像 build 后会「触发」父镜像的 ONBUILD 指令，相当于父镜像执行一些子镜像构建之后的收尾操作。 EXPOSE\b\b 与 -p 的区别EXPOSE 暴露端口，更容易理解的说法是「声明端口」。声明容器运行时提供的服务端口，注意：这只是一个声明，容器并不会\b因为此声明就会开启\b这个端口的服务。使用此命令有两个好处： 帮助镜像的使用者理解这个镜像的守护端口，以方便映射配置 容器运行时的随机端口 -p 分配会自动映射 EXPOSE 的端口。 案例Base镜像（scratch）Docker Hub 中 99% 的镜像都是通过在 base 镜像中安装和配置需要的软件构建出来的。 自定义镜像 my-centos目的：练习基础指令 需求：进入 centos 镜像中，会发现： 工作目录是 / 根目录 不支持 vim 命令 不支持 ifconfig 命令 这是因为 centos 镜像是一个最基础的镜像，共用本机系统内核，去除了不是必须的一些软件及命令或功能。我们的需求是自己构建一个 centos 镜像，使其默认进入我们指定的工作目录，并支持以上两个命令。 1234# pwd/Users/harry/Learning/docker-note/docker-file# touch DockerFile &amp;&amp; ll-rw-r--r-- 1 harry staff 0B 4 24 00:33 DockerFile 「编写 DockerFile」 1234567891011121314# vim DockerFileFROM centos # 指定基础镜像MAINTAINER harry&lt;yuzh233@gmail.com&gt; # 设置镜像构建者信息ENV MY_PATH /usr/local # 设置一个环境变量WORKDIR $MY_PATH # 指定工作目录，使用环境变量RUN yum -y install vim # 执行命令：安装 vimRUN yum -y install net-tools # 执行命令：安装 net-toolsEXPOSE 8088 # 暴露端口CMD echo 'my workdir is $MY_PATH' # 容器启动执行：打印字符串CMD /bin/bash # 容器启动真正执行的命令 「执行构建」 docker build -f 路径 -t 镜像名:TAG . 123456789101112131415161718192021222324252627282930313233343536373839404142434445# docker build -f DockerFile -t izhiliu/centos:v1 .# DockerFile 就在当前路径下，不用指定目录Sending build context to Docker daemon 2.048kB# 可以看到，有几行 DockerFile 就构建几层镜像。Step 1/9 : FROM centos ---&gt; 9f38484d220fStep 2/9 : MAINTAINER harry&lt;yuzh233@gmail.com&gt; ---&gt; Running in 4966da40f5e8Removing intermediate container 4966da40f5e8 ---&gt; 32eb4f4c77baStep 3/9 : ENV MY_PATH /usr/local ---&gt; Running in 8b4d372d1404Removing intermediate container 8b4d372d1404 ---&gt; b412c79d5a02Step 4/9 : WORKDIR $MY_PATH ---&gt; Running in 42d2d2df5804Removing intermediate container 42d2d2df5804 ---&gt; 082bb5098dbfStep 5/9 : RUN yum -y install vim# ......开始安装 vim v......Complete!Removing intermediate container 3536627f1160 ---&gt; 58f9bbd23b2eStep 6/9 : RUN yum -y install net-tools ---&gt; Running in 3a6d39924e48# ...... 开始安装 net-tools ......Complete!Removing intermediate container 3a6d39924e48 ---&gt; 2065a365b531Step 7/9 : EXPOSE 8088 ---&gt; Running in b836df8bcfb6Removing intermediate container b836df8bcfb6 ---&gt; 190f68eeb2d8Step 8/9 : CMD echo 'my workdir is $MY_PATH' ---&gt; Running in cadea312695eRemoving intermediate container cadea312695e ---&gt; 8d6c248e24c9Step 9/9 : CMD /bin/bash ---&gt; Running in e5ff383a4407Removing intermediate container e5ff383a4407 ---&gt; a8a7bed31bd7# 出现下面两行代表构建成功Successfully built a8a7bed31bd7Successfully tagged izhiliu/centos:v1 「验证新镜像」 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEizhiliu/centos v1 87ebc03d1d90 32 seconds ago 425MB# &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 镜像构建成功！# docker run -it 87ebc03d1d90[root@1bd54814f9c5 local]# pwd/usr/local# &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 根目录指定成功！# touch file# vim file -&gt; 有效# &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; vim 安装成功！# ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.17.0.2 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:02 txqueuelen 0 (Ethernet) RX packets 12 bytes 968 (968.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 loop txqueuelen 1 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0# &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; net-tools 安装成功！# docker history izhiliu/centos:v1# 执行这条命令可以看到某个镜像的构建过程，可以看到镜像从头到尾构建，显示根据构建时间倒序展示。IMAGE CREATED CREATED BY SIZE COMMENT87ebc03d1d90 14 minutes ago /bin/sh -c #(nop) CMD [\"/bin/sh\" \"-c\" \"/bin… 0Bddc2e1121ff8 14 minutes ago /bin/sh -c #(nop) CMD [\"/bin/sh\" \"-c\" \"echo… 0Ba1010b933008 14 minutes ago /bin/sh -c #(nop) EXPOSE 8088 0B670892d19e9f 14 minutes ago /bin/sh -c yum -y install net-tools 84.1MBfb03334297ef 14 minutes ago /bin/sh -c yum -y install vim 139MBdaceee7c426b 15 minutes ago /bin/sh -c #(nop) WORKDIR /usr/local 0Bf39af63b22d3 15 minutes ago /bin/sh -c #(nop) ENV MY_PATH=/usr/local 0Bef7f5536cec3 15 minutes ago /bin/sh -c #(nop) MAINTAINER harry&lt;yuzh233@… 0B# docker inspect izhiliu/centos:v1 查看容器信息......\"Author\": \"harry&lt;yuzh233@gmail.com&gt;\",...... CMD/ENTERPOINT 镜像案例一）DockerFile 中可以有不多个 CMD 指令，但只有最后一个生效。并且最后一个 CMD 指令会被 docker run 之后的参数替换（如果有） 「演示」 1234567891011121314151617181920212223242526# 查看 tomcat 官方 DockerFile，最后一行：CMD [\"catalina.sh\", \"run\"]# tomcat 容器就是通过这行命令启动起来的，我们试着在启动时指定其他命令：docker run -it --name cat -p 7070:8080 tomcat ls -l# 我们用 ls -l 命令替换掉了 [\"catalina.sh\", \"run\"]total 152-rw-r--r-- 1 root root 19539 Apr 10 14:33 BUILDING.txt-rw-r--r-- 1 root root 6090 Apr 10 14:33 CONTRIBUTING.md-rw-r--r-- 1 root root 57092 Apr 10 14:33 LICENSE-rw-r--r-- 1 root root 1726 Apr 10 14:33 NOTICE-rw-r--r-- 1 root root 3255 Apr 10 14:33 README.md-rw-r--r-- 1 root root 7139 Apr 10 14:33 RELEASE-NOTES-rw-r--r-- 1 root root 16262 Apr 10 14:33 RUNNING.txtdrwxr-xr-x 2 root root 4096 Apr 13 00:10 bindrwxr-sr-x 2 root root 4096 Apr 10 14:33 confdrwxr-sr-x 2 root staff 4096 Apr 13 00:10 includedrwxr-xr-x 2 root root 4096 Apr 13 00:09 libdrwxrwxrwx 2 root root 4096 Apr 10 14:31 logsdrwxr-sr-x 3 root staff 4096 Apr 13 00:10 native-jni-libdrwxr-xr-x 2 root root 4096 Apr 13 00:09 tempdrwxr-xr-x 7 root root 4096 Apr 10 14:31 webappsdrwxrwxrwx 2 root root 4096 Apr 10 14:31 work# 可以看到最后一行命令执行成功了，查看容器进程：docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES202be91cd7ec tomcat \"ls -l\" About a minute ago Exited (0) About a minute ago cat# tomcat 没有启动起来，原因是我们用 ls -a 命令代替了启动 tomcat 的命令 二）docker run 之后的参数会被当作参数传递给 ENTRYPOINT，形成新的命令组合。 定制一个查看当前 ip 信息的容器，DockerFile如下： 1234567# 安装 curl 工具，发起请求到查ip的网站查询返回信息# curl 命令可以用来执行下载、发送各种 HTTP 请求，指定 HTTP 头部等操作。FROM centosRUN yum install -y curl # 执行安装CMD [\"curl\",\"-s\",\"http://ip.cn\"]# 执行构建docker build -f DockerFile2 -t show-ip . 启动容器，会看到 http://ip.cn 的相应信息展示到了控制台，curl -s xxx 命令执行成功。但是当我们需要在容器启动时变更启动中的参数时，CMD就不起作用了。 如我们希望在容器运行时给 curl -s http://ip.cn 加一个 -i 参数用来显示完整的相应头信息，此时会报错说找不到命令，原因是将 -i 当作一个命令去替换掉了 curl -s http://ip.cn 命令，这显然不是我们想看到的。 这种情况可以使用 ENTRYPOINT，只需在 DockerFile 中替换 CMD 指令为 ENTRYPOINT 即可。ENTRYPOINT [&quot;curl&quot;,&quot;-s&quot;,&quot;xxxx&quot;]，此时我们在容器启动时指定的参数会以参数的形式追加到 curl -s http://ip.cn 后面而不是替换原来命令了。 自定义镜像 Tomcat自定义一个 tomcat 的镜像，使其启动就是运行了一个 tomcat，实际上就是以 centos 为基础镜像安装了 jdk 和 tomcat 的环境，并设置为启动而已。 「步骤」 创建 DockerFile 所在目录，准备镜像所需要的 jdk 和 tomcat 安装包。 12345678------------------------------------------------------------~/Learning/docker-note/docker-file/my-tomcat(master*) » pwd &amp;&amp; ll harry@192/Users/harry/Learning/docker-note/docker-file/my-tomcattotal 375368-rw-r--r-- 1 harry staff 0B 5 2 21:35 Dockerfile-rwxr-xr-x@ 1 harry staff 8.5M 6 5 2018 apache-tomcat-7.0.75.tar.gz-rwxr-xr-x@ 1 harry staff 175M 6 5 2018 jdk-8u121-linux-x64.tar.gz------------------------------------------------------------ 编写 DockerFile 12345678910111213141516171819202122232425262728~/Learning/docker-note/docker-file(master*) » cd my-tomcat harry@192FROM centosMAINTAINER harry&lt;yuzh233@gmail.com&gt;ADD apache-tomcat-7.0.75.tar.gz /usr/localADD jdk-8u121-linux-x64.tar.gz /usr/localRUN yum -y install vimENV WORK_PATH /usr/localWORKDIR $WORK_PATH# 设置 java 环境目录，此文件夹名可以在本地将 jdk-8u121-linux-x64.tar.gz 得到ENV JAVA_HOME /usr/local/jdk1.8.0_121ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarENV CATALINA_HOME /usr/local/apache-tomcat-7.0.75ENV CATALINA_BASE /usr/local/apache-tomcat-7.0.75ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/binEXPOSE 8080# ENTRYPOINT [\"/usr/local/apache-tomcat-7.0.75/bin/startup.sh\"]# CMD [\"/usr/local/apache-tomcat-7.0.75/bin/startup.sh\",\"run\"]# tail 命令：查看文件最后指定行，-f 参数不停的读取。CMD /usr/local/apache-tomcat-7.0.75/bin/startup.sh \\ &amp;&amp; tail -f /usr/local/c/logs/catalina.out PS：容器启动命令加上 tail 是使其输出日志以免以 -d 后台运行时由于前台进程无事可做自动停止容器。 构建镜像 docker build -f Dockerfile -t yuzh/lovely-cat . 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455Sending build context to Docker daemon 192.2MBStep 1/14 : FROM centos ---&gt; 9f38484d220fStep 2/14 : MAINTAINER harry&lt;yuzh233@gmail.com&gt; ---&gt; Using cache ---&gt; ef7f5536cec3Step 3/14 : ADD apache-tomcat-7.0.75.tar.gz /usr/local ---&gt; ce38ea3cc5bfStep 4/14 : ADD jdk-8u121-linux-x64.tar.gz /usr/local ---&gt; 9bb44d59445fStep 5/14 : RUN yum -y install vim ---&gt; Running in 4e44d91a2a47# ......Complete!Removing intermediate container 4e44d91a2a47 ---&gt; 5dfdd1d562eeStep 6/14 : ENV WORK_PATH /usr/local ---&gt; Running in 11087250850aRemoving intermediate container 11087250850a ---&gt; 81440053e1c9Step 7/14 : WORKDIR $WORK_PATH ---&gt; Running in dbc004146319Removing intermediate container dbc004146319 ---&gt; 240cc0a13f09Step 8/14 : ENV JAVA_HOME /usr/local/jdk1.8.0_121 ---&gt; Running in 9c1f3a418a1fRemoving intermediate container 9c1f3a418a1f ---&gt; 1a27a3df60abStep 9/14 : ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar ---&gt; Running in 0f8cc5d9ea9cRemoving intermediate container 0f8cc5d9ea9c ---&gt; 35126d06a7caStep 10/14 : ENV CATALINA_HOME /usr/local/apache-tomcat-7.0.75 ---&gt; Running in 0e015a7542f0Removing intermediate container 0e015a7542f0 ---&gt; 22af3e7209e9Step 11/14 : ENV CATALINA_BASE /usr/local/apache-tomcat-7.0.75 ---&gt; Running in 0dc6317ab454Removing intermediate container 0dc6317ab454 ---&gt; cfd95a85a2d3Step 12/14 : ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin ---&gt; Running in b1b9a6a3e859Removing intermediate container b1b9a6a3e859 ---&gt; f03c22aef15dStep 13/14 : EXPOSE 8080 ---&gt; Running in 61a077e13bdeRemoving intermediate container 61a077e13bde ---&gt; afc175ba3243Step 14/14 : ENTRYPOINT [\"/usr/local/apache-tomcat-7.0.75/bin/startup.sh\"] ---&gt; Running in 753701ca8f2bRemoving intermediate container 753701ca8f2b ---&gt; 9a7ad3e1deb1Successfully built 9a7ad3e1deb1Successfully tagged yuzh/lovely-cat:latest------------------------------------------------------------ 运行新建的容器 12345678910~/Learning/docker-note/docker-file/my-tomcat(master*) » docker image ls harry@192REPOSITORY TAG IMAGE ID CREATED SIZEyuzh/lovely-cat latest 4d2b3d59f957 2 minutes ago 731MB------------------------------------------------------------~/Learning/docker-note/docker-file/my-tomcat(master*) » docker run -d -p 8080:8080 4d2b3d59f957 harry@192------------------------------------------------------------~/Learning/docker-note/docker-file/my-tomcat(master*) » docker ps harry@192CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESe3b5a9979497 4d2b3d59f957 \"/bin/sh -c '/usr/lo…\" 5 minutes ago Up 5 minutes 0.0.0.0:8080-&gt;8080/tcp sleepy_hopper------------------------------------------------------------ 验证 12345678910111213141516171819202122232425~/Learning/docker-note/docker-file/my-tomcat(master*) » docker exec -it e3b5a9979497 /bin/bash harry@192# 验证：工作目录# [root@e3b5a9979497 local] # pwd/usr/local# 验证：vim# [root@e3b5a9979497 local]# vim apache-tomcat-7.0.75/logs/catalina.outMay 02, 2019 2:21:19 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Server version: Apache Tomcat/7.0.75May 02, 2019 2:21:19 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Server built: Jan 18 2017 20:54:42 UTCMay 02, 2019 2:21:19 PM org.apache.catalina.startup.VersionLoggerListener logINFO: Server number: 7.0.75.0May 02, 2019 2:21:19 PM org.apache.catalina.startup.VersionLoggerListener logINFO: OS Name: LinuxMay 02, 2019 2:21:19 PM org.apache.catalina.startup.VersionLoggerListener logINFO: OS Version: 4.9.125-linuxkitMay 02, 2019 2:21:19 PM org.apache.catalina.startup.VersionLoggerListener log......# 验证 jdk------------------------------------------------------------~/Learning/docker-note/docker-file/my-tomcat(master*) » docker exec -it e3b5a9979497 java -version harry@192java version \"1.8.0_121\"Java(TM) SE Runtime Environment (build 1.8.0_121-b13)Java HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode)------------------------------------------------------------ 发布 Web 应用 挂载数据卷，重新启动容器。 这样做的好处是不用进入容器查看日志，直接查看主机与容器共享的文件。发布 web 应用只需要在本地将 war 包放到共享文件夹，重启容器即可。 1234# docker run -it -p 8888:8080 \\# -v ~/Learning/docker-note/docker-file/my-tomcat/webapp:/usr/local/apache-tomcat-7.0.75/webapps \\# -v ~/Learning/docker-note/docker-file/my-tomcat/logs:/usr/local/apache-tomcat-7.0.75/logs \\# 4d2b3d59f957 新建 web 项目，将 web 包复制到容器的 webapp 目录下。容器 tomcat 即可。 安装 MySqlMysql DockerHub 官方文档 「总体步骤」 docker search –filter=stars=30 mysql docker pull mysql:latest docker run -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag 进入到了 mysql 容器，通过命令行连接到 mysql 客户端：mysql -u root -p …… 「输入密码」 …… 数据库操作（show databases; use mysql; show tables; select * from user; ……） 修改默认配置文件： Mysql 默认的配置文件在：/etc/mysql/my.cnf，我们可以在容器启动时以数据卷的方式挂载自己的配置文件到容器上： 12# 假如 /my/custom 是我们的自定义配置文件docker run -v /my/custom:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag 这将会以 /etc/mysql/my.cnf 和 /my/custom 组合配置的方式新启动一个容器实例，后者优先级大于前者。 不修改配置文件，使用命令参数配置 Mysql 通过命令标志的形式传递给 mysqld，可以使我们更加灵活的配置 mysql 而不需要配置文件。如：修改所有表的编码方式只需在容器启动时添加以下参数 1docker run -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci 存储数据 有两种方式存储应用程序在 Docker 容器运行中产生的数据。 让 Docker 使用自己的数据卷管理方式存储将数据库文件写入到主机，这种方式最方便快捷，但是缺点是数据文件不方便找到和管理。 自己创建文件夹，使其挂载到 mysql 的数据文件。 1docker run -v /my/own/datadir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag 备份数据 1docker exec some-mysql sh -c 'exec mysqldump --all-databases -uroot -p\"$MYSQL_ROOT_PASSWORD\"' &amp;gt; /some/path/on/your/host/all-databases.sql Docker Compose 启动 Mysql 最简单的例子： 1234567891011121314151617# Use root/example as user/password credentialsversion: '3.1'services: db: image: mysql command: --default-authentication-plugin=mysql_native_password restart: always environment: MYSQL_ROOT_PASSWORD: admin ports: - 3336:3306 adminer: image: adminer restart: always ports: - 8080:8080 如何\b在主机客户端连接容器中的 Mysql 服务端 Compose 中的应用\b属于自己的网络，外界不能访问。首先需要\b暴露端口，注意：尽量不要使用 3306，因为主机大多数安装了Mysql，此端口会被\b占用。 其次，连接命令类似于如下： 12# note: -P 是指定端口，-p 是指定密码mysql -h localhost -P 3336 --protocol=tcp -u root -p 需要额外指定参数：--protocol=tcp，因为我们的 Mysql 在\b Docker 里面，socket 将不可用，所以需要通过 TCP 连接它，在 MySQL 命令中设置“-protocol”将改变这一点。 引用：https://stackoverflow.com/questions/33001750/connect-to-mysql-in-a-docker-container-from-the-host 安装 RedisRedis DockerHub 官方文档 redis 命令手册 docker pull redis 启动 redis 服务端：docker run -d -p 6379:6379 -v ~/Learning/docker-note/redis/data:/data redis redis-server –appendonly yes暴露端口，挂载本地文件到 redis 的持久化文件。避免容器删除 key 丢失。 上面只是启动了服务端，容器运行后需要我们进入容器手动启动 redis 客户端进行测试。 1234如何找到 redis 命令地址？可以通过查看 DockerHub 上 Redis 的 DockerFile文件得知在：`/usr/local/bin/`。cd /usr/local/bin/ &amp;&amp; ./redis-cli# exec redis commend ...... 「测试持久化」 12345678910111213141516171819# 在当前容器设置了三个 key127.0.0.1:6379&gt; keys *1) \"k2\"2) \"k1\"3) \"k3\"# 查看宿主机持久化文件：------------------------------------------------------------~/Learning/docker-note/redis/data(master*) » pwd harry@192/Users/harry/Learning/docker-note/redis/data------------------------------------------------------------~/Learning/docker-note/redis/data(master*) » cat appendonly.aof harry@192*2$6SELECT$10*3...... 证明是挂载成功的，然后删除容器，重新启动一个新容器，看数据是否同步过去了。 宿主机连接 docker 中的 redis： 自定义配置文件 定制 DockerFile 的形式 123FROM redisCOPY redis.conf /usr/local/etc/redis/redis.confCMD [ \"redis-server\", \"/usr/local/etc/redis/redis.conf\" ] 命令行参数指定，灵活，推荐。 1docker run -v /myredis/conf/redis.conf:/usr/local/etc/redis/redis.conf redis redis-server /usr/local/etc/redis/redis.conf 练习：Spring Boot 单体应用容器化使用上面的 test-dockerfile 项目，构建一个镜像，通过容器运行并访问。 添加一个最简单的 Dockerfile 123456FROM tomcat:latestENV WORK_PATH /usr/local/tomcatADD /target/test-dockerfile-0.0.1-SNAPSHOT.jar ${WORK_PATH}/webapps/test-dockerfile-0.0.1-SNAPSHOT.jarEXPOSE 8081# PS：ENTRYPOINT [\"\",\"${WORK_PATH}\"] 这种方式是 exec 的形式执行，不会解析环境变量。除非使用 shell 的方式。ENTRYPOINT java -jar ${WORK_PATH}/webapps/test-dockerfile-0.0.1-SNAPSHOT.jar 在项目根路径下执行：docker build -f Dockerfile -t my-webapp:latest . 运行：docker run -it -p 8081:8080 my-webapp:latest 访问：http://localhost:8081/api/hello-docker PS：IDEA 2019 版集成了 Docker 工具，不过我还是使用命令吧😂。 仓库学会使用「容器镜像服务」，官方有详细文档说明，这里只记录主要步骤及问题。 1）创建镜像仓库，指定代码源 2) 登陆私有镜像仓库 1docker login --username=yuzh233 registry.cn-hangzhou.aliyuncs.com PS：修改密码入口：容器服务首页 -&gt; 访问凭证 3） 上传镜像到私有仓库 1234567docker login --username=yuzh233 registry.cn-hangzhou.aliyuncs.com# docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/yuzh/test-dockerfile:[镜像版本号]# ImageId 就是本地构建好需要上传到远程仓库的镜像IDdocker tag fccdeb7abef7 registry.cn-hangzhou.aliyuncs.com/yuzh/test-dockerfile:latestdocker push registry.cn-hangzhou.aliyuncs.com/yuzh/test-dockerfile:[镜像版本号] 4） 从私有仓库拉取镜像 1docker pull registry.cn-hangzhou.aliyuncs.com/yuzh/test-dockerfile:[镜像版本号] 5）登出远程仓库 docker logout [仓库地址] 1e.g: docker logout registry.cn-shanghai.aliyuncs.com","link":"/2019/05/11/Docker 补救指南（一）—— 基础使用/"},{"title":"Atom 使用","text":"不支持 markdown 语法？需要安装插件 language-markdown。 如何在 Atom 使用 Terminal？How to open the terminal in Atom?安装插件：platformio-ide-terminal 自动保存插件禁用自带的 autosave，安装 autosave-onchange 文件图标插件file-icons 预览增强markdown-preview-enhanced markdown 编辑插件markdown-writer Json 格式化插件pretty-json","link":"/2019/08/06/Atom 使用/"},{"title":"oh-my-zsh 配置","text":"安装GITHUB 地址 主题配置安装之后，zsh默认自带的主题文件在 ~/.oh-my-zsh/thems/中。 修改主题：在 ~/.zshrc 配置文件，修改 ZSH_THEME 属性。 查看当前主题命令：zsh 还可以可以设置随机主题，值为random。其他好看的主题： strug.zsh-theme philips.zsh-theme half-life.zsh-theme juanghurtado.zsh-theme maran.zsh-theme blinks.zsh-theme agnoster.zsh-theme norm.zsh-theme","link":"/2019/08/06/oh-my-zsh配置/"}],"tags":[{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"maven","slug":"maven","link":"/tags/maven/"},{"name":"无关代码","slug":"无关代码","link":"/tags/无关代码/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"idea","slug":"idea","link":"/tags/idea/"},{"name":"tomcat","slug":"tomcat","link":"/tags/tomcat/"},{"name":"lombook","slug":"lombook","link":"/tags/lombook/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"aliyun","slug":"aliyun","link":"/tags/aliyun/"},{"name":"aop","slug":"aop","link":"/tags/aop/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"spring-boot","slug":"spring-boot","link":"/tags/spring-boot/"},{"name":"dockerfile","slug":"dockerfile","link":"/tags/dockerfile/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"dubbo","slug":"dubbo","link":"/tags/dubbo/"},{"name":"分布式","slug":"分布式","link":"/tags/分布式/"},{"name":"cokie","slug":"cokie","link":"/tags/cokie/"},{"name":"jsonp","slug":"jsonp","link":"/tags/jsonp/"},{"name":"sso","slug":"sso","link":"/tags/sso/"},{"name":"freeMarker","slug":"freeMarker","link":"/tags/freeMarker/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"算法","slug":"算法","link":"/tags/算法/"},{"name":"数据结构","slug":"数据结构","link":"/tags/数据结构/"},{"name":"solr","slug":"solr","link":"/tags/solr/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"集群","slug":"集群","link":"/tags/集群/"},{"name":"jms","slug":"jms","link":"/tags/jms/"},{"name":"nio","slug":"nio","link":"/tags/nio/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"线程","slug":"线程","link":"/tags/线程/"},{"name":"springboot","slug":"springboot","link":"/tags/springboot/"},{"name":"atom","slug":"atom","link":"/tags/atom/"},{"name":"zsh","slug":"zsh","link":"/tags/zsh/"}],"categories":[{"name":"docker-note","slug":"docker-note","link":"/categories/docker-note/"},{"name":"linux-note","slug":"linux-note","link":"/categories/linux-note/"},{"name":"english-learning","slug":"english-learning","link":"/categories/english-learning/"},{"name":"spring-boot","slug":"english-learning/spring-boot","link":"/categories/english-learning/spring-boot/"},{"name":"maven","slug":"english-learning/maven","link":"/categories/english-learning/maven/"},{"name":"interview","slug":"interview","link":"/categories/interview/"},{"name":"bug-fix","slug":"bug-fix","link":"/categories/bug-fix/"},{"name":"spring-boot","slug":"spring-boot","link":"/categories/spring-boot/"}]}