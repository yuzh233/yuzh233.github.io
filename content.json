{"pages":[{"title":"About Me","text":"TODO… 主题配置相关Brand 标识hexo 根目录 _config.yml 配置 title 生成 categories 和 tags 页面将 themes/icarus/_source 下的 categories 和 tags 目录拷贝到 hexo/source 目录 Profile主题的 _config.yml 配置 RECENT 略缩图设置每一篇文章添加标签：thumbnail: /img/random/14.jpg, img 文件夹是属于 hexo 根目录的。 首页显示文章摘要侵入性较强，在文章的指定部分添加标签：&lt;!-- more --&gt;，该标签之前的内容被作为摘要。 更改主题内容模块页面宽度../hexo/themes/icarus/source/css/_variables.styl 123456789// Layoutblock-margin = 40pxarticle-padding = 20pxmobile-nav-width = 280px# 自定义宽度，默认 7main-column = 10sidebar-column = 3profile-column = 3sidebar-column-tablet = 4 更改代码样式样式存在于：/opt/hexo/themes/icarus/source/css/_highlight 文件夹，60余种。 修改主题 _config.yml 的 highlight： Valine 评论12345678valine: # Valine Comment System https://github.com/xCss/Valine on: true # enter true to enable appId: IaNb4n1EqHakKzNDh6jR1qYJ-gzGzoHsz # enter the leancloud application appId here appKey: Hg7CxatEfuCfhqOsl7XYtEOv # enter the leancloud application appKey here notify: true # enter true to enable &lt;Mail notifier&gt; https://github.com/xCss/Valine/wiki/Valine-%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E9%82%AE%E4%BB%B6%E6%8F%90%E9%86%92%E8%AE%BE%E7%BD%AE # 需要设置true，否则插件不生效。 verify: true # enter true to enable &lt;Validation code&gt; placeholder: Just Do It... # enter the comment box placeholder TOC 支持每篇文件添加标签：toc: true 即可。","link":"/about/index.html"}],"posts":[{"title":"First Post","text":"第一篇，心情却不是很好。 &emsp;&emsp;起初只是室友不经意间的一句话，说：某某人现在在自学，还参加了学校的软件杯比赛，还报名了培训班，说应该学的比我还要好的多了。当时听完心里挺不舒服的，想说点什么证明自己来怼他，不过还是算了，毕竟我们关系还不错，没必要为了这点小事伤了和气显得自己多小气的样子，我知道和他辩解没有用，我也不想怪他什么，毕竟软件这个专业只有自己真心投入了才知道过程的艰辛。可是今天这种情况让我有点莫名的心酸… &emsp; &emsp;和往常一样一起吃完中午饭回来，路上看到他的许多同学去上课。说点题外的：大二了，这垃圾学校知道自己教学水平不行和培训机构合作怂恿同学们去培训，培训还得自己出钱。培训老师抓住大多数人的普遍心理让他们醒悟过来觉得现在开始学习，四个月后轻轻松松就可以学到所有技术点，然后坐着办公室拿高薪，敲着小代码，喝着下午茶，过着轻轻松松的生活，好不惬意… 一个个积极的报名去培训上课。我不想说培训机构有什么不好，我自己这两年学习过来的资料大多数都是培训机构的，论师资力量这垃圾学校是没得比的。 &emsp; &emsp;回来的路上自然的聊起培训的事，说什么记不太清，反正字里行间意思就是说他们多努力，多自觉的样子，周末还一个个去上课，这就算了，拿我比较干什么！心里压抑的情绪顿时忍不住了，我说没什么了不起的，他们要是自觉想学的话也不会想到现在去报班，如果不是大二培训机构隔三岔五的来洗脑会有这么多 焕然大悟、怎么就要毕业了、再不学习来不及了、我还什么都没学到怎么找工作的同志们回头赎罪的吗？ “我说我大一入学就自学 C语言 他们在干什么”； “大一第一个学期后的寒假自学 Java 他们又在做什么”； “大一毕业后的暑假自学 Web基础 他们又在干什么”； “大二第一个学期毕业的寒假自学 J2EE框架，练习项目他们又在想些什么！”； “现在大二下学期了，大三在校一个月学校就要求必须出去实习了，我在学习热门 开源框架 巩固基础参加 中国软件杯 比赛写项目而他们，才想起来知道要学习了吗？！”（当然并不是说暑假只能学习，我强调的是自主学习的态度。） &emsp; &emsp;“—— 他们在学习啊”。 &emsp; &emsp;回味深长的一句话，我笑笑，没付出过真的不知道过程的艰辛，付出了被人一句话否定的感觉也真是挺不好受的。算了算了，室友的性格我知道，不能怪他。 &emsp; &emsp;昨天高考结束了，有人欢喜有人愁，不管怎么说，他们都解放了，心中的石头也算放下了，该想什么做什么，毕业前想做不能做的现在可以随着自己了，接下来的就是尽人事听天命吧。突然之间感觉两年过的好快，仿佛我的高考就在昨天，还记得那天晚上和着班上的几个男男女女叫着肖哥一起去唱K，回来在宾馆一起打着扑克，最主要的是那晚鼓起勇气跟赖着坐了一年的 同桌or前后排or左右斜对面 对的同一个女生说了自己的想法，这也是我唯一没有感到遗憾的事了。 &emsp; &emsp;两个月后不情愿的来到了这个地方，和我一起的有高中同一个班上很努力搞学习的被老师看好乖乖男孩，他励志要考上二本（对于我们小学开始就在这种教学质量不高一类的学校读到高中的并且平行班的人来说，能考上二本已经很不错了）。虽然考的不好，但我们都没有选择复读，对于我来说高中那几年想读却不知道如何发力，仅仅靠着考上大学就轻松了的想法读书逼迫自己学习的那种迷茫，看不清道路感觉真的难以言表。话又说回来，我这个高中朋友到了新学校我不知道他哪来的乐观心态，计划着往后的三年“大学生活”如何过的多姿多彩，搞不懂这破地方有什么好憧憬的，有时候也蛮欣赏他们这种心态的。可是我满脑子里想的是，高中阶段不知所措的那几年我现在要以这种方式补回来，我是来赎罪的，我愧对自己，也愧对家人。 &emsp; &emsp;军训后上的第一门专业课叫 C语言程序设计 ，给我们上课的老师是一个实习生，搞IOS开发的，兼职来给我们上课。一个礼拜一节专业课，好充实的呢，MD。学校的初衷是让我们接触计算机语言的思想，字节啊、变量常量啊、语句啊、基本数据结构啊（虽然只粗略的提到了数组，仅此而已）。这就算了，由于是第一次上这种专业课，觉得老师讲的还可以，但是看书的目录总觉得讲的少了太多太多，老师也说了没想过给我们讲太多，当时我就不乐意了，我TM是来赎罪的你给我讲这么点我怎么学习知识！于是我开始接触网络学习，最开始下载了 网易云课堂 在里面看到邵发老师的 C/C++学习指南，看了有170多个课时，开始听了几节，觉得这个老师很有风格，由浅入深并且讲的很好很好，当时不知道哪来的毅力决定了把这个课程全部搞完。每天看视频当连续剧一样看，睡觉之前醒来之后都是视频，买了作者的书籍，在线练习题也全部自己认真练习并且整理成错题（高中养来的习惯）。就不知不觉培养了我对编程的兴趣。现在想想这都是缘分，如果不是这个课程对我的影响或许我和大多数在校生一样迷茫把！ &emsp; &emsp;后来的学习过程就不说了，无数次遇到困难，由于进度比学校都要快，没人帮我，只能自己百度查资料翻博客，久而久之我觉得网上的资源比在校老师实用的多，遇到过手贱、环境、语法、逻辑等各种无厘头的错误，但是从来没想到过放弃。最近日常解决bug看到网上一个妹子的博客简介是：从哪里跌倒，就在那里趴下，起来之后你会发现新大陆的。 这句话写的真的不错，深有体会，bug fix 之后的喜悦感真的只有自己经历过才知道。 &emsp; &emsp;就这样我带着不甘心的情绪学习到了现在，记得入学后我发的第一条朋友圈是 既然当不了鸡头，就争取做到凤尾。 语文水平不好只能说成这样了，不过我确实也做到了，最起码在班上专业上来说，我觉得自己水平第二没人有自信说第一，不过和他们比专业这毫无意义。当然不能自大，除了学习方面我还有很多方面需要向他们学习。 &emsp; &emsp;两年过来，结识了其他班上很多志同道合的朋友，学习到了很多，认识到自己的不足，即将步入找工作的浪潮，压力很大，任务很重，要学的很多，我会继续努力。 &emsp; &emsp;说了这么多，气也消了，想想也没必要，做好自己就行了何必在意别人怎么看呢。曾经是文科生，但是本身很恶心鸡汤，从来不想记录什么，生活重要的是过程，也没什么文采，写给自己看的。 &emsp; &emsp;—— 就这样。 &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp;","link":"/2018/06/09/First Post/"},{"title":"Linux下搭建Hexo博客环境","text":"Linux下搭建Hexo博客环境 前不久在自己电脑上搭建了基于 Github+Hexo 的个人博客，今天试着在Linux下搭建hexo环境并通过域名解析本地IP运行起来。刚好前几天在阿里云买了ECS云服务器和域名，还不是很熟练，不用白不用。😄 Steps 1 ：安装Git 安装git依赖包 1 yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel gcc perl-ExtUtils-MakeMaker 删除已有的git 1 yum remove git 下载git源码 切换到包文件目录： 1 cd /usr/src 下载git安装包 1 wget https://www.kernel.org/pub/software/scm/git/git-2.8.3.tar.gz 解压git安装包 12 tar -zxvf git-2.8.3.tar.gz cd git-2.8.3 配置git安装路径，usr目录一般用于存放共享的系统资源 1 ./configure prefix=/usr/local/git/ 编译并且安装 1 make &amp;&amp; make install 将git指令添加到环境变量中 1 vi /etc/profile 在最后一行加入 1 export PATH=$PATH:/usr/local/git/bin 刷新配置文件 1 source /etc/profile 然后，查看git版本号 1 git --version next… Steps 2 ：安装Node.js环境 安装Node.js依赖包 1yum -y install gcc-c++ openssl-devel 检查Python版本 1python --version 检查Python的版本，必须在2.6及以上才可以，如果低于这个版本还需要安装Python，当前Centos6系统，默认支持2.6。 下载和安装Node.js，注意先到opt目录下 12345wget http://nodejs.org/dist/node-latest.tar.gztar -zxvf node-latest.tar.gzcd node-v0.12.7./configuremake &amp;&amp; make install 我以为源码编译安装十几分钟就行了，然而足足安装了一个多小时。。。😭不过还好成功了。 接下来的才是主角 Steps 3： 安装Hexo环境 采用npm方式来部署hexo静态博客 1npm install -g hexo 安装期间出现了警告，有点小紧张，安装了这么久不会前功尽弃把！还好最后成功了，警告无所谓了只要不是错误~~ 查看hexo版本信息 创建hexo部署的文件夹，初始化hexo在该目录 成功 安装依赖包 1npm install 生成hexo静态页面 1hexo generate / 或者 hexo g &nbsp;&nbsp;&nbsp;至此，hexo已搭建成功并且能够在本机（linux）访问了；然而，这里是远程连接阿里云的ECS实例，没有图形化界面无法从浏览器直观的看到服务跑起来之后的页面。所以我们需要在自己的电脑从公网访问 http://39.106.15.140:4000 嗯看起来是这样子的，试试把… 无法连接服务器，不对啊，我不是开了服务了嘛！有毒把~(￢︿̫̿￢☆) Steps 4 ： 阿里云ECS云服务器安全组设置呵呵天真，天真的以为开了服务就可以从公网访问了，看看这个。 什么鬼？这是阿里云安全组规则列表，相当于防火墙。从列表看出并没有开放hexo默认的4000，所以外网是访问不到的。 栗子：22/22 代表开放端口的范围是22-22，只开放22号端口的意思，linux默认开放22端口用于ssh远程登陆，这也是可以远程XShell6登陆成功的原因。 知道了原因下面添加一条安全组规则 添加之后记得刷新！ 然后再次访问，会出现hexo默认博客界面了 over~ 0点17了，好怕猝😵�😵，睡了睡了。。。","link":"/2018/06/15/Linux下搭建Hexo博客环境/"},{"title":"IDEA+Maven+Tomcat插件实现热部署","text":"傻了吧唧的其实不是什么大问题，但是这几天脑子有点混乱，情绪很低迷，搞得自己很郁闷。😔切记戒骄戒躁，遇到问题不要心急，静下心来，佛系调bug~~😵 一直都把热部署的概念搞错了，热部署是指项目发布到服务器之后，以不重启服务器为前提本地重新打包发布到服务器上面运行。 说起来很好理解，但是本地tomcat热部署和Maven的Tomcat插件热部署还是有些区别的，一直没走出这个误区，静下心来想下真傻😔 Tomcat本地热部署本地启动服务器，本地重新打包发布，run和redeploy是同一个工具本地启动tomcat服务，不重启服务器的前提下更新war包资源。配置很简单当需要更新资源时点击右上角选择redeploy重新发布即可。 Maven+Tomcat插件热部署不一定是本地启动服务器，本地重新打包发布，run和redeploy不是同一个工具 搞清原理，热部署主要的作用是在不关闭服务器的时候添加或修改项目，tomcat必须要开着，并且保证能访问manager手动管理里面的项目。 就是说插件热部署有一个前提，就是服务器已经在运行，maven的tomcat插件不负责启动服务器，只是负责重新发布到指定的服务器资源中（远程服务器）。 第一步：修改tomcat的conf/tomcat-users.xml配置文件。注意：该tomcat是在本地虚拟机中的，当然也可以本地win开一个添加用户名、密码、权限。 123&lt;role rolename=\"manager-gui\" /&gt;&lt;role rolename=\"manager-script\" /&gt;&lt;user username=\"admin\" password=\"admin\" roles=\"manager-gui, manager-script\"/&gt; 然后 启动Tomcat ，通过CMD或批处理命令或其他工具启动，不要用Tomcat插件启动就行。此时已经可以通过访问 http://192.168.184.130:8080/manager/text 进入tomcat的管理页面发布部署项目了，但是一般不会这么做，我们使用tomcat插件进行热部署。 第二步：配置maven和tomcat关联关系maven当然是在本地开发环境了账号密码同上配置，在maven安装目录中的settings.xml中配置。 1234567&lt;!-- 在&lt;servers&gt;节点下添加 --&gt;&lt;server&gt; &lt;!-- 配置服务器名，maven插件需要引用该插件名 --&gt; &lt;id&gt;tomcat7&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin&lt;/password&gt;&lt;/server&gt; 第三步：pom引入插件1234567891011121314151617181920&lt;build&gt; &lt;plugins&gt; &lt;!-- 配置Tomcat插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;path&gt;/hotDeploy&lt;/path&gt; &lt;port&gt;8080&lt;/port&gt; &lt;!-- 用于配置热部署 --&gt; &lt;url&gt;http://192.168.184.130:8080/manager/text&lt;/url&gt; &lt;server&gt;tomcat7&lt;/server&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin&lt;/password&gt; &lt;update&gt;true&lt;/update&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 第四步：配置好引用本地maven的setting文件 第五步：重新打包发布，实现热部署tomcat已经启动了，这里只重新打包发布.命令：tomcat7:deploy 发布成功： 可算把这个搞清楚了~","link":"/2018/07/29/IDEA-Maven-Tomcat插件实现热部署/"},{"title":"Linux下部署个人站点后的运行问题","text":"Linux下部署个人站点后的运行问题 &nbsp;&nbsp;昨天已经把个人站点部署在linux成功并可以发布运行，有一个问题，就是当退出远程登陆SSH之后，hexo的进程会被杀死导致无法访问，今天早上看了几篇博客之后知道怎么回事了，做一下记录。 1、进程杀死原因1.1、进程与会话 进程组： 一个或多个进程的集合，每一个进程组都有唯一一个进程组ID，即进程组 会话期： 一个或多个进程组的集合，有唯一一个会话期首进程（session leader）。会话期ID为首进程的ID。 控制进程: 与控制终端（如ssh）连接的会话期首进程叫做控制进程。当前与终端交互的进程称为前台进程组， 其余进程组称为后台进程组。 PID = 进程ID （由内核根据延迟重用算法生成）PPID = 父进程ID（只能由内核修改）PGID = 进程组ID（子进程、父进程都能修改）SID = 会话ID（进程自身可以修改，但有限制，详见下文）TPGID= 控制终端进程组ID（由控制终端修改，用于指示当前前台进程组） 关键点：每次用户登陆终端会产生一个会话session，session从登陆开始到结束为止，而这一段时间内在该会话中执行的所有进程都属于本会话。 1.2、挂断信号SIGHUP挂断信号默认操作是终止进程 当终端接口检测到网络连接断开，将挂断信号发送给控制进程（会话期首进程） 如果会话期首进程终止，则该挂断信号发送到该会话期前台进程组. 一个进程退出导致一个孤儿进程组中产生时，如果任意一个孤儿进程组进程处于STOP状态，发送SIGHUP和SIGCONT信号到该进程组中所有进程. 1.3、hexo 进程中断原因： SSH退出连接或因网络问题中断连接，ssh终端检测到连接中断会将挂断信号SIGHUP发送到与终端连接的控制进程。 控制进程被终止了，属于同一个会话期的其他进程也被终止了。 2、解决办法说了那么多，意思就是说ssh 打开以后，bash等都是他的子程序，一旦ssh关闭，系统将所有相关进程杀掉！！ 导致一旦ssh关闭，执行中的任务就取消了。 2.1、nohub命令与&amp;命令作用：后台执行 当平时在终端操作时，不希望运行一个程序占满了屏幕导致无法进行其他操作时，这时候就需要后台运行了。本情形下：退出ssh后希望hexo依然继续工作，也需要后台运行了。 &amp; 命令比如 1hexo s &amp; 虽然前台有打印，但是ctrl+c之后程序并没有退出，依然可以从公网访问。但是有一个弊端就是：当退出控制进程之后该后台进程会被杀死，所以希望退出之后继续运行需要使用 nohup nohup 命令1nohup hexo s &amp; 此时hexo进程已经后台运行了，可以看到一句话“忽略输入并将输出追加到’nohup.out’”，就是说把当前 hexo s 命令的输出文件追加到当前目录的 nohup.out 文件中去了，vim看一下。 可以让程序输入到指定位置 1nohup hexo s &gt;/opt/output/out.file 2&gt;&amp;1 &amp; 什么意思不记录了。 后台运行之后可以通过 jobs 查看当前后台进程，注意：jobs只显示当前会话期的后台进程，如果退出之后是查看不到 hexo的后台进程的，不过可以通过 ps -aux 进程命令查看到。 1ps -aux | grep hexo 当不需要后台运行时 1kill PID 可以发现退出之后jobs是看不到后台进程的. 3、将ip地址映射到域名 &nbsp;&nbsp;这里就需要用到域名的DNS解析了，由于前面已经搭建了放在Github的Hexo环境，自己的 yuzh.xyz 域名DNS解析中 A记录 和 @记录 均指向到了github博客仓库地址 https://github.com/yuzh233/yuzh233.github.io 所对应的ip。所以通过 www.yuzh.xyz 和 yuzh.xyz 是不能够访问 linux下的hexo的。 3.1、 GitHub仓库作为服务器部署办法 修改hexo根目录配置文件 _config.yml 1234567# Deployment## Docs: https://hexo.io/zh-cn/docs/deployment.htmldeploy: type: git # 仓库地址，不是url地址，是拷贝仓库时的地址。 repo: https://github.com/yuzh233/yuzh233.github.io.git branch: master hexo是依据这个部署到git仓库的。 上传到git仓库 先安装上传的插件 1npm install hexo-deployer-git --save 上传命令，每次有更新都需要 “生成 -&gt; 部署” 123hexo cleanhexo generatehexo deploy 绑定域名 该步可以跳过，不过我就是要绑定。 在source文件夹下新建一个名为CNAME的文件，里面写指定的域名 比如 www.yuzh.xyz 添加一条 DNS 解析。添加一条 A 记录和 @ 记录，IP地址填写hexo部署到git的仓库的地址，怎么获取仓库地址对应的ip？ ping yuzh233.github.io 可以得到ip，这里有一个问题，仅仅通过这个ip就访问到了我的仓库吗？为什么不需要设置端口号啊(・∀・(・∀・ ) ，不管了，反正就是访问到了。 然后访问的时候输入 www.yuzh.xyz 或 yuzh.xyz 就到了我的仓库了（设置了解析的结果），我的仓库由于添加了CNAME记录，将仓库的域名指向了文本中的域名了。 3.2、 云ECS linux环境服务器部署办法 首先当然是 linux后台运行hexo s进程了。 然后 ECS 安全组不能把默认4000端口拦截了。 绑定域名 由于一级域名已经被git中的仓库绑定了，这里可以更换DNS解析重新绑定到我的linux主机中，访问方式：www.yuzh.xyz:4000 为什么这里要加端口而绑定到git仓库时却不需要端口呢？鬼知道为什么~ 部署到git的时候通过一个ip直接访问到了仓库地址。但是访问linux主机中的应用本来就是要加端口的。 这里不想更改DNS解析，但是可以使用二级域名解析哦~ 二级域名是免费的 可以设置多个二级域名，指向到不同的主机地址 如： 这样通过 blog.yuzh.xyz:4000可以访问到linux下的hexo环境了。 然而，还是要加个端口号，不想显式加端口，怎么办？—— 使用隐形URL作为解析记录 如此，通过访问 bg.yuzh.xyz 转发到了 blog.yuzh.xyz:4000 再访问到了hexo应用了。 注意：使用隐形URL或显性URL跳转需要备案。备案条件：1.主机在国内 2.ECS租用3个月以上 3.域名已经实名验证","link":"/2018/06/16/Linux下部署个人站点后的运行问题/"},{"title":"dubbo监控中心-dubbo-admin.war的打包和部署","text":"dubbo监控中心-dubbo-admin.war的打包和部署 一个 dubbo-admin.war 的打包从昨晚搞到今天中午，差点没吐出一口老血🤮错误的过程不记录了，都是泪。 Sept 1克隆dubbo源码，地址：https://github.com/apache/incubator-dubbo/tree/dubbo-2.5.4克隆之后看到的： Sept 2接下来，安装所有工程。注意：如果是用IDE克隆下来的，不要直接install，直接安装会进行测试，这里不需要测试，直接使用cmd方式。 12将dubbo的jar安装到本地maven仓库mvn install -Dmaven.test.skip=true 然后，进入到dubbo-admin目录，给dubbo-admin打包 1mvn package -Dmaven.test.skip 然后会在编译后的目录target中看到打包文件： Sept 3理所当然的把 dubbo-admin-2.5.4-SNAPSHOT.war 放在webapps下跑一下试试，还没跑起来启动就报错：信息是“找不到applicationContext.xml”按道理直接拷贝下来的应该不会有问题啊！ 版本有冲突，只好改了，注意：版本控制的模块是 dubbo-parent ，但是在没有发现这个工程目录，怎么改？将根目录导入到IDEA，全部的工程就都导入进来了。 然后修改spring版本为 1&lt;spring_version&gt;3.2.9.RELEASE&lt;/spring_version&gt; 指定注册中心的地址： Sept 4cmd重新编译安装，发布到本地tomcat做测试 可以看到已经是修改后的版本了，启动tomcat。 注意：得先开启zookepper注册中心。 Sept 5部署监控中心到远程服务器，这里以本地linux为例。上传war包： 复制到webapps： 进入到tomcat/bin，启动tomcat： 注意：得先开启zookepper注册中心。 默认root登陆密码是root，guest登陆密码是guest 这里将练习的一个项目发布到了zookeeper，可以看到如下监控信息： 坑安装duboo-admin.war的环境和部署dubbo-admin.war的环境最好保持一致，否则各种问题。本机windows:jdk1.8.0_172+apache-tomcat-8.5.32linux保持一致 参考博客：https://blog.csdn.net/qq_32349641/article/details/52488003","link":"/2018/07/06/dubbo监控中心-dubbo-admin-war的打包和部署/"},{"title":"SpringAop中JoinPoint对象使用时出现的问题","text":"介绍不写了，API也不写了，记录问题解决。 切面类： 123456789101112131415161718192021222324252627282930313233package xyz.yuzh.aspect;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.AfterReturning;import org.aspectj.lang.annotation.Aspect;import org.springframework.stereotype.Component;/** * 日志切面 * * @Author: z.yu * @Date: 2018/06/19 20:35 */@Aspect@Componentpublic class LogAspect { /** * 如果代理Handler，该Handler不能继承类。 */ @AfterReturning(pointcut = \"execution(* xyz.yuzh.service.*.*(..))\") public void log(JoinPoint point) { Object[] args = point.getArgs(); for (Object a : args) { System.out.println(\"入参数 -&gt; \" + a + \",\"); } System.out.println(\"方法签名：\" + point.getSignature()); System.out.println(\"目标对象：\" + point.getTarget()); System.out.println(\"代理对象：\" + point.getThis()); System.out.println(\"-----------------------\"); }} 1、 自动代理aop的配置需要写在 spring.xml 中，因为 spring-mvc.xml 配置成只扫描的到 handler，spring.xml才能扫描到其他Component（如切面类：LogAspect）。 true代表CGLIB动态代理 false代表JDK动态代理（默认） 1&lt;aop:aspectj-autoproxy proxy-target-class=\"false\"&gt;&lt;/aop:aspectj-autoproxy&gt; 2、 使用 @AfterReturning时，如果指定了返回值，那么目标方法有返回值的才会匹配的到1234@AfterReturning(pointcut = \"execution(* xyz.yuzh.service.*.*(..))\",returning = \"returnValue\")public void log2(JoinPoint point,Object returnValue) { //...} 3、目标方法如果是继承或实现得到的，是代理不到的，除非覆盖其父级方法。4、如果目标方法是 Handler中的方法，没有被代理到？ web容器加载顺序：ServletContext -&gt; context-param -&gt; listener-&gt; filter -&gt; servlet 首先一点：spring的Bean和springMVC的Bean所在的上下文是不同的 前面切入点在service层时，自动代理 &lt;aop:aspectj-autoproxy/&gt; 配置到spring.xml，即这里的bean是可以被代理到的。serviceBean被spring.xml扫描到，LogAspect作为切面才会生效。 @Component 作为spring容器中的bean被加载到了。 @Aspect 施加了该注解的spring容器的bean的切面应用成功。 代理handler中的方法步骤： &lt;aop:aspectj-autoproxy/&gt; 放到spring-mvc.xml ，该配置文件才是扫描handler的。 手动创建bean -&gt; &lt;bean id=&quot;logAspect&quot; class=&quot;xyz.yuzh.aspect.LogAspect&quot;&gt;&lt;/bean&gt;，因为扫描不到。 移除LogAspect的@Component注解，因为已经手动创建了，重复创建可能会出现错误。 good night(￣o￣) . z Z","link":"/2018/06/19/SpringAop中JoinPoint对象使用时出现的问题/"},{"title":"spring与aspectJ版本冲突问题","text":"版本冲突真是让人脑阔疼。用这个 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;4.2.7&lt;/version&gt;&lt;/dependency&gt; 代替这个 12345678910&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.8.7&lt;/version&gt;&lt;/dependency&gt; maven会自动处理spring与aspect的依赖关系。依赖了 aspectwearer.jar，没有引用 aspectjrt.jar 但是也可以用，主要是可以看到aspect的版本号，以便于手动加入想要的aspect包。","link":"/2018/06/19/spring与aspectJ版本冲突问题/"},{"title":"分布式技术入坑指南（五）","text":"13.网页静态化之FreeMarker14.反向代理/负载均衡服务器：Nginx 网页静态化 什么是静态化？通过一些技术手段（Freemarker/valocity）将动态的页面（jsp,asp.net,php) 转换成静态的页面，通过浏览器直接访问静态页面。为什么要静态化？ 通过浏览器直接访问静态的页面,不需要经过程序处理，它的访问速度高。稳定性好。 更有效的防止安全漏洞问题，比如不易遭受黑客攻击。 静态的页面更容易被搜索引擎收录。 更多概念见笔记文档，快速入门及整合Spring访问项目学习仓库地址：https://github.com/yuzh233/FreeMarker 反向代理/负载均衡Nginx应用场景 http服务器Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。虚拟主机可以实现在一台服务器虚拟出多个网站。例如个人网站使用的虚拟主机。反向代理，负载均衡当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群时可以使用nginx做反向代理。并且多台服务器可以平均分担负载，不会因为某台服务器负载高宕机而某台服务器闲置的情况。 安装及编译步骤见笔记文档 Nginx配置虚拟主机通过端口区分…/nginx/conf/nginx.conf中配置以下节点 123456789101112131415161718192021222324252627# 一个server节点就是一个虚拟主机server { # 第一个web应用的端口 listen 80; # 所在地址 server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { # Html是nginx安装目录下的html目录，也是该应用的静态资源文件存放的根目录 / root html; index index.html index.htm; }}# 第二台虚拟主机server { # 第二个web应用的端口 listen 81; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { # 第二个web应用的资源文件放在html-81中，访问的时候 / 代表该目录 root html-81; index index.html index.htm; }} 修改配置重新加载 ./nginx -s reload ，无需重启。访问第一个web服务：http://localhost:80访问第二个web服务：http://localhost:81其实就是充当了tomcat. 通过域名区分域名概念：略略略域名访问流程：略略略配置方式：…/nginx/conf/nginx.conf 中 123456789101112131415161718192021222324# 前面已经有一个虚拟主机用了这个端口，删了。这是第一个虚拟主机server { listen 80; # 域名 server_name www.taobao.com; #charset koi8-r; #access_log logs/host.access.log main; location / { root html-taobao; index index.html index.htm; }}# 第二个虚拟主机server { listen 80; # 域名 server_name www.baidu.com; #charset koi8-r; #access_log logs/host.access.log main; location / { root html-baidu; index index.html index.htm; }} 修改本机host文件才能访问伪域名 nginx服务器IP：www.taobao.com nginx服务器IP：www.baidu.com 其实访问的都是同一个应用。 Nginx配置反向代理正向代理：反向代理 反向代理服务器决定哪台服务器提供服务。 反向代理服务器不提供服务器。也只是请求的转发。 实现反向代理两个域名指向同一台nginx服务器，用户访问不同的域名显示不同的网页内容。配置：两只猫、两个域名、一个nginx服务器。 12345678910111213141516171819202122232425262728293031323334# 反向代理服务器下的第一个服务器upstream tomcat1 { # 访问该服务器的ip及端口 server 192.168.184.130:8080;}server { # 默认监听80端口，这样就不需要指定端口访问。 listen 80; # 用户访问时的域名。 server_name www.sina.com.cn; #charset koi8-r; #access_log logs/host.access.log main; location / { # nginx通过前面的tomcat1转发到指定的网站，访问tomcat1就是访问192.168.25.148:8080 proxy_pass http://tomcat1; index index.html index.htm; }}# 反向代理服务器下的第二个服务器upstream tomcat2 { # 访问该服务器的ip及端口 server 192.168.184.130:8081;}server { listen 80; server_name www.sohu.com; #charset koi8-r; #access_log logs/host.access.log main; location / { proxy_pass http://tomcat2; index index.html index.htm; }} Nginx配置负载均衡一个服务由多台服务器提供，需要把负载分配到不同的服务器处理。负载均衡的策略: 默认轮询，即一个一个轮着来 分配权重 server 192.168.25.148:8082 weight=2; ,weight代表权重 通过IP地址的hash值 做映射 通过URL的方式计算出Hash值 随机策略 最少并发量。 12345678910111213141516171819# 反向代理服务器下的第三个服务器，用于测试Nginx负载均衡upstream tomcat3 { # 假如该WEB服务下有多个服务器提供 server 192.168.184.130:8080; server 192.168.184.130:8081;}server { # 默认监听80端口，这样就不需要指定端口访问。 listen 80; # 用户访问时的域名。 server_name www.yuzhtest.xyz; #charset koi8-r; #access_log logs/host.access.log main; location / { # nginx通过前面的tomcat1转发到指定的网站，访问tomcat1就是访问192.168.25.148:8080 proxy_pass http://tomcat3; index index.html index.htm; }}","link":"/2018/07/26/分布式技术入坑指南（五）/"},{"title":"分布式技术入坑指南（六）","text":"15. SSO单点登陆系统搭建模块划分： sso.taotao.interface sso.taotao.service sso.taotao.web 两个问题： 不同域名之间Cookie是不能共享的，这也意味着用户在 sso.taotao.com 系统登陆之后，跳转到 taotao.com 后记录用户登陆凭证(token)的Cookie不存在，访问某些个人信息时提示重新登陆。 不同域名之间的跨域请求是不会返回数据的，比如 item.taotao.com 下一个订单需要发送一个请求到 sso.taotao.com 校验当前用户是否登陆，请求发送成功并且会被处理，但是数据是返回不到 item.taotao.com 系统的。 解决办法： 设置Cookie的doMain属性 以JSONP的方式请求获得数据 Cookie跨域学习cookie的两个属性： pathpath属性是设置cookie存在的路径的，比如在当前目录下存入了一个cookie，那么该目录及子目录下的所有资源请求都能查看到这个cookie，但是父级目录是看不到的。 * 设置 path=“/” ,即cookie可被站点根目录下所有文件访问到。 * 设置 path=“/AAA/” ,即cookie可被站点根目录下的AAA目录下的所有文件访问到。 domain前面实现了cookie同域之间的访问，但在分布式系统中，跨域访问频繁，怎么做到跨域访问cookie不丢失呢？比如在 sso.taotao 登陆之后用户的token存入浏览器，想要在 order.taotao.com 系统中获取这个token，需要存放cookie的时候设置domain属性： domain=“taotao.com” 跨域访问前提是域名之间具有相同部分，一般是二级域名之间的访问。 参考博客：https://www.cnblogs.com/st-leslie/p/5720460.html JSONP JSONP与JSON不是一回事JSON是一种数据交换格式，而JSONP是一种非官方跨域数据交互协议 Ajax： 123456789101112131415161718192021&lt;html&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;jsonp&lt;/title&gt; &lt;script type=\"text/javascript\" src=\"jquery-1.6.4.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; $(document).ready(function(){ $.ajax({ type:\"get\", url:\"local.js\", // url:\"http://192.168.184.130:82/remote.js\", dataType:\"json\", success:function(json){ alert(json.data); } }); }); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; local.js 1{data:\"local\"} 结果是可以请求到本地json数据，但是当访问远程的remote.js时资源无法访问😔 值得庆幸的是：在Web页面调用Js文件却不受跨域的影响，注意：不是ajax请求，凡是通过有src属性的标签调用跨域资源都是不受影响的，比如&lt;script&gt;标签 既然能够远程调用js文件，那么怎么获取文件中的数据为我所用呢？其实很简单。 测试：本地一个方法要获得远程的json数据： 1234567&lt;script type=\"text/javascript\"&gt; //回调方法 function method(json){ alert(json.data); }&lt;/script&gt;&lt;script type=\"text/javascript\" src=\"http://192.168.184.130:82/remote.js\"&gt;&lt;/script&gt; remote.js 12/*远程js中调用*/method({data:\"remote\"}) 其实就是远程的js中调用了本地所需要数据的回调方法。 同样的道理，在Ajax请求中，跨域请求一个url，我们要求控制器返回的数据格式为：callbackMethod(jsonStr)，也就是对返回的json包裹一个前台js的回调方法名称。我们需要做的：1. 告诉控制器回调方法叫什么； 2.在回调方法写获得数据后的逻辑，而控制器返回json的同时回调了该方法。 知道原理，异步请求跨域数据的方法应该这么写： 12345678910111213141516171819&lt;html&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;jsonp&lt;/title&gt; &lt;script type=\"text/javascript\" src=\"jquery-1.6.4.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; //回调方法 function callbackMethod(json){ alert(json.data); } //通过标签调用json数据 var url = \"http://192.168.184.130:82/remote.js\"; var script = document.createElement('script'); script.setAttribute('src', url); document.getElementsByTagName('head')[0].appendChild(script); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; Jquery对JSONP实现了封装，自动生成了回调函数并取出数据给success方法调用： 1234567891011121314151617181920212223&lt;html&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;jsonp&lt;/title&gt; &lt;script type=\"text/javascript\" src=\"jquery-1.6.4.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; $(document).ready(function(){ $.ajax({ type:\"get\", url:\"http://192.168.184.130:82/remote.js\", dataType:\"jsonp\", //下面两行可不写，意思就是 http://192.168.184.130:82/remote.js?callback=callbackMethod，不写会自动生成。 jsonp: \"callback\", jsonpCallback:\"callbackMethod\", success:function(json){ alert(json.data); } }); }); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 参考博文：https://www.cnblogs.com/dowinning/archive/2012/04/19/json-jsonp-jquery.htmlhttps://www.cnblogs.com/JinQuanLi/p/6551415.html 注册登陆业务实现sso-interface定义注册登陆的接口 根据参数和类型来校验参数； 注册用户； 根据用户名和密码登录； 根据token获取用户的信息； 用户登出 sso-service登陆逻辑： 校验数据； 与数据库对比，如果成功将密码设为null，要求存入redis中的用户对象不保存密码； 随机生成用户Token，传给controller，用于创建cookie； 模拟Session。以key=XXX:Token，value=用户对象Json字符串存入Redis，设置Redis中的key过期时间 校验用户的Token是否存在： 根据token拼接Redis中的Key，查找Redis中是否存在对应的value； 如果查到，返回用户对象，重新设置Redis中key的过期时间； 未查到，返回错误 发布服务，以便其他系统调用 sso-web登陆逻辑： 调用服务，接收用户登陆后的Token 创建Cookie（跨域），key为指定标识符，value=token，设置cookie的过期时间（模拟session） 校验用户的Token是否存在：可能会存在其他系统跨域调用本控制器检查用户是否登陆，本系统中跨域请求使用JSONP的方式，因此方法签名应提供一个callback的参数，用来以方法名包裹返回Json的数据。 判断是否是JONSP请求，如果是：调用服务检测Redis是否存在token返回检测结果，并用函数名包裹json数据； 如果不是，调用服务正常返回json数据 访问认证以拦截器形式实现 依赖sso-service、sso-web工程 从cookie中取token。 没有token，需要跳转到登录页面。 有token。调用sso系统的服务，根据token查询用户信息。 如果查不到用户信息。用户登录已经过期。需要跳转到登录页面。 查询到用户信息。放行。 方案一：拦截器写在sso-web中，其他系统依赖sso-web工程，mvc配置文件配置Interceptor的类在sso-web工程中，优点是不需要每个系统都写拦截器，只需要配置，缺点是拦截条件不方便定制。 方案一：每个系统实现自己的拦截器，调用sso-service服务进行校验用户token。 可把我累坏了🤮","link":"/2018/07/27/分布式技术入坑指南（六）/"},{"title":"单例设计模式","text":"单例设计模式，即某个类在整个系统中只能有一个实例对象可被获取和使用的代码模式。例如：代表JVM运行环境的Runtime类 要点： 某个类只能有一个实例； 构造器私有化 是它必须自行创建这个实例； 含有一个该类的静态变量来保存这个唯一的实例 是它必须自行向整个系统提供这个实例; 对外提供获取该实例对象的方式：（1）直接暴露（2）用静态变量的get方法获取 饿汉式直接创建对象，不存在线程安全问题 缺点：不管是否需要这个对象，都会创建。 方式1：直接实例化饿汉式好处：简洁直观，外部可以直接获取这个实例。 1234567public class Singleton1 { public static final Singleton1 SINGLETON = new Singleton1(); private Singleton1(){ }} 方式2：枚举式最简洁的方式：枚举类型，表示该类型的对象是有限的几个，我们可以限定为一个，就成了单例。 123public enum Singleton2 { SINGLETON} 方式3：静态代码块饿汉式适合在实例化时需要进行复杂的初始化操作时使用，比如初始化实例时需要加载配置文件中的参数作为实例变量。 12345678910111213141516171819202122232425262728293031public class Singleton3 { private static Singleton3 SINGLETON; private String info; static{ Properties properties = new Properties(); try { // 配置文件加载之后会在编译目录里面，通过获取字节码加载器对象取到编译目录中的文件。 properties.load(Singleton3.class.getClassLoader().getResourceAsStream(\"xyz/yuzh/interview/singleton/info.properties\")); } catch (IOException e) { } SINGLETON = new Singleton3(properties.getProperty(\"info\")); } private Singleton3(String info){ this.info = info; } public static Singleton3 getInstance(){ return SINGLETON; } @Override public String toString() { return \"Singleton3{\" + \"info='\" + info + '\\'' + '}'; }} 懒汉式延迟创建对象 方式1：线程不安全单线程下是线程安全的，但是多线程下是不安全的。 123456789101112public class Singleton4 { private static Singleton4 singleton; private Singleton4() { } public static Singleton4 getInstance() { if (singleton == null) { singleton = new Singleton4(); } return singleton; }} 用例： 123456789101112131415161718192021222324public class Singleton4Test { public static void main(String[] args) throws ExecutionException, InterruptedException { /*Callable&lt;Singleton4&gt; callable = new Callable&lt;Singleton4&gt;() { @Override public Singleton4 call() throws Exception { return Singleton4.getInstance(); } };*/ Callable&lt;Singleton4&gt; callable = () -&gt; { return Singleton4.getInstance(); }; ExecutorService es = Executors.newFixedThreadPool(5); Future&lt;Singleton4&gt; future1 = es.submit(callable); // 提交一个任务 Future&lt;Singleton4&gt; future2 = es.submit(callable); // 再提交一个任务 es.shutdown(); Singleton4 s1 = future1.get(); Singleton4 s2 = future2.get(); System.out.println(s1 == s2); }} 结果： false 方式2：线程安全123456789101112131415161718public class Singleton5 { private static Singleton5 singleton; private Singleton5() { } public static Singleton5 getInstance() { if (singleton == null) { synchronized (Singleton5.class) { if (singleton == null) { singleton = new Singleton5(); } } } return singleton; }} 方式3：静态内部类形式，线程安全最简洁的方式，在内部类被加载和初始化时，才创建 SINGLETON 实例对象。静态内部类不会自动随着外部类的加载和初始化而初始化，它是要单独去加载和初始化的。因为是在内部类加载和初始化时，创建的，因此是线程安全的 12345678910111213public class Singleton6{ private Singleton6() { } public static class Inner{ private static final Singleton6 SINGLETON = new Singleton6(); } public static Singleton6 getInstance(){ return Inner.singleton; }}","link":"/2018/10/30/单例设计模式/"},{"title":"如何给通过脚本添加的 元素注册事件","text":"前端弱渣，记录一下问题解决： 1234// 事件冒泡：给动态添加的 html 元素注册事件$(\"body\").on(\"click\", \".blog-edit-user\", function () { // .blog-edit-user 是需要被注册事件的元素标签} 参考：https://www.jb51.net/article/120018.htm","link":"/2018/10/13/如何给通过脚本添加的 元素注册事件/"},{"title":"成员变量与局部变量","text":"12345678910111213141516171819202122232425public class Demo1 { static int s; int i; int j; { int i = 1; i++; j++; s++; } public void test(int j) { j++; i++; s++; } public static void main(String[] args) { Demo1 obj1 = new Demo1(); Demo1 obj2 = new Demo1(); obj1.test(10); obj1.test(20); obj2.test(30); System.out.println(obj1.i + \",\" + obj1.j + \",\" + obj1.s); System.out.println(obj2.i + \",\" + obj2.j + \",\" + obj2.s); }} 执行结果： 2,1,5 1,1,5 考点： 就近原则 变量的分类 成员变量：类变量、实例变量 局部变量 非静态代码块的执行：每次创建实例对象都会执行 方法的调用规则：调用一次执行一次 局部变量与成员变量的区别： 值存储的位置 局部变量：栈 实例变量：堆 类变量：方法区，与类相关联，仅存一份 作用域 局部变量：从声明处开始，到所属的 } 结束 实例变量：在当前类中“this.”(有时this.可以缺省)，在其他类中“对象名.”访问 类变量：在当前类中“类名.”(有时类名.可以省略)，在其他类中“类名.”或“对象名.”访问 生命周期 局部变量：每一个线程，每一次调用执行都是新的生命周期 实例变量：随着对象的创建而初始化，随着对象的被回收而消亡，每一个对象的实例变量是独立的 类变量：随着类的初始化而初始化，随着类的卸载而消亡，该类的所有对象的类变量是共享的 分析： 一、运行 main 方法，开始执行类初始化方法&lt;clinit&gt;()，该方法由静态类变量显示赋值代码、静态代码块组成，在此用例中，只有静态变量赋值语句：static int s; 类变量 s 存在于方法区中，该类的所有实例共享这一份变量 此时 s = 0 二、line1： Demo1 obj1 = new Demo1(); 创建实例，执行 &lt;init&gt;()，该方法由非静态变量显示赋值代码、非静态代码块、构造器组成，此用例中根据顺序先执行非静态变量显示赋值代码，然后执行非静态代码块，构造器无赋值语句可忽略。创建 obj1 对象，在堆中开辟了一份 obj1 实例的内存空间，保存着 i、j 两个实例变量 非静态变量显示赋值代码执行后： obj1.i = 0 obj1.j = 0 -------------------------- 非静态代码块执行后： // i 还是为0，根据就近原则，非静态代码块中的自增的变量 i 不是实例变量i，而是局部变量i，代码块结束之后该变量消亡 obj1.i = 0 obj1.j = 1 Demo.s = 1 // 共享变量，类变量 三、line2： Demo1 obj2 = new Demo1(); 创建实例，执行 &lt;init&gt;() 后,实例变量和 obj1 一样，但是类变量发生变化 obj2.i = 0 obj2.j = 1 Demo.s = 2 // 由于是共享变量，此时类变量递增为2 四、line3： obj1.test(10); main 方法传了形参 10 的值给 test 方法，JVM 为 test() 在栈中开辟了一个空间存储局部变量 j ,由于未指明自增的 j 是哪个变量，根据就近原则，给局部变量 j 自增为 11，然后再给obj1的其他实例变量赋值 obj1.i = 1 // 自增1 obj1.j = 1 // 自增的局部变量j，要想指定自增实例变量，可以通过指定 this.j++ Demo.s = 3 // 继续自增 五、line4： obj1.test(20); obj1.i = 2 obj1.j = 1 Demo.s = 4 六、line5： obj2.test(30); obj2.i = 1 obj2.j = 1 Demo.s = 5 每创建一个Demo的实例，就会在堆中开辟新的这个该对象实例的变量空间，不同实例变量之间互不影响，随着实例的回收而消亡，但是类变量是独有一份的，每个实例操作的是同一份。故此时 obj1 和 obj2 的输出： obj1.i = 2 obj1.j = 1 obj1.s = 5 // 类变量也可以通过实例引用调用 obj2.i = 1 obj2.j = 1 obj2.s = 5","link":"/2018/11/03/成员变量与局部变量/"},{"title":"数据库常用事务传播行为与隔离级别","text":"事务传播行为当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。例如：方法可能继续在现有事务中运行，也可能开启一个新的事务，并在自己的事务中运行。 事务传播行为由事务传播属性指定，以下是 Spring 支持的 7 种传播行为： 传播属性 描述 REQUIRED* 如果由事务在运行，当前的方法就在这个事务内运行。否则，就开启一个新的事务，并在自己的事务中运行。 REQUIRES_NEW* 当前方法必须启动新事务，并在自己的事务中运行。如果有事务正在运行，将该事务挂起。 SUPPORTS 如果有事务在运行，当前的方法就在这个事务中运行。否则它可以不运行在事务中。（有事务环境可以运行在事务，没有也行） NOT_SUPPORT 当前的方法不应该运行在事务中，如果有运行的事务，将它挂起。 MANDATORY 当前方法必须运行在事务内部，如果没有正在运行的事务，就抛出异常。 NERVER 当前的方法不应该运行在事务中，如果有运行的事务，就抛出异常。 NESTED 如果有事务在运行，当前的方法就应该在这个事务的嵌套事务中运行。否则，就开启一个新的事务，并在它自己的事务内运行。 [ 模拟一个事务方法调用另一个事务方法 ] 123456789101112131415161718192021222324@Service(\"userService\")public class UserServiceImpl{ @Autowired BookService bookService; @Transactional(propagation = Propagation.REQUIRED) // 默认值 public void buyBooks(int userId, int[] booksId){ for(int bookId : booksId){ bookService.pay(userId, bookId); } }}@Service(\"bookService\")public class BookServiceImpl{ @Transactional public void pay(int userId, int bookId){ // TODO 查询图书实体 // TODO 查询用户实体 // TODO 减少库存 // TODO 减少账户余额 }} 上面的伪代码意思是用户调用事务方法：buyBooks() 购买多本图书，buyBooks() 多次调用事务方法：pay()。默认情况下，两个方法的传播行为都是 REQUIRED,即： 虽然pay()自带事务，但是不起作用，因为调用方buyBooks()本身是事务方法，所以共用一个事务。 考虑这样一种情况：假如用户需要购买两本书，当 buyBooks() 第一次正常调用 pay() 后，库存减少一本书，用户余额减少对应的书的价格。但是第二次调用 buyBooks() 时发生异常：用户余额不足以购买第二本书，数据库回滚。此时用户是购买了一本书成功？还是两本书购买都没成功？ 当传播行为是 REQUIRED 时：两本书都购买失败。尽管第一本书购买成功了，但是第二次购买还是在 buyBooks() 方法发生的，pay() 并没有起作用，所以事务一起失败。 当传播行为是 REQUIREDS_NEW 时：第一本书购买成功，第二本书购买失败。buyBooks() 方法处在一个事务环境中，pay() 也处在自己的事务环境中，当 buyBooks() 执行到调用 pay() 时，当前的事务会挂起，去执行完毕 pay() 的事务之后再继续执行自己的事务。注意：buyBooks() 方法中除了 pay() 不受自己的事务控制之外，其他代码仍处于自己的事务环境之中。 事务隔离级别事务隔离控制一般应用在多线程并发访问操作数据库的时出现的并发问题上 数据库并发问题假设现有两个事务：Transactional-1 和 Transactional-2 并发执行。 脏读 Transactional-1 将某条记录的 age 值从 20 修改为 30。（未提交） Transactional-2 读取了 Transactional-1 更新后的值：30。 Transactional-1 回滚，age 值回到了 20。 Transactional-2 读到的 30 就是一个无效的值。（读到了其他事务更新但未提交的值） 不可重复读 Transactional-1 读取了 age 的值为 20。（读取无需事务） Transactional-2 将 age 的值修改为 30。（已提交） Transactional-1 再次读取 age 的值为 30，和第一次读取的不一致。 幻读 Transactional-1 读取了 student 表中的一部分数据。 Transactional-2 向 student 表中插入了新的行。 Transactional-1 读取 student 表时，多出了新的行。 隔离级别隔离级别越高，数据一致性越好。并发性能越弱。 读未提交：READ UNCOMMITTED 允许 Transactional-1 读取 Transactional-2 未提交的修改。 读已提交：READ COMMITTED 一般设置这个级别 要求 Transactional-1 只能读取 Transactional-2 已提交的修改 可重复度：REPEATABLE READ 确保 Transactional-1 可以多次从一个字段中读取相同的值，即：Transactional-1 执行期间禁止其他事务对这个字段更新。（可理解为行锁） 串行化：SERIALIZABLE 确保 Transactional-1 可以多次从一个表读取到相同的行，在 Transactional-1 执行期间禁止其他事务对这个表进行添加、更新、删除操作。可以避免任务并发问题，但性能下降。（可理解为表锁）","link":"/2018/11/04/数据库常用事务传播行为与隔离级别/"},{"title":"方法的参数传递机制","text":"1234567891011121314151617181920212223242526272829public class Demo1 { public static void main(String[] args) { int i = 1; String str = \"hello\"; Integer num = 200; int[] arr = {1, 2, 3, 4, 5}; MyData my = new MyData(); change(i, str, num, arr, my); System.out.println(\"i = \" + i); System.out.println(\"str = \" + str); System.out.println(\"num = \" + num); System.out.println(\"arr = \" + Arrays.toString(arr)); System.out.println(\"my.a = \" + my.a); } public static void change(int j, String s, Integer n, int[] a, MyData m) { j += 1; s += \"world\"; n += 1; a[0] += 1; m.a += 1; }}class MyData { int a = 10;} 运行结果 i = 1 str = hello num = 200 arr = [2,2,3,4,5] my.a = 11 考点： 方法的参数传递机制 String、Integer 等包装类的不可变性 方法传递机制： 基本数据类型是值传递 引用类型是地址值传递 特殊类型如 String、包装类等对象不可变 分析： 方法中的变量称为局部变量，每个方法在栈中有属于自己的方法区，局部变量存在自己的方法区。change() 方法执行之前，内存结构简单如下： 执行 change() 方法，参数传递代码执行之前： change() 方法执行完毕： change() 执行之后，change 方法区被释放，观察 main 方法区的箭头指向： i 只是将值复制了一份给 j，本身的值没变 str 代表的 “hello” 这一份常量，由于 String 不可变性，change 对这个常量拼接形成了新的常量，但是 str 指向的还是原来的 “hello” num 是 Integer 不可变类型，在堆中也创建了另外一份变量，本身没变 arr 是基本数据类型，值被改变 m 是引用类型，change 中保存了这个引用，并将实例变量 a 改变了","link":"/2018/10/30/方法的参数传递机制/"},{"title":"树的三种遍历方式","text":"以上是一个树结构，我们需要以三种不同的方式遍历它，先创建树的节点对象： 12345678910111213141516171819/** * 树节点 * * @author yu.zh [yuzh233@gmail.com] * @date 2018/11/08 */public class TreeNode { private String value; private TreeNode leftNode; private TreeNode rightNode; public TreeNode(String value) { this.value = value; this.leftNode = null; this.rightNode = null; } // getter and setter} 再构建一棵树： 1234567891011121314151617181920212223242526272829303132/** * 创建一个树结构 * * @author yu.zh [yuzh233@gmail.com] * @date 2018/11/08 */public class TreeCreator { private TreeCreator() { } public static TreeNode getInstance() { return TreeCreatorFactory.root; } public static class TreeCreatorFactory { private static TreeNode root; static{ root = new TreeNode(\"A\"); // 一级节点 root.setLeftNode(new TreeNode(\"B\")); root.setRightNode(new TreeNode(\"C\")); // 二级节点 root.getLeftNode().setLeftNode(new TreeNode(\"D\")); root.getLeftNode().setRightNode(new TreeNode(\"E\")); root.getRightNode().setRightNode(new TreeNode(\"F\")); // 三级节点 root.getLeftNode().getRightNode().setLeftNode(new TreeNode(\"G\")); } }} 前序遍历前序遍历思想是先遍历父节点，再遍历左子节点，最后遍历右子节点。分析上面的树结构： 先打印 A； A有左子节点和右子节点，先打印左子节点 B；（前序遍历先求父节点，不管B有没有子节点都会先遍历自己） B有左子节点和右子节点，先打印左子节点 D； D没有子节点，看父节点B的右子节点，打印 E。 节点E有左子节点，打印 G A的左子节点执行完毕，执行右子节点C，打印 C C没有左子节点，有右子节点，打印 F 中序遍历中序遍历思想是先遍历左子节点，再遍历父节点，最后遍历右子节点。分析上面的树结构： A有左子节点B，B有子节点D，D没有子节点，打印 D （中序遍历先遍历左子节点再遍历父节点，所以需要往下递归直到没有子节点为止。） D节点的父节点是B，打印 B B的右子节点是E，E有子节点G，根据中序规则，先打印 G 再打印 E B的父节点是A，打印 A A右节点是C，C没有左子节点，于是打印自己 C C的右子节点是F，打印 F 后序遍历中序遍历思想是先遍历左子节点，再遍历右子节点，最后遍历父节点。分析上面的树结构： A有左子节点B，B有子节点D，D没有子节点，打印 D （后序遍历最后才遍历父节点，有子节点需要一直递归下去直到没有子节点。） D有兄弟节点E，但是E也有子节点，先打印E的子节点 G G打印完了，没有兄弟节点，打印父节点 E D和E都执行完了，打印他们的父节点 B B有兄弟节点C，C有子节点F，打印 F C的子节点都打印完了，打印自己 C A的B和C都打印完了，打印自己 A 后序遍历方式常用作简易的计算器处理，如我的算法笔记： 补全表达式转为中序表达式 中序表达式转后序表达式 后序表达式求值实现简单计算器","link":"/2018/11/08/树的三种遍历方式/"},{"title":"根据树的前序和后序表达式构造唯一树","text":"原题是“根据树的前序和后序表达式求中序表达式”，构造出了树求中序表达式还是问题吗？ 构造树是需要一定技巧的，需要不断的递归分析。将大规模分为小规模，将每个小规模再细分，直到不可再分，树也就构建好了。就跟 归并排序 一样 前序和中序分别是： pre: A B D E G C F on: D B G E A C F 分析（选择题）从前序表达式入手：我们知道前序遍历的第一个节点是根节点，由此确定 A 就是根节点 再来看中序表达式，根据中序表达式规则，先遍历左子节点，再遍历父节点，再遍历右子节点，我们可以确定 A 左边的都是左子树，右边的都是右子树。 在 on 中看得出 A 的左子树个数是 4，于是我们可以在 pre 中定位 A 的左子树和右子树： A 的左子树前序序列是 B D E G，右子树前序序列是 C F，根据前序表达式规则，每一个序列的第一个是整个序列的根节点，于是可以推断出 A 的左子树的根节点和右子树的根节点分别是 B、C 循环上面的的方法，分析 B 的左子树。（右子树暂时不管，等左子树分析完毕之后再分析。） pre: B D E G on: D B G E 由 B 的左边只有 D 可推导出 D 是 B 的左子树，并且是唯一节点。E 是 B 的右子树的根节点。 然后推断 B 的右子树 pre: E G ——&gt; （序列的第一个是头，因为总是从头先遍历）E 是 G 的父节点 on: G E ——&gt; “左、父、右” 推导出 G 是 E 的左子节点 至此，根节点 A 的左子树有了归宿，现在分析右子树： pre: C F ——&gt; C 是 F 的头节点 on: C F ——&gt; “先左再头再右” 推导出 F 是 C 的右子节点 所以它的后序表达式是：DGEBFCA 归纳 对于一串前序表达式和中序表达式，我们总是先取前序表达式的第一个节点，因为它是头。 再根据这个头在中序中的位置来 划分 头的左子树和右子树，根据中序中的左子树和右子树的个数在前序中确定左子树范围和右子树范围。 每一个范围的序列都有前序表达式和中序表达式，循环调用步骤 1 ，直到序列只有一个。 代码实现（编程题）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class TreeTraversal { /** * 根据前序和中序表达式构建树 */ public static TreeNode createTreeByPreOrderAndInOrder(String preOrder, String inOrder) { if (preOrder.isEmpty()) { return null; } char root = preOrder.charAt(0); // 获取前序的第一个字符 int rootIndex = inOrder.indexOf(root); // 获取根节点在中序中的位置 TreeNode rootNode = new TreeNode(preOrder.substring(0, 1)); // 创建根节点 int leftCount = rootIndex; // 根节点的左子树的中序表达式字符数量 // 递归构建左子树 rootNode.setLeftNode(createTreeByPreOrderAndInOrder( preOrder.substring(1, leftCount + 1), // 截取前序表达式中 根节点 左边的字符串 inOrder.substring(0, leftCount)) // 截取中序表达式中 根节点 左边的字符串 ); // 递归构建右子树 rootNode.setRightNode(createTreeByPreOrderAndInOrder( preOrder.substring(leftCount + 1), // 截取前序表达式中 根节点 右边的字符串 inOrder.substring(leftCount + 1) // 截取前序表达式中 根节点 右边的字符串 )); return rootNode; } public static void main(String[] args) { // 构造树 TreeNode root = TreeCreator.getInstance(); System.out.print(\"pre: \\t\"); preOrder(root); System.out.println(); System.out.print(\"in: \\t\"); inOrder(root); System.out.println(); System.out.print(\"post: \\t\"); postOrder(root); // 根据前序和中序求后序 System.out.println(\"\\n---------- createTreeByPreOrderAndInOrder ----------\"); TreeNode rootNode = createTreeByPreOrderAndInOrder(\"ABDEGCF\", \"DBGEACF\"); postOrder(rootNode); }}","link":"/2018/11/08/根据树的前序和后序表达式构造唯一树/"},{"title":"源码角度分析 CharacterEncodingFilter 解决 Post 请求中文乱码问题","text":"Post 乱码Spring MVC 提供 CharacterEncodingFilter 拦截请求处理编码格式问题12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package org.springframework.web.filter;public class CharacterEncodingFilter extends OncePerRequestFilter { private String encoding; // 指定的编码格式 private boolean forceRequestEncoding = false; // 是否设置请求编码格式 private boolean forceResponseEncoding = false; // 是否设置响应编码格式 public CharacterEncodingFilter() { } /** * xml配置：一般只需要设置编码格式即可，默认支持请求编码转换 */ public CharacterEncodingFilter(String encoding) { this(encoding, false); } /** * 也可以设置指定编码 and 是否设置请求和响应的编码转换 */ public CharacterEncodingFilter(String encoding, boolean forceEncoding) { this(encoding, forceEncoding, forceEncoding); } /** * 设置指定编码 and 单独设置是否进行请求编码转换 或 响应的编码转换 */ public CharacterEncodingFilter(String encoding, boolean forceRequestEncoding, boolean forceResponseEncoding) { Assert.hasLength(encoding, \"Encoding must not be empty\"); this.encoding = encoding; this.forceRequestEncoding = forceRequestEncoding; this.forceResponseEncoding = forceResponseEncoding; } public void setEncoding(String encoding) { this.encoding = encoding; } public String getEncoding() { return this.encoding; } public void setForceEncoding(boolean forceEncoding) { this.forceRequestEncoding = forceEncoding; this.forceResponseEncoding = forceEncoding; } public void setForceRequestEncoding(boolean forceRequestEncoding) { this.forceRequestEncoding = forceRequestEncoding; } public boolean isForceRequestEncoding() { return this.forceRequestEncoding; } public void setForceResponseEncoding(boolean forceResponseEncoding) { this.forceResponseEncoding = forceResponseEncoding; } public boolean isForceResponseEncoding() { return this.forceResponseEncoding; } @Override protected void doFilterInternal( HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { String encoding = getEncoding(); if (encoding != null) { // 若 foreceRequestEncoding 参数为 true 则进行请求参数编码转换，没有设置字符编码时默认设置请求字符编码。 if (isForceRequestEncoding() || request.getCharacterEncoding() == null) { request.setCharacterEncoding(encoding); } // 若 foreceResponseEncoding 参数为 true 则进行响应参数编码转换 if (isForceResponseEncoding()) { response.setCharacterEncoding(encoding); } } filterChain.doFilter(request, response); }} 所以我们可以在xml文件中配置加载 CharacterEncodingFilter，通过配置不同的构造器参数决定是否将请求和响应的字符编码转换还是单独设置请求和响应。 注意：字符编码过滤器需要放在最前面。 123456789101112131415161718192021222324252627&lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;!-- 必须指定。若只配置一个 encoding 参数，将处理请求的字符编码，不处理响应的字符编码 --&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 若设置 encoding 和 forceEncoding 参数，请求和响应都处理字符编码 --&gt; &lt;!-- &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; --&gt; &lt;!-- 分别指定是否处理请求字符编码和响应字符编码 --&gt; &lt;init-param&gt; &lt;param-name&gt;forceRequestEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceResponseEncoding&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; Get 乱码若服务器是 tomcat，修改 tomcat 的配置文件 server.xml。在第一个 Connerctor 节点添加 URIEncoding 标签： 1&lt;Connector URIEncoding=\"UTF-8\" port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt;","link":"/2018/11/06/源码角度分析 CharacterEncodingFilter 解决 Post 请求中文乱码问题/"},{"title":"类初始化和实例初始化","text":"运行结果： (5)(1)(10)(6)(9)(3)(2)(9)(8)(7) (9)(3)(2)(9)(8)(7) 以上代码考察的知识点有三个： 类的初始化过程 实例初始化过程 方法的重写 类的初始化过程一个类要创建实例需要先加载并初始化该类 main 方法所在的类需要先加载和初始化，不管main方法是否有其他操作。 一个子类要初始化需要先初始化父类 一个类的初始化就是执行 &lt;clinit&gt;() 方法 &lt;clinit&gt;() 方法由静态类变量显示赋值代码 和 静态代码块组成 类变量显示赋值代码和静态代码块从上到下顺序执行 &lt;clinit&gt;() 方法只执行一次 结合用例分析运行子类的main方法，先不管执行了什么，首先会加载该类，该类如有父类会先加载父类。 执行父类的&lt;clinit&gt;() 方法，该方法中执行一次，该方法的内容由静态类变量和静态代码块组成： 静态实例变量赋值代码在前，被先执行，调用了 method() 方法，打印 (5) 其次是静态代码块被执行，打印 (1) 父类加载完毕，加载子类的&lt;clinit&gt;() 方法： 静态实例变量赋值代码在前，被先执行，打印 (10) 接着静态代码块，打印 (6) 结果就是：(5)(1)(10)(6) 实例初始化过程实例化初始化就是执行&lt;init&gt;()方法 &lt;init&gt;() 方法可能重载有多个，由几个构造器就有几个 &lt;init&gt; 方法 &lt;init&gt;() 方法由非静态实例变量赋值代码、非静态代码块、对应构造器代码组成 非静态实例变量赋值代码和非静态代码块代码按顺序执行，对应的构造器总是最后执行 每次创建实例对象，调用对应构造器，执行的就是对应的 &lt;init&gt; 方法 &lt;init&gt;() 方法首行是super()或super(参数列表)，即对应父类的&lt;init&gt;() 方法 方法的重写final、静态方法、private修饰的方法不可被重写 对象的多态性： 子类如果重写了父类的方法，通过子类对象调用的一定是子类重写过的代码 非静态方法默认的调用对象是this this对象在构造器或者说&lt;init&gt;方法中就是正在创建的对象 结合用例分析main 方法的 Son s1 = new Son(); 被执行，类加载器开始执行 &lt;init&gt;() &lt;init&gt;() 首行是 super()，于是执行父类的 &lt;init&gt;()，该方法由非静态实例变量赋值代码、非静态代码块、构造器组成 非静态实例变量赋值代码 test() 在前先被执行，应该是打印 (4)，但是因为多态的特性，子类重写了test()，init() 初始化方法中this指向的是正在创建的子类对象 Son，调用的正是子类的test()。所以打印 (9) 然后是父类的非静态代码块被执行，打印 (3) 最后是父类的指定构造器，子类调用的是无参构造器，所以父类的无参构造器先被调用，打印 (2) 父类的 &lt;init&gt;() 执行完毕，再执行子类的 &lt;init&gt;()： 子类 test() 又被执行了一次，打印 (9) 子类的非静态代码块执行，打印 (8) 最后构造器执行，打印 (7) 至此，第一行打印（空格为了区分类初始化和实例初始化）：(5)(1)(10)(6) (9)(3)(2)(9)(8)(7) main 方法又执行了一次子类对象，由于类的初始化&lt;clinit&gt;()只创建一次，所以(5)(1)(10)(6)不被打印，而(9)(3)(2)(9)(8)(7)又被执行了一次。 颠倒位置，再测试一遍 执行父类 &lt;clinit&gt;()，依次打印：类静态变量 (5)、类静态代码块 (1) 执行子类 &lt;clinit&gt;()，依次打印：类静态代码块 (6)、类静态变量 (10) 执行父类 &lt;init&gt;()，依次打印：非静态代码块 (3)、非静态实例变量（多态机制） (9)、构造器 (2) 执行子类 &lt;init&gt;()，依次打印：非静态代码块 (8)、非静态实例变量 (9)、构造器 (7) 最终结果： -- 空格为了区分类初始化和实例初始化 -- (5)(1)(6)(10) (3)(9)(2)(8)(9)(7) (3)(9)(2)(8)(9)(7)","link":"/2018/10/30/类初始化和实例初始化/"},{"title":"自增变量","text":"先看一段代码： 1234567891011public class Demo1 { public static void main(String[] args) { int i = 1; // i = 1 i = i++; // i = 1 int j = i++; // j = 1 int k = i + ++i * i++; // k = 11 System.out.println(\"i = \" + i); System.out.println(\"j = \" + j); System.out.println(\"k = \" + k); }} 结果： i = 4 j = 1 k = 11 分析： 之前在算法中学到，运算操作都是通过栈来完成的，最典型的比如双栈表达式取值，一个操作符栈、一个操作数栈。运行一串表达式，遇到数值入操作数栈，遇到符号入操作符栈，执行操作时依次弹出。 首先明确一点：自增操作是不入栈的，直接修改变量的值。 执行流程： int i = 1; 首先 常量 1 入栈，遇到 = 号，弹出 1 赋值给变量 i，此时 i = 1 i = i++; i = 1 入栈，i 变量自增：i = 2，但是此时操作数栈中的 i 依然是 1，再将操作数栈中的 1 赋值给变量 i，这一操作就原本的 i = 2 覆盖掉了变成了 1。此时 i = 1 j = i++; i = 1 入栈，i 变量自增为2，遇到 = 将 i = 1赋值给 j ,j = 1 k = i + ++i * i++; i = 2 入栈 i 自增之后入栈，i = 3 i 入栈 ，i = 3，变量自增为 4，但是操作数中的 i 依旧为 3 栈运算：2 + 3 * 3 = 11","link":"/2018/10/30/自增变量/"},{"title":"解决使用 bootstrap 更新操作时-模态框回显传值问题","text":"回顾 ModelAndView之前的印象中，我使用 ModelAndView 的场景是在需要重定向页面时带上参数。最近在做博客系统开发时学到了新的一招，就是 ModelAndView 不仅可以跳转页面，还可以”跳转”页面的部分内容！比如这样：new ModelAndView(&quot;users/list :: #user_div&quot;,map); —— 这句话的意思是找到 user/list.html 将其中的指定 div 的 html 代码作为字符串返回值输出出去（如果这个 div 有取值标签将会被赋值）。如果是同步请求将会输出到浏览器实现刷新，如果是异步则会作为 data 的字符串文本数据（html代码） 解决模态框回显传值问题很多情况下有这样的需求：点击编辑按钮弹出一个固定 html 内容的模态框，怎么在弹出前根据 id 先获取数据再展示给用户看呢？ 首先点击编辑按钮触发事件发起异步请求查找一个实体对象； 控制层返回的不是 json，而是 ModelAndView 对象，并且只返回需要被填充的模态框的部分页面代码（html）比如：new ModelAndView(&quot;users/list :: #模态框表单id&quot;,map); 这样就将这部分的页面的 html 代码（包括map中的值）直接传给了前台 js 中。 js 获取的 data 数据则是需要展示给用户看的表单html 代码了（包括回显的值），通过 js 在指定的 div（模态框表单id的‘父级元素：divID ’） 中填充这个数据：$(&quot;#divID&quot;).html(data); —— data 是后台返回的模态框 html。 这样就会将后台传过来的 html 代码以及赋值好的数据作为表单回显内容 覆盖之前未填充数据的表单 展示给用户。 实例：博客系统后台管理用户管理编辑操作","link":"/2018/10/13/解决使用 bootstrap 更新操作时-模态框回显传值问题/"},{"title":"Spring Annotation development","text":"https://docs.spring.io/spring/docs/5.0.9.RELEASE/spring-framework-reference/web.html 组件注册 @Configuration @ComponentScan @Bean @Scope @Lazy @Conditional @Import 生命周期 @Bean 指定初始化和销毁方法 实现 InitializingBean和DisposableBean 指定初始化和销毁方法 @PostConstruct / @PreDestroy 指定初始化和销毁方法 属性赋值 @Value 赋值 @PropertySource 加载外部配置文件 自动装配 @Autowired / @Qualifier / @Primary @Resource / @Inject 实现 Aware 注入 Spring 底层组件 @Profile 环境搭建 @Profile 环境激活 AOP @Aspect / @Pointcut / @Before / @After / @AfterReturning / @AfterThrowing / @Around @EnableAspectJAutoProxy 事务 @Transactional @EnableTransactionManagement DataSource / Template / PlatformTransactionManager Servlet 自定义组件 @WebServlet / @WebFilter / @WebListener ServletContainerInitializer 初始化器 利用 ServletContainerInitializer.ServletContext / ServletContextListener.ServletContext 添加第三方组件 SpringMVCWeb 配置类组件加载流程： 导入 webmvc 包后，lib 中多了一个 spring-web-4.3.12.RELEASE.jar web容器在启动的时候，会扫描每个jar包下的 META-INF/services/javax.servlet.ServletContainerInitializer 。此时在 spring-web-4.3.12.RELEASE.jar 包中扫描到了该文件： 加载文件中指定的类： org.springframework.web.SpringServletContainerInitializer SpringServletContainerInitializer 会加载 WebApplicationInitializer 接口下所有的组件。并且为 WebApplicationInitializer 组件创建对象（当组件不是接口，不是抽象类时） 我们的 web配置类 要继承的类： AbstractAnnotationConfigDispatcherServletInitializer 是 WebApplicationInitializer 接口的间接子类。 12345678910111213141516171819202122232425262728public class MyWebAppInitializer extends AbstractAnnotationConfigDispatcherServletInitializer { /** * 加载根容器的配置类：Spring配置 */ @Override protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class[]{RootConfig.class}; } /** * 加载webmvc容器的配置类：SpringMVC 配置 */ @Override protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class[]{MvcConfig.class}; } /** * 获取 DispatcherServlet 的映射信息 * &lt;p&gt; * - `/` 拦截所有请求（包括静态资源（xx.js,xx.png）），但是不包括*.jsp； * - `/*` 拦截所有请求；连*.jsp页面都拦截；jsp页面是tomcat的jsp引擎解析的； */ @Override protected String[] getServletMappings() { return new String[]{\"/\"}; }} SpringMVC 配置类123456789101112131415161718192021222324252627282930313233343536373839@ComponentScan(value = {\"xyz.yuzh.learn.spring.annotation\"}, includeFilters = { @ComponentScan.Filter(type = FilterType.ANNOTATION, classes = Controller.class)}, useDefaultFilters = false)@EnableWebMvc // 开启 SpringMVC 定制配置功能，等同于 &lt;mvc:annotation-driven/&gt;public class WebConfig extends WebMvcConfigurerAdapter { // WebMvcConfigurerAdapter抽象类 实现了 WebMvcConfigurer 接口来定制MVC的所有配置，实现抽象类使得我们不必重写所有所有接口方法 /** * 定制视图解析器 */ @Override public void configureViewResolvers(ViewResolverRegistry registry) { registry.jsp(\"/WEB-INF/views/\", \".jsp\"); // 若不加参数默认为：(\"/WEB-INF/\",\".jsp\") } /** * 开启静态资源访问 相当于 &lt;mvc:default-servlet-handler&gt; * springMVC 默认拦截所有的请求包括静态资源，解除静态资源访问限制，但仅对WEB根目录下文件有效，如果文件在WEB-INF解除无效。 */ /*@Override public void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) { configurer.enable(); }*/ /** * 定制拦截器 */ @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new MyIntercepter()).addPathPatterns(\"/**\"); // 拦截所有目录及文件 } /** * 这种方式访问 WEB-INF 下的静态资源 &lt;mvc:resources location=\"/WEB-INF/resources/\" mapping=\"/resources/**\"/&gt; */ @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\"/resources/**\").addResourceLocations(\"/WEB-INF/resources/\"); }} 更多配置查阅 文档 异步处理Servlet 3.0 异步处理在Servlet 3.0之前，Servlet采用Thread-Per-Request的方式处理请求。即每一次Http请求都由某一个线程从头到尾负责处理。 如果一个请求需要进行IO操作，比如访问数据库、调用第三方服务接口等，那么其所对应的线程将同步地等待IO操作完成， 而IO操作是非常慢的，所以此时的线程并不能及时地释放回线程池以供后续使用，在并发量越来越大的情况下，当线程池已满，许多请求不能及时的被处理。这将带来严重的性能问题。 即便是像Spring、Struts这样的高层框架也脱离不了这样的桎梏，因为他们都是建立在Servlet之上的。为了解决这样的问题，Servlet 3.0引入了异步处理，然后在Servlet 3.1中又引入了非阻塞IO来进一步增强异步处理的性能。 123456789101112131415161718192021222324252627282930313233@WebServlet(value = \"/async\", asyncSupported = true) // 支持异步处理asyncSupported=truepublic class HelloAsyncServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { // 开启异步模式 System.out.println(\"主线程开始。。。\" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); AsyncContext startAsync = req.startAsync(); //业务逻辑进行异步处理; 开始异步处理 startAsync.start(new Runnable() { @Override public void run() { try { System.out.println(\"副线程开始 \" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); sayHello(); startAsync.complete(); // 异步处理完 AsyncContext asyncContext = req.getAsyncContext(); // 获取到异步上下文 ServletResponse response = asyncContext.getResponse(); // 获取响应 response.getWriter().write(\"hello async...\"); System.out.println(\"副线程结束 \" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); } catch (Exception e) { } } }); System.out.println(\"主线程结束。。。\" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); } public void sayHello() throws Exception { System.out.println(Thread.currentThread() + \" processing...\"); Thread.sleep(3000); }} SpringMVC 异步处理基于 Callable 的简单异步处理。返回 Callable 结果对象，将 Callable 对象放入异步处理线程处理结果，主线程结束，等待异步线程返回结果渲染页面。 1234567891011121314151617181920212223242526272829@Controllerpublic class AsyncController { /** * 异步处理 * 1. 控制器返回 Callable * 2. Spring 异步处理，将Callable 提交到 TaskExecutor 使用一个隔离的线程进行执行 * 3. DispatcherServlet 和所有的 Filter 退出 web 容器的线程，但是 response 保持打开状态； * 4. Callable 返回结果，Spring MVC 将请求重新派发给容器，恢复之前的处理； * 5. 根据 Callable 返回的结果。Spring MVC 继续进行视图渲染流程等（从收请求-视图渲染）。 */ @ResponseBody @RequestMapping(\"/async01\") public Callable&lt;String&gt; async01() { System.out.println(\"主线程开始.\" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); Callable&lt;String&gt; callable = new Callable&lt;String&gt;() { @Override public String call() throws Exception { System.out.println(\"副线程开始.\" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); Thread.sleep(2000); System.out.println(\"副线程开始.\" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); return \"Callable&lt;String&gt; async01()\"; } }; System.out.println(\"主线程结束.\" + Thread.currentThread() + \"-&gt;\" + System.currentTimeMillis()); return callable; }} 基于 DeferredResult 的异步处理。这种方式的特点在于可以从不同的线程异步地产生返回值，配合 JMS ，可以实现在其他控制器中返回本次请求的结果。 12345678910@GetMapping(\"/quotes\")@ResponseBodypublic DeferredResult&lt;String&gt; quotes() { DeferredResult&lt;String&gt; deferredResult = new DeferredResult&lt;String&gt;(); // 把这个对象存在一个地方 return deferredResult;}// 在某个地方获取对象并存入对象的值然后返回deferredResult.setResult(data); 用例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Controllerpublic class AsyncController { /************************************************** * DeferredResult **************************************************/ /** * 处理请求：创建订单 * - 1. 构建 DeferredResult 对象，设置超时事件，失败提示 * - 2. 通过 JMS 发送一个 DeferredResultQueue 对象的消息，该对象存储 DeferredResult. * - 3. 若接收端在限定时间内给 DeferredResult 存入了结果，则返回 DeferredResult 的结果，否则结果是失败提示。 */ @ResponseBody @RequestMapping(\"/createOrder\") public DeferredResult&lt;Object&gt; createOrder() { DeferredResult&lt;Object&gt; deferredResult = new DeferredResult&lt;&gt;((long) 3000, \"create fail...\"); // 模拟发送消息：把结果对象存入一个队列中，假设 DeferredResultQueue 队列就是消息通知内容 DeferredResultQueue.save(deferredResult); // 等待异步存入结果到 deferredResult 中并返回，超时则失败 return deferredResult; } /** * 模拟异步的存入请求结果：执行创建 * - 1. 监听 JMS 消息，获得消息内容（DeferredResultQueue对象） * - 2. 从消息对象 DeferredResultQueue 中拿到 DeferredResult 延迟异步结果对象。 * - 3. 执行业务逻辑，赋值。 */ @ResponseBody @RequestMapping(\"/create\") public String create() { //创建订单 String order = UUID.randomUUID().toString(); // 获取到消息通知，从中获取到需要存取结果的对象 DeferredResult&lt;Object&gt; deferredResult = DeferredResultQueue.get(); // 向结果对象存入值，请求返回结果 deferredResult.setResult(order); return \"success: \" + order; }}class DeferredResultQueue { private static ConcurrentLinkedQueue&lt;DeferredResult&lt;Object&gt;&gt; queue = new ConcurrentLinkedQueue&lt;DeferredResult&lt;Object&gt;&gt;(); public static void save(DeferredResult&lt;Object&gt; deferredResult) { queue.add(deferredResult); } public static DeferredResult&lt;Object&gt; get() { return queue.poll(); }} SSM 零配置整合 Web： WebInitializer spring context / spring mvc context / postFilter … Spring：RootConfig dataSource / transactionManager / sqlSessionFactory … Spring MVC: DispatcherServletConfig viewResolvers / resourceHandlers … demo","link":"/2018/09/13/Spring-Annotation-development/"},{"title":"分布式技术入坑指南（三）","text":"11.Solr索引库的搭建与使用（单机版和集群版）下载地址：https://lucene.apache.org/solr/ 单机版搭建* 版本：solr-4.10.3 * windows下的配置完全一样。 第一步：把solr 的压缩包上传到Linux系统第二步：解压solr。第三步：把solr部署到Tomcat下。 路径：`/opt/solr-4.10.3/dist/solr-4.10.3.war` 第四步：解压缩war包。可以启动Tomcat解压。第五步：把/root/solr-4.10.3/example/lib/ext目录下的所有的jar包，添加到solr工程中。第六步：创建一个solrhome。安装包自带有一个solrhome：/example/solr，该目录就是一个solrhome。复制此目录到自己创建solrhome。第七步：关联solr及solrhome。需要修改solr工程的web.xml文件。 12345&lt;env-entry&gt; &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt; &lt;env-entry-value&gt;/opt/solrhome&lt;/env-entry-value&gt; &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt;&lt;/env-entry&gt; 第八步：启动Tomcathttp://192.168.184.130:8080/solr/ 使用添加文档必须有id域，其他域 必须在solr的schema.xml中定义。 schema.xml中定义 本系统业务所需要的业务域有：1、商品Id 使用schema.xml中的id域2、商品标题3、商品卖点4、商品价格5、商品图片6、分类名称7、商品描述 配置中文分词器创建对应的业务域。需要制定中文分析器。下载地址：https://code.google.com/archive/p/ik-analyzer/downloads 第一步：把中文分析器添加到solr工程中。 1、把IKAnalyzer2012FF_u1.jar添加到solr工程的lib目录下。 2、把扩展词典、配置文件放到solr工程的WEB-INF/classes目录下。 第二步：配置一个FieldType，制定使用IKAnalyzer 修改solrHome中的schema.xml文件，添加FieldType。 路径：`/opt/solrhome/collection1/conf/schema.xml` 123&lt;fieldType name=\"text_ik\" class=\"solr.TextField\"&gt; &lt;analyzer class=\"org.wltea.analyzer.lucene.IKAnalyzer\"/&gt;&lt;/fieldType&gt; 第三步：配置业务域，type制定使用自定义的FieldType。设置业务系统Field 123456789101112&lt;field name=\"item_title\" type=\"text_ik\" indexed=\"true\" stored=\"true\"/&gt;&lt;field name=\"item_sell_point\" type=\"text_ik\" indexed=\"true\" stored=\"true\"/&gt;&lt;field name=\"item_price\" type=\"long\" indexed=\"true\" stored=\"true\"/&gt;&lt;field name=\"item_image\" type=\"string\" indexed=\"false\" stored=\"true\" /&gt;&lt;field name=\"item_category_name\" type=\"string\" indexed=\"true\" stored=\"true\" /&gt;&lt;field name=\"item_desc\" type=\"text_ik\" indexed=\"true\" stored=\"false\" /&gt;&lt;field name=\"item_keywords\" type=\"text_ik\" indexed=\"true\" stored=\"false\" multiValued=\"true\"/&gt;&lt;copyField source=\"item_title\" dest=\"item_keywords\"/&gt;&lt;copyField source=\"item_sell_point\" dest=\"item_keywords\"/&gt;&lt;copyField source=\"item_category_name\" dest=\"item_keywords\"/&gt;&lt;copyField source=\"item_desc\" dest=\"item_keywords\"/&gt; 第四步：重启tomcat Tomcat启动后访问不了？多次出现这样的问题，启动之后访问不了，一定要看日志！/opt/apache-tomcat-8.5.32/logs/catalina.out。 由于本机中dubbo-admin和solr放在了同一个tomcat，而dubbo-admin启动需要先开启zookeeper服务，所以tomcat一直处于启动状态。 Linux中多次启动关闭Tomcat下次启动会异常，需要强制杀死进程 kill -s 9 pid 然后再启动。 测试CRUD使用SolrJ可以实现索引库的增删改查操作。 Maven: 12345&lt;!-- solr客户端 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.solr&lt;/groupId&gt; &lt;artifactId&gt;solr-solrj&lt;/artifactId&gt;&lt;/dependency&gt; 添加到文档1234567891011121314151617181920212223242526/** * 第一步：把solrJ的jar包添加到工程中。 * 第二步：创建一个SolrServer，使用HttpSolrServer创建对象。 * 第三步：创建一个文档对象SolrInputDocument对象。 * 第四步：向文档中添加域。必须有id域，域的名称必须在schema.xml中定义。 * 第五步：把文档添加到索引库中。 * 第六步：提交。 * * @throws Exception */@Testpublic void addDocument() throws Exception { // 第一步：把solrJ的jar包添加到工程中。 // 第二步：创建一个SolrServer，使用HttpSolrServer创建对象。 SolrServer solrServer = new HttpSolrServer(\"http://192.168.184.130:8080/solr\"); // 第三步：创建一个文档对象SolrInputDocument对象。 SolrInputDocument document = new SolrInputDocument(); // 第四步：向文档中添加域。必须有id域，域的名称必须在schema.xml中定义。 document.addField(\"id\", \"test001\"); document.addField(\"item_title\", \"测试商品\"); document.addField(\"item_price\", \"199\"); // 第五步：把文档添加到索引库中。 solrServer.add(document); // 第六步：提交。 solrServer.commit();} 删除文档1234567891011121314151617181920212223242526/** * 第一步：创建一个SolrServer对象。 * 第二步：调用SolrServer对象的根据id删除的方法。 * 第三步：提交。 * * @throws Exception */@Testpublic void deleteDocumentById() throws Exception { // 第一步：创建一个SolrServer对象。 SolrServer solrServer = new HttpSolrServer(\"http://192.168.184.130:8080/solr\"); // 第二步：调用SolrServer对象的根据id删除的方法。 solrServer.deleteById(\"1\"); // 第三步：提交。 solrServer.commit();} /** * 根据查询删除 */@Testpublic void deleteDocumentByQuery() throws Exception { SolrServer solrServer = new HttpSolrServer(\"http://192.168.184.130:8080/solr\"); solrServer.deleteByQuery(\"title:change.me\"); solrServer.commit();} 查询文档1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * 第一步：创建一个SolrServer对象 * 第二步：创建一个SolrQuery对象。 * 第三步：向SolrQuery中添加查询条件、过滤条件。。。 * 第四步：执行查询。得到一个Response对象。 * 第五步：取查询结果。 * 第六步：遍历结果并打印。 * * @throws Exception */@Testpublic void queryDocument() throws Exception { // 第一步：创建一个SolrServer对象 SolrServer solrServer = new HttpSolrServer(\"http://192.168.184.130:8080/solr\"); // 第二步：创建一个SolrQuery对象。 SolrQuery query = new SolrQuery(); // 第三步：向SolrQuery中添加查询条件、过滤条件。。。 query.setQuery(\"*:*\"); // 第四步：执行查询。得到一个Response对象。 QueryResponse response = solrServer.query(query); // 第五步：取查询结果。 SolrDocumentList solrDocumentList = response.getResults(); System.out.println(\"查询结果的总记录数：\" + solrDocumentList.getNumFound()); // 第六步：遍历结果并打印。 for (SolrDocument solrDocument : solrDocumentList) { System.out.println(solrDocument.get(\"id\")); System.out.println(solrDocument.get(\"item_title\")); System.out.println(solrDocument.get(\"item_price\")); }}/** * 高亮查询 */@Testpublic void queryDocumentWithHighLighting() throws Exception { // 第一步：创建一个SolrServer对象 SolrServer solrServer = new HttpSolrServer(\"http://192.168.184.130:8080/solr\"); // 第二步：创建一个SolrQuery对象。 SolrQuery query = new SolrQuery(); // 第三步：向SolrQuery中添加查询条件、过滤条件。。。 query.setQuery(\"测试\"); //指定默认搜索域 query.set(\"df\", \"item_keywords\"); //开启高亮显示 query.setHighlight(true); //高亮显示的域 query.addHighlightField(\"item_title\"); query.setHighlightSimplePre(\"&lt;em&gt;\"); query.setHighlightSimplePost(\"&lt;/em&gt;\"); // 第四步：执行查询。得到一个Response对象。 QueryResponse response = solrServer.query(query); // 第五步：取查询结果。 SolrDocumentList solrDocumentList = response.getResults(); System.out.println(\"查询结果的总记录数：\" + solrDocumentList.getNumFound()); // 第六步：遍历结果并打印。 for (SolrDocument solrDocument : solrDocumentList) { System.out.println(solrDocument.get(\"id\")); //取高亮显示 Map&lt;String, Map&lt;String, List&lt;String&gt;&gt;&gt; highlighting = response.getHighlighting(); List&lt;String&gt; list = highlighting.get(solrDocument.get(\"id\")).get(\"item_title\"); String itemTitle = null; if (list != null &amp;&amp; list.size() &gt; 0) { itemTitle = list.get(0); } else { itemTitle = (String) solrDocument.get(\"item_title\"); } System.out.println(itemTitle); System.out.println(solrDocument.get(\"item_price\")); }} 搭建搜索服务工程 分布式集群版一些概念 SolrCloud是Solr提供基于Solr和Zookeeper的分布式搜索方案，它的主要思想是使用Zookeeper作为集群的配置信息中心。 Solr集群的系统架构 需要实现的solr集群架构 Zookeeper作为集群的管理工具。1、集群管理：容错、负载均衡。2、配置文件的集中管理3、集群的入口 搭建伪分布式 需要三个zookeeper节点 需要四个tomcat节点 Zookeeper集群搭建第一步：创建solr集群的根目录 /opt/solrCloud/第二步：解压 zookeeper.tar.gz 并在根目录下复制三份 123drwxr-xr-x. 11 1000 1000 4096 7月 22 20:15 zookeeper01drwxr-xr-x. 11 root root 4096 7月 22 20:18 zookeeper02drwxr-xr-x. 11 root root 4096 7月 22 20:18 zookeeper03 第三步：在每一个zookeeper中创建data目录，在data中创建文件 myid，内容就是每个实例的id，比如：1，2，3第四步：把每一个zookeeper下的conf目录下的zoo_sample.cfg文件改名为zoo.cfg第五步：修改配置文件 dataDir clientPort 集群的节点列表 1.集群的节点列表，1、2、3代表节点的id2.ip后的端口号是zookeeper内部通讯的端口和投票选举的端口，每个端口不能重复。 第六步：启动每个zookeeper实例 12345678910[root@yuzh solrCloud]# vim zookeeper_start_all.sh cd /opt/solrCloud/zookeeper01/bin./zkServer.sh startcd /opt/solrCloud/zookeeper02/bin./zkServer.sh startcd /opt/solrCloud/zookeeper03/bin./zkServer.sh start 授权、启动。 Solr集群搭建第一步：创建四个tomcat实例。每个tomcat运行在不同的端口。8180、8280、8380、8480第二步：部署solr的war包。把单机版的solr工程复制到集群中每个的tomcat中。第三步：为每个solr实例创建一个对应的solrhome。使用单机版的solrhome复制四份。 12345678drwxr-xr-x. 4 root root 4096 7月 23 14:40 solrhome01drwxr-xr-x. 4 root root 4096 7月 23 14:40 solrhome02drwxr-xr-x. 4 root root 4096 7月 23 14:40 solrhome03drwxr-xr-x. 4 root root 4096 7月 23 14:40 solrhome04drwxr-xr-x. 9 root root 4096 7月 22 20:23 tomcat01drwxr-xr-x. 9 root root 4096 7月 22 20:24 tomcat02drwxr-xr-x. 9 root root 4096 7月 22 20:24 tomcat03drwxr-xr-x. 9 root root 4096 7月 22 20:24 tomcat04 第四步：需要修改每个tomcat实例中的solr的web.xml文件。把solrhome关联起来。 12345&lt;env-entry&gt; &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt; &lt;env-entry-value&gt;/opt/solrCloud/solrhome01&lt;/env-entry-value&gt; &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt;&lt;/env-entry&gt; 第五步：配置SolrCloud相关的配置。每个solrhome下都有一个solr.xml，把其中的ip及端口号配置好。 123456789&lt;solrcloud&gt; &lt;!-- 本机IP --&gt; &lt;str name=&quot;host&quot;&gt;192.168.184.130&lt;/str&gt; &lt;!-- 每个solr对应的solrhome所属的tomcat端口号 --&gt; &lt;int name=&quot;hostPort&quot;&gt;8180&lt;/int&gt; &lt;str name=&quot;hostContext&quot;&gt;${hostContext:solr}&lt;/str&gt; &lt;int name=&quot;zkClientTimeout&quot;&gt;${zkClientTimeout:30000}&lt;/int&gt; &lt;bool name=&quot;genericCoreNodeNames&quot;&gt;${genericCoreNodeNames:true}&lt;/bool&gt;&lt;/solrcloud&gt; 第六步：让zookeeper统一管理配置文件。 需要把`solrhome/collection1/conf`目录上传到zookeeper。上传任意solrhome中的配置文件即可。（需要保证zookeeper集群是启动的状态） 使用工具上传配置文件：执行/opt/solr-4.10.3/example/scripts/cloud-scripts/zkcli.sh注意不是zookeeper/bin中的zkCli.sh ./zkcli.sh -zkhost 192.168.184.130:2181,192.168.184.130:2182,192.168.184.130:2183 -cmd upconfig -confdir /opt/solrCloud/solrhome01/collection1/conf -confname myconf 第七步：修改每一个tomcat/bin目录下的catalina.sh 文件，关联solr和zookeeper。把此配置添加到配置文件中： 1JAVA_OPTS=&quot;-DzkHost=192.168.184.130:2181,192.168.184.130:2182,192.168.184.130:2183&quot; 第八步：启动每个tomcat实例。要保证zookeeper集群是启动状态。第九步：访问集群 http://192.168.184.130:8180/solr 创建新的Collection进行分片处理:http://192.168.184.130:8180/solr/admin/collections?action=CREATE&amp;name=collection2&amp;numShards=2&amp;replicationFactor=2删除不用的Collection:http://192.168.184.130:8180/solr/admin/collections?action=DELETE&amp;name=collection1 注意：关闭防火墙吧，端口太多了。每次开机之后防火墙会自动重启。 使用solrJ管理集群123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package xyz.taotao.search.test;import org.apache.solr.client.solrj.SolrQuery;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.impl.CloudSolrServer;import org.apache.solr.client.solrj.response.QueryResponse;import org.apache.solr.common.SolrDocument;import org.apache.solr.common.SolrDocumentList;import org.apache.solr.common.SolrInputDocument;import org.junit.Test;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/23 14:46 * Solr集群版客户端连接测试 */public class SolrCloudTest { @Test public void add() throws Exception { //1.创建集群版Solr，传入zookeeper集群地址。 CloudSolrServer solrServer = new CloudSolrServer(\"192.168.184.130:2181,192.168.184.130:2182,192.168.184.130:2183\"); //2.设置默认集合属性 solrServer.setDefaultCollection(\"collection2\"); //3.创建文档对象 SolrInputDocument document = new SolrInputDocument(); //4.向文档对象添加业务域（这些域要在配置文件 schema.xml 中存在） document.addField(\"id\", \"test01\"); document.addField(\"item_title\", \"测试商品\"); document.addField(\"item_price\", \"100\"); //5.把文档对象写入索引库 solrServer.add(document); //6.提交操作 solrServer.commit(); } @Test public void query() throws Exception { //创建solrServer对象实现类CloudSolrServer对象 CloudSolrServer solrServer = new CloudSolrServer(\"192.168.184.130:2181,192.168.184.130:2182,192.168.184.130:2183\"); //设置查询的默认集合 solrServer.setDefaultCollection(\"collection2\"); //创建SolrQuery查询 SolrQuery solrQuery = new SolrQuery(); //添加查询条件 solrQuery.setQuery(\"*:*\"); //执行查询，得到结果集对象 QueryResponse queryResponse = solrServer.query(solrQuery); //操作结果 SolrDocumentList resultList = queryResponse.getResults(); System.out.println(\"总记录数：\" + resultList.getNumFound()); for (SolrDocument solrDocument : resultList) { System.out.println(solrDocument.get(\"id\")); System.out.println(solrDocument.get(\"item_title\")); System.out.println(solrDocument.get(\"item_price\")); } }} 把搜索业务功能切换到集群版 12345678910111213141516171819202122232425&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd\"&gt; &lt;!-- 单机版 --&gt; &lt;!-- &lt;bean id=\"httpSolrServer\" class=\"org.apache.solr.client.solrj.impl.HttpSolrServer\"&gt; &lt;constructor-arg name=\"baseURL\" value=\"http://192.168.184.130:8080/solr\"/&gt; &lt;/bean&gt;--&gt; &lt;!-- 集群版 --&gt; &lt;bean id=\"cloudSolrServer\" class=\"org.apache.solr.client.solrj.impl.CloudSolrServer\"&gt; &lt;constructor-arg name=\"zkHost\" value=\"192.168.184.130:2181,192.168.184.130:2182,192.168.184.130:2183\"&gt;&lt;/constructor-arg&gt; &lt;property name=\"defaultCollection\" value=\"collection2\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; OVER~~😭","link":"/2018/07/22/分布式技术入坑指南（三）/"},{"title":"分布式技术入坑指南（二）","text":"10.Redis集群的搭建及业务实现Redis集群的搭建及业务实现redis集群（Redis-cluster）架构图 环境准备 至少3个节点，为了集群的高可用，为每一个节点增加一个备份机。（6台服务器）。搭建伪分布式集群方案：在一台机器里面运行6个redis实例。端口需要不同（7001-7006） 1、使用ruby脚本搭建集群。需要ruby的运行环境。安装ruby： 12yum install rubyyum install rubygems 2、从官网下载 redis-3.0.4.gem 并上传到 linux 中 地址：https://rubygems.org/gems/redis/versions 3、安装ruby运行时所使用的包 1gem install redis-3.0.0.gem 搭建步骤 需要6台redis服务器。搭建伪分布式。需要6个redis实例。需要运行在不同的端口7001-7006注意：搭建前 如果节点里有数据，需要删除（rdb文件，aof文件）。 第一步：创建6个redis实例，每个实例运行在不同的端口。需要修改redis.conf配置文件。配置文件中还需要把cluster-enabled yes前的注释去掉。 12345678910[root@localhost redis-cluster]# pwd/usr/local/redis-cluster[root@localhost redis-cluster]# ll总用量 80drwxr-xr-x. 3 root root 4096 7月 10 21:12 redis01drwxr-xr-x. 3 root root 4096 7月 10 21:53 redis02drwxr-xr-x. 3 root root 4096 7月 10 21:53 redis03drwxr-xr-x. 3 root root 4096 7月 10 21:53 redis04drwxr-xr-x. 3 root root 4096 7月 10 21:53 redis05drwxr-xr-x. 3 root root 4096 7月 10 21:54 redis06 每个实例内容如下 12345678910111213141516[root@localhost redis-cluster]# cd redis01[root@localhost redis01]# ll总用量 4drwxr-xr-x. 2 root root 4096 7月 10 22:39 bin[root@localhost redis01]# cd bin[root@localhost bin]# ll总用量 15508-rw-r--r--. 1 root root 18 7月 10 22:39 dump.rdb-rw-r--r--. 1 root root 769 7月 10 22:02 nodes.conf-rwxr-xr-x. 1 root root 4589155 7月 10 21:12 redis-benchmark-rwxr-xr-x. 1 root root 22217 7月 10 21:12 redis-check-aof-rwxr-xr-x. 1 root root 45435 7月 10 21:12 redis-check-dump-rwxr-xr-x. 1 root root 4693114 7月 10 21:12 redis-cli-rw-r--r--. 1 root root 41391 7月 10 21:14 redis.conflrwxrwxrwx. 1 root root 12 7月 10 21:12 redis-sentinel -&gt; redis-server-rwxr-xr-x. 1 root root 6466389 7月 10 21:12 redis-server 实际上一个实例就是一个redis安装文件（不是安装包），为每个实例复制一份redis.conf，分别配置不同的端口、cluster-enabled yes注释打开。 第二步：启动每个redis实例。 通过脚本批量启动全部服务 1234567891011121314151617181920vim redis-cluster-start-all.sh 添加如下：cd /usr/local/redis-cluster/redis01/bin./redis-server redis.confcd /usr/local/redis-cluster/redis02/bin./redis-server redis.confcd /usr/local/redis-cluster/redis03/bin./redis-server redis.confcd /usr/local/redis-cluster/redis04/bin./redis-server redis.confcd /usr/local/redis-cluster/redis05/bin./redis-server redis.confcd /usr/local/redis-cluster/redis06/bin./redis-server redis.conf 然后授予可执行权限、执行即可。 123456789[root@localhost redis-cluster]# ./redis-cluster-start-all.sh [root@localhost redis-cluster]# ps -ef |grep redisroot 4001 1 10 22:14 ? 00:00:00 ./redis-server *:7001 [cluster]root 4003 1 8 22:14 ? 00:00:00 ./redis-server *:7002 [cluster]root 4009 1 7 22:14 ? 00:00:00 ./redis-server *:7003 [cluster]root 4013 1 2 22:14 ? 00:00:00 ./redis-server *:7004 [cluster]root 4017 1 2 22:14 ? 00:00:00 ./redis-server *:7005 [cluster]root 4021 1 2 22:14 ? 00:00:00 ./redis-server *:7006 [cluster]root 4028 3302 0 22:14 pts/0 00:00:00 grep redis 第三步：使用ruby脚本搭建集群。 从Redis解压目录下的src下的拷贝redis-trib.rb文件到redis-cluster目录中 执行创建 1./redis-trib.rb create --replicas 1 192.168.184.130:7001 192.168.184.130:7002 192.168.184.130:7003 192.168.184.130:7004 192.168.184.130:7005 192.168.184.130:7006 第四步 创建关闭集群的脚本：（不是必须的） 12345678910111213141516171819vim 命令创建一个文件 redis-cluster-stop-all.sh cd /usr/local/redis-cluster/redis01/bin./redis-cli -p 7001 shutdowncd /usr/local/redis-cluster/redis02/bin./redis-cli -p 7002 shutdowncd /usr/local/redis-cluster/redis03/bin./redis-cli -p 7003 shutdowncd /usr/local/redis-cluster/redis04/bin./redis-cli -p 7004 shutdowncd /usr/local/redis-cluster/redis05/bin./redis-cli -p 7005 shutdowncd /usr/local/redis-cluster/redis06/bin./redis-cli -p 7006 shutdown 然后授予可执行权限、执行即可。 集群使用Redis-cli连接集群。-c：代表连接的是redis集群 123456789101112[root@localhost bin]# ./redis-cli -p 7001 -c127.0.0.1:7001&gt; set adsadsafd jkljlkjl-&gt; Redirected to slot [16142] located at 192.168.184.130:7006OK192.168.184.130:7006&gt; get adsadsafd&quot;jkljlkjl&quot;192.168.184.130:7006&gt; set key2 v2-&gt; Redirected to slot [4998] located at 192.168.184.130:7001OK192.168.184.130:7001&gt; get key2&quot;v2&quot;192.168.184.130:7001&gt; Jedis客户端连接Redis集群服务器注意：开放集群的7001-7006端口 12345678910111213141516171819@Testpublic void testJedisCluster() throws Exception { // 第一步：使用JedisCluster对象。需要一个Set&lt;HostAndPort&gt;参数。Redis节点的列表。 Set&lt;HostAndPort&gt; nodes = new HashSet&lt;&gt;(); nodes.add(new HostAndPort(\"192.168.184.130\", 7001)); nodes.add(new HostAndPort(\"192.168.184.130\", 7002)); nodes.add(new HostAndPort(\"192.168.184.130\", 7003)); nodes.add(new HostAndPort(\"192.168.184.130\", 7004)); nodes.add(new HostAndPort(\"192.168.184.130\", 7005)); nodes.add(new HostAndPort(\"192.168.184.130\", 7006)); JedisCluster jedisCluster = new JedisCluster(nodes); // 第二步：直接使用JedisCluster对象操作redis。在系统中单例存在。 jedisCluster.set(\"hello\", \"100\"); String result = jedisCluster.get(\"hello\"); // 第三步：打印结果 System.out.println(result); // 第四步：系统关闭前，关闭JedisCluster对象。 jedisCluster.close();} 实现业务 因为集群是比较消耗成本的，所以在实际开发中，一般生产环境使用集群，开发环境使用单机版。我们在项目整合中都需要有。可以开发一个接口，有单机版的实现类和集群版的实现类。使用时可以面向接口开发，不影响业务逻辑，使用spring管理实现类，部署时切换实现类即可。 接口封装常用的操作redis的方法抽取出一个接口，分别对应单机版和集群版创建两个实现类。 123456789101112131415161718192021package xyz.taotao.content.service;/** * Created with IntelliJ IDEA. * Jedis接口 * @Author: yu_zh * @DateTime: 2018/07/14 23:32 */public interface JedisClient { String set(String key, String value); String get(String key); Boolean exists(String key); Long expire(String key, int seconds); Long ttl(String key); Long incr(String key); Long hset(String key, String field, String value); String hget(String key, String field); Long hdel(String key, String... field); } 单机版实现类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package xyz.taotao.content.service.impl;import org.springframework.beans.factory.annotation.Autowired;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import xyz.taotao.content.service.JedisClient;/** * Created with IntelliJ IDEA. * 单机版实现 * @Author: yu_zh * @DateTime: 2018/07/14 23:35 */public class JedisClientPool implements JedisClient { @Autowired private JedisPool jedisPool; @Override public String set(String key, String value) { Jedis jedis = jedisPool.getResource(); String result = jedis.set(key, value); jedis.close(); return result; } @Override public String get(String key) { Jedis jedis = jedisPool.getResource(); String result = jedis.get(key); jedis.close(); return result; } @Override public Boolean exists(String key) { Jedis jedis = jedisPool.getResource(); Boolean result = jedis.exists(key); jedis.close(); return result; } @Override public Long expire(String key, int seconds) { Jedis jedis = jedisPool.getResource(); Long result = jedis.expire(key, seconds); jedis.close(); return result; } @Override public Long ttl(String key) { Jedis jedis = jedisPool.getResource(); Long result = jedis.ttl(key); jedis.close(); return result; } @Override public Long incr(String key) { Jedis jedis = jedisPool.getResource(); Long result = jedis.incr(key); jedis.close(); return result; } @Override public Long hset(String key, String field, String value) { Jedis jedis = jedisPool.getResource(); Long result = jedis.hset(key, field, value); jedis.close(); return result; } @Override public String hget(String key, String field) { Jedis jedis = jedisPool.getResource(); String result = jedis.hget(key, field); jedis.close(); return result; } @Override public Long hdel(String key, String... field) { Jedis jedis = jedisPool.getResource(); Long result = jedis.hdel(key, field); jedis.close(); return result; }} 集群版实现类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package xyz.taotao.content.service.impl;import org.springframework.beans.factory.annotation.Autowired;import redis.clients.jedis.JedisCluster;import xyz.taotao.content.service.JedisClient;/** * Created with IntelliJ IDEA. * 集群版实现类 * @Author: yu_zh * @DateTime: 2018/07/14 23:44 */public class JedisClientCluster implements JedisClient { @Autowired private JedisCluster jedisCluster; @Override public String set(String key, String value) { return jedisCluster.set(key, value); } @Override public String get(String key) { return jedisCluster.get(key); } @Override public Boolean exists(String key) { return jedisCluster.exists(key); } @Override public Long expire(String key, int seconds) { return jedisCluster.expire(key, seconds); } @Override public Long ttl(String key) { return jedisCluster.ttl(key); } @Override public Long incr(String key) { return jedisCluster.incr(key); } @Override public Long hset(String key, String field, String value) { return jedisCluster.hset(key, field, value); } @Override public String hget(String key, String field) { return jedisCluster.hget(key, field); } @Override public Long hdel(String key, String... field) { return jedisCluster.hdel(key, field); }} 配置：spring-redis.xml注意：单机版和集群版只能放开一个 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;!-- 用于激活已经注册的Bean --&gt; &lt;context:annotation-config&gt;&lt;/context:annotation-config&gt; &lt;!-- 配置单机版的连接 --&gt; &lt;bean id=\"jedisPool\" class=\"redis.clients.jedis.JedisPool\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"6379\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 创建单机版的实现类 --&gt; &lt;bean id=\"jedisClientPool\" class=\"xyz.taotao.content.service.impl.JedisClientPool\"/&gt; &lt;!--------------------------------------------------------&gt; &lt;!-- 配置集群版 --&gt; &lt;bean class=\"redis.clients.jedis.JedisCluster\"&gt; &lt;constructor-arg name=\"nodes\"&gt; &lt;set&gt; &lt;bean class=\"redis.clients.jedis.HostAndPort\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"7001\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=\"redis.clients.jedis.HostAndPort\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"7002\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=\"redis.clients.jedis.HostAndPort\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"7003\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=\"redis.clients.jedis.HostAndPort\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"7004\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=\"redis.clients.jedis.HostAndPort\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"7005\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=\"redis.clients.jedis.HostAndPort\"&gt; &lt;constructor-arg name=\"host\" value=\"192.168.184.130\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"port\" value=\"7006\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 创建集群版的实现类 --&gt; &lt;bean class=\"xyz.taotao.content.service.impl.JedisClientCluster\"&gt;&lt;/bean&gt; 封装代码测试redis客户端Bean只在spring-redis.xml中注册，所以只需加载这个配置文件，注意：需要激活已经注册的Bean才能注入到属性。 12345678910@Testpublic void testJedisClient() throws Exception { //初始化Spring容器 ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"classpath:spring-redis.xml\"); //从容器中获得JedisClient对象（接口） JedisClient jedisClient = applicationContext.getBean(JedisClient.class); jedisClient.set(\"testJedis\", \"500\"); String result = jedisClient.get(\"testJedis\"); System.out.println(result);} 为查询添加缓存创建Json工具类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package xyz.taotao.utils;import java.util.List;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.JavaType;import com.fasterxml.jackson.databind.ObjectMapper;/** * 使用 jackson-databind 工具包封装Json */public class JsonUtils { // 定义jackson对象 private static final ObjectMapper MAPPER = new ObjectMapper(); /** * 将对象转换成json字符串。 * * @param data * @return */ public static String objectToJson(Object data) { try { String string = MAPPER.writeValueAsString(data); return string; } catch (JsonProcessingException e) { e.printStackTrace(); } return null; } /** * 将json结果集转化为对象 * * @param jsonData json数据 * @param beanType 对象中的object类型 * @return */ public static &lt;T&gt; T jsonToPojo(String jsonData, Class&lt;T&gt; beanType) { try { T t = MAPPER.readValue(jsonData, beanType); return t; } catch (Exception e) { e.printStackTrace(); } return null; } /** * 将json数据转换成pojo对象list * * @param jsonData * @param beanType * @return */ public static &lt;T&gt; List&lt;T&gt; jsonToList(String jsonData, Class&lt;T&gt; beanType) { JavaType javaType = MAPPER.getTypeFactory().constructParametricType(List.class, beanType); try { List&lt;T&gt; list = MAPPER.readValue(jsonData, javaType); return list; } catch (Exception e) { e.printStackTrace(); } return null; }} 添加缓存，不能影响业务。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package xyz.taotao.service.impl;import com.github.pagehelper.PageHelper;import com.github.pagehelper.PageInfo;import org.apache.commons.lang3.StringUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Service;import xyz.taotao.mapper.TbItemMapper;import xyz.taotao.pojo.EasyUIDataGridResult;import xyz.taotao.pojo.TbItem;import xyz.taotao.pojo.TbItemExample;import xyz.taotao.redis.JedisClient;import xyz.taotao.service.ItemService;import xyz.taotao.utils.JsonUtils;import java.util.List;/** * Created with IntelliJ IDEA. * * @Author: yu_zh * @DateTime: 2018/07/05 19:02 */@Servicepublic class ItemServiceImpl implements ItemService { @Autowired TbItemMapper tbItemMapper; @Autowired private JedisClient jedisClient; @Value(\"ITEM_LIST_KEY\") private String ITEM_LIST_KEY; /** * 为查询列表项添加缓存 * 结构：Hash * &lt;p&gt; * item_list_key * | * 1,50 —— EasyUIDataGridResult Json字符串 * 2,50 —— EasyUIDataGridResult Json字符串 * 3,50 —— EasyUIDataGridResult Json字符串 * &lt;p&gt; * 缓存不能影响业务流程，用try-catch起来。 * * @param page 查询页码 * @param rows 查询行数 * @return EasyUIDataGridResult */ @Override public EasyUIDataGridResult getItemList(int page, int rows) { //查询缓存 try { String json = jedisClient.hget(ITEM_LIST_KEY, page + \"-\" + rows); //判断json是否为空 if (StringUtils.isNotBlank(json)) { //把json转换成list System.out.println(\"获得缓存\"); return JsonUtils.jsonToPojo(json, EasyUIDataGridResult.class); } } catch (Exception e) { e.printStackTrace(); } //设置分页信息 PageHelper.startPage(page, rows); //查询数据，设置查询条件 TbItemExample example = new TbItemExample(); List&lt;TbItem&gt; tbItemList = tbItemMapper.selectByExample(example); //封装分页结果集 PageInfo&lt;TbItem&gt; pageInfo = new PageInfo&lt;&gt;(tbItemList); //创建分页对象 EasyUIDataGridResult result = new EasyUIDataGridResult((int) pageInfo.getTotal(), pageInfo.getList()); //向缓存中添加数据 try { jedisClient.hset(ITEM_LIST_KEY, page + \"-\" + rows, JsonUtils.objectToJson(result)); System.out.println(\"放入redis -&gt; \" + page + \"-\" + rows); System.out.println(JsonUtils.objectToJson(result)); } catch (Exception e) { e.printStackTrace(); } return result; }} 控制台打印：Redis数据库： 缓存同步对添加了缓存的数据进行更新（增、删、改）之后，需要同步最新的数据放入缓存。做法就是删除对应缓存的key，再次获取数据会先查询数据库，再放入缓存。","link":"/2018/07/14/分布式技术入坑指南（二）/"},{"title":"分布式技术入坑指南（四）","text":"12.Java消息队列学习与使用ActiveMQ官网：http://activemq.apache.org/ 安装 解压 cd到bin目录 ./activemq start 访问，默认端口：8161 默认用户名与密码：admin 使用两种模式 点对点 发布/订阅 需要包： 1234567891011121314151617&lt;!-- 消息队列整合包 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt;&lt;/dependency&gt;&lt;!-- activemq --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;${activemq.version}&lt;/version&gt;&lt;/dependency&gt; 点对点模式目的地实现类 —— Queue发送消息 12345678910111213141516171819202122232425262728293031323334353637383940414243package xyz.yuzh.activemq.queue;import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 12:31 * 消息发送端 * 点对点模式 */public class QueueProducer { public static void main(String[] args) throws Exception{ // 第一步：创建ConnectionFactory对象，需要指定服务端ip及端口号。 //brokerURL服务器的ip及端口号 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"tcp://192.168.184.130:61616\"); // 第二步：使用ConnectionFactory对象创建一个Connection对象。 Connection connection = connectionFactory.createConnection(); // 第三步：开启连接，调用Connection对象的start方法。 connection.start(); // 第四步：使用Connection对象创建一个Session对象。 //第一个参数：是否开启事务。true：开启事务，第二个参数忽略。 //第二个参数：当第一个参数为false时，才有意义。消息的应答模式。1、自动应答2、手动应答。一般是自动应答。 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); // 第五步：使用Session对象创建一个Destination对象（topic、queue），此处创建一个Queue对象。 //参数：队列的名称。 Queue queue = session.createQueue(\"queue-test\"); // 第六步：使用Session对象创建一个Producer对象。 MessageProducer producer = session.createProducer(queue); // 第七步：创建一个Message对象，创建一个TextMessage对象。 /*TextMessage message = new ActiveMQTextMessage(); message.setText(\"hello activeMq,this is my first test.\");*/ TextMessage textMessage = session.createTextMessage(\"hello activeMq,this is my first test.\"); // 第八步：使用Producer对象发送消息。 producer.send(textMessage); // 第九步：关闭资源。 producer.close(); session.close(); connection.close(); }} 接收消息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package xyz.yuzh.activemq.queue;import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 12:31 * 消息接收端 */public class QueueConsumer { public static void main(String[] args) throws Exception { // 1.创建一个连接工厂 （Activemq的连接工厂）参数：指定连接的activemq的服务 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"tcp://192.168.184.130:61616\"); // 2.获取连接 Connection connection = connectionFactory.createConnection(); // 3.开启连接 connection.start(); // 4.根据连接对象创建session // 第一个参数：表示是否使用分布式事务（JTA） // 第二个参数：如果第一个参数为false,第二个参数才有意义；表示使用的应答模式 ：自动应答，手动应答.这里选择自动应答。 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); // 5.根据session创建Destination(目的地，queue topic,这里使用的是queue) Queue queue = session.createQueue(\"queue-test\"); // 6.创建消费者 MessageConsumer consumer = session.createConsumer(queue); //7.接收消息 //第一种/* while(true){ //接收消息 （参数的值表示的是超过一定时间 以毫秒为单位就断开连接） Message message = consumer.receive(10000); //如果message为空，没有接收到消息了就跳出 if(message==null){ break; } if(message instanceof TextMessage){ TextMessage messaget = (TextMessage)message; System.out.println(\"&gt;&gt;&gt;获取的消息内容：\"+messaget.getText());//获取消息内容 } }*/ //第二种： //设置监听器,其实开启了一个新的线程。 consumer.setMessageListener((m) -&gt; { //接收消息，如果有消息才进入，如果没有消息就不会进入此方法 if (m instanceof TextMessage) { TextMessage message = (TextMessage) m; try { //获取消息内容 System.out.println(\"&gt;&gt;&gt;获取的消息内容：\" + message.getText()); } catch (JMSException e) { e.printStackTrace(); } } }); Thread.sleep(10000);//睡眠10秒钟。 // 9.关闭资源 consumer.close(); session.close(); connection.close(); }} 发布/订阅模式目的地实现类 —— Topic 发送消息 12345678910111213141516171819202122232425262728293031323334353637383940package xyz.yuzh.activemq.topic;import org.apache.activemq.ActiveMQConnectionFactory;import org.apache.activemq.command.ActiveMQTextMessage;import javax.jms.*;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 12:50 * 发布订阅模式 */public class TopicProducer { public static void main(String[] args) throws Exception { // 1.创建一个连接工厂 （Activemq的连接工厂）参数：指定连接的activemq的服务 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"tcp://192.168.184.130:61616\"); // 2.获取连接 Connection connection = connectionFactory.createConnection(); // 3.开启连接 connection.start(); // 4.根据连接对象创建session // 第一个参数：表示是否使用分布式事务（JTA） // 第二个参数：如果第一个参数为false,第二个参数才有意义；表示使用的应答模式 ：自动应答，手动应答.这里选择自动应答。 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); // 5.根据session创建Destination(目的地，queue topic,这里使用的是topic) Topic topic = session.createTopic(\"topic-test\"); // 6.创建生产者 MessageProducer producer = session.createProducer(topic); // 7.构建消息对象，（构建发送消息的内容） 字符串类型的消息格式（TEXTMessage） TextMessage textMessage = new ActiveMQTextMessage(); textMessage.setText(\"发送消息123\");// 消息的内容 // 8.发送消息 producer.send(textMessage); // 9.关闭资源 producer.close(); session.close(); connection.close(); }} 接收消息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package xyz.yuzh.activemq.topic;import org.apache.activemq.ActiveMQConnectionFactory;import javax.jms.*;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 12:50 */public class TopicConsumer { public static void main(String[] args) throws Exception { // 1.创建一个连接工厂 （Activemq的连接工厂）参数：指定连接的activemq的服务 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"tcp://192.168.184.130:61616\"); // 2.获取连接 Connection connection = connectionFactory.createConnection(); // 3.开启连接 connection.start(); // 4.根据连接对象创建session // 第一个参数：表示是否使用分布式事务（JTA） // 第二个参数：如果第一个参数为false,第二个参数才有意义；表示使用的应答模式 ：自动应答，手动应答.这里选择自动应答。 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); // 5.根据session创建Destination(目的地，queue topic,这里使用的是queue) Topic topic = session.createTopic(\"topic-test\"); // 6.创建消费者 MessageConsumer consumer = session.createConsumer(topic); // 7.接收消息 while (true) { //接收消息 （参数的值表示的是超过一定时间 以毫秒为单位就断开连接） Message message = consumer.receive(100000); //如果message为空，没有接收到消息了就跳出 if (message == null) { break; } if (message instanceof TextMessage) { TextMessage messaget = (TextMessage) message; System.out.println(\"&gt;&gt;&gt;获取的消息内容：\" + messaget.getText());//获取消息内容 } } // 第二种： // 设置监听器,其实开启了一个新的线程。 /* consumer.setMessageListener((m) -&gt; { // 接收消息，如果有消息才进入，如果没有消息就不会进入此方法 if (m instanceof TextMessage) { TextMessage messaget = (TextMessage) m; try { // 获取消息内容 System.out.println(\"&gt;&gt;&gt;获取的消息内容：\" + messaget.getText()); } catch (JMSException e) { e.printStackTrace(); } } }); Thread.sleep(10000);// 睡眠10秒钟。*/ // 9.关闭资源 consumer.close(); session.close(); connection.close(); }} 与Spring整合这里只做测试，发送与接收均在同一系统并在同一配置文件 mvc配置 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd\"&gt; &lt;!-- ActiveMQ的连接工厂 --&gt; &lt;bean id=\"targetConnection\" class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.184.130:61616\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- Spring通用的connectionfacotry 指定真正使用的连接工厂 --&gt; &lt;bean id=\"connectionFactory\" class=\"org.springframework.jms.connection.SingleConnectionFactory\"&gt; &lt;property name=\"targetConnectionFactory\" ref=\"targetConnection\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 接收和发送消息时使用的模板类 --&gt; &lt;bean class=\"org.springframework.jms.core.JmsTemplate\"&gt; &lt;property name=\"connectionFactory\" ref=\"connectionFactory\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 目的地实现类：Queue、Topic --&gt; &lt;bean id=\"queueDestination\" class=\"org.apache.activemq.command.ActiveMQQueue\"&gt; &lt;constructor-arg name=\"name\" value=\"item-change-queue\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- &lt;bean id=\"topicDestination\" class=\"org.apache.activemq.command.ActiveMQTopic\"&gt; &lt;constructor-arg name=\"name\" value=\"item-change-topic\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; --&gt; &lt;!-- 配置消息接收监听器 --&gt; &lt;bean id=\"myMessageListener\" class=\"xyz.yuzh.activemq.spring.SpringActiveMqReciveListener\"&gt;&lt;/bean&gt; &lt;bean class=\"org.springframework.jms.listener.DefaultMessageListenerContainer\"&gt; &lt;property name=\"connectionFactory\" ref=\"connectionFactory\"&gt;&lt;/property&gt; &lt;property name=\"destination\" ref=\"queueDestination\"&gt;&lt;/property&gt; &lt;property name=\"messageListener\" ref=\"myMessageListener\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 发送消息 123456789101112131415161718192021222324252627282930313233343536373839package xyz.yuzh.activemq.spring;import org.apache.xbean.spring.context.ClassPathXmlApplicationContext;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.jms.core.JmsTemplate;import org.springframework.jms.core.MessageCreator;import javax.jms.Destination;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.Session;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 17:21 * 消息发送端 */public class SpringActiveMqSend { public static void main(String[] args) throws Exception{ //初始化容器 ApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:spring-activemq.xml\"); //获得JMS模板对象 JmsTemplate jmsTemplate = context.getBean(JmsTemplate.class); //获得消息队列目的地（注意是jms接口的包，不是activemq的包。） Destination queueDestination = context.getBean(Destination.class); //发送消息 jmsTemplate.send(queueDestination, (s) -&gt; { StringBuilder message = new StringBuilder(); for (int i = 1 ; i &lt;= 100;i++){ message.append(\"测试消息\"+i+\"\\n\"); } return s.createTextMessage(message.toString()); }); Thread.sleep(100000); }} 接收消息 123456789101112131415161718192021222324252627282930package xyz.yuzh.activemq.spring;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 18:06 * 消息接收监听器 */public class SpringActiveMqReciveListener implements MessageListener { @Override public void onMessage(Message message) { if(message instanceof TextMessage){ TextMessage textMessage = (TextMessage)message; String text; try { text = textMessage.getText(); System.out.println(\"SpringActiveMqReciveListener-&gt; \"+text); } catch (JMSException e) { e.printStackTrace(); } } }} 具体业务场景下使用manager-service工程更新一个商品（增删改查），search-service工程要在索引库中更新该商品。 manager-service系统（发送消息端）spring-activemq.xml 123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd\"&gt; &lt;!-- 系统间通信 —— 消息发送方 --&gt; &lt;bean id=\"targetConnection\" class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.184.130:61616\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 通用的connectionfacotry 指定真正使用的连接工厂 --&gt; &lt;bean id=\"connectionFactory\" class=\"org.springframework.jms.connection.SingleConnectionFactory\"&gt; &lt;property name=\"targetConnectionFactory\" ref=\"targetConnection\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 接收和发送消息时使用的类 --&gt; &lt;bean id=\"jmsTemplate\" class=\"org.springframework.jms.core.JmsTemplate\"&gt; &lt;property name=\"connectionFactory\" ref=\"connectionFactory\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 订阅通知模式 --&gt; &lt;bean id=\"topicDestination\" class=\"org.apache.activemq.command.ActiveMQTopic\"&gt; &lt;constructor-arg name=\"name\" value=\"item-change-topic\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt;&lt;/beans&gt; Service 1234567891011121314151617181920212223@Servicepublic class ItemServiceImpl implements ItemService { //...... @Resource private JmsTemplate jmsTemplate; @Resource private Destination topicDestination; //...... @Override public Object addItem() { //执行商品添加逻辑 //TODO... //发送一个消息通知搜索系统更新该商品到索引库 jmsTemplate.send(topicDestination, (s) -&gt;{ System.out.println(\"发送方-&gt; 添加操作，商品编号是123\"); return s.createTextMessage(\"addItem:123\"); }); return null; }} search-service系统（接收消息端）spring-activemq.xml 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd\"&gt; &lt;!-- 系统间通信 —— 消息接收方 --&gt; &lt;bean id=\"targetConnection\" class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.184.130:61616\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 通用的connectionfacotry 指定真正使用的连接工厂 --&gt; &lt;bean id=\"connectionFactory\" class=\"org.springframework.jms.connection.SingleConnectionFactory\"&gt; &lt;property name=\"targetConnectionFactory\" ref=\"targetConnection\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 接收和发送消息时使用的类 --&gt; &lt;bean id=\"jmsTemplate\" class=\"org.springframework.jms.core.JmsTemplate\"&gt; &lt;property name=\"connectionFactory\" ref=\"connectionFactory\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 订阅通知模式 --&gt; &lt;bean id=\"topicDestination\" class=\"org.apache.activemq.command.ActiveMQTopic\"&gt; &lt;!-- name不和发送端保持一致接收不到消息！ --&gt; &lt;constructor-arg name=\"name\" value=\"item-change-topic\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 接收消息的监听器 --&gt; &lt;bean class=\"org.springframework.jms.listener.DefaultMessageListenerContainer\"&gt; &lt;property name=\"connectionFactory\" ref=\"connectionFactory\"&gt;&lt;/property&gt; &lt;property name=\"destination\" ref=\"topicDestination\"&gt;&lt;/property&gt; &lt;property name=\"messageListener\" ref=\"itemChangeListener\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; Service 12345678910111213141516171819202122232425262728293031323334353637383940414243package xyz.taotao.search.activemq.recive;import org.apache.solr.client.solrj.SolrServer;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage;/** * Created with IntelliJ IDEA. * Author: yu_zh * DateTime: 2018/07/24 23:22 * 商品改变后通知该方法更新索引库 */@Componentpublic class ItemChangeListener implements MessageListener { @Autowired private SolrServer solrserver; @Override public void onMessage(Message message) { if (message instanceof TextMessage) { TextMessage textMessage = (TextMessage) message; String text = \"\"; try { text = textMessage.getText(); if (text.contains(\"addItem\")) { String itemId = text.substring(text.lastIndexOf(\":\")+1); //通知索引库服务提供者更新商品 //TODO... System.out.println(\"接收方-&gt; 索引库更新产品:\"+itemId); } } catch (JMSException e) { e.printStackTrace(); } } }} 推荐博客：http://elim.iteye.com/blog/1893038","link":"/2018/07/25/分布式技术入坑指南（四）/"},{"title":"NIO","text":"Java Non blocking IO 学习笔记 Java NIO 简介 Java NIO（Non blocking IO）是从Java 1.4版本开始引入的一个新的IO API，可以替代标准的Java IO API。NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同，NIO支持面向缓冲区的、基于通道的IO操作。NIO将以更加高效的方式进行文件的读写操作。 Java NIO 与 IO 的主要区别 IO NIO 面向流(Stream Oriented) 面向缓冲区(Buffer Oriented) 阻塞IO(Blocking IO) 非阻塞IO(Non Blocking IO) (无) 选择器(Selectors) 缓冲区(Buffer)和通道(Channel) Java NIO系统的核心在于：通道(Channel)和缓冲区(Buffer)。通道表示打开到 IO 设备(例如：文件、套接字)的连接。若需要使用 NIO 系统，需要获取用于连接 IO 设备的通道以及用于容纳数据的缓冲区。然后操作缓冲区，对数据进行处理。简而言之，Channel 负责传输， Buffer 负责存储。 缓冲区缓冲区（Buffer）：一个用于特定基本数据类型的容器。由 java.nio 包定义的，所有缓冲区都是 Buffer 抽象类的子类。 Java NIO 中的 Buffer 主要用于与 NIO 通道进行交互，数据是从通道读入缓冲区，从缓冲区写入通道中的。 Buffer 就像一个数组，可以保存多个相同类型的数据。根据数据类型不同(boolean 除外) ，有以下 Buffer 常用子类： ByteBuffer / CharBuffer / ShortBuffer / IntBuffer / LongBuffer / FloatBuffer / DoubleBuffer 上述 Buffer 类 他们都采用相似的方法进行管理数据，只是各自管理的数据类型不同而已。都是通过如下方法获取一个 Buffer 对象： static XxxBuffer allocate(int capacity) : 创建一个容量为 capacity 的 XxxBuffer 对象 基本属性： 容量 (capacity) ：表示 Buffer 最大数据容量，缓冲区容量不能为负，并且创建后不能更改。 限制 (limit)：第一个不应该读取或写入的数据的索引，即位于 limit 后的数据不可读写。缓冲区的限制不能为负，并且不能大于其容量。 位置 (position)：下一个要读取或写入的数据的索引。缓冲区的位置不能为负，并且不能大于其限制 标记 (mark)与重置 (reset)：标记是一个索引，通过 Buffer 中的 mark() 方法指定 Buffer 中一个特定的position，之后可以通过调用 reset() 方法恢复到这个 position. 标记、位置、限制、容量遵守以下不变式： 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity 常用方法： 方 法 描 述 byte get() 读取单个字节 Buffer put(byte b) 写入单个字节到缓冲区 Buffer clear() 清空缓冲区并返回对缓冲区的引用 Buffer flip() 将缓冲区的界限设置为当前位置，并将当前位置充值为 0 int capacity() 返回 Buffer 的 capacity 大小 boolean hasRemaining() 判断缓冲区中是否还有元素 int limit() 返回 Buffer 的界限(limit) 的位置 Buffer limit(int n) 将设置缓冲区界限为 n, 并返回一个具有新 limit 的缓冲区对象 Buffer mark() 对缓冲区设置标记 int position() 返回缓冲区的当前位置 position Buffer position(int n) 将设置缓冲区的当前位置为 n , 并返回修改后的 Buffer 对象 int remaining() 返回 position 和 limit 之间的元素个数 Buffer reset() 将位置 position 转到以前设置的 mark 所在的位置 Buffer rewind() 将位置设为为 0， 取消设置的 mark 用例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class TestBuffer { @Test public void test() { // 分配一个指定容量的缓冲区 ByteBuffer buffer = ByteBuffer.allocate(1024); System.out.println(\"-----&lt; allocate &gt;-----\"); showAttribute(buffer); // position:0 - limit:1024 - capacity:1024 // 存数据到缓冲区 buffer.put(\"abcde\".getBytes()); // 存入了5个字节 System.out.println(\"-----&lt; put &gt;-----\"); showAttribute(buffer); // position:5 - limit:1024 - capacity:1024 // 切换到读取数据，将缓冲区的界限设置为当前位置（5），并将当前位置充值为 0（从0开始读取） buffer.flip(); System.out.println(\"-----&lt; flip &gt;-----\"); showAttribute(buffer); // position:从 0 开始读 - limit:5 - capacity:1024 // 这个时候如果存入数据会报错，因为指针在0，界限是5，而存入的数据长度10大于界限。// buffer.put(\"zhangyu123\".getBytes()); // 取数据 byte[] bytes = new byte[buffer.limit()]; buffer.get(bytes); System.out.println(new String(bytes, 0, bytes.length)); System.out.println(\"-----&lt; get &gt;-----\"); showAttribute(buffer); // position:5 - limit:5 - capacity:1024 // 重复读取 buffer.rewind(); System.out.println(\"-----&lt; rewind &gt;-----\"); showAttribute(buffer); // position:0 - limit:5 - capacity:1024 // 清空缓存区，缓存区的数据依旧存在，只是position到了0，limit和capacity变为最大容量数值，数据处于游离状态。 buffer.clear(); System.out.println(\"-----&lt; clear &gt;-----\"); showAttribute(buffer); // position:0 - limit:1024 - capacity:1024 } @Test public void testMark() { String s = \"abcde\"; ByteBuffer buffer = ByteBuffer.allocate(1024); buffer.put(s.getBytes()); buffer.flip(); byte[] bytes = new byte[buffer.limit()]; buffer.get(bytes, 0, 2); // 从缓冲区获取从0开始的两个字符 System.out.println(new String(bytes, 0, bytes.length)); // ab System.out.println(\"position:\" + buffer.position()); // 2 buffer.mark(); // 对位置 2 做标记，继续往下读。 buffer.get(bytes, 2, 2); System.out.println(new String(bytes, 0, bytes.length)); // abcd System.out.println(\"position:\" + buffer.position()); // 4 buffer.reset(); // position 重新恢复到了 2 System.out.println(\"position:\" + buffer.position()); // 2 System.out.println((char) buffer.get()); // 获取下一个字节 c if (buffer.hasRemaining()) System.out.println(buffer.remaining()); // 获得剩余字节数量 2 } @Test public void test3() { //分配直接缓冲区 ByteBuffer buf = ByteBuffer.allocateDirect(1024); System.out.println(buf.isDirect()); } public void showAttribute(ByteBuffer buffer) { System.out.println(\"position:\" + buffer.position()); System.out.println(\"limit:\" + buffer.limit()); System.out.println(\"capacity:\" + buffer.capacity()); }} 非直接缓冲区：通过 allocate() 方法分配缓冲区，将缓冲区建立在 JVM 的内存中。 直接缓冲区：通过 allocateDirect() 方法分配直接缓冲区，将缓冲区建立在物理内存中。可以提高效率。弊端：直接在系统内存中建立（分配、销毁）缓存比在JVM中建立缓存内存消耗要大,并且当我们的应用程序将数据写入到系统内存之后数据是不可控的（不归应用程序管了），缓存中的数据什么写入到磁盘由操作系统决定。使用直接缓冲区最好的场景是当我们需要长时间在缓存中操作数据或者大量的数据时，此时的效率会得到很大的提高。 通道 通道（Channel）：由 java.nio.channels 包定义的。Channel 表示 IO 源与目标打开的连接。Channel 类似于传统的“流”。只不过 Channel 本身不能直接访问数据，Channel 只能与Buffer 进行交互。 主要实现类： java.nio.channels.Channel 接口： |--FileChannel |--SocketChannel |--ServerSocketChannel |--DatagramChannel 获取通道的几种方式： Java 针对支持通道的类提供了 getChannel() 方法 本地 IO： FileInputStream/FileOutputStream RandomAccessFile 网络IO： Socket ServerSocket DatagramSocket 在 JDK 1.7 中的 NIO.2 针对各个通道提供了静态方法 open() 在 JDK 1.7 中的 NIO.2 的 Files 工具类的 newByteChannel() 文件通道(FileChannel)FileChannel 的常用方法： 方 法 描 述 int read(ByteBuffer dst) 从 Channel 中读取数据到 ByteBuffer long read(ByteBuffer[] dsts) 将 Channel 中的数据“分散”到 ByteBuffer[] int write(ByteBuffer src) 将 ByteBuffer 中的数据写入到 Channel long write(ByteBuffer[] srcs) 将 ByteBuffer[] 中的数据“聚集”到 Channel long position() 返回此通道的文件位置 FileChannel position(long p) 设置此通道的文件位置 long size() 返回此通道的文件的当前大小 FileChannel truncate(long s) 将此通道的文件截取为给定大小 void force(boolean metaData) 强制将所有对此通道的文件更新写入到存储设备中 以文件传输体验通道的数据传输： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class TestFileChannel { /** * 利用通道和非直接缓冲区传输文件 */ @Test public void test1() throws IOException { FileInputStream in = null; FileOutputStream out = null; FileChannel inChannel = null; FileChannel outChannel = null; try { in = new FileInputStream(\"img/mm.jpg\"); out = new FileOutputStream(\"img/mm2.jpg\"); // 通过输入输出流获得通道 inChannel = in.getChannel(); outChannel = out.getChannel(); // 构建缓冲区 ByteBuffer buffer = ByteBuffer.allocate(1024); while (inChannel.read(buffer) != -1) { // 从输入通道中读取内容到缓冲区 buffer.flip(); // 切换成读取数据模式 outChannel.write(buffer); // 写入缓冲区数据到输出通道 buffer.clear(); // 清空缓冲区，用于下一次存储 } } catch (IOException e) { e.printStackTrace(); } finally { outChannel.close(); inChannel.close(); out.close(); in.close(); } } /** * 利用通道和直接缓冲区传输文件（内存映射文件） */ @Test public void test2() throws IOException { /** * open() 方式打开通道 * * StandardOpenOption.READ : 以只读方式创建通道 * StandardOpenOption.CREATE: 若文件存在覆盖，不存在创建。 * StandardOpenOption.CREATE_NEW: 若文件不存在创建，存在报错。 */ FileChannel inChannel = FileChannel.open(Paths.get(\"img/mm.jpg\"), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(\"img/mm2.jpg\"), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE); // 构建内存映射文件（数据在物理内存中的映射，也是直接缓冲区） MappedByteBuffer inMappedBuf = inChannel.map(FileChannel.MapMode.READ_ONLY, 0, inChannel.size()); MappedByteBuffer outMappedBuf = outChannel.map(FileChannel.MapMode.READ_WRITE, 0, inChannel.size()); // 对直接缓冲区进行数据读取 System.out.println(\"byte:\" + inMappedBuf.limit() + \"k\"); byte[] dst = new byte[inMappedBuf.limit()]; inMappedBuf.get(dst); outMappedBuf.put(dst); inChannel.close(); outChannel.close(); } /** * 直接利用通道进行传输，将源通道中的数据传输到目标通道中去。 */ @Test public void test3() throws IOException { FileChannel inChannel = FileChannel.open(Paths.get(\"img/mm.jpg\"), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(\"img/mm2.jpg\"), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE); inChannel.transferTo(0, inChannel.size(), outChannel); // 把输入管道的数据传到输出管道中去// outChannel.transferFrom(inChannel,0,inChannel.size()); // 从输入管道中传输数据到输出管道中来 outChannel.close(); inChannel.close(); }} RandomAccessFile 类在某些应用场景，我们需要在一个数据流中的末尾插入数据，通常的方式是先把文件全部读取出来，再用插入的数据拼接到末尾，然后重新写入。但是当数据量特别大时，内存占用会特别的高甚至溢出。 RandomAccessFile是Java中输入，输出流体系中功能最丰富的文件内容访问类，它提供很多方法来操作文件，包括读写支持，与普通的IO流相比，它最大的特别之处就是支持任意访问的方式，程序可以直接跳到任意地方来读写数据。如果我们只希望访问文件的部分内容，而不是把文件从头读到尾，使用RandomAccessFile将会带来更简洁的代码以及更好的性能。 通过用例练习RandomAccessFile： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class TestRandomAccessFile { /** * 读取任意位置的文件内容 * &lt;p&gt; * r 代表以只读方式打开指定文件 * rw 以读写方式打开指定文件 * rws 读写方式打开，并对内容或元数据都同步写入底层存储设备 * rwd 读写方式打开，对文件内容的更新同步更新至底层存储设备 */ @Test public void randomReadFile() throws IOException { RandomAccessFile read = new RandomAccessFile(\"src/subject_1/TestBuffer.java\", \"r\"); System.out.println(\"文件指针初始位置：\" + read.getFilePointer()); read.seek(1000); // 将指针定位到某个位置 FileChannel readChannel = read.getChannel(); // 从指定位置开始读取，获得通道 ByteBuffer buffer = ByteBuffer.allocate(1024); // 创建缓冲区，可以将容量设为通道大小`(int) readChannel.size()`这样就不用循环读取 // 控制台打印的同时还将数据传输到输出通道 RandomAccessFile write = new RandomAccessFile(\"src/subject_1/TestBuffer.txt\", \"rw\"); FileChannel writeChannel = write.getChannel(); while (readChannel.read(buffer) != -1) { // 不断的将输入通道中的数据读取到缓冲区 buffer.flip(); // 开启读取模式，读取完毕之后 position 到了数据末尾，进行下一次读取。 System.out.println(new String(buffer.array(), 0, buffer.limit())); writeChannel.write(buffer); buffer.clear(); } } /** * 追加数据到文件的指定位置 */ @Test public void randomWriteFile() throws IOException { RandomAccessFile write = new RandomAccessFile(\"src/subject_1/TestBuffer.txt\", \"rw\"); write.seek(write.length()); // 将文件指针移动到末尾 write.write(\"---------&lt; this is append content &gt;--------\".getBytes()); } /** * 在任意处插入数据，如果不将插入点之后的数据备份的话，插入的数据会覆盖插入点之后的数据。 * &lt;p&gt; * - 将插入点之后的数据存入临时文件 * - 将数据插入到插入点 * - 将临时文件中的内容插入到旧文件 */ @Test public void randomReadWriteFile() throws IOException { File tempFile = File.createTempFile(\"src/subject_1/tmp\", \"txt\", null); tempFile.deleteOnExit(); // JVM退出时删除 // 建立临时文件的输入输出通道 FileChannel temInChannel = new FileInputStream(tempFile).getChannel(); FileChannel temOutChannel = new FileOutputStream(tempFile).getChannel(); RandomAccessFile target = new RandomAccessFile(\"src/subject_1/target.txt\", \"rw\"); int seekIndex = 1210; // 插入点 target.seek(seekIndex); FileChannel targetChannel = target.getChannel(); // 将目标文件插入点之后的数据创建通道传输到临时文件中的通道 temOutChannel.transferFrom(targetChannel, 0, targetChannel.size()); // 指针回到插入点，插入数据。 target.seek(seekIndex); target.write(\"[ this is append content ]\\n\".getBytes()); // 复制插入点之后的数据.读取临时文件通道中的数据，将临时文件通道数据传输到目标文件通道。如果能读取到说明数据传输成功 ByteBuffer buffer = ByteBuffer.allocate(2048); while (temInChannel.read(buffer) != -1) { buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.limit())); targetChannel.write(buffer); buffer.clear(); } }} 分散和聚集分散读取（Scattering Reads）是指从 Channel 中读取的数据“分散”到多个 Buffer 中（按照缓冲区的顺序，从 Channel 中读取的数据依次将 Buffer 填满）。 聚集写入（Gathering Writes）是指将多个 Buffer 中的数据“聚集”到 Channel（按照缓冲区的顺序，写入 position 和 limit 之间的数据到 Channel）。 12345678910111213141516171819202122232425public class ScatterAndGather { /** * 分散读取与聚集写入 */ @Test public void test1() throws IOException { RandomAccessFile file = new RandomAccessFile(\"src/subject_1/target.txt\", \"rw\"); FileChannel channel = file.getChannel(); // 分配两个缓冲区 ByteBuffer buf1 = ByteBuffer.allocate(100); ByteBuffer buf2 = ByteBuffer.allocate((int) channel.size() - 100); // 分散读取到缓冲区 ByteBuffer[] buffers = {buf1, buf2}; channel.read(buffers); // 将输入通道的中的数据依次分散读取到不同的缓冲区 for (ByteBuffer buffer : buffers) { buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.limit())); System.out.println(\"-----&lt; 分割 &gt;-----\"); } // 聚集写入到文件 FileChannel bakChannel = new RandomAccessFile(\"src/subject_1/target_bak.txt\", \"rw\").getChannel(); bakChannel.write(buffers); }} 字符集 Charset123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class TestCharset { /** * 查看支持的所有字符集 */ @Test public void test1() { SortedMap&lt;String, Charset&gt; map = Charset.availableCharsets(); Set&lt;Map.Entry&lt;String, Charset&gt;&gt; set = map.entrySet(); Iterator&lt;Map.Entry&lt;String, Charset&gt;&gt; iterator = set.iterator(); while (iterator.hasNext()) { Map.Entry&lt;String, Charset&gt; entry = iterator.next(); System.out.println(entry.getKey() + \" &lt;&gt; \" + entry.getValue()); } System.out.println(\"defaultCharset: \" + Charset.defaultCharset()); } /** * 编码：字符 -&gt; 字节数组 * 解码：字节数组 -&gt; 字符 */ @Test public void test2() throws CharacterCodingException { // 以指定编码加载字符集 Charset gbk = Charset.forName(\"GBK\"); Charset utf8 = Charset.forName(\"UTF-8\"); // 创建编码器 CharsetEncoder gbkEncoder = gbk.newEncoder(); CharsetEncoder utf8Encoder = utf8.newEncoder(); // 创建解码器 CharsetDecoder utf8Decoder = utf8.newDecoder(); CharsetDecoder gbkDecoder = gbk.newDecoder(); // 将数据放到缓冲区 CharBuffer buffer = CharBuffer.allocate(1024); buffer.put(\"测试编码解码\"); // 对字符使用 GBK 编码，切换到读模式，指针从0开始。 buffer.flip(); ByteBuffer byteBuffer = gbkEncoder.encode(buffer); // ByteBuffer byteBuffer = utf8Encoder.encode(buffer); // 使用 UTF8 编码 for (int i = 0; i &lt; byteBuffer.limit(); i++) { System.out.println(byteBuffer.get()); } // 使用 GBK 解码 byteBuffer.flip(); CharBuffer cb = gbkDecoder.decode(byteBuffer); System.out.println(new String(cb.array(), 0, cb.limit())); // 使用 UTF8 解码，失败 byteBuffer.flip(); CharBuffer cb1 = utf8Decoder.decode(byteBuffer); System.out.println(new String(cb1.array(), 0, cb1.limit())); }} NIO 的非阻塞式网络通信 传统的 IO 流都是阻塞式的。也就是说，当一个线程调用 read() 或 write() 时，该线程被阻塞，直到有一些数据被读取或写入，该线程在此期间不能执行其他任务。因此，在完成网络通信进行 IO 操作时，由于线程会阻塞，所以服务器端必须为每个客户端都提供一个独立的线程进行处理，当服务器端需要处理大量客户端时，性能急剧下降。Java NIO 是非阻塞模式的。当线程从某通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务。线程通常将非阻塞 IO 的空闲时间用于在其他通道上执行 IO 操作，所以单独的线程可以管理多个输入和输出通道。因此，NIO 可以让服务器端使用一个或有限几个线程来同时处理连接到服务器端的所有客户端。 通过用例代码验证阻塞式网络通信： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class BlockingNioTest { /** * 客户端：发送数据 */ @Test public void client() throws IOException, InterruptedException { // 打开网络IO通道 SocketChannel socketChannel = SocketChannel.open(new InetSocketAddress(\"localhost\", 1998)); // 读模式打开本地传输文件通道 FileChannel inChannel = FileChannel.open(Paths.get(\"img/mm.jpg\"), StandardOpenOption.READ); // 传输 ByteBuffer buffer = ByteBuffer.allocate(1024); while (inChannel.read(buffer) != -1) { buffer.flip(); socketChannel.write(buffer); buffer.clear(); } /** * 接收服务端反馈信息 * 调用 read()/write() 方法当前线程会进入阻塞状态，如果不强制停止write，不会进行下面的操作。 */ socketChannel.shutdownOutput(); while (socketChannel.read(buffer) != -1) { System.out.println(\"接收服务器反馈中...\"); buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.limit())); buffer.clear(); } inChannel.close(); socketChannel.close(); } /** * 服务器端：接收数据 */ @Test public void server() throws IOException { // 打开网络IO通道 ServerSocketChannel ssChannel = ServerSocketChannel.open(); // 绑定连接，进入阻塞状态 ssChannel.bind(new InetSocketAddress(\"localhost\", 1998)); // 获取客户端的连接通道 System.out.println(\"服务端等待获取客户端连接通道...\"); SocketChannel socketChannel = ssChannel.accept(); System.out.println(\"成功获取到客户端连接通道！\"); // 从客户端连接通道读取数据到本地 FileChannel outChannel = FileChannel.open(Paths.get(\"src/subject_2/mm.jpg\"), StandardOpenOption.WRITE, StandardOpenOption.CREATE); // 传输 ByteBuffer buffer = ByteBuffer.allocate(1024); while (socketChannel.read(buffer) != -1) { buffer.flip(); outChannel.write(buffer); buffer.clear(); } /*发送反馈信息给客户端*/ buffer.put(\"[服务端]：消息接收成功！\".getBytes()); buffer.flip(); socketChannel.write(buffer); outChannel.close(); socketChannel.close(); ssChannel.close(); }} 选择器(Selector)选择器（Selector） 是 SelectableChannle 对象的多路复用器，Selector 可以同时监控多个 SelectableChannel 的 IO 状况，也就是说，利用 Selector 可使一个单独的线程管理多个Channel。Selector 是非阻塞 IO 的核心。 java.nio.channels.Channel 接口： |--SelectableChannel |--SocketChannel |--ServerSocketChannel |--DatagramChannel |--Pipe.SinkChannel |--Pipe.SourceChannel 非阻塞式IO及选择器的用例说明： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class NonBlockingNioTest { @Test public void client() throws IOException { SocketChannel sChannel = SocketChannel.open(new InetSocketAddress(\"localhost\", 1998)); sChannel.configureBlocking(false); //切换非阻塞模式 ByteBuffer buf = ByteBuffer.allocate(1024); buf.put((new Date().toString()).getBytes()); buf.flip(); sChannel.write(buf); buf.clear(); sChannel.close(); } @Test public void server() throws IOException { ServerSocketChannel ssChannel = ServerSocketChannel.open(); ssChannel.configureBlocking(false); // 服务端通道切换非阻塞模式 ssChannel.bind(new InetSocketAddress(1998)); Selector selector = Selector.open(); // 获取选择器 /* * 将服务器通道注册到选择器上, 并且指定“监听接收事件”。 * - 读: SelectionKey.OP_READ * - 写: SelectionKey.OP_WRITE * - 连接: SelectionKey.OP_CONNECT * - 接收: SelectionKey.OP_ACCEPT */ ssChannel.register(selector, SelectionKey.OP_ACCEPT); // 轮询式的获取选择器上已经“准备就绪”的事件 while (selector.select() &gt; 0) { // 获取当前选择器中所有注册的“选择键(已就绪的监听事件)” Iterator&lt;SelectionKey&gt; it = selector.selectedKeys().iterator(); while (it.hasNext()) { SelectionKey sk = it.next(); // 获取准备“就绪”的事件 if (sk.isAcceptable()) { // 若事件是 “接收就绪”，获取客户端连接 SocketChannel sChannel = ssChannel.accept(); sChannel.configureBlocking(false); // 客户端切换非阻塞模式 sChannel.register(selector, SelectionKey.OP_READ); // 将客户端通道注册到选择器上 } else if (sk.isReadable()) { // 获取当前选择器上“读就绪”状态的通道 SocketChannel sChannel = (SocketChannel) sk.channel(); ByteBuffer buf = ByteBuffer.allocate(1024); int len = 0; while ((len = sChannel.read(buf)) &gt; 0) { buf.flip(); System.out.println(new String(buf.array(), 0, len)); buf.clear(); } } it.remove(); // 取消选择键 SelectionKey } } }} SocketChannel、ServerSocketChannel、DatagramChannelJava NIO中的SocketChannel是一个连接到TCP网络套接字的通道。操作步骤： 打开 SocketChannel 读写数据 关闭 SocketChannel Java NIO中的 ServerSocketChannel 是一个可以监听新进来的TCP连接的通道，就像标准IO中的ServerSocket一样。 Java NIO中的DatagramChannel是一个能收发UDP包的通道。操作步骤： 打开 DatagramChannel 接收/发送数据 管道(Pipe)Java NIO 管道是2个线程之间的单向数据连接。Pipe有一个source通道和一个sink通道。数据会被写到sink通道，从source通道读取。 1234567891011121314151617181920public class PipTest { @Test public void test1() throws IOException { Pipe pipe = Pipe.open(); // 获取管道 ByteBuffer buf = ByteBuffer.allocate(1024); // 将缓冲区中的数据写入管道 Pipe.SinkChannel sinkChannel = pipe.sink(); buf.put(\"通过单向管道发送数据\".getBytes()); buf.flip(); sinkChannel.write(buf); Pipe.SourceChannel sourceChannel = pipe.source(); // 读取缓冲区中的数据 buf.flip(); int len = sourceChannel.read(buf); System.out.println(new String(buf.array(), 0, len)); sourceChannel.close(); sinkChannel.close(); }} Java NIO2 (Path、Paths 与 Files )java.nio.file.Path 接口代表一个平台无关的平台路径，描述了目录结构中文件的位置。 Paths 提供的 get() 方法用来获取 Path 对象： Path get(String first, String … more) : 用于将多个字符串串连成路径。 方法 描述 boolean endsWith(String path) 判断是否以 path 路径结束 boolean startsWith(String path) 判断是否以 path 路径开始 boolean isAbsolute() 判断是否是绝对路径 Path getFileName() 返回与调用 Path 对象关联的文件名 Path getName(int idx) 返回的指定索引位置 idx 的路径名称 int getNameCount() 返回Path 根目录后面元素的数量 Path getParent() 返回Path对象包含整个路径，不包含 Path 对象指定的文件路径 Path getRoot() 返回调用 Path 对象的根路径 Path resolve(Path p) 将相对路径解析为绝对路径 Path toAbsolutePath() 作为绝对路径返回调用 Path 对象 String toString() 返回调用 Path 对象的字符串表示形式 java.nio.file.Files 用于操作文件或目录的工具类。 方法 描述 Path copy(Path src, Path dest, CopyOption … how) 文件的复制 Path createDirectory(Path path, FileAttribute&lt;?&gt; … attr) 创建一个目录 Path createFile(Path path, FileAttribute&lt;?&gt; … arr) 创建一个文件 void delete(Path path) 删除一个文件 Path move(Path src, Path dest, CopyOption…how) 将 src 移动到 dest 位置 long size(Path path) 返回 path 指定文件的大小 boolean exists(Path path, LinkOption … opts) 判断文件是否存在 boolean isDirectory(Path path, LinkOption … opts) 判断是否是目录 boolean isExecutable(Path path) 判断是否是可执行文件 boolean isHidden(Path path) 判断是否是隐藏文件 boolean isReadable(Path path) 判断文件是否可读 boolean isWritable(Path path) 判断文件是否可写 boolean notExists(Path path, LinkOption … opts) 判断文件是否不存在 SeekableByteChannel newByteChannel(Path path, OpenOption…how) 获取与指定文件的连接 DirectoryStream newDirectoryStream(Path path) 打开 path 指定的目录 InputStream newInputStream(Path path, OpenOption…how) 获取 InputStream 对象 OutputStream newOutputStream(Path path, OpenOption…how) 获取 OutputStream 对象 自动资源管理 Java 7 增加了一个新特性，该特性提供了另外一种管理资源的方式，这种方式能自动关闭文件。这个特性有时被称为自动资源管理(Automatic Resource Management, ARM)， 该特性以 try 语句的扩展版为基础。自动资源管理主要用于，当不再需要文件（或其他资源）时，可以防止无意中忘记释放它们。 语法： try( 需要关闭的资源声明 ){ //可能发生异常的语句 }catch( 异常类型 变量名 ){ //异常的处理语句 } …… finally{ //一定执行的语句 } 当 try 代码块结束时，自动释放资源。因此不需要显示的调用 close() 方法。该形式也称为“带资源的 try 语句”。注意： try 语句中声明的资源被隐式声明为 final ，资源的作用局限于带资源的 try 语句 可以在一条 try 语句中管理多个资源，每个资源以“;” 隔开即可。 需要关闭的资源，必须实现了 AutoCloseable 接口或其自接口 Closeable 12345678910111213public class TestNIO_2 { //自动资源管理：自动关闭实现 AutoCloseable 接口的资源 @Test public void test(){ try(FileChannel inChannel = FileChannel.open(Paths.get(\"1.jpg\"), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(\"2.jpg\"), StandardOpenOption.WRITE, StandardOpenOption.CREATE)){ ByteBuffer buf = ByteBuffer.allocate(1024); inChannel.read(buf); }catch(IOException e){} }}","link":"/2018/09/07/NIO/"},{"title":"算法第一章 基础","text":"第一章 基础基础编程模型格式化输出从标准输出流中打印随机生成的数值，“%.2f\\n”表示输出两位小数精度的浮点型数值并换行。 cmd运行需要注意的几个地方： 我们的工程一般使用utf-8编码，但是windows系统默认gbk编码，所以编译javac会出现“找不到gbk编码的字符映射”。解决办法：编译时指定参数 -encoding utf-8 “找不到某个类”，程序中引用了非当前目录的jar文件，在本路径编译会找不到jar包，需要执行参数：-Djava.ext.dirs=jar包作为路径。 “无法运行主类”，检查是否配置了classpath环境变量，CLASSPATH=&quot;.;%JAVA_HOME%\\lib;%JAVA_HOME%\\lib\\tools.jar;&quot; 如果被编译类有包，需要在该包下执行编译和运行，最终该类的编译和运行命令： javac -Djava.ext.dirs=D:\\IdeaProjects\\Algorithms\\lib -encoding utf-8 chapter_1/programming_model/RandomSeq.java java -Djava.ext.dirs=D:\\IdeaProjects\\Algorithms\\lib chapter_1/programming_model/RandomSeq 10 1 100 12345678910111213public class RandomSeq { public static void main(String[] args) { // 打印n个(lo,hi)之间的随机值 int N = Integer.parseInt(args[0]); double lo = Double.parseDouble(args[1]); double hi = Double.parseDouble(args[2]); for (int i = 0; i &lt; N; i++) { // 返回随机实数 double x = StdRandom.uniform(lo, hi); StdOut.printf(\"%.2f\\n\", x); } }} 注意：java要求参数的数据类型和转换代码表示的数据类型必须相同，printf()的第一个String字符串也可以包含其他字符。所有非格式的字符串会被传递到输出之中，而格式化的字符串则会被参数的值所代替。例如： 1Std.printf(\"PI is %.2f\\n\",Math.PI); 会打印出：PI is 3.14 标准输入特点标准输入流最重要的特点就是这些值会在程序读取之后消失，程序读取了就不能回退再次读取。 重定向与管道使输出重定向到一个文件中，而不是终端打印：java RandomSeq 1000 100.0 200.0 &gt; data.txt，每次打印都会向文件追加内容。 从文件读取输入流而不是等待用户输入，“&lt;”是一个操作符，它告诉系统从文件中作为输入流而不是等终端用户输入。java Average &lt; data.txt 将一个程序的输出重定向为一个程序的输入叫做管道。java RandomSeq 1000 100.0 200.0 | Java Average，该命令将RandomSeq的标准输出和Average的标准输入指定为了同一个流。看起来的效果就是Average运行时从RandomSeq的输出作为了自己的输入。这种写法的好处在于它能够突破输入输出流长度的限制，有效的利用了系统资源。RandomSeq调用了printf()时，向输入流末尾添加了一条字符串；Average调用readDouble()时，就从输入流开头删除了一个字符串。 二分查找读取终端输入流中的值，如果该值在指定文件中不存在则返回这个值，否则不返回。 1234567891011121314151617181920212223242526272829303132333435363738public class BinarySearch { public static int rank(int key, int[] arr) { // 使用lo和hi变量保证key一定在arr[lo...hi]中 int lo = 0; int hi = arr.length - 1; for (int i = 0; i &lt; hi; i++) { // 取中间值索引，当查找的范围在左边，lo始终为0，当查找的范围在右边，中间值索引就是起始值索引+前后折半的值 int mid = lo + (hi - lo) / 2; // 小于中间值，查找范围缩小到左边 if (key &lt; arr[i]) { hi = mid - 1; } // 大于中间值，查找范围缩小到右边 if (key &gt; arr[i]) { lo = mid + 1; } else { return i; } } return -1; } public static void main(String[] args) { long start = System.currentTimeMillis(); // Reads all integers from a file and returns them as an array of integers. argument：filename int[] whitelist = In.readInts(args[0]); Arrays.sort(whitelist); while (!StdIn.isEmpty()) { // Reads the next token from standard input, parses it as an integer, int key = StdIn.readInt(); if (rank(key, whitelist) &lt; 0) { StdOut.println(key); } } long end = System.currentTimeMillis(); StdOut.println(\"time-&gt;:\" + (end - start)); }} 命令行参数： 编译忽略过期警告： javac -Djava.ext.dirs=D:\\IdeaProjects\\Algorithms\\lib -Xlint:deprecation -encoding utf-8 chapter_1/programming_model/BinarySearch.java 运行：传入一个文件路径，等待用户输入，比较输入的值是否在文件中存在 java -Djava.ext.dirs=D:\\IdeaProjects\\Algorithms\\lib chapter_1/programming_model/BinarySearch D:\\IdeaProjects\\Algorithms\\algs4-data\\tinyW.txt 运行：传入一个文件路径，指定输入流来源于文件，从tinyT.txt中作为输入流，比较tinyT.txt里的每个值是否在tinyW.txt中存在 java -Djava.ext.dirs=D:\\IdeaProjects\\Algorithms\\lib chapter_1/programming_model/BinarySearch D:\\IdeaProjects\\Algorithms\\algs4-data\\tinyW.txt &lt; D:\\IdeaProjects\\Algorithms\\algs4-data\\tinyT.txt 数据抽象背包、队列和栈背包（Bag）是一种不支持从中删除元素的数据类型，其主要目的用来帮助用例（应用程序）收集元素并迭代遍历搜集到的所有元素（检查背包是否为空，或获取背包中元素的数量）。使用背包说明元素的处理是无序的。 典型用例：计算标准输入中所有double值的平均值和标准差 1234567891011121314151617181920212223public class Stats { public static void main(String[] args) { Bag&lt;Double&gt; numbers = new Bag&lt;Double&gt;(); while (!StdIn.isEmpty()) { numbers.add(StdIn.readDouble()); } int N = numbers.size(); double sum = 0.0; for (double x : numbers) { sum += x; } double mean = sum / N; sum = 0.0; for (double x : numbers) { sum += (x - mean) * (x - mean); } double std = Math.sqrt(sum / N - 1); StdOut.printf(\"Mean: %.2f\\n\", mean); StdOut.printf(\"Std dec: %.2f\\n\", std); }} 队列（Queue）是一种基于先进先出（FIFO）策略的集合类型。队列是许多日常现象的模型，也是无数应用程序的核心。 典型用例：读取文件中的所有数字并放入数组中，使用队列和好处在于用例无需知道文件中的数字的大小即可将文件中的所有数字放入数组中，首先将文件中的所有数字按顺序放入队列中，再从队列中按顺序一个一个取出放入数组，队列中元素的顺序就是文件中数字的顺序。 1234567891011121314151617181920public class QueueDemo { public static int[] readInts(String name) { In in = new In(name); Queue&lt;Integer&gt; q = new Queue&lt;&gt;(); while (!in.isEmpty()) { q.enqueue(in.readInt()); } int N = q.size(); int[] a = new int[N]; for (int i = 0; i &lt; N; i++) { a[i] = q.dequeue(); } return a; } public static void main(String[] args) { readInts(args[0]); }} 下压栈（栈、Stack）是一种基于后进先出（LIFO）策略的集合类型。生活中常见的后进先出策略的例子比如：桌面上放成一叠的邮件，当收信时将邮件压入（push）最顶端，取信时从最顶端将其弹出（pop）。这种策略好处在于我们能够及时的看到最新的邮件，坏处就是当没有清理栈时，某些较早的邮件永远不会被阅读。 典型用例：用元素保存集合的同时颠倒他们的顺序，Reverse会把标准输入中的所有整数逆序排列。 123456789101112public class Reverse { public static void main(String[] args) { Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); while (!StdIn.isEmpty()) { stack.push(StdIn.readInt()); } for (int i : stack) { StdOut.println(i); } }} 栈的典型用例：双栈算术表达式求值算法编写一个算法来模拟系统运算算术表达式： ( 1 + ( ( 2 + 3 ) * ( 4 * 5 ) ) ) ，输入一个表达式字符串，为了简化问题，我们假设表达式只由运算符+、-、*、/，小括号，和数字组成，并且每个元素之间都用一个空格隔开。 双栈算术表达式求值算法核心利用了用两个栈：一个保存运算符、一个保存操作数。处理逻辑如下： 当遇到操作数将操作数压入操作数栈 当遇到运算符将运算符压入运算符栈 忽略左括号 当遇到右括号时，弹出一个运算符，弹出所需数量的操作数，并将操作数和运算符的运算结果压入操作数栈 123456789101112131415161718192021222324252627282930313233343536373839404142public class Evaluate { public static void main(String[] args) { Stack&lt;String&gt; ops = new Stack&lt;&gt;(); Stack&lt;Double&gt; vals = new Stack&lt;&gt;(); while (!StdIn.isEmpty()) { // 循环读取每一个操作符，如果是运算符则压入运算符栈 String s = StdIn.readString(); if (s.equals(\"(\")) { } else if (s.equals(\"+\")) { ops.push(s); } else if (s.equals(\"-\")) { ops.push(s); } else if (s.equals(\"*\")) { ops.push(s); } else if (s.equals(\"/\")) { ops.push(s); } else if (s.equals(\"sqrt\")) { ops.push(s); } else if (s.equals(\")\")) { // 如果运算符为 ） ，弹出运算符和操作数，计算结果并压入操作数栈 String op = ops.pop(); double v = vals.pop(); // 弹出栈顶的操作数。弹出栈元素是在栈中删除了的 if (op.equals(\"+\")) { v = vals.pop() + v; // 再弹出一个栈顶操作数，与前面弹出的栈顶操作数（v）做运算并重新赋值给变量v } else if (op.equals(\"-\")) { v = vals.pop() - v; // 第二次弹出的操作数在前，第一次弹出的操作数在后。因为先进栈的操作数后弹出，后进栈的元素先弹出 } else if (op.equals(\"*\")) { v = vals.pop() * v; } else if (op.equals(\"/\")) { v = vals.pop() / v; } else if (op.equals(\"sqrt\")) { v = Math.sqrt(v); } vals.push(v); // 运算后的值入栈，进行运算的两个操作数被弹出（删除）了。 } else { // 如果既不是运算符也不是括号，则就是数字，将其压入数值栈。 vals.push(Double.parseDouble(s)); } } StdOut.println(vals.pop()); }} 求值算法轨迹图： 集合类数据类型的实现基于顺序存储结构的集合类型实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class ResizingArrayStack&lt;Item&gt; implements Iterable&lt;Item&gt; { private Item[] a; private int N; public ResizingArrayStack(int cap) { a = (Item[]) new Object[cap]; } public void push(Item item) { if (N == a.length) { resize(a.length * 2); } a[N++] = item; } public Item pop() { Item item = a[--N]; a[N] = null; if (N &gt; 0 &amp;&amp; N == a.length / 4) { resize(a.length / 2); } return item; } public boolean isEmpty() { return N == 0; } public int size() { return N; } public void resize(int max) { Item[] temp = (Item[]) new Object[max]; for (int i = 0; i &lt; N; i++) { temp[i] = a[i]; } a = temp; } @Override public Iterator&lt;Item&gt; iterator() { return new ReverseArrayStack&lt;&gt;(); } private class ReverseArrayStack&lt;Item&gt; implements Iterator&lt;Item&gt; { private int i = N; @Override public boolean hasNext() { return i == 0; } @Override public Item next() { return (Item) a[--i]; } }} 基于链式存储结构的集合类型实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class LinkedStack&lt;Item&gt; implements Iterable&lt;Item&gt; { private Node first; private int N; private class Node&lt;Item&gt; { private Item item; private Node next; } private class listIterator&lt;Item&gt; implements Iterator&lt;Item&gt; { private Node currentNode = first; @Override public boolean hasNext() { return currentNode != null; } @Override public Item next() { Item item = (Item) currentNode.item; currentNode = currentNode.next; return item; } } public void push(Item item) { Node oldFirst = first; first = new Node&lt;&gt;(); first.item = item; first.next = oldFirst; N++; } public Item pop() { Node&lt;Item&gt; oldFirst = first; first = first.next; N--; return oldFirst.item; } public boolean isEmpty() { return first == null; } public int size() { return N; } @Override public Iterator&lt;Item&gt; iterator() { return new listIterator&lt;&gt;(); }} 123456789101112131415161718192021222324public class LinkedQueue&lt;Item&gt; implements Iterable { // ...... public void enqueue(Item item) { Node&lt;Item&gt; oldLast = last; last = new Node(); last.item = item; if (isEmpty()) { first = last; } else { oldLast.next = last; } N++; } public Item dequeue() { Node&lt;Item&gt; oldFirst = first; first = first.next; if (isEmpty()) { last = null; } N--; return oldFirst.item; }} 更多拓展在练习题： 下压栈： 补全表达式转为中序表达式 中序表达式转后序表达式 后序表达式求值实现简单计算器 队列： 读取倒数第K个字符串 链表： LinkedStackExercise.java 双向链式存储结构集合数据类型实现： Ex31_DoubleLinkedStack.java 随机背包： Ex34_RandomBag.java Josephus生存游戏： Ex37_Josephus.java 可连接队列、栈： Ex47.java 算法分析案例研究：并查集（union-find）算法问题由来 —— 动态连通性问题： 程序从输入中每次读取一对整数 P 和 Q ，如果已知的所有整数对不能证明他们是“相连”的，那么把他们“连起来”，并打印；如果能证明他们是相连的则不处理，继续读取下一对整数对。当两个对象（整数点）相连时称为属于一个等价类。 概念：如果两个对象“相连”是一种等价关系，那么它具有以下特性： 自反性：P和P是相连的（就是一个点和自己本身是相连的，em…）； 对称性：若P和Q是相连的，那么Q和P也是相连的； 传递性：若P和Q相连且Q和R相连，那么P和R是相连的 理解并查集以上问题其实就是并查集的一个具体案例，关于并查集，解释如下： 并查集，在一些有N个元素的集合应用问题中，我们通常是在开始时让每个元素构成一个单元素的集合，然后按一定顺序将属于同一组的元素所在的集合合并，其间要反复查找一个元素在哪个集合中。 “并查集”是一种不相交集合的数据类型，初始时并查集中的元素是不相交的，经过一系列的基本操作(Union)，最终合并成一个大的集合。 API 初始化触点 连接触点 某个触点所在的连通分量 判断两个触点是否在同一个连通分量之中 返回连通分量的数量 123456789101112131415161718192021public interface UF { /** * 连接P和Q */ void union(int p, int q); /** * p所在分量（相等整数对）的标识符 */ int find(int p); /** * p和q存在同一分量返回true */ boolean connected(int p, int q); /** * 分量的个数 */ int count();} 实现一：quick-find 算法数据结构：数组 用数组 id[] 表示每一个触点的值，数组索引表示触点，触点的值就是分量的值，触点值相同表明分量相同。 初始化时每个触点的值都是该触点的索引。 比如：触点0 = id[0] = 0; 触点1 = id[1] = 1; 触点3 = id[3] = 3; 多个触点属于同一个连通分量时，其中某个触点的值“代表”该连通分量的值，把其他触点的值统一成所属分量的代表值，比如： 要把id[4] (值为4) 和 id[8] (值为8) 相连为同一分量，可以把id[4]的值改成id[8]的值，那么把 id[8] 值称为该连通分量的代表（或标识符或值）；也可以把id[8]的值改成id[4]的值，连通分量的值就是id[4]了。 要把id[5] (值为5) 和 id[4] (假设所属分量值为8) 相连为同一分量，连通分量的值以id[5]为代表，那么所有值为 8 的分量的值都改成了 5。 连通分量中的所有触点的值是统一的。 算法分析可以快速进行 find 操作，即可以快速判断两个节点是否连通。 同一连通分量的所有节点的 id 值相等。 但是 union 操作代价却很高，需要将其中一个连通分量中的所有节点 id 值都修改为另一个节点的 id 值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class QuickFind implements UF { private int[] id; // 连通分量标识符集合 private int count; // 连通分量数量 /** * 初始化所有连通分量 */ QuickFind(int N) { count = N; id = new int[N]; for (int i = 0; i &lt; count; i++) { id[i] = i; } } @Override public void union(int p, int q) { int pID = find(p); int qID = find(q); if (pID == qID) { // 已经在同一个分量中不做处理 return; } for (int i = 0; i &lt; count; i++) { if (id[i] == pID) { id[i] = qID; } count--; } } @Override public int find(int p) { return id[p]; } @Override public boolean connected(int p, int q) { return id[p] == id[q]; } @Override public int count() { return count; }} 实现二：quick-union 算法数据结构：树 同样以 id[] 表示每一个节点（触点）的值，但节点的值不是分量的值，每一个节点值是以其父节点的索引号的id[]值，该节点最终的值是根节点的值（父节点指向父节点，直到指向根节点）。 比如节点4（id[4]=9） 是 节点8 的父节点，那么节点8id[8]的值就是id[4]，即：id[8] = id[4] = 9 初始化时每个触点的值都是该触点的索引，并且都是根节点。 属于同一个连通分量的所有节点都属于同一颗数，判断是否属于同一分量需要判断是否属于同一棵树，我们可以把根节点代表分量的标识符。 两个节点的联合操作，操作的是两个节点的根节点，只需要将一个根节点的父节点设为另外一个根节点，这样两个节点（分量）联合成了一个节点（分量）。 比如：初始化时，每个节点都是根节点。 id[0] = 0; id[1] = 1; id[3] = 3; id[7] = 7 … 联合节点 0 和 1，将id[0]的父节点设为id[1]，即：id[0] = id[1] = 1 联合节点 3 和 0，将id[3]的父节点设为id[0]，即：id[3] = id[0] = id[1] = 1 联合节点 1 和 7，将id[1]的父节点设为id[7]，即：id[1] = id [7] = 7（此时id[3] = id[0] = id[1] = id [7] = 7） 算法分析可以快速进行 union 操作，只需要修改一个节点的 id 值即可。 union操作，固定的将左边的树链接到右边的树，导致树的深度很深，进行find()操作时效率变低。 但是 find 操作开销很大，因为同一个连通分量的节点 id 值不同，id 值只是用来指向另一个节点。因此需要一直向上查找操作，直到找到最上层的节点。 这种方法可以快速进行 union 操作，但是 find 操作和树高成正比，最坏的情况下树的高度为触点的数目。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class QuickUnion implements UF { private int[] id; // 树的每一个节点（触点） private int count; // 连通分量（根节点）的数量 QuickUnion(int N) { count = N; id = new int[N]; for (int i = 0; i &lt; count; i++) { id[i] = i; } } @Override public void union(int p, int q) { // 获取两个节点所属分量（根节点） int pRoot = find(p); int qRoot = find(q); if (pRoot == qRoot) { return; } // 把p的根节点的爸爸设为q的根节点，这样p和q就有了共同的爸爸。 id[pRoot] = qRoot; count--; } @Override public int find(int p) { // 当id[p]的值是本身，说明它是根节点（分量名）；若不是，向上循环找到根节点。 while (p != id[p]) { p = id[p]; } return p; // 所在分量就是根节点 } @Override public boolean connected(int p, int q) { return id[p] == id[q]; } @Override public int count() { return count; }} 轨迹图： 实现三：加权 quick-union 算法算法分析加权 quick-union 算法的出现是为了解决 quick-union 中find()操作随着树的深度加深成本变得越来越昂贵的问题。 不再固定的将左边的树链接到右边的树，而是根据树的深度（节点的个数）决定将深度小的树链接在深度大的树，由此降低find()操作次数。 数据结构 和 quick-union 结构相同，仅仅添加了一个用于记录每个分量个数的数组 不再是把p的根节点的爸爸设为q的根节点了，而是比较p的分量个数和q的分量个数，分量个数小的认分量个数大的当爸爸 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class WeightQuickUnion implements UF { private int[] id; // 每个触点的值是父链接 private int count; // 连通分量个数 private int[] sz; // 各个根节点对应的分量大小（节点个数） WeightQuickUnion(int N) { count = N; id = new int[N]; for (int i = 0; i &lt; count; i++) { id[i] = i; } // 初始化每个根节点对应分量的大小都是1 sz = new int[N]; for (int i = 0; i &lt; count; i++) { sz[i] = 1; } } @Override public void union(int p, int q) { int pRoot = find(p); int qRoot = find(q); if (pRoot == qRoot) { return; } // 不再是把p的根节点的爸爸设为q的根节点了，而是比较p的分量个数和q的分量个数，分量个数小的认分量个数大的当爸爸 if (sz[pRoot] &gt; sz[qRoot]) { id[qRoot] = pRoot; sz[pRoot] += sz[qRoot]; } else { // 当p分量大小 &lt;= q分量大小时，默认q的根节点认q的根节点当爸爸 id[pRoot] = qRoot; sz[qRoot] += sz[pRoot]; } count--; } @Override public int find(int p) { while (p != id[p]) { p = id[p]; } return p; } @Override public boolean connected(int p, int q) { return find(p) == find(q); } @Override public int count() { return count; }} 轨迹图： 实现四：路径压缩的加权 quick-union 算法算法分析路径压缩的加权 quick-union 算法是为了优化find()操作，减少查找父节点的次数，从而提升查找的效率； 使用路径压缩的加权 quick-union 算法是解决动态连通性问题的最优解； 它将每一个子节点都挂在根节点形成一个近似扁平的树状结构； 每次查找指定节点的根元素（分量）时，都将路径上（该节点的所有父节点）遇到所有节点挂在根节点之下； 压缩加权后的算法find()效率与 quick-find 的效率非常接近。 12345678910111213141516171819202122232425262728293031323334public class WeightQuickUnion implements UF { public int pathCompressionFind(int p) { // 先向上循环找到根节点 int root = p; while (root != id[root]) { root = id[root]; } // 再次循环，如果当前节点不是根节点，把当前节点挂在根节点上成为根节点的一级节点。 while (p != id[p]) { int tem = p; p = id[p]; id[tem] = root; } return root; } public void union(int p, int q) { int pRoot = pathCompressionFind(p); int qRoot = pathCompressionFind(q); if (pRoot == qRoot) { return; } // 不再是把p的根节点的爸爸设为q的根节点了，而是比较p的分量个数和q的分量个数，分量个数小的认分量个数大的当爸爸 if (sz[pRoot] &gt; sz[qRoot]) { id[qRoot] = pRoot; sz[pRoot] += sz[qRoot]; } else { // 当p分量大小 &lt;= q分量大小时，默认q的根节点认q的根节点当爸爸 id[pRoot] = qRoot; sz[qRoot] += sz[pRoot]; } count--; }}","link":"/2018/08/05/算法第一章 基础/"},{"title":"算法第二章 排序","text":"第二章 排序待排序的元素需要实现 Java 的 Comparable 接口，该接口有 compareTo() 方法，可以用它来判断两个元素的大小关系。 定义算法模板类API 1234567891011121314151617181920212223242526272829303132333435363738394041424344public abstract class Example { /** * 具体排序算法实现 */ public abstract void sort(Comparable[] a); /** * 对元素进行比较 * @return first &lt; second ? true : false */ public static boolean less(Comparable first, Comparable second) { return first.compareTo(second) &lt; 0; } /** * 把两个元素交换位置 */ public static void exch(Comparable[] a, int i, int j) { Comparable tem = a[i]; a[i] = a[j]; a[j] = tem; } /** * 返回序列是否有序（asc） */ public static boolean isSorted(Comparable[] a) { for (int i = 1; i &lt; a.length; i++) { if (less(a[i], a[i - 1])) { // 后面的元素 &lt; 前面的元素 不是升序排列 返回false return false; } } return true; } public static void show(Comparable[] a) { for (int i = 0; i &lt; a.length; i++) { StdOut.print(a[i] + \" \"); } StdOut.println(); }} 选择排序首先在数组中找到最小的元素，将其和第一个元素交换；然后继续在第一个元素之后的元素中寻找最小元素，将其和第二个元素交换… 循环往复直到将整个数组排序。 外循环遍历数组的每个当前元素 内循环遍历当前元素之后的所有元素寻找最小值 算法分析优点：数据移动次数最少，选择排序的交换次数和数组长度N成线性关系，其他排序算法不具备该特征。 缺点：运行时间与输入（整个序列的值）无关，一个值相同的或有序的序列和一个随机无序的序列进行排序的时间一样长。 123456789101112131415161718192021public class Selection extends Example { @Override public void sort(Comparable[] a) { int N = a.length; for (int i = 0; i &lt; N; i++) { int minIndex = i; for (int j = i + 1; j &lt; N; j++) { if (less(a[j], a[minIndex])) { minIndex = j; // 如果后续元素小于最小元素，把后续元素索引赋给最小元素索引。 } exch(a, i, minIndex); // 交换原最小元素与新最小元素位置 } } } public static void main(String[] args) { String[] a = new In().readAllStrings(); new Selection().sort(a); assert isSorted(a); // 验证：确认排序后的算法是有序的，当序列元素相同时无法通过验证。 show(a); }} 插入排序将当前元素插入到当前元素之前的合适位置 首先从数组的第二个元素（目标元素）开始，当目标元素小于前面的元素，交换两者位置（否则不变）；然后目标元素变为第三个元素，将其与第二个元素比较，若小则交换位置（此时目标元素索引为1），再将其与第一个元素对比，循环往复… 外循环遍历每一个需要插入的目标元素 内循环将目标元素与其左边的每一个元素对比、交换位置，直至目标元素被插入到了合适的位置。 目标元素（a[i]）从左到右移动时，其左侧的元素始终时有序的，当其移动到了最右边，数组也完成了排序。 算法分析插入排序所需的时间取决于数组中元素的初始位置。因为当元素有序时不会进行交换，对于一个元素很大的且元素有序（或接近有序）的序列进行排序会比随机顺序的序列进行排序要快得多。 12345678910111213public class Insertion extends Example { @Override public void sort(Comparable[] a) { int N = a.length; for (int i = 1; i &lt; N; i++) { // 将当前元素 a[i] 与 其左边的所有元素对比、交换位置 for (int j = i; j &gt; 0 &amp;&amp; less(a[j], a[j - 1]); j--) { // 后面的元素比前面的元素小才进行排序 exch(a, j, j - 1); } } }} 大幅度提高插入排序的速度，只需要在内循环中将较大的元素向右移动而不总是交换两个元素（这样访问数组的次数会减半），实现见 练习。 12345678910111213public class Ex25 extends Example { public void sort(Comparable[] a) { int n = a.length; for (int i = 1; i &lt; n; i++) { Comparable target = a[i]; // 保存目标元素的值 int j; // 保存目标元素应该插入的位置 for (j = i; j &gt; 0 &amp;&amp; less(target, a[j - 1]); j--) { a[j] = a[j - 1]; // 前驱元素后移 } a[j] = target; } }} 选择排序与插入排序比较从直观上来说： 选择排序不会访问索引左侧的元素（每次都是从目标元素的索引右边遍历所有元素取最小值进而与目标元素交换位置） 插入排序不会访问索引右侧的元素（每次都是目标元素与其左边的每一个元素做对比进而交换位置） 首先规定输入模型：数组中的元素随机排序，且主键值不重复。 速度对比： 1000条数据排序100次，选择排序花费0.4s，插入排序花费0.1s； 10000条数据排序100次，选择排序花费43.6s，插入排序花费10.2s； 结论： 对于随机排序的无重复主键，插入排序和选择排序的运行时间都是平方级别的。 123456789101112131415161718192021222324252627282930313233343536public class SortCompare { public static double time(String alg, Comparable[] a) { StopWatch watch = new StopWatch(); if (alg.equals(\"Insertion\")) { new Insertion().sort(a); } if (alg.equals(\"Selection\")) { new Selection().sort(a); } return watch.elapsedTime(); } //使用alg算法将长度为N的数组排序T次 public static double timeRandomInput(String alg, int N, int T) { double total = 0.0; Double[] a = new Double[N]; // 目标数组 for (int t = 0; t &lt; T; t++) { for (int i = 0; i &lt; N; i++) { a[i] = StdRandom.uniform(); // 生成随机值 } total += time(alg, a); // 计算T次时间总和 } return total; } public static void main(String[] args) { String alg1 = args[0]; String alg2 = args[1]; int N = Integer.parseInt(args[2]); int T = Integer.parseInt(args[3]); double t1 = timeRandomInput(alg1, N, T); // 算法1的总时间 double t2 = timeRandomInput(alg2, N, T); // 算法2的总时间 StdOut.printf(\"the %s algorithm takes %.1f seconds.\\n\", alg2, t2); StdOut.printf(\"the %s algorithm takes %.1f seconds.\\n\", alg1, t1); }} 希尔排序希尔排序是插入排序的增强版，是为了改进插入排序对于处理大规模乱序数组排序速度过慢的问题。实质上是分组插入排序，该方法又称缩小增量排序。 该方法的基本思想是：先将整个待排元素序列分割成若干个子序列（由相隔某个“增量”的元素组成的）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序。因为直接插入排序在元素基本有序的情况下（接近最好情况），效率是很高的，因此希尔排序在时间效率上比前两种方法有较大提高。 序列分组轨迹图： 参考：https://blog.csdn.net/IWantToHitRen/article/details/51583047 对于希尔排序和插入排序速度的对比： 10000条数据排序100次，插入排序用时12.3s，希尔排序用时0.3s!； 50000条数据排序100次，插入排序用时380.7s，希尔排序用时1.8s!； 以下是结合网上对希尔排序的理解实现的算法以及《算法 第四版》原文中的算法。 12345678910111213141516171819202122232425262728293031323334353637383940public class Shell extends Example { /** * 根据网上总结自己实现的算法 */ @Override public void sort(Comparable[] a) { int N = a.length; for (int gap = N / 2; gap &gt; 0; gap /= 2) { // gap：增量（步数），每次循环增量减少一倍，直至增量为1（此时对全部元素进行插入排序）完成排序。 for (int i = 0; i &lt; gap; i++) { // 把整体序列分为若干子序列。a[i]是每一组的第一个元素 for (int j = i + gap; j &lt; N; j += gap) { // 每间隔一个增量，获得一个该组的元素。 int tarIndex = j; // 目标元素索引，当前元素索引。 for (int k = tarIndex; k &gt; i &amp;&amp; less(a[k], a[k - gap]); k -= gap) { // 对子序列进行插入排序，将该元素与本组左边所有元素进行比较。 exch(a, k, k - gap); } } } } } /** * 原文的算法，增量使用了递增序列，有时间再来理解。 */ public void sort3(Comparable[] a) { int N = a.length; int h = 1; while (h &lt; N / 3) { h = 3 * h + 1; } while (h &gt;= 1) { // 子数组插入排序 for (int i = h; i &lt; N; i++) { for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j - h]); j -= h) { exch(a, j, j - h); } } h = h / 3; } }} 归并排序归并排序的核心是归并操作，归并排序每次将数组 递归的 拆分成两半分别排序，再将两半的结果 合并 起来最终实现整个数组的排序。 归并操作归并操作的前提是数组的两边是分别 有序 的，将一个“两边有序的数组”合并成一个“整体有序的数组”。 1234567891011121314151617181920212223242526public class Merge extends Example { private static Comparable aux[]; // 辅助数组，用于合并操作。 //TODO sort() public static void merge(Comparable[] a, Comparable[] aux, int lo, int mid, int hi) { int le = lo; int ri = mid + 1; for (int k = lo; k &lt;= hi; k++) { aux[k] = a[k]; } for (int k = lo; k &lt;= hi; k++) { if (le &gt; mid) { a[k] = aux[ri++]; // 左边元素用尽，将右边元素一个一个放入a[] } else if (ri &gt; hi) { a[k] = aux[le++]; // 右边元素用尽，将左边元素一个一个放入a[] } else if (less(aux[ri], aux[le])) { a[k] = aux[ri++]; // 右边元素小于左边元素，右边元素放入a[]，右边元素索引+1 } else { a[k] = aux[le++]; // 左边元素小于右边元素，左边元素放入a[]，左边元素索引+1 } } }} 自顶向下归并排序归并排序不断（递归）的将大数组插拆分为两半，直到不可再拆（小数组仅剩“左右”两个元素），再将两边的数组合并成一个整体有序的大数组。 1234567891011121314151617public class Merge extends Example { private static Comparable aux[]; // 辅助数组，用于合并操作。 @Override public void sort(Comparable[] a) { aux = new Comparable[a.length]; sort(a, 0, a.length - 1); } private void sort(Comparable[] a, int lo, int hi) { if (hi &lt;= lo) return; int mid = lo + (hi - lo) / 2; sort(a, lo, mid); // 左半边排序 sort(a, mid + 1, hi); // 右半边排序 merge(a, aux, lo, mid, hi); // 合并子数组 }} 每一个节点都是 merge() 操作形成的子数组。当数组不可再分（递归到了最小情况），merge()通过交换前后元素实现排序。 改进对于小规模数组使用插入排序 测试数组是否有序 有参考价值博客：图解排序算法(四)之归并排序 自底向上归并排序先归并微型数组，再成对归并得到的子数组，直到归并形成一个大数组，排序结束。 第一轮：将大数组的每一个元素当作一个子数组（最小的子数组），两两归并 子数组（将大小为1的子数组归并成大小为2的子数组）。 第二轮：一轮归并之后每个子数组存在 2 个元素，再 四四归并 子数组（将大小为2的子数组归并为大小为4的子数组）。 第三轮：二轮归并之后每个子数组存在 4 个元素，再 八八归并 子数组（将大小为4的子数组归并为大小为8的子数组）。 …… 如此往复，直到子数组大小 &gt;= 待排序的大数组，完成了排序。 123456789101112131415161718192021222324public class MergeBU extends Example { private static Comparable aux[]; @Override public void sort(Comparable[] a) { int N = a.length; aux = new Comparable[N]; for (int sz = 1; sz &lt; N; sz = sz + sz) { // 控制子数组大小呈倍数递增 /** * 遍历每个子数组 * lo 每个子数组的第一个元素 * lo &lt; N - sz 控制最后一个子数组的开头 * lo = lo + sz + sz 跳到下一个子数组开头 * Math.min(lo + sz + sz - 1, N - 1) 最后一个子数组的大小有可能不是sz的整数倍，lo + sz + sz - 1可能会出现数组越界。 */ for (int lo = 0; lo &lt; N - sz; lo = lo + sz + sz) { int mid = lo + sz - 1; int hi = Math.min(lo + sz + sz - 1, N - 1); merge(a, aux, lo, mid, hi); } } assert isSorted(a); }} 可视图： 快速排序快速排序同归并排序一样是一种分治的排序算法。它通过 切分 递归的将数组分为两个部分，对两个部分分别排序，并保证左边的元素都 &lt;= 切点，右边的元素都 &gt;= 切点。 每次切分都能保证子数组左边的元素小于切点，右边的元素大于切点。通过递归，对左半边和右半边数组再次切分，最终达到整个数组的有序。 切分算法： 切点定为子数组的第一个元素（可以是任意元素） 指针 i 从左往右扫描 大于 切点的值，找到即退出扫描；指针 j 从右往左扫描 小于 切点的值，找到即退出扫描。 交换 a[i] 与 a[j] 的位置，小的值放在左边，大的值放在右边。 若 i 扫描完毕找不到最大值，说明 切点 就是最大值；若 j 扫描完毕找不到最小值，说明 切点 就是最小值 为什么指针相遇(i &gt;= j)切分结束？因为相遇了代表所有元素都已遍历完毕。 指针相遇（双向扫描完毕）之后，交换 切点(v) 与 a[j] 的值，此时a[j]是最后一个小于 v 的值，而切点到了数组中间，最后返回切点索引。 博客参考，对于理解很有帮助：坐在马桶上看算法：快速排序 12345678910111213141516171819202122232425262728293031public class Quick extends Example { @Override public void sort(Comparable[] a) { StdRandom.shuffle(a); sort(a, 0, a.length - 1); } private void sort(Comparable[] a, int lo, int hi) { if (hi &lt;= lo) return; int j = partition(a, lo, hi); // 切分 sort(a, lo, j - 1); // 左半边排序 sort(a, j + 1, hi); // 右半边排序 } private int partition(Comparable[] a, int lo, int hi) { int i = lo, j = hi + 1; // 左右扫描的指针 Comparable v = a[lo]; // 切分的元素 while (true) { while (less(a[++i], v)) { // 指针 i 从左往右扫描大于v的值 if (i == hi) break; } while (less(v, a[--j])) { // 指针 j 从右往左扫描小于v的值 if (j == lo) break; } if (i &gt;= j) break; // 为什么 i &gt;= j 退出外循环？ exch(a, i, j); // 小值放左边，大值放右边。 } exch(a, lo, j); return j; }} 快速排序最好的情况下是每次都正好能将数组对半分，这样递归调用次数才是最少的。 最坏的情况下，第一次从最小的元素切分，第二次从第二小的元素切分，如此这般。为了防止数组最开始就是有序的，在进行快速排序时需要随机打乱数组。 改进 对于小数组，使用插入排序。只需将递归结束条件从 if (hi &lt;= lo) return; 改为：if (hi &lt;= lo + 15) { new Insertion().sort(a); return; } 三取样切分：选取较优的切点元素来提高性能。将子数组的一小部分元素中的中位数作为切点来切分数组效果为好，一般取3个元素。参考：图解排序算法(五)之快速排序——三数取中法 对于含有大量重复元素的数组，该算法还是会继续切分数组，增加不必要的性能开销。解决方案：三向切分算法：Quick3way.java 以上改进 均未！实现！太搞脑子了😣~~~ 优先队列在某些拥有大量输入N（数十亿甚至无限）的用例中，需要在大量输入中取最大（或最小）的前M个值。解决这种需求，数组排序的代价特别高昂，原因有2点：1. 数据量特别大，不可能将十亿个数放进数组排序，有可能内存都装不下；2. 只需要取前M的有序的值，并不需要将所有数据排序，甚至都无法获取全部的数据。 优先队列可以解决这类问题，有了优先队列，只需要创建一个大小为M的队列即可代替创建大小为总数据量N的数组。 API 方法 描述 MaxPQ() 创建一个优先队列 MaxPQ(int max) 创建一个初始容量的优先队列 MaxPQ(Key[] arr) 用arr[]中的元素创建一个优先队列 void insert(Key v) 向优先队列插入一个元素 Key max() 返回最大元素 Key delMax() 删除最大元素 boolean isEmpty() 判断是否为空 int size() 查看队列大小 初级实现基于无序数组的优先队列：MaxPQ4DisArray.java 基于有序数组的优先队列：MaxPQ4Array.java 基于无序链表栈的优先队列：MaxPQ4Linked.java 基于堆的优先队列二叉堆的定义与表示法 二叉堆（完全二叉树，之不过在这叫做堆）是一种基于数组的数据结构。既然是树形结构，必然有一个根节点，根节点下面挂着（一个或）两个子节点，每个子节点作为父节点又挂着两个子节点。同级节点之间无关顺序，父节点大于等于子节点。当一个二叉树的每个节点都大于等于它的两个子节点时，被称之为“堆有序”。 如何用数组存储具有层级顺序关系的二叉堆呢？ 首先，二叉堆在数组中按索引位置 1 开始存储（不使用数组的第一个元素） 在一个堆中位置 k 的节点的父节点的位置为 k/2，而它的两个子节点的位置分别为 k*2, K*2+1，这样就可以通过计算索引在树中上下移动。 二叉堆表示： 二叉堆在数组中的存储结构： 用长度为 N+1 的数组 pq[] 来表示一个大小为 N 的堆，因为堆元素存放与 pq[1]到pq[N]之中，所以实际数组的长度要是堆的元素大小+1。 由下至上的堆有序化（上浮）当堆的有序化因为某个节点变得比其父节点更大而被打破，我们需要交换该节点和其父节点来修复堆。交换后该节点比它的两个子节点（一个是交换之前的父节点，另一个比它更小，因为是旧父节点的子节点）都要大了，但该节点仍然有可能比现在的父节点要大，所以需要再一次交换，使得该节点不断上浮直到遇到了更大的节点或到达堆顶。 123456789public class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt; implements IMaxPQ&lt;Key&gt; { //...... public void swim(int k) { while (k &gt; 1 &amp;&amp; less(k / 2, k)) { exch(k / 2, k); k = k / 2; } } } 由上至下的堆有序化（下沉）下沉与上浮相反，当有序状态因为某个节点变得比它的两个（或其中之一）子节点要小被打破，那么需要交换该节点与其较大的一个子节点来保持平衡。倘若交换之后该节点仍比现在的子节点之一要大，继续交换，直至向下交换到该节点的子节点都比它小或到达堆的底部。 疑问：“父节点怎么会变得比子节点要小呢？添加一个元素在数组末尾时会通过上浮移动到合适的位置的啊。” — 这跟删除最大元素的算法有关，移除堆顶元素时，会用数组的最后一个元素替补最大元素，所以此时存在元素下沉的必要。 123456789101112public class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt; implements IMaxPQ&lt;Key&gt; { //...... public void sink(int k) { while (2 * k &lt;= N) { int j = 2 * k; if (j &lt; N &amp;&amp; less(j, j + 1)) j++; if (!less(k, j)) break; exch(k, j); k = j; } } } 堆的上浮与下沉： 优先队列实现理解了上浮和下沉，优先队列核心的两个api就能实现了，对于 插入元素，只需将元素添加到数组末尾，增加堆的大小并让新元素上浮到合适的位置；对于 删除最大元素，我们从数组顶端去除最大元素，并将数组最后一个元素放到顶端，减少堆的大小并让元素下沉到合适的位置即可。 12345678910111213141516171819202122232425262728293031323334353637public class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt; implements IMaxPQ&lt;Key&gt; { private Key[] pq; // 基于堆的完全二叉树 private int N; // 堆元素数量 @Override public void insert(Key v) { if (N == pq.length - 1) resize(pq.length * 2); pq[++N] = v; swim(N); } @Override public Key delMax() { if (isEmpty()) throw new NoSuchElementException(\"Priority queue underflow\"); Key max = pq[1]; exch(1, N--); pq[N + 1] = null; // 防止对象游离 sink(1); if (N &gt; 0 &amp;&amp; (pq.length - 1) / 4 == N) resize(pq.length / 2); return max; } @Override public Key max() { if (isEmpty()) throw new NoSuchElementException(\"Priority queue underflow\"); return pq[1]; } private void resize(int max) { assert max &gt; N; Key[] temp = (Key[]) new Comparable[max]; for (int i = 1; i &lt; N + 1; i++) { temp[i] = pq[i]; } pq = temp; }} 基于堆的优先队列API能够保证插入元素和删除最大元素的用时和队列的大小仅成对数关系。 索引优先队列二叉树存储的不是元素值，而是元素值的key；通过这个 key 在元素数组 element[] 中找到元素值；用keyIndex[]存储key的索引。 先补点智商，干了这碗鸡汤：索引优先队列的工作原理与简易实现 提醒：前方高能！！！传送门 堆排序以优先队列实现的排序算法，将原始数组元素放入一个优先队列中，由于在队列中可以轻易的获得最大值，每次获取的最大值可以组成一个递减序列。如果获取的最大值不删除，而是将其和队列的最后一个元素交换，第二次将新的最大值与数组的倒数第二个值交换，循环往复，直至数组元素遍历完，排序完成。 堆的构建将原始数组元素组成一个完全二叉树结构，一个简单的方式就是将数组 从左至右 执行 上浮 操作，直至每个元素放到了合适的位置。 上浮操作生成堆会扫描数组的每一个元素，更好的方式是 从右至左 执行 下沉 操作，它只需要扫描数组一半的元素，因为不需要比较叶子节点。 排序交换堆顶元素和最后一个元素，每次交换之后重新下沉以维持堆的有序状态。 由于在堆结构中不使用数组的第一个位置的元素，导致原始数组的第一个元素值必须为null，要以正常存储的方式使用堆排序，只需要在 less() 和 exch() 中将传入的索引-1即可。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class Heap { public void sort(Comparable[] a) { int n = a.length - 1; // 构造堆 sinkGenerationHead(a, n);// swimGenerationHead(a, n); // 堆排序 while (n &gt; 1) { exch(a, 1, n--); sink(a, 1, n); } } //下沉生成大顶堆（最优） public void sinkGenerationHead(Comparable[] a, int n) { for (int i = n / 2; i &gt;= 1; i--) { // 从右到左 sink(a, i, n); } } // 上浮生成大顶堆 public void swimGenerationHead(Comparable[] a, int n) { for (int k = 0; k &lt; n; k++) { // 必须是从左到右 swim(a, k, n); } } public void sink(Comparable[] a, int k, int n) { while (2 * k &lt;= n) { int j = 2 * k; if (j &lt; n &amp;&amp; less(a, j, j + 1)) j++; if (!less(a, k, j)) break; exch(a, k, j); k = j; } } public void swim(Comparable[] a, int k, int n) { while (k &gt; 1 &amp;&amp; less(a, k / 2, k)) { exch(a, k / 2, k); k = k / 2; } } private boolean less(Comparable[] a, int i, int j) { return a[i].compareTo(a[j]) &lt; 0; } private void exch(Comparable[] a, int i, int j) { Comparable tem = a[i]; a[i] = a[j]; a[j] = tem; } public static void main(String[] args) { Comparable[] a = new Comparable[]{null, 2, 0, 5, 7, 9, 8, 3, 1, 4, 6}; Heap heap = new Heap(); heap.sort(a); for (int i = 0; i &lt; a.length; i++) { StdOut.print(a[i] + \" \"); } }} 总结在java中的排序都是基于指针的，除了原始数据类型以外，我们操作的都是数据的引用（指针），而非数据本身。指针排序增加了一层间接性，因为数组保存的是待排序对象的引用，而非对象本身。 在一些情况下，对于排序之后的数据要求不可改变键值，如果能修改，那么数组将不再有序。类似的，优先队列在能改变键值的情况下也不太可能正常工作（索引优先队列能改变键值并维持有序是每次改变之后都进行上浮下沉操作）。限定排序元素不可变可以使用java的不可变数据类型，如八大封装类型和String，以及自定义的不可变数据类型（不可变类型：实例变量以private、final修饰；不提供setter方法；提供带参构造器以初始化实例变量）。 在java中实现任意数据类型排序的方法就是实现Comparable接口，重写其compareTo方法。但当我们对该数据类型的排序方法有多个时，我们可以创建一个比较器对象，使其实现Comparator接口，重写compare方法，进行比较时根据需求传入不同Comparator接口的实现即可。 如果一个排序算法能够保留数组中重复元素的相对位置则可以被称之为 稳定的，对于排序算法稳定性的要求在某些场景尤为重要。 对于前面学习过的各种排序算法的性能特点如下： 算 法 是否稳定 是否为原地排序 时间复杂度 空间复杂度 备 注 选择排序 否 是 N^2 1 插入排序 是 是 介于N和N^2之间 1 取决于输入元素的排列情况 希尔排序 否 是 NlogN? N^(6/5)? 1 快速排序 否 是 NlogN lgN 运行效率由概率提供保证 三向快速排序 否 是 介于N和NlogN之间 lgN 运行效率由概率保证，同时也取决于输入元素的分布情况 归并排序 是 否 NlogN N 堆排序 否 是 NlogN 1 大多数情况下，快速排序是最好的选择。但是如果稳定性很重要而空间不是问题的情况下，归并排序可能是最好的。 java 函数库中对原始数据类型使用三向切分快速排序，对于引用类型使用归并排序。这么做也印证着用速度和空间（对于原始数据类型）来换取稳定性（对于引用类型）。","link":"/2018/08/14/算法第二章 排序/"},{"title":"Git 实用指南","text":"版本控制系统（VCS） 版本控制 / 主动提交 / 中央仓库 构成了一个最核心的版本控制系统。 版本控制：最基本的功能 版本控制系统最基本的功能是版本控制。版本控制，简单的理解就是在文件中的修改历程中保存修改历史，我们可以方便的撤销之前对文件的修改。 在普通文本编辑器中，我们可以使用 Undo 操作回退到上一次的操作；在程序编码，我们可以通过 VCS 回退到指定的一次操作，而不仅仅是上一次操作。 主动提交机制：VCS 与普通文本编辑器的区别 使用普通文本编辑器的时候，一次保存就是一次改动，对版本的 控制 仅仅是回退到上一次操作。而正常情况下，我们的程序代码修改的生命周期十分长，一次代码的修改，在几天后、几个月后、甚至几年后都可能被翻出来。此时像普通编辑器的“自动保存提交”的功能在对历史代码审查、回退中会变得非常繁琐和无章可循。所以和普通文本编辑器的“撤销”功能不同，VCS 保存修改历史，使用 主动提交改动 的机制。 所谓 主动提交改动 ，是指每次代码的修改和保存不会自动提交，需要手动提交（commit）到仓库，VCS 会把这次提交记录到版本历史中，当往后需要回退到这个版本，可以在 VCS 的历史提交纪录中找到这条记录。中央仓库：多人合作的同步需求 中央仓库作为代码的存储中心，所有人的改动都上传到这里，所有人都可以看到并下载别人上传的改动。 版本控制 / 主动提交 / 中央仓库 这三个要素，共同构成了版本控制系统 VCS 的核心：开发团队中的每个人向中央仓库中主动提交自己的改动和同步别人的改动，并在需要的时候查看和操作历史的版本，这就是版本控制系统。 中央式版本控制系统 最基本的模型是：在一台服务器中初始化一个中央仓库，每个人从中央仓库下载初始版本开始并行开发，提交各自的代码到中央仓库并更新其他人的代码同步到自己的机器上。 团队中的每个人需要做的就是：1. 第一次加入团队，从中央仓库取代码到本地； 2. 写好的新功能提交到中央仓库； 3. 同事有新的代码提交，及时同步到本地。实际开发中当然还会经常需要处理代码冲突、查看代码历史、回退代码版本等。 分布式版本控制系统（DVCS）分布式 VCS 和中央式 VCS 的区别在于：分布式 VCS 除了有中央仓库之外，还有本地仓库，团队中的每个人的机器上都有一个本地仓库，这个仓库中保存着版本的所有历史，每个人都可以在自己的机器的本地仓库中提交代码、查看历史而无需联网与中央仓库交互，取而代之的，只需要和本地仓库交互。 中央式 VCS 的中央仓库有两个主要功能：保存版本历史 / 同步代码 。而在分布式的 VCS 中，保存版本历史转移到了每个人的本地仓库，中央仓库只剩下同步代码这一个主要任务。当然中央仓库也会保存版本历史，不过这个历史只是作为团队同步代码的中转站。 快速上手 在 github 上新建一个仓库： git-practical-guide 在指定路径克隆该远程仓库到本地： git clone https://github.com/yuzh233/git-practical-guide.git 查看日志： git log ，若日志信息太长，按 q 退出。 12345678$ git logcommit 0a00230727018a14d481fe482e8e85f7b312e39c (HEAD -&gt; master, origin/master, origin/HEAD)Author: yu_zh &lt;yuzh233@163.com&gt;Date: Wed Oct 3 00:23:27 2018 +0800 Initial commit -- github 默认创建了一次提交 新建一个文件，自己创建一个提交：但先查看一下状态 git status 12345678910111213$ git statusOn branch masterYour branch is up to date with 'origin/master'.Untracked files: (use \"git add &lt;file&gt;...\" to include in what will be committed) README.mdnothing added to commit but untracked files present (use \"git add\" to track)-- 当前分支是主分支，并且当前分支是最新的（相对于中央仓库）-- 有一个未追踪的文件 “README.md” ,可以使用 git add 追踪文件（提交） 追踪文件： git add README.md，再次 git status。 添加全部文件到暂存区：git add . / git add -A 12345678910$ git statusOn branch masterYour branch is up to date with 'origin/master'.Changes to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) new file: README.md-- 当前分支是最新的，已暂存一个新文件：README.md，该文件由“未追踪”变成了“已暂存”，表明这个文件被改动的部分已进入“暂存区” 提交文件：git commit 。进入 vim 填写提交的描述信息保存退出即可。也可以 git commit -m &quot;描述信息&quot; 123456789101112131415161718192021222324252627$ git commit*** Please tell me who you are.Run git config --global user.email \"you@example.com\" git config --global user.name \"Your Name\"to set your account's default identity.Omit --global to set the identity only in this repository.fatal: unable to auto-detect email address (got 'Administrator@YU-ZH.(none)')-- 首次提交需要指明身份（额外一点：github的贡献值是以邮箱地址作为提交的记录标识，如果 setting 里面没有添加该邮箱，那么贡献值会不存在。）Administrator@YU-ZH MINGW64 /d/IdeaProjects/git-practical-guide (master)$ git config --global user.email \"yuzh233@gmail.com\"Administrator@YU-ZH MINGW64 /d/IdeaProjects/git-practical-guide (master)$ git config --global user.name \"yu.zh\"Administrator@YU-ZH MINGW64 /d/IdeaProjects/git-practical-guide (master)$ git commit[master 967f40b] add README.md 1 file changed, 76 insertions(+) create mode 100644 README.md 再查看一次日志吧：git log 123456789101112131415$ git logcommit 967f40b3fd29f102fc84f62ac9d20243db2a99b4 (HEAD -&gt; master)Author: yu.zh &lt;yuzh233@gmail.com&gt;Date: Wed Oct 3 21:50:03 2018 +0800 add README.mdcommit 0a00230727018a14d481fe482e8e85f7b312e39c (origin/master, origin/HEAD)Author: yu_zh &lt;yuzh233@163.com&gt;Date: Wed Oct 3 00:23:27 2018 +0800 Initial commit-- 可以看到，一共有两次提交记录，最近的一次提交在最前面。-- origin/master, origin/HEAD 是对远端仓库的 master 和 HEAD 的本地镜像。 当我们的文件有修改时，需要更新到本地仓库。先看一下状态是个好习惯： git status 123456789101112131415$ git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use \"git push\" to publish your local commits)Changes not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: README.mdno changes added to commit (use \"git add\" and/or \"git commit -a\")-- 当前位于主分支，当前分支“领先于”远程仓库主分支一个提交-- 未提交的一个更改 README.md ，git 认识这个文件，但它不是一个新文件了，我们把它同步为最新的。 依然是： git add README.md 查看状态： git status 1234567891011$ git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use \"git push\" to publish your local commits)Changes to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) modified: README.md-- 一个文件被改动了 提交： git commit 此时查看下日志：git log 123456789101112131415161718$ git logcommit 7ba78ab8cef21de0174884ef13fb6210f9552fe3 (HEAD -&gt; master)Author: yu.zh &lt;yuzh233@gmail.com&gt;Date: Wed Oct 3 22:10:13 2018 +0800 update README.mdcommit 967f40b3fd29f102fc84f62ac9d20243db2a99b4Author: yu.zh &lt;yuzh233@gmail.com&gt;Date: Wed Oct 3 21:50:03 2018 +0800 add README.mdcommit 0a00230727018a14d481fe482e8e85f7b312e39c (origin/master, origin/HEAD)Author: yu_zh &lt;yuzh233@163.com&gt;Date: Wed Oct 3 00:23:27 2018 +0800 Initial commit 此时本地仓库已经领先于中央仓库，把本地仓库推送到中央仓库：git push / git push origin master 小结 git clone url git log git status git add 文件 / git add . / git add -A git commit / git commit -m “info” git push / git push origin master 本地初始化仓库并推送到 GitHub 某个项目文件夹执行 git init git log / git add / git commit / git status 啥的都来一遍 在 github 创建与本地同名的仓库，如果本地有 README.md 远程就不要勾选创建这个文件，否则会冲突。 关联远程库: git remote add origin git@github.com:yuzh233/demo.git or git remote add origin https://github.com/yuzh233/demo.git 推送到远程库：git push -u origin master ，需要先关联 GitHub 与本机的 SSH Key. 关联 GitHub 与本机的 SSH Key 先确保已经在 git 中保存了全局用户名和邮箱 git config –global user.name “yourname” git config –global user.email“your@email.com“ 删除 C:\\Users\\Administrator.ssh\\known_hosts 文件 bash 输入 ssh-keygen -t rsa -C &quot;yuzh233@gmail.com&quot;，出现提示信息，一路回车，然后系统会自动在.ssh文件夹下生成两个文件，id_rsa 和 id_rsa.pub。 打开 id_rsa.pub 将全部内容复制到 Github-&gt;setting-&gt;SSH and GPG keys-&gt;New SSH key-&gt;key ssh -T git@github.com git pullpull 指令用于从中央仓库更新代码到本地仓库。当多人协作开发时，同事 A 先于同事 B push 自己的本地仓库代码到中央仓库后，同事 B 再 push 自己的本地仓库时会报错，原因是远程仓库含有本地没有的 commit 而导致 push 失败。此时同事 B 需要使用 git pull 将同事 A push 到远程仓库的内容更新下来，这样同事 B 的本地仓库就含有远程仓库的commit了，然后同事 B 才能执行自己的 push。 一种场景：同事A commit了一条记录并 push 到远程仓库。同事B 也在自己的本地仓库中 commit 了一条记录后试图 push。此时 git 会发现远程仓库含有本地未有的提交 push 失败。于是同事B 执行 git pull ，此时的 pull 并不会和往常一样结束，而是会进入一个 vim 的信息提示界面，需要输入提交信息（git默认填写了信息），原因是git不仅发现远程仓库含有本地仓库没有的提交，本地仓库也含有远程仓库没有的提交，git会将远程仓库的 commit 和本地仓库的 commit 合并（git mage）产生一条新的提交并添加默认描述信息。 退出保存信息提示界面之后，pull就完成了，然后执行 push，此时本地仓库含有远程仓库所有的提交不会失败。 HEAD / master / branch 理解指向 commit 的快捷方式：引用 括号里的 HEAD -&gt; master, origin/master, origin/HEAD ，都是指向这个 commit 的引用。commit 后面一大串的字符是当前提交的唯一标识符（SHA-1 校验和），提供引用机制是为了简化标识符，方便记忆。 HEAD 指向当前最新的 commit ，当前 commit 在哪里，HEAD 就在哪里，这是一个永远指向当前 commit 的引用。 HEAD 除了可以指向 commit，还可以指向一个 branch，当它指向某个 branch 的时候，会通过这个 branch 来间接地指向某个 commit；另外，当 HEAD 在提交时自动向前移动的时候，它会像一个拖钩一样带着它所指向的 branch 一起移动。 我们创建一个 commit 之后查看 log： 最新的 commit 被创建后，HEAD 和 master 这两个引用都指向了它，而在上面第一张图中的后两个引用 origin/master 和 origin/HEAD 则依然停留在原先的位置。 branch 可以理解为从初始 commit 到 branch 所指向的 commit 之间的所有 commit 集合的一个串。 所有的 branch 之间都是平等的 branch 包含了从初始 commit 到它的所有路径，而不是一条路径。并且，这些路径之间也是彼此平等的。 master 是一个特殊的 branch ,是git默认的分支（主分支）。新创建一个 repository 的第一个 commit 时，会把 master 指向它，并把 HEAD 指向 master。 新建的仓库中的第一个 commit 会被 master 自动指向 在 git clone 时，会自动 checkout 出 master branch xx / checkout branch xx / checkout -d xx / branch -d xx / branch -a创建一个分支：git branch feature1 切换到这个分支：git checkout feature1，此时 HEAD 指向了 feature1 这和分支了。 创建一个分支并切换过去：git checkout -b feature1 我们在 feature1 分支中创建一个提交：添加 feature1.txt。此时 HEAD指向了 feature1，feature1 指向当前提交。 又切换回 master 分支：git checkout master，在 master 创建一个提交：添加 master.txt，此时出现了分叉（两个分支有不同的提交）。 删除刚刚创建的分支：git branch -d feature1 HEAD 指向的 branch 不能删除。如果要删除 HEAD 指向的 branch，需要先用 checkout 把 HEAD 指向其他地方。 branch 只是一个引用，删除引用并不会删除该引用路径上的所有 commit 集合（不过一个 commit 不在任何一个 branch 路径上，就是个野生 commit 了，会被 git 垃圾回收掉） 没有被合并到 master 过的 branch 在删除时会失败。强制删除将 -d 改为 -D 删除远程的分支：git push origin -d feature1 查看所有分支：git branch -a push 的本质push 是把当前的分支上传到远程仓库，并把这个 branch 的路径上的所有 commits 也一并上传。 push 的时候，如果当前分支是一个本地创建的分支，需要指定远程仓库名和分支名，用 git push origin 分支名 的格式，而不能只用 git push；或者可以通过 git config 修改 push.default 来改变 push 时的行为逻辑。 push 之后上传当前分支，并不会上传 HEAD；远程仓库的 HEAD 是永远指向默认分支（即 master）的。 git merge &lt;被合并分支&gt;merge(合并) 从目标 commit（被合并分支的最新commit） 和当前 commit （即 HEAD 所指向的最新 commit）分叉的位置起，把目标 commit 的路径上的所有 commit 的内容一并应用到当前 commit，然后自动生成一个新的 commit。 HEAD 指向 master，说明当前在主分支，执行 git merge branch1之后 git 会 在 commit 2 （交叉位置），将commit 5 和commit 6 合并到 commit 4，然后生成一个新的提交。 首先创建一个分支 branch1，开始并行开发： git branch branch1 ------------------------------------- 在 master 分支创建两个文件： touch a.txt touch b.txt 添加并提交这两个文件： git add a.txt b.txt git commit -m &quot;add a.txt b.txt&quot; 此时 master 分支有这两个文件 ------------------------------------- 切换到 branch1 分支： git chekout branch1 创建一个文件 c.txt 添加并提交： touch c.txt git add c.txt git commit -m &quot;add c.txt&quot; 此时 branch1 分支含有 c.txt 这个文件 -------------------------------------- master 有自己的新提交：“a.txt / b.txt”，branch1有自己的新提交：“c.txt”，此时想将 branch1 的提交合并到 master 主分支上： git checkout master 先切换到主分支 git merge branch1 于是 master 就含有 a.txt / b.txt / c.txt 这三个文件了。 冲突（conflict） merge 在做合并的时候，是有一定的自动合并能力的：如果一个分支改了 A 文件，另一个分支改了 B 文件，那么合并后就是既改 A 也改 B，这个动作会自动完成；如果两个分支都改了同一个文件，但一个改的是第 1 行，另一个改的是第 2 行，那么合并后就是第 1 行和第 2 行都改，也是自动完成。但如果两个分支修改了同一部分内容，merge 的自动算法就搞不定了。这种情况 Git 称之为：冲突（Conflict）。 例如：git仓库中有一个文件 shopping-list.txt，内容如下： 移动硬盘 女装 我们用两个分支分别修改文件的同一个地方，先创建一个分支 feature1： 1git branch feature1 在 master 中修改内容并提交： 12345 移动硬盘 女装（已买）git add shopping-list.txtgit commit -m \"购买女装\" 切换到 feature1 修改并提交： 1234567git checkout feature1 移动硬盘 女装（没买）git add shopping-list.txtgit commit -m \"没买女装\" 此时切换回 master ，执行 git merge feature1，git 傻了 在 shopping-list.txt 中出现了 “merge conflict”，自动合并失败，要求 “fix conflicts and then commit the result”（把冲突解决掉后提交） 第一步：解决冲突，打开冲突的文件： 移动硬盘 &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD 女装（已买） ======= 女装（没买） &gt;&gt;&gt;&gt;&gt;&gt;&gt; feature1 发现内容有些变化，Git 虽然没有帮你完成自动 merge，但它对文件还是做了一些工作：它把两个分支冲突的内容放在了一起，并用符号标记出了它们的边界以及它们的出处。 我们要保留主分支的更改，即：“购买女装”，只要删除掉 feature1 的修改，再把 Git 添加的那三行 &lt;&lt;&lt; === &gt;&gt;&gt; 辅助文字也删掉，保存文件退出，冲突就解决了。 第二步：手动提交，提交解决冲突之后的文件： 12git add shopping-list.txt # 这里 commit 前也需要先 add 一下git commit 如果要放弃这次 merge ，可以执行： 1git merge --abort HEAD 领先于目标 commit如果 merge 时的目标 commit 和 HEAD 处的 commit 并不存在分叉，而是 HEAD 领先于目标 commit。 那么 merge 就没必要再创建一个新的 commit 来进行合并操作，因为并没有什么需要合并的。在这种情况下， Git 什么也不会做，merge 是一个空操作。 HEAD 落后于目标 commit如果 HEAD 和目标 commit 不存在分叉，但 HEAD 落后于目标 commit。那么 Git 会直接把 HEAD（以及它所指向的 branch，如果有的话）移动到目标 commit。这也叫做：“fast-forward”。 fast-forward 这种场景在 pull 中经常遇到：本地的 master 没有新提交，而远端仓库中有同事提交了新内容到 master，此时的 HEAD 落后于目标 commit（远程的 HEAD），而造成 “fast-forward”。 Feature Branching 工作流 之前的工作模型是：所有人都在 master 分支上工作，commit 了代码通过 push 推送到远程仓库，获取别人的 commit 通过 pull。这种模型的局限性在于：每一个人的代码在被大家看到的时候，是它正式进入生产环境的时候。所有人的代码都直接 push 到远程的 master，这就导致了每个人的代码在正式启用（投入生产环境）前无法被别人看到。 这样就让代码在正式启用前的讨论和审阅极不方便。 feature branching 工作流解决了这种问题，该工作流的核心特点如下： 任何一个新功能（feature）和 bug 的修复都用一个新的 branch 来写； branch 写完之后，合并到 master，再删除这个 branch。 这种工作流为团队协作间的 代码审阅 / 一人多任务 提供解决方案。 代码审阅（branch / commit / push / review / merge）假如要开发一个新的功能，我们创建一个分支 books ，开始开发： git checkout -b books # 创建分支并切换过去 十几个 commit 过后，功能开发完毕，告诉同事功能开发完毕，有时间帮我 review 一下呗，分支名是 books，然后把这个分支 push 上去： # 确保当前在 books 分支，将当前分支 push 到远程仓库的 books 分支。 git push origin books [ 模拟同事：review 刚刚上传的 books 分支：] # 克隆同事的仓库到桌面（如果同事有这个仓库就是 git pull ） git clone https://github.com/yuzh233/git-practical-guide.git cd git-practical-guide git checkout books # 切换到同事刚刚开发新功能的分支：books 开始 review ... [ review 完毕，同事：我觉得很 OK 啊~ 可以合并了！] 于是我一顿操作： git checkout master git pull # 保持更新，是个好习惯 git merge books -- 此时 books 分支的内容合并到了 master 工作目录 -- 紧接着，把合并后的 master push 上去，并删除本地和远程的 books 分支： git push git branch -d books # 删除本地 books 分支 git push origin -d books # 删除远程 books 分支 一切都是这么的完美，然而此时一个同事发现不对，说：“嘿！你的代码缩进怎么是 tab ，快改成空格，不然砍死你哦~”，我一看情况不对，立马重复上面的操作：新建分支、改代码、推送上去、同事审阅、合并、再推送、删除分支，ok，空格党觉得很ok，乎~ perfect。[ 然而，发现事情没有这么简单… ] 12345678910git branch booksgit checkout books--- tab 改为 空格 git add / git commit ---git push origin books--- review... ok ---git checkout mastergit merge books # 这里会出现 Fast-forward，原因是当前commit（HEAD）落后于目标commit（books 的 commit 比 master 的 HEAD 领先）git pushgit branch -d booksgit push origin -d books pull request 在上一主题，同事取到我的新功能审阅代码，都是在自己本地中打开，觉得有问题一般都是通过短信电话，发邮件等。这样的审阅是很不方便的，而 pull request 就是对前面代码审阅过程的简化。 pull request 不是 git 的内容，而是 git 服务提供商（如 GitHub）提供的一种便捷功能，可以让团队方便的讨论一个 branch，并在讨论结束后一件合并这个 branch 到 master。 如：现在创建一个分支修改购物清单：“购买SSD”，并推送到远程仓库，github 会自动提示是否 pull request: 创建一个 pull request： 创建之后，其他同事就可以在 github 上看到我们的拉请求。他们可以在这个页面查看我们的所有 commit 并提建议，我们就可以根据同事们的建议提交新的 commit 并 push 到这个分支，这个页面会随着 push 展示最新的 commit。 我们在 feature1 分支又决定不买SSD了，于是更新后重新 push，此时该界面也同步更新了一条 commit： 就这样，根据同事的意见不断的 push 新 commit 之后，最终一致决定没问题可以合并到 master 了，点击 Merge pull request ，GitHub 会自动在中央仓库中将 feature1 合并到 master。 一人多任务利用 feature branching 工作流，一个多任务并行开发变得简单多了。当一个新任务下发时，我们仅需要将当前任务的分支简单收尾一下，回到主分支再开辟一个新任务的分支就可以开发新的任务了。 关于 addadd 指令除了 git add 文件名 这种用法外，还可以使用 add . 来直接把工作目录下的所有改动全部放进暂存区 add 添加的是文件改动，而不是文件名。也就是说,对文件修改之后通过 add 放入暂存区，再修改一次该文件，然后执行 commit，第二次的修改并没有提交，原因是第二次改动了内容没有重新 add。 add 也支持匹配表达式，如 add *.java add 文件进暂存区，又不想 add 了，使用：git reset HEAD filename 看看我改了什么 查看历史记录 git log 查看详细历史记录 git log -p 查看概要历史记录 git log --stat 查看当前（HEAD指向的） commit 的信息 git show 查看指定 commit 的信息：git show &lt;commit的引用&gt; 查看指定 commit 中的某个文件的改动：git show 2edc shopping-list.txt 查看工作区和暂存区的区别：git diff 查看暂存区和上一条提交的区别：git diff --staged 查看工作目录和上一条 commit 的区别：git diff HEAD 不喜欢 merge 的分叉？用 rebase 把 rebase —— 给当前 commit 序列重新设置基础点（也就是父 commit）。就是说，把指定的 commit 以及所在的 commit 串，以指定的目标 commit 为基础（头），重新作为一次提交。 例如：下面是一个 merge 操作: git merge branch1 如果把 merge 换成 rebase： git checkout branch1 git rebase master 可以看到，通过 rebase，将 commit 5 和 commit 6 这个 commit 串，从原有的父节点 commit 2 移到现在的父节点 commit 4。通过这样，让原本分叉的提交历史重新回到了一条线。这种 [ 重新设置基础点 ] 的操作，就是 rebase 的含义。 在 branch1 分支 rebase master 之后，branch1 跑到 master 前面变成了同一条线，但是实际上还是两个彼此独立的分支，只不过 branch1 现在是以 master 的 HEAD（即：commit 4） 作为 基础点（commit 串的头）。master 的 HEAD 是 commit 4，branch1 的 HEAD 是 commit 8，并且 branch1 的 commits 领先于 master 的 commits。 我们希望用 rebase 之后能实现和 merge 一样的合并两条分支的效果，那么怎么做呢？其实还是需要用到 merge 操作，当前分支（master）与目标分支（branch1）没有分叉，并且当前 HEAD 落后于目标分支的 commit，使用 merge，将 HEAD 移到目标的 commit，这就是前面学到过的 Fast-Forward。 git checkout master # 还需先切换回 master git merge branch1 [ 蒙圈了怎么办，演示一把： ] -----------&lt; 新建一个分支 &gt;----------- git branch branch1 -----------&lt; 在 master 创建一个提交 &gt;----------- touch a.txt git add a.txt git commit -m &quot;add a.txt&quot; -----------&lt; 在 branch1 创建一个提交 &gt;----------- git checkout branch1 touch b.txt / touch c.txt git add b.txt c.txt git commit -m &quot;add b.txt c.txt&quot; -----------&lt; 想把 branch1 合并到 master 但是不想有分叉 &gt;----------- # 注意：必须先切换到被合并的分支！ git checkout branch1 git rebase master [ 此时，branch1 和 master 属于同一条线，但是 branch1 领先于 master：] [ branch1 的新提交是 a.txt / b.txt ，master 的新提交是 a.txt，此时合并到 master：git checkout master / git merge branch1] [ 可以看出是一个快速前移操作，此时的日志：master 已经移到了最新的 commit] 注意事项 merge 操作是在合并分支上进行的； rebase 操作是在 被合并 分支上进行的，这点很重要。 rebase 是带着当前 commit 移到别的 commit 上「去」，而 merge 则是把别的 commit 合并过「来」 “ 为什么要在被合并分支 branch1 上执行 rebase，在合并分支 master上执行 merge，而不是直接在 master上执行 rebase 呢？” —— 简单的理解就是：这两种 rebase 本身就是两种不同的情况，如果在 master 上 rebase：git checkout master / git rebase branch1 ，master 就会带着它的 commit 串内容作为新的 commit 跑到 branch1 的 HEAD 前面去啦！ master 跑到了 branch1 这条线上，master 的 commit 的内容还是以前的内容，但是却不是同一个 commit 了，只不过是内容相同的另外一个 commit罢了。而如果远程仓库有之前 master 的 commit，但是在本地仓库中找不到远程库对应的这个 commit，会因为远程库含有本地没有的 commit 导致 push 失败！ 应用场景 你自己开发分支一直在做，然后某一天，你想把主线的修改合到你的分支上，做一次集成，这种情况就用 rebase 比较好。把你的提交都放在主线修改的头上。 参考：git rebase 还是 merge的使用场景最通俗的解释 修正 commit用 commit --amend 修复当前提交的错误。在 commit 一条提交之后发现写错了，我要买：“机械键盘”，可以使用 commit --amend 指令来修正本次提交的错误。git 不会在当前 commit 上增加 commit ，而是把当前 commit 里的内容和暂存区的内容合并起来形成一个新的 commit，用新的 commit 把当前的 commit 替换掉。 [ 我们在购物清单中添加一个：“薄膜键盘”，提交之后发现写错了… 于是将内容重新修改，并重新 add 到暂存区，使用 commit –amend 指令覆盖当前提交：] 修正之后可以发现只有一条 commit 记录。 修正指定 commit 交互式 rebase：git rebase -i &lt;指定 commit 链的头&gt; 所谓交互式 rebase，就是在 rebase 的操作执行之前，指定要 rebase 的 commit 链中的每一个 commit 是否需要进一步修改。 -------&lt; 第一次提交 &gt;------- 我们在文件 rebase-i.txt 中添加一行 aaaaa 后执行提交：git add rebase-i.txt / git commit -m &quot;aaaaa&quot; -------&lt; 第二次提交 &gt;------- 在文件 rebase-i.txt 中又添加一行 bbbbb 后执行提交：git add rebase-i.txt / git commit -m &quot;bbbbb&quot; 查看日志： 但是发现 “aaaaa” 这个提交的内容写错了，想要修改这次提交。由于不是最新的提交，不能使用 commit –amend 来修正。 可以使用 rabse，不过此时的 rebase 是在同一条基线上，也叫 [原地 rebase]，通过原地变基，指定一个 commit ，将其所在的 commits 串从父基础点断开。然后对该 commits 串中的每一个 commit 修改后重新挂在原来的父基础点。 使用 git rebase -i HEAD^^ or git rebase -i HEAD~2 来指定从哪个 commit 开始变基。（rebase 之前需要将工作空间新的修改放入暂存区，所以现在有了三条提交。） 我们要修正指定的 commit，将需要被修正的 commit 对应的操作由 pick 改为 edit（应用当前的提交，但是停下来修正）： 根据提示信息：rebase 已经停到了 “aaaaa” 这个提交，现在可以修正这个提交： 12修改 aaaaa 为 aaaaa_amendgit commit --amend # 应用这个修复 修复了第一个之后，执行：git rebase --continue 继续执行第二个：第二个也是修复，对文件修改 amend 之后继续 continue ，第三个 commit 是默认操作是 pick（应用当前的提交），不执行任何操作，至此rebase完毕。 撤销 commit —— resetgit add 后撤销： 撤销所有add文件 git reset HEAD . 撤销单个add文件 git reset HEAD -filename git commit 后撤销： 只回退 commit 的信息，保留修改代码：git reset --soft head 回退到上次 commit 版本，不保留修改代码：git reset --hard head^ HEAD：回退到当前版本（啥也没干） HEAD^ ：回退到上一个版本 reset 本质上不是撤销提交，而是移动 HEAD ，并且「捎带」上 HEAD 所指向的 branch（如果有的话），用来重置 HEAD 以及它所指向的 branch 的位置。 reset --hard HEAD^ 之所以起到了撤销前一个 commit 的效果，是因为它把 HEAD 和它所指向的 branch 一起移动到了当前 commit 的父 commit 上，从而起到了「撤销」的效果： 注意： --hard： 添加这个参数会抛弃当前工作区的修改 --soft： 添加这个参数会回退到之前的版本，但是保留当前工作区的修改，可以重新提交 撤销指定 commit —— rebase -i现有三条提交，要撤销第二条提交： git rebase -i HEAD~3 操作当前 commit 所在 commits 链中三条 commit： 撤销某个 commit ，将这一行删除即可。此时第二条 commit 被删掉了： 撤销已 push 的 commit —— revertgit revert 撤销某次操作，此次操作之前和之后的 commit 和 history 都会保留，并且把这次撤销作为一次最新的提交。 比如我们我们对文件rebase-i.txt添加两次修改并提交两次后 push 到远程库： 我们要撤销前一次提交:”bbb”，也就是删除文件中的“bbb”这一行：git revert HEAD 可以看到执行完之后增加了一条新的 commit，它的内容和最新的 commit 是相反的，从而和最新的 commit 相互抵消，达到撤销的效果。 把新的 commit 再 push 上去，这个 commit 的内容就被撤销了。它和前面所介绍的撤销方式 reset 相比，最主要的区别是，这次改动只是被「反转」了，并没有在历史中消失掉，你的历史中会存在两条 commit ：一个原始 commit ，一个对它的反转 commit。 checkout —— 不止可以签出分支前面学习过，使用：git checkout &lt;branch-name&gt; 可以切换到指定分支，即：把 HEAD 指向指定的 branch，然后签出这个 branch 所对应的 commit 的工作目录。 实际上 checkout 的本质是签出指定的 commit，不止可以切换 branch，也可以直接指定 commit 作为参数，来把 HEAD 移动到指定的 commit。 对于签出（checkout）的概念，简单的理解就是切换分支并在本地仓库中取出指定分支的内容到工作目录。 [ 演示：] 创建一个文件abc.txt并作为一个提交 使用 reset 撤回提交（不保留修改代码）： git reset --hard HEAD^ 可以看到刚刚的提交被撤销了，HEAD 带着 master 一起指向了上一条 commit： 如果用 checkout 来撤销提交：git checkout HEAD^ 可以看到，HEAD 已经和刚刚它指向的 branch -&gt; master 脱离了，此时如果继续提交更改，HEAD 就会跟着新的 commit 跑，而 master 依旧停到原地。当我们切换 master 之后，HEAD会因为没有所属分支而提示：“你有n个提交没有连接到分支,可以通过：git branch &lt;new-branch-name&gt; commitID 将新提交放到新创建的分支上去。然后可以将该分支合并到 master。” stash 临时存放工作目录的改动 保存工作目录的修改（不包含未 add 过的文件）并清空工作目录：git stash 恢复保存过的修改：git stash pop 包含未 add 过的文件使用：git stash -u 切换分支之前提交当前分支的修改，免去了不必要的麻烦，也没必要使用 stash 了。 恢复误删的 branch reflog 是 “reference log” 的缩写，使用它可以查看 Git 仓库中的引用的移动记录。如果不指定引用，它会显示 HEAD 的移动记录。 恢复指定 branch ，只需要查看 branch 最后一次移动的记录，那么其之前的一个 commit 就是删除之前的数据，使用 checkout 签出这个 commit 的内容到新的分支。实际上不会恢复分支，而是恢复分支里的内容并放到新的分支。使用这个方法，不仅可以恢复分支，还可以执行其他操作，比如恢复 reset 的数据。 假如误删了 branch1，那么可以查看一下 HEAD 的移动历史： git reflog HEAD 的最后一次移动行为是「从 branch1 移动到 master」。而在这之后，branch1 就被删除了。所以它之前的那个 commit 就是 branch1 被删除之前的位置了，也就是第二行的 c08de9a。 现在就可以切换回 c08de9a，然后重新创建 branch1: git checkout c08de9a git checkout -b branch1 这样分支里的内容就已经恢复到新建的同名分支里面了。","link":"/2018/10/07/Git 实用指南/"},{"title":"分布式技术入坑指南（一）","text":"知识点:1.SOA分布式架构2.Maven-多模块搭建3.初识dubbo、zookepper4.多工程之间的整合5.学习MyBatis逆向工程6.学习PageHelper7.了解SEO：搜索引擎优化，以及使用伪静态化尽可能的提高推广度8.内容管理系统 — 统一表字段抽取9.mapper中使用“主键返回” SOA(Service Oriented Architecture)面向服务的架构&nbsp;&nbsp;也就是把工程都拆分成服务层工程、表现层工程。服务层中包含业务逻辑，只需要对外提供服务即可。表现层只需要处理和页面的交互，业务逻辑都是调用服务层的服务来实现。工程都可以独立部署。 Maven-多模块搭建&nbsp;&nbsp;Maven的常见打包方式：jar、war、pom。Pom工程一般都是父工程，管理jar包的版本、maven插件的版本、统一的依赖管理。聚合工程。 本项目工程结构：taotao-parent：父工程，打包方式pom，管理jar包的版本号。项目中所有工程都应该继承父工程。&nbsp;&nbsp;|–taotao-common：通用的工具类通用的pojo,util。打包方式jar&nbsp;&nbsp;|–taotao-manager：服务层工程。聚合工程。Pom工程&nbsp;&nbsp;|–taotao-manager-dao：打包方式jar&nbsp;&nbsp;|–taotao-manager-pojo：打包方式jar&nbsp;&nbsp;|–taotao-manager-interface：打包方式jar&nbsp;&nbsp;|–taotao-manager-service：打包方式：war (为了发布服务的方便)&nbsp;&nbsp;|–taotao-manager-web：表现层工程。打包方式war taotao-parentpom123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 父工程，打包方式pom，管理jar包的版本号。项目中所有工程都应该继承父工程. --&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;artifactId&gt;taotao-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!-- 所有子工程 --&gt; &lt;modules&gt; &lt;module&gt;taotao-common&lt;/module&gt; &lt;module&gt;taotao-manager&lt;/module&gt; &lt;module&gt;taotao-manager-web&lt;/module&gt; &lt;module&gt;MybatisGenerator&lt;/module&gt; &lt;module&gt;taotao-protal-web&lt;/module&gt; &lt;module&gt;taotao-content&lt;/module&gt; &lt;/modules&gt; &lt;!-- 集中定义依赖版本号 --&gt; &lt;properties&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;spring.version&gt;4.2.4.RELEASE&lt;/spring.version&gt; &lt;mybatis.version&gt;3.2.8&lt;/mybatis.version&gt; &lt;mybatis.spring.version&gt;1.2.2&lt;/mybatis.spring.version&gt; &lt;mybatis.paginator.version&gt;1.2.15&lt;/mybatis.paginator.version&gt; &lt;mysql.version&gt;5.1.32&lt;/mysql.version&gt; &lt;slf4j.version&gt;1.6.4&lt;/slf4j.version&gt; &lt;jackson.version&gt;2.4.2&lt;/jackson.version&gt; &lt;druid.version&gt;1.0.9&lt;/druid.version&gt; &lt;httpclient.version&gt;4.3.5&lt;/httpclient.version&gt; &lt;jstl.version&gt;1.2&lt;/jstl.version&gt; &lt;servlet-api.version&gt;2.5&lt;/servlet-api.version&gt; &lt;jsp-api.version&gt;2.0&lt;/jsp-api.version&gt; &lt;joda-time.version&gt;2.5&lt;/joda-time.version&gt; &lt;commons-lang3.version&gt;3.3.2&lt;/commons-lang3.version&gt; &lt;commons-io.version&gt;1.3.2&lt;/commons-io.version&gt; &lt;commons-net.version&gt;3.3&lt;/commons-net.version&gt; &lt;!-- 3.4.2-fix是从官方的3.4.2版本添加修改之后形成的自己的工程 --&gt; &lt;!--&lt;pagehelper.version&gt;3.4.2-fix&lt;/pagehelper.version&gt;--&gt; &lt;!--&lt;pagehelper.version&gt;3.4.2&lt;/pagehelper.version&gt;--&gt; &lt;!--该版本已经修复了使用逆向工程导致pageHelper无效的问题 --&gt; &lt;pagehelper.version&gt;4.1.0&lt;/pagehelper.version&gt; &lt;jsqlparser.version&gt;0.9.1&lt;/jsqlparser.version&gt; &lt;commons-fileupload.version&gt;1.3.1&lt;/commons-fileupload.version&gt; &lt;jedis.version&gt;2.7.2&lt;/jedis.version&gt; &lt;solrj.version&gt;4.10.3&lt;/solrj.version&gt; &lt;dubbo.version&gt;2.5.4&lt;/dubbo.version&gt; &lt;zookeeper.version&gt;3.4.7&lt;/zookeeper.version&gt; &lt;zkclient.version&gt;0.1&lt;/zkclient.version&gt; &lt;activemq.version&gt;5.13.0&lt;/activemq.version&gt; &lt;freemarker.version&gt;2.3.23&lt;/freemarker.version&gt; &lt;quartz.version&gt;2.2.2&lt;/quartz.version&gt; &lt;/properties&gt; &lt;!-- 父工程统一项目的所有依赖，该依赖对子工程无效，只起到版本控制的效果，子工程根据需要复制部分的依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 时间操作组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;${joda-time.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Apache工具组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;${commons-lang3.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;${commons-io.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-net&lt;/groupId&gt; &lt;artifactId&gt;commons-net&lt;/artifactId&gt; &lt;version&gt;${commons-net.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Jackson Json处理工具包 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;${jackson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- httpclient --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;${httpclient.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- quartz任务调度框架 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;${quartz.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 单元测试 --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 日志处理 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;${mybatis.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;${mybatis.spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 分页相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.miemiedev&lt;/groupId&gt; &lt;artifactId&gt;mybatis-paginator&lt;/artifactId&gt; &lt;version&gt;${mybatis.paginator.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;${pagehelper.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySql --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 最牛逼的连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- JSP相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;${jstl.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;${servlet-api.version}&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;${jsp-api.version}&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 文件上传组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;${commons-fileupload.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Redis客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;${jedis.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- solr客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.solr&lt;/groupId&gt; &lt;artifactId&gt;solr-solrj&lt;/artifactId&gt; &lt;version&gt;${solrj.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- dubbo相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;${dubbo.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;${zookeeper.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;${zkclient.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;${activemq.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;${freemarker.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;finalName&gt;${project.artifactId}&lt;/finalName&gt; &lt;plugins&gt; &lt;!-- 资源文件拷贝插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;2.7&lt;/version&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- java编译插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;!-- 插件版本的管理 --&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- 配置Tomcat插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;8080&lt;/port&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 配置打包时跳过测试 ，首次配置使用的时候会自动联网进行下载 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.12.4&lt;/version&gt; &lt;configuration&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!-- 子工程需要覆写这个配置，该配置并不会继承到子工程。 --&gt; &lt;resources&gt; &lt;!-- 解决安装后java目录下的资源文件不发布的问题（默认maven是在resources下找资源文件） --&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;!-- 如果配置文件resources中也有，还需要配置这个 --&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources &lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; 举例：taotao-manager的pom123456789101112131415161718192021222324252627282930&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 服务层工程。聚合工程。Pom工程 --&gt; &lt;artifactId&gt;taotao-manager&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;taotao-manager-dao&lt;/module&gt; &lt;module&gt;taotao-manager-pojo&lt;/module&gt; &lt;module&gt;taotao-manager-interface&lt;/module&gt; &lt;module&gt;taotao-manager-service&lt;/module&gt; &lt;/modules&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;artifactId&gt;taotao-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!-- 依赖通用工程 --&gt; &lt;dependency&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;artifactId&gt;taotao-common&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; taotao-manager-service 的 pom12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;taotao-manager&lt;/artifactId&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;taotao-manager-service&lt;/artifactId&gt; &lt;!-- service是以服务模块单独跑服务器的，需要打成war应用包。 --&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;!-- 需要依赖dao模块 --&gt; &lt;dependency&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;artifactId&gt;taotao-manager-dao&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 需要依赖接口模块 --&gt; &lt;dependency&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;artifactId&gt;taotao-manager-interface&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;!-- 版本已经在parent控制了，这里添加也无效！ --&gt; &lt;/dependency&gt; ...... &lt;!-- 添加dubbo依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;!-- 排除依赖 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.jboss.netty&lt;/groupId&gt; &lt;artifactId&gt;netty&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; ...... &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;8081&lt;/port&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 使用tomcat的Maven插件启动123456789101112&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;8081&lt;/port&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; &nbsp;&nbsp;注：启动之前需要编译+安装模块到本地仓库，并且注意根据模块的层级关系确保安装的顺序！ 不想安装过程测试、资源文件拷贝不上等配置参考parent pom dubbo、zookepper SOA架构，表现层和服务层是不同的工程。某些需求的实现需要两个系统之间进行通信。Dubbo便是这类框架之一 DUBBO是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，是阿里巴巴SOA服务化治理方案的核心框架。 Dubbo是资源调度和治理中心的管理工具。 Dubbo 是类似于webservice的关于系统之间通信的框架，并可以统计和管理服务之间的调用情况（包括服务被谁调用了，调用的次数是如何，以及服务的使用状况）。 dubbo的架构 Provider: 暴露服务的服务提供方。 Consumer: 调用远程服务的服务消费方。 Registry: 服务注册与发现的注册中心。 Monitor: 统计服务的调用次调和调用时间的监控中心。 Container: 服务运行容器。 接入spring提供服务： 1234567891011121314151617181920212223242526&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd\"&gt; &lt;context:component-scan base-package=\"xyz.taotao.service\"&gt;&lt;/context:component-scan&gt; &lt;!-- 使用 dubbo 发布服务 --&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=\"taotao-manager\"/&gt; &lt;dubbo:registry protocol=\"zookeeper\" address=\"192.168.184.130:2181\"/&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\"/&gt; &lt;!-- 声明需要暴露的服务接口 --&gt; &lt;dubbo:service interface=\"xyz.taotao.service.TestService\" ref=\"testServiceImpl\"&gt;&lt;/dubbo:service&gt; &lt;dubbo:service interface=\"xyz.taotao.service.ItemService\" ref=\"itemServiceImpl\"&gt;&lt;/dubbo:service&gt;&lt;/beans&gt; 引入服务： 12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.2.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd\"&gt; &lt;!-- 引用dubbo服务 --&gt; &lt;dubbo:application name=\"taotao-manager-web\"/&gt; &lt;dubbo:registry protocol=\"zookeeper\" address=\"192.168.184.130:2181\"/&gt; &lt;!-- 引用指定的服务接口 --&gt; &lt;dubbo:reference interface=\"xyz.taotao.service.TestService\" id=\"testService\"&gt;&lt;/dubbo:reference&gt; &lt;dubbo:reference interface=\"xyz.taotao.service.ItemService\" id=\"itemService\"&gt;&lt;/dubbo:reference&gt; &lt;dubbo:reference interface=\"xyz.taotao.content.service.ContentService\" id=\"contentService\"&gt;&lt;/dubbo:reference&gt; &lt;dubbo:reference interface=\"xyz.taotao.content.service.ContentCategoryService\" id=\"contentCategoryService\"&gt;&lt;/dubbo:reference&gt;&lt;/beans&gt; 注意模块之间的依赖关系！ 注册中心 zookepper&nbsp;&nbsp;注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。使用dubbo-2.3.3以上版本，官方建议使用zookeeper作为注册中心。 在linux中安装zookepper第一步：安装jdk 第二步：解压缩zookeeper压缩包 第三步：将conf文件夹下zoo_sample.cfg复制一份，改名为zoo.cfg 第四步：修改配置dataDir属性，指定一个真实目录（进入zookeeper解压目录，创建data目录：mkdir data) 第五步： 启动zookeeper：bin/zkServer.sh start 关闭zookeeper：bin/zkServer.sh stop 查看zookeeper状态：bin/zkServer.sh status 注意开放防火墙的端口： 查看防火墙：service iptables status 添加规则：vim /etc/sysconfig/iptables 添加之后刷新配置：scource /etc/sysconfig/iptables 监控中心安装&nbsp;&nbsp;参考上一篇：https://www.yuzh.xyz/2018/07/06/dubbo%E7%9B%91%E6%8E%A7%E4%B8%AD%E5%BF%83-dubbo-admin-war%E7%9A%84%E6%89%93%E5%8C%85%E5%92%8C%E9%83%A8%E7%BD%B2/ 多工程之间的整合 dao模块管理dao层，放映射文件。 interface（分为dao-interface、service-interface）模块管理接口，放接口。 service模块管理service层，放SqlMapConfig.xml、连接池、sessionFactory、事务、dobbo服务等等… web模块管理controller层，放web.xml、spring、mvc、dubbo相关… MyBatis逆向工程就是导入一个工程，配置一下，生成数据库中对应的pojo和mapper pom 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;taotao-parent&lt;/artifactId&gt; &lt;groupId&gt;xyz.taotao&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;MybatisGenerator&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.6&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- 生成插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;configuration&gt; &lt;!--配置文件的位置--&gt; &lt;configurationFile&gt;src/main/resources/generatorConfig.xml&lt;/configurationFile&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Generate MyBatis Artifacts&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 配置生成规则： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt;&lt;generatorConfiguration&gt; &lt;!--mysql 连接数据库jar 这里选择自己本地位置--&gt; &lt;classPathEntry location=\"H:/[ 包 ] Lib/Other/mysql-connector-java-5.1.7-bin.jar\"/&gt; &lt;context id=\"testTables\" targetRuntime=\"MyBatis3\"&gt; &lt;commentGenerator&gt; &lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt; &lt;property name=\"suppressAllComments\" value=\"true\"/&gt; &lt;/commentGenerator&gt; &lt;!--数据库连接的信息：驱动类、连接地址、用户名、密码 --&gt; &lt;jdbcConnection driverClass=\"com.mysql.jdbc.Driver\" connectionURL=\"jdbc:mysql://localhost:3306/taotao\" userId=\"root\" password=\"admin\"&gt; &lt;/jdbcConnection&gt; &lt;!-- 默认false，把JDBC DECIMAL 和 NUMERIC 类型解析为 Integer，为 true时把JDBC DECIMAL 和 NUMERIC 类型解析为java.math.BigDecimal --&gt; &lt;javaTypeResolver&gt; &lt;property name=\"forceBigDecimals\" value=\"false\"/&gt; &lt;/javaTypeResolver&gt; &lt;!-- targetProject:生成PO类的位置 --&gt; &lt;javaModelGenerator targetPackage=\"xyz.yuzh.pojo\" targetProject=\"src/main/java\"&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name=\"enableSubPackages\" value=\"false\"/&gt; &lt;!-- 从数据库返回的值被清理前后的空格 --&gt; &lt;property name=\"trimStrings\" value=\"true\"/&gt; &lt;/javaModelGenerator&gt; &lt;!-- targetProject:mapper映射文件生成的位置 如果maven工程只是单独的一个工程，targetProject=\"src/main/java\" 若果maven工程是分模块的工程，targetProject=\"所属模块的名称\"，例如： targetProject=\"ecps-manager-mapper\"，下同--&gt; &lt;sqlMapGenerator targetPackage=\"xyz.yuzh.mapper\" targetProject=\"src/main/java\"&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name=\"enableSubPackages\" value=\"false\"/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- targetPackage：mapper接口生成的位置 --&gt; &lt;javaClientGenerator type=\"XMLMAPPER\" targetPackage=\"xyz.yuzh.mapper\" targetProject=\"src/main/java\"&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name=\"enableSubPackages\" value=\"false\"/&gt; &lt;/javaClientGenerator&gt; &lt;!-- 指定数据库表 --&gt; &lt;table schema=\"\" tableName=\"tb_content\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_content_category\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_item\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_item_cat\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_item_desc\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_item_param\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_item_param_item\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_order\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_order_item\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_order_shipping\"&gt;&lt;/table&gt; &lt;table schema=\"\" tableName=\"tb_user\"&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 点击插件运行-&gt;自动生成pojo和mapper在指定位置。然后复制到自己需要的工程里面，注意：没有自动实现序列化。 参考地址：https://blog.csdn.net/liudongdong0909/article/details/51534735 PageHelper导包之后在Mybatis的全局文件中配置SqlMapConfig.xml中配置拦截器插件 123456&lt;plugins&gt; &lt;plugin interceptor=\"com.github.pagehelper.PageHelper\"&gt; &lt;!-- 设置数据库类型 Oracle,Mysql,MariaDB,SQLite,Hsqldb,PostgreSQL六种数据库--&gt; &lt;property name=\"dialect\" value=\"mysql\"/&gt; &lt;/plugin&gt;&lt;/plugins&gt; 测试代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package xyz.taotao.pagehelper;import com.github.pagehelper.PageHelper;import com.github.pagehelper.PageInfo;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import xyz.taotao.mapper.TbItemMapper;import xyz.taotao.pojo.TbItem;import xyz.taotao.pojo.TbItemExample;import java.util.List;/** * Created with IntelliJ IDEA. * * @Author: yu_zh * @DateTime: 2018/07/05 14:36 */public class TestPageHelper { @Test public void testPageHelper() { //初始化spring容器 ApplicationContext ac = new ClassPathXmlApplicationContext(\"spring-dao.xml\"); //获取mapper代理对象 TbItemMapper tbItemMapper = ac.getBean(TbItemMapper.class); //设置分页信息 PageHelper.startPage(3, 100); //调用mapper方法查询数据 //查询条件对象 TbItemExample tbItemExample = new TbItemExample(); TbItemExample.Criteria criteria = tbItemExample.createCriteria(); //创建时间不为空才查询，免去了mapper中编辑sql criteria.andCreatedIsNotNull(); //第一个查询列表被分页 List&lt;TbItem&gt; tbItemList = tbItemMapper.selectByExample(tbItemExample); //第二个不会被分页 List&lt;TbItem&gt; tbItemList2 = tbItemMapper.selectByExample(tbItemExample); //获取分页信息 PageInfo&lt;TbItem&gt; tbItemPageInfo = new PageInfo&lt;&gt;(tbItemList); //遍历信息列表 tbItemPageInfo.getList(); System.out.println(\"被分页后条数：\"+tbItemPageInfo.getEndRow()); System.out.println(\"总记录数\"+tbItemPageInfo.getTotal()); System.out.println(\"页数\"+tbItemPageInfo.getPages()); System.out.println(\"当前页\"+tbItemPageInfo.getPageNum()); System.out.println(\"页大小\"+tbItemPageInfo.getPageSize()); int i = 1; for (TbItem item : tbItemList2) { i++; } System.out.println(\"全部条数：\"+i); }} 了解SEO &nbsp;&nbsp;百度这样的搜索引擎对于.html后缀的网页的搜索排名优先级是高于jsp的，我们可以在不改变网页是jsp格式的前提下，通过控制springmvc拦截.html请求达到浏览器始终都是.html后缀显示的效果。 比如： 12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:web=\"http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\" id=\"WebApp_ID\" version=\"2.5\"&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;/index.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!-- spring-mvc --&gt; &lt;servlet&gt; ...... &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;....&lt;/servlet-name&gt; &lt;!-- 伪静态化：SEO 搜索引擎优化--&gt; &lt;url-pattern&gt;*.html&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 12345页面控制器：@RequestMapping(value = \"/index\",method = RequestMethod.GET)public String index(){ return \"index\";} 访问一个站点的主页，用户一般都是 http://www.yuzh.xyz/ 或者有经验一点的会这样 http://www.yuzh.xyz/index.html 通常情况下，mvc的拦截形式是 / ，表示拦截所有非 jsp\\html的资源访问请求，这时/和/index.html两者的效果可能不一样。 如果主页在/WEB-INF/下，/index.html是会报404的，只有以/形式通过控制器跳转到主页。 回到伪静态化的话题，既然要实现伪静态化，就必须把拦截形式设为*.html，那么当用户输入两种不同的url是怎么跳转到主页的呢？ 1）当输入地址/，mvc没有拦截到，转而找欢迎页&lt;welcome-file&gt;/index.html&lt;/welcome-file&gt;，于是找/index.html，如果webapps下有页面就直接返回，如果没有就进入到mvc（此时已经被mvc拦截到了），前面mvc配置了@RequestMapping(value =&quot;/index&quot;)，于是进入了控制器方法，最终在控制器中跳转页面。 2）当输入地址/index.html，直接被mvc所拦截，不需要进欢迎页，直接到了控制器跳转页面。 3）注意：配置伪静态化后，url地址必须以.html才能访问资源。访问控制器的方法需要”映射路径+.html“，比如：@RequestMapping(value = “/getList”)，访问这个方法需要”getList.html“的形式，很奇怪哦~ 不然无法被拦截到啊！ 内容管理系统 — 抽取抽象表违反了数据库范式，但以便于开发 1) 随着硬件水平的迅猛发展，硬件成本的降低，数据库范式和开发效率上大多数情况下选择后者，现代企业开发中，通常会为了简单有效的管理数据和应用系统的效率，违反三大范式的要求，以空间换时间。2) 内容管理系统（content management system，CMS）是一种位于WEB 前端（Web 服务器）和后端办公系统或流程（内容创作、编辑）之间的软件系统。内容的创作人员、编辑人员、发布人员使用内容管理系统来提交、修改、审批、发布内容。这里指的“内容”可能包括文件、表格、图片、数据库中的数据甚至视频等一切你想要发布到Internet网站的信息。3) 就是后台管理维护前台的页面和页面中的内容可以动态展示。 栗子：本商城的门户系统首页中存在多个小板块，比如大广告位、淘淘快报、商品展示位…如果对于每一个小板块都创建一张表进行维护将会十分的麻烦，前台一个页面调整（增加删除修改），后台对应将会是pojo、mapper、dao、service、controller都要改动，于是试着把这些所有板块抽取一张统一的分类表。 把首页的每个展示功能（大广告位，淘淘快报等），看作是一个分类，每个展示功能里面展示的多条信息，看作是分类下的内容。 例如：首页大广告，对应的是大广告分类，而大广告位展示的多张图片，就是大广告分类下的内容，前台需要获取大广告的图片，只需要根据大广告的id查询对应的内容即可。 内容分类表：tb_content_category，需要存储树形结构的数据。（大分类下有小分类） 内容表：tb_content，将所有信息统一到一张表。 比如有些板块不需要`price`这个字段，当字段不足时，就用该字段存点其他的。 mapper中使用“主键返回”在自动生成的sql中添加 &lt;selectKey/&gt; 节点： 1234567891011&lt;insert id=\"insert\" parameterType=\"xyz.taotao.pojo.TbContentCategory\" &gt; &lt;selectKey keyProperty=\"id\" resultType=\"long\" order=\"AFTER\"&gt; select last_insert_id(); &lt;/selectKey&gt; insert into tb_content_category (id, parent_id, name, status, sort_order, is_parent, created, updated) values (#{id,jdbcType=BIGINT}, #{parentId,jdbcType=BIGINT}, #{name,jdbcType=VARCHAR}, #{status,jdbcType=INTEGER}, #{sortOrder,jdbcType=INTEGER}, #{isParent,jdbcType=BIT}, #{created,jdbcType=TIMESTAMP}, #{updated,jdbcType=TIMESTAMP}) &lt;/insert&gt;","link":"/2018/07/08/分布式技术入坑指南（一）/"},{"title":"线程高级","text":"Java并发编程包 java.util.concurrent 的学习笔记 简介 在 Java 5.0 提供了 java.util.concurrent （简称JUC ）包，在此包中增加了在并发编程中很常用的实用工具类，用于定义类似于线程的自定义子系统，包括线程池、异步 IO 和轻量级任务框架。提供可调的、灵活的线程池。还提供了设计用于多线程上下文中的 Collection 实现等。 volatile 关键字-内存可见性 内存可见性（Memory Visibility）是指当某个线程正在使用对象状态而另一个线程在同时修改该状态，需要确保当一个线程修改了对象状态后，其他线程能够看到发生的状态变化。 通过一个用例验证可见性：子线程修改共享资源的状态（写操作），主线程访问共享资源（读操作），如果为true打印一段符号并退出循环。 1234567891011121314151617181920212223242526272829public class TestVolatile { public static void main(String[] args) { // 线程1 ThreadDemo td = new ThreadDemo(); new Thread(td).start(); // 主线程循环的访问共享资源 while(true){ if(td.isFlag()){ System.out.println(\"------------------\"); break; } } }}class ThreadDemo implements Runnable { private boolean flag = false; // 共享资源 @Override public void run() { try { Thread.sleep(200); } catch (InterruptedException e) { } flag = true; System.out.println(\"flag=\" + isFlag()); }} 运行结果： 可以看到，子线程将资源状态改为true之后，而主线程一直处在循环状态，并未打印一段符号，说明此时共享资源状态还是false，而子线程明明将状态改为true来着的，这是什么原因呢？ 计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。 程序运行时，JVM为每一个线程分配一个独立的缓存来提高效率。共享资源存放在主存（堆内存、物理内存）中，“每个线程操作共享资源时，先从主存中读取共享资源放入自己的缓存区，在自己的缓存区中对资源进行修改，然后将修改更新到主存中去。” 从用例可以看出，子线程睡了2s，所以主线程先执行，获得了资源状态为false。然后子线程将状态改为true并将修改更新到主存中，但是主线程一直处在循环状态，这是因为while的运行调用了底层的代码处理非常之快，快到都没有来得及更新主存中的共享资源数据。 现在知道是因为子线程更新缓存中的值到主存去了而另外一个线程没有来得及刷新缓存来更新主存中的数据，所以导致的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。 Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。 子线程对主存进行了修改，主线程没有立即看到，所以出现了概念中的可见性问题。 解决方案： 方式一：使用synchronized和Lock（后面学）保证可见性。它能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。 12345678while (true) { synchronized (td) { if (td.isFlag()) { System.out.println(\"------------------\"); break; } }} 每次访问加锁数据都会从主存中刷新数据，所以主线程正常退出。 但是由于 synchronized 关键字会极低的影响运行效率，所以还有一种方式：使用 volatile 关键字保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 volatile 和 synchronized 的区别： volatile 不保证互斥性。一个线程对共享资源访问另外一个线程也能访问，不具备互斥性。 volatile 不保证原子性。见下一节 synchronized 保证原子性是因为对共享资源加锁，每次只能一个线程访问，一个线程在同步代码块中执行操作之后另一个线程才会进入。 引用：Java并发编程：volatile关键字解析 原子变量-CAS算法首先明白 i++ 操作是不具备原子性的，i++分为三个步骤：首先线程从主存中获取变量i的值，然后执行 i + 1，再将 i+1 赋值给i，然后写入到线程自己的工作内存，最后写入到主存。 假如线程1获取了volatile修饰的共享变量i还未来得及操作，但此时被线程2抢夺了时间片进行了 +1 操作并写入到主存，此时主存的 i 的值已被更改。 由于线程1只是对共享变量进行读取操作并没有对变量进行修改，所以不会导致线程2的工作内存中缓存变量i的缓存无效，所以线程2会直接去主存读取i的值。然后线程1对线程2修改之前的i进行+1之后写入到主存，此次的线程2更新的值被线程1给覆盖掉了。 原子变量原子变量是保证了变量具有原子性的特征，对该变量的操作要么全部成功，要么全部失败。原子变量通过以下两点保证变量的原子性。 使用 volatile 修饰符保证变量的内存可见性 使用 CAS 算法通过内存值和预估值的比对实现原子性 java.util.concurrent 包中常见原子变量及API： 类 对应类型 AtomicBoolean boolean AtomicInteger int AtomicLong long AtomicReference 参数化类型 T AtomicIntegerArray int[] AtomicLongArray long[] AtomicMarkableReference Pair AtomicReferenceArray T[] AtomicStampedReference Pair 核心方法：boolean compareAndSet(expectedValue, updateValue) CAS算法CAS (Compare-And-Swap) 是一种硬件对并发的支持，针对多处理器操作而设计的处理器中的一种特殊指令，用于管理对共享数据的并访问。 CAS 是一种无锁的非阻塞算法的实现。 CAS 包含了 3 个操作数： 需要读写的内存值 V 进行比较的值 A 拟写入的新值 B 当且仅当 V 的值等于 A 时，CAS 通过原子方式用新值 B 来更新 V 的值，否则不会执行任何操作。 重现i++操作：初始化时 i=0, 线程2从主存中获取到共享变量i，内存值V=0；此时线程1抢夺到了时间片也从主存中获取到共享变量i，内存值V=0；并且进行+1操作，+1时CAS算法再次读取主存的值发现i没变，所以比较值A=0，对比V == A为true 则以B=1更新V，写入到线程1的工作内存，再写入到主存。 此时主存中的值i=1，但是线程2在线程1修改之前就读取到了 i 的值，V=0，然后进行+1操作，CAS算法再次从主存获取i值发现已经变化了：A=1，此时 V == A 为false，则取消更新。 ConcurrentHashMap 锁分段机制 Java 5.0 在 java.util.concurrent 包中提供了多种并发容器类来改进同步容器的性能。ConcurrentHashMap 同步容器类是Java 5 增加的一个线程安全的哈希表。对与多线程的操作，介于 HashMap 与 Hashtable 之间。内部采用“锁分段”机制替代 Hashtable 的独占锁。进而提高性能。 多线程环境下，使用 HashMap 是线程不安全的。为了保证线程安全，我们可以通过使用Collectinos集合工具类中的synchronized方法来将非线程安全的容器类转为对应线程安全的容器类。其内部就是给每个方法加了一把synchronized锁。另外一种方式就是使用 HashMap 的线程安全类 Hashtable。 Hashtable 采用了表锁机制，任何一个线程对容器访问其他线程会进入阻塞或轮询状态。由于Hashtable 为每个方法使用了同一把锁（每一个被synchronized修饰的方法都是使用的java内置锁，锁的是方法所属对象本身），一个线程获得了锁进入某个同步方法，其他线程都不能进入被该锁修饰的其他同步方法，除非锁被释放抢到了锁。在并发编程中，极低的降低了效率。 另外 Hashtable 这种表锁机制（每个同步方法使用同一把锁）在并发的复合操作中会产生异常。例如：在迭代操作中，线程1调用了同步的 hashNext() 方法发现有下一个元素准备调用同步的 next() 方法获取元素时，时间片被线程2抢夺过去将某个元素修改了，此时会抛出并发异常ConcurrentModificationException。多个同步方法组成的操作不是同步操作了。 为了解决这种问题于是有了锁分段机制，这个机制将容器中的数据分为一段一段存储，为每一段加一把锁，不同的锁之间互不干扰，当一个线程占用其中一段数据的时候另一个线程可以访问另一段的数据。以此提高了并发效率。 以下是常用并发容器类对应的未加同步的容器类： 并发容器类 非同步容器类 ConcurrentHashMap HashMap ConcurrentSkipListMap TreeMap ConcurrentSkipListSet TreeSet CopyOnWriteArrayList ArrayList CopyOnWriteArraySet Set 当希望许多线程访问一个容器类的时候，ConcurrentHashMap 通常优于同步的 HashMap。ConcurrentSkipListMap 通常优于同步的TreeMap。当期望的读数和遍历远远大于列表的更新数时，CopyOnWriteArrayList 优于同步的 ArrayList。 CountDownLatch 闭锁CountDownLatch 一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 闭锁可以延迟线程的进度直到其到达终止状态，闭锁可以用来确保某些活动直到其他活动都完成才继续执行： 确保某个计算在其需要的所有资源都被初始化之后才继续执行; 确保某个服务在其依赖的所有其他服务都已经启动之后才启动; 等待直到某个操作所有参与者都准备就绪再继续执行 一个简单的用例，统计所有线程执行某个同步操作的总计时间。主线程需要在其他线程执行完毕之前等待，直至闭锁计数器为0解除等待状态。 12345678910111213141516171819202122232425262728293031323334353637public class TestCountDownLatch { public static void main(String[] args) { final CountDownLatch latch = new CountDownLatch(50); // 创建一个闭锁对象 LatchDemo ld = new LatchDemo(latch); long start = System.currentTimeMillis(); for (int i = 0; i &lt; 50; i++) { new Thread(ld).start(); // 每一个线程执行一次运算 } try { latch.await(); // 主线程进入等待，直至闭锁计算器为0，解除等待状态。 } catch (InterruptedException e) { } long end = System.currentTimeMillis(); System.out.println(\"耗费时间为：\" + (end - start)); // 其他线程都执行完毕统计所有线程执行的总时间 }}class LatchDemo implements Runnable { private CountDownLatch latch; // 维护一个闭锁对象 public LatchDemo(CountDownLatch latch) { this.latch = latch; } @Override public void run() { try { for (int i = 0; i &lt; 50000; i++) { if (i % 2 == 0) { System.out.println(i); } } } finally { latch.countDown(); // 每个线程执行完毕计数器-1 } }} 实现 Callable 接口创建线程的第三种方式：实现 Callable 接口，这是一个带泛型的接口，实现这个接口的线程可以返回泛型参数的值并可以抛出异常。 12345678910111213141516171819202122232425public class TestCallable { public static void main(String[] args) { ThreadDemo td = new ThreadDemo(); // 线程对象 FutureTask&lt;Integer&gt; result = new FutureTask&lt;&gt;(td); // 用于接收线程结果的对象 new Thread(result).start(); // 启动 try { Integer sum = result.get(); //FutureTask没有获取到结果之前，线程进入阻塞状态，因此也可用于闭锁。 System.out.println(sum); System.out.println(\"------------------------------------\"); } catch (InterruptedException | ExecutionException e) { e.printStackTrace(); } }}class ThreadDemo implements Callable&lt;Integer&gt; { @Override public Integer call() throws Exception { int sum = 0; for (int i = 0; i &lt;= 100000; i++) { sum += i; } return sum; }} Lock 同步锁 在 Java 5.0 之前，协调共享对象的访问时可以使用的机制只有 synchronized 和 volatile 。Java 5.0 后增加了一些新的机制，但并不是一种替代内置锁的方法，而是当内置锁不适用时，作为一种可选择的高级功能。ReentrantLock 实现了 Lock 接口，并提供了与synchronized 相同的互斥性和内存可见性。但相较于synchronized 提供了更高的处理锁的灵活性。 解决多线程安全问题，加锁的第二种方式。相对于 synchronized 上锁使用 lock 可更具有灵活性，并且是显式锁，上锁和释放锁需要手动完成。需要注意的是当同步代码出现异常必须保证 unlock 操作一定会执行，否则由于没释放锁其他线程会一直处于阻塞状态。 12345678910111213141516171819202122232425262728293031public class TestLock { public static void main(String[] args) { Ticket ticket = new Ticket(); new Thread(ticket, \"1号窗口\").start(); new Thread(ticket, \"2号窗口\").start(); new Thread(ticket, \"3号窗口\").start(); }}class Ticket implements Runnable { private int tick = 100; private Lock lock = new ReentrantLock(); @Override public void run() { while (true) { lock.lock(); //上锁 try { if (tick &gt; 0) { try { Thread.sleep(200); } catch (InterruptedException e) { } System.out.println(Thread.currentThread().getName() + \" 完成售票，余票为：\" + --tick); } } finally { lock.unlock(); //释放锁 } } }} Condition 控制线程通信首先回顾一下生产者消费者模型，直接上代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class TestProducerAndConsumer { public static void main(String[] args) { Clerk clerk = new Clerk(); Producer producer = new Producer(); producer.setClerk(clerk); Consumer consumer = new Consumer(); consumer.setClerk(clerk); new Thread(producer,\"生产者A：\").start(); new Thread(consumer,\"消费者B：\").start(); }}// 店员（维护共享资源——产品，生产和消费）@Dataclass Clerk { private int product; public synchronized void production(){ if (product &gt;= 10) { System.out.println(\"已满！\"); try { this.wait(); } catch (InterruptedException e) { } } else { System.out.println(Thread.currentThread().getName()+\"生产了：\" + ++product); this.notifyAll(); } } public synchronized void consumption(){ if (product &lt;= 0) { System.out.println(\"缺货！\"); try { this.wait(); } catch (InterruptedException e) { } } else { System.out.println(Thread.currentThread().getName()+\"消费了：\" + product--); this.notifyAll(); } }}// 生产者@Dataclass Producer implements Runnable{ private Clerk clerk; @Override public void run() { for (int i = 0; i &lt; 20; i++){ clerk.production(); } }}// 消费者@Dataclass Consumer implements Runnable{ private Clerk clerk; @Override public void run() { for (int i = 0; i &lt; 20; i++){ clerk.consumption(); } }} 运行结果部分截图： 以上结果看似交替有序的执行，但是存在一个潜在的问题。当我们将仓库容量设为1，库存有了一个产品就满了，生产者挂起，通知消费者运行。 if (product &gt;= 1) { System.out.println(&quot;已满！&quot;); try { this.wait(); } catch (InterruptedException e) { } } else { System.out.println(Thread.currentThread().getName()+&quot;生产了：&quot; + ++product); this.notifyAll(); } 再让生产者每次生产之前睡一秒： for (int i = 0; i &lt; 20; i++){ try { Thread.sleep(200); } catch (InterruptedException e) { } clerk.production(); } 看看运行情况… 发现程序没有正常停止 为什么会出现这种情况呢？首先：生产者每次生产之前都会睡上一秒，这就意味着时间片总是被消费者先抢去了，每次都是消费者没货了进入阻塞状态之后生产者才慢吞吞的抢到了时间片进行生产。 再看一次消费者的代码： public synchronized void consumption() { if (product &lt;= 0) { System.out.println(&quot;缺货！&quot;); try { this.wait(); } catch (InterruptedException e) { } } else { System.out.println(Thread.currentThread().getName() + &quot;消费了：&quot; + product--); this.notifyAll(); } } 注意：这个 else 是问题的关键点。 生产者消费者同时开抢，由于生产者0要睡上一会，于是毫不意外的被消费者0抢到时间片，进入缺货分支里面陷入了等待状态，此时生产者0 睡完1秒生产了一个产品，唤醒所有线程。消费者0由于已经在消费的同步代码块里面所以继续执行退出了本次循环，该消费者0没有消费产品。 接着，生产者1和消费者1抢时间片，生产者每次都要睡觉怎么抢的过消费者，于是消费者1抢到了，发现有货！通知所有线程，消费者2又抢到了时间，发现没货，此时生产1才“被迫”拿到时间片生产一个产品，通知所有线程。由于生产者每次都要等待所以每次都被消费者抢到时间，消费者2执行完毕。消费者2没有消费就结束。 生产者2与消费者3开抢，消费者3胜。有货！消费完毕通知所有线程，消费者4又抢到了，没货。此时生产者2又“被迫”生产了一个，通知所有线程… 好吧，消费者5抢到了，消费完美滋滋。消费者6又来了，缺货！生产者3“被迫”生产…… 每次都是消费者抢到CPU时间片执行权，而生产者每次都是在消费者没货时等待状态下才有机会执行，而由于存在else分支导致有些消费者并没有消费产品就结束了。 最后的结果是消费者早早的遍历完20次，而生产者迟迟没有遍历完20次，慢慢吞吞的… 最关键的： 由于消费者早就消费完了，生产者生产了一个唤醒所有，只有自己被唤醒没人和它抢，就又进入了生产者方法，发现库存满了！于是乎，等待其他线程唤醒自己，然而没有其他线程了，就没人唤醒自己了… 解决办法：去掉else分支 public synchronized void production() { if (product &gt;= 1) { System.out.println(&quot;已满！&quot;); try { this.wait(); } catch (InterruptedException e) { } } System.out.println(Thread.currentThread().getName() + &quot;生产了：&quot; + ++product); this.notifyAll(); } public synchronized void consumption() { if (product &lt;= 0) { System.out.println(&quot;缺货！&quot;); try { this.wait(); } catch (InterruptedException e) { } } System.out.println(Thread.currentThread().getName() + &quot;消费了：&quot; + product--); this.notifyAll(); } 这样保证了每次消费者都能消费到产品，然而只有一个消费者和一个生产者的情况下是没问题的，当分别有两个呢？ 乱套了… 这个稍微想想很好理解，比如刚开始第一个消费者线程抢到了时间进入缺货分支陷入等待，于是生产者生产了一个，开始抢夺时间，假如此时被第二个消费者线程抢到时间进入了消费代码块，但是第一个消费线程已经进入了它就会继续执行完毕，于是乎两个消费者线程消费了同一份产品。 这就是 虚假唤醒 ，那么怎么解决呢？真是令人头大… 其实也很简单，将生产消费的同步代码块中由 if 改为 while就行了。 public synchronized void production() { while (product &gt;= 1) { System.out.println(&quot;已满！&quot;); try { this.wait(); } catch (InterruptedException e) { } } System.out.println(Thread.currentThread().getName() + &quot;生产了：&quot; + ++product); this.notifyAll(); } public synchronized void consumption() { while (product &lt;= 0) { System.out.println(&quot;缺货！&quot;); try { this.wait(); } catch (InterruptedException e) { } } System.out.println(Thread.currentThread().getName() + &quot;消费了：&quot; + product--); this.notifyAll(); } 一次等待之后，当要继续执行下面的代码，再次判断一次是否有货，有才消费，没有就继续等待。 至此，线程间通信的潜在问题及虚假唤醒问题完美解决了。 接下来就是通过使用Lock锁取代Synchronized锁，而Condiction则是对线程通信进行控制的条件变量的对象。 Condition 接口描述了可能会与锁有关联的条件变量。这些变量在用法上与使用 Object.wait 访问的隐式监视器类似，但提供了更强大的功能。需要特别指出的是，单个 Lock 可能与多个 Condition 对象关联。为了避免兼容性问题，Condition 方法的名称与对应的 Object 版本中的不同。在 Condition 对象中，与 wait、notify和notifyAll 方法对应的分别是await、signal 和 signalAll。Condition 实例实质上被绑定到一个锁上。要为特定 Lock 实例获得Condition 实例，请使用其 newCondition() 方法。 123456789101112131415161718192021222324252627282930313233343536373839class Clerk1 { private int product; private Lock lock = new ReentrantLock(); // 加 Lock 锁 Condition condition = lock.newCondition(); // 通过 lock 获得锁关联变量对象 public void production() { lock.lock(); try { while (product &gt;= 1) { System.out.println(\"已满！\"); try { condition.await(); } catch (InterruptedException e) { } } System.out.println(Thread.currentThread().getName() + \"生产了：\" + ++product); condition.signalAll(); } finally { lock.unlock(); } } public void consumption() { lock.lock(); try { while (product &lt;= 0) { System.out.println(\"缺货！\"); try { condition.await(); } catch (InterruptedException e) { } } System.out.println(Thread.currentThread().getName() + \"消费了：\" + product--); condition.signalAll(); } finally { lock.unlock(); } }} 线程按序交替 编写一个程序，开启 3 个线程，这三个线程的 ID 分别为A、B、C，每个线程将自己的 ID 在屏幕上打印 10 遍，要求输出的结果必须按顺序显示。如：ABCABCABC…… 依次递归 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class TestABCAlternate { public static void main(String[] args) { ABCAlternate alternate = new ABCAlternate(); new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; 10; i++) { alternate.printA(); } } },\"A\").start(); new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; 10; i++) { alternate.printB(); } } },\"B\").start(); new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; 10; i++) { alternate.printC(); } } },\"C\").start(); }}class ABCAlternate { private int num = 1; Lock lock = new ReentrantLock(); Condition con1 = lock.newCondition(); Condition con2 = lock.newCondition(); Condition con3 = lock.newCondition(); public void printA() { lock.lock(); try { if (num != 1) { try { con1.await(); } catch (InterruptedException e) { } } System.out.print(Thread.currentThread().getName()); num = 2; con2.signal(); } finally { lock.unlock(); } } public void printB() { lock.lock(); try { if (num != 2) { try { con2.await(); } catch (InterruptedException e) { } } System.out.print(Thread.currentThread().getName()); num = 3; con3.signal(); } finally { lock.unlock(); } } public void printC() { lock.lock(); try { if (num != 3) { try { con3.await(); } catch (InterruptedException e) { } } System.out.print(Thread.currentThread().getName()); num = 1; con1.signal(); } finally { lock.unlock(); } }} ReadWriteLock 读写锁ReadWriteLock 维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。只要没有 writer，读取锁可以由多个 reader 线程同时保持。写入锁是独占的。 ReadWriteLock 读取操作通常不会改变共享资源，但执行写入操作时，必须独占方式来获取锁。对于读取操作占多数的数据结构。 ReadWriteLock 能提供比独占锁更高的并发性。而对于只读的数据结构，其中包含的不变性可以完全不需要考虑加锁操作 用例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class TestReadWriterLock { public static void main(String[] args) { ReadWriterLock rwLock = new ReadWriterLock(); new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; 100; i++) { rwLock.read(); } } }, \"ReadLock:\").start(); new Thread(new Runnable() { @Override public void run() { rwLock.writer(233); } }, \"WriterLock:\").start(); }}class ReadWriterLock { private int resource; private ReadWriteLock rwLock = new ReentrantReadWriteLock(); public void read() { try { rwLock.readLock().lock(); System.out.println(Thread.currentThread().getName() + resource); } finally { rwLock.readLock().unlock(); } } public void writer(int n) { try { rwLock.writeLock().lock(); resource = n; System.out.println(Thread.currentThread().getName() + resource); } finally { rwLock.writeLock().unlock(); } }} 运行结果部分截图： 线程八锁线程八锁，实际上是多线程编程中经常遇到的八种情况。通过八种场景学习总结线程锁的特性。 场景一：两个普通同步方法，两个线程，是同一把锁（this锁），存在互斥关系。 123456789101112131415161718192021222324252627282930public class TestThread8Monitor { public static void main(String[] args) { Number number = new Number(); new Thread(new Runnable() { @Override public void run() { number.one(); } }).start(); new Thread(new Runnable() { @Override public void run() { number.two(); } }).start(); }}class Number { public synchronized void one() { System.out.println(\"one\"); } public synchronized void two() { System.out.println(\"two\"); }} 运行结果： one two 场景二：让同步方法 one() 睡3秒，观察结果。同一把锁，存在互斥关系，一个同步方法没有释放锁其他所有同步方法阻塞。 public synchronized void one() { try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;one&quot;); } 运行结果： one two 场景三：新增一个同步方法 three()，三个同步方法，三个线程，一个线程对象，竞争打印。 public synchronized void one() { System.out.println(&quot;one&quot;); } public synchronized void two() { System.out.println(&quot;two&quot;); } public synchronized void three() { System.out.println(&quot;three&quot;); } 运行结果： one three two 场景四：新增一个 Number 对象。两个线程对象，两个同步方法。不同锁之间（两个this不是同一个this）的同步方法不存在互斥。 public static void main(String[] args) { Number number = new Number(); Number number2 = new Number(); new Thread(new Runnable() { @Override public void run() { number.one(); } }).start(); new Thread(new Runnable() { @Override public void run() { number2.two(); } }).start(); } 两个同步方法： public synchronized void one() { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;one&quot;); } public synchronized void two() { System.out.println(&quot;two&quot;); } 运行结果： two one 场景五：同一个线程对象，一个静态同步方法，一个非静态同步方法。不同锁之间的同步方法不存在互斥。 public static synchronized void one() { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;one&quot;); } public synchronized void two() { System.out.println(&quot;two&quot;); } 运行结果： two one 场景六：同一个线程对象，两个静态同步方法，是相同的锁（Class锁），存在互斥。 public static synchronized void one() { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;one&quot;); } public static synchronized void two() { System.out.println(&quot;two&quot;); } 运行结果： one two 场景七：新增一个线程对象。两个线程对象，两个静态同步方法。同一把锁存在互斥性。 public static void main(String[] args) { Number number = new Number(); Number number2 = new Number(); new Thread(new Runnable() { @Override public void run() { number.one(); } }).start(); new Thread(new Runnable() { @Override public void run() { number2.two(); } }).start(); } 静态同步方法： public static synchronized void one() { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;one&quot;); } public static synchronized void two() { System.out.println(&quot;two&quot;); } 运行结果： one two 场景八：新增一个线程对象。两个线程对象，一个静态同步方法，一个非静态同步方法。非同一把锁不存在竞争 public static synchronized void one() { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;one&quot;); } public synchronized void two() { System.out.println(&quot;two&quot;); } 运行结果： two one 结论： 静态同步方法的锁是 Class 锁，非静态同步方法的锁是 this 锁，不同的对象是不同的 this 锁。 某一个时刻内，只能有一个线程持有锁，无论几个方法。相同的锁，一个线程获得锁，其他线程都得等待。 线程池创建线程的第四种方式，线程池：提供了一个线程队列，队列中保存着所有等待状态的线程。避免了创建与销毁额外开销，提高了响应的速度。 线程池的体系结构： java.util.concurrent.Executor : 负责线程的使用与调度的根接口 |--**ExecutorService 子接口: 线程池的主要接口 |--ThreadPoolExecutor 线程池的实现类 |--ScheduledExecutorService 子接口：负责线程的调度 |--ScheduledThreadPoolExecutor ：继承ThreadPoolExecutor，实现ScheduledExecutorService ThreadPoolExecutor和ScheduledThreadPoolExecutor可以创建连接池对象，但是使用工厂获得对象是最好的方式。工具类 Executors 的常用API及描述： 方法 描述 ExecutorService newFixedThreadPool() 创建固定大小的线程池 ExecutorService newCachedThreadPool() 缓存线程池，线程池的数量不固定，可以根据需求自动的更改数量，可以自动进行线程回收 ExecutorService newSingleThreadExecutor() 创建单个线程池。线程池中只有一个线程 ScheduledExecutorService newScheduledThreadPool() 创建固定大小的线程，可以延迟或定时的执行任务 用例说明： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class TestThreadPool { public static void main(String[] args) throws Exception { //创建线程池 ExecutorService pool = Executors.newFixedThreadPool(5); ThreadPoolDemo tpd = new ThreadPoolDemo(); //5个线程执行10个任务，某些线程会被回收 for (int i = 0; i &lt; 10; i++) { pool.submit(tpd); // 可传 Callable 和 Runnable接口作为任务对象 } //关闭线程池 pool.shutdown(); /** 以 Callable 作为任务 **/ List&lt;Future&lt;Integer&gt;&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) { Future&lt;Integer&gt; future = pool.submit(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { int sum = 0; for (int i = 0; i &lt;= 100; i++) { sum += i; } return sum; } }); list.add(future); } pool.shutdown(); for (Future&lt;Integer&gt; future : list) { System.out.println(future.get()); } }}class ThreadPoolDemo implements Runnable { private int i = 0; @Override public void run() { while (i &lt;= 100) { System.out.println(Thread.currentThread().getName() + \" : \" + i++); } }} 线程调度一个 ExecutorService，可安排在给定的延迟后运行或定期执行的命令。 123456789101112131415161718192021222324public class TestScheduledThreadPool { public static void main(String[] args) throws ExecutionException, InterruptedException { // 线程池的任务调度 ScheduledExecutorService pool = Executors.newScheduledThreadPool(5); // 十个任务 for (int i = 0; i &lt; 5; i++) { /** * 参数一：任务 * 参数二：延迟时间 * 参数一：时间单位 */ ScheduledFuture&lt;Integer&gt; future = pool.schedule(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { int num = new Random().nextInt(100); return num; } }, 1, TimeUnit.SECONDS); System.out.println(future.get()); } // 关闭线程池 pool.shutdown(); }} ForkJoinPool 分支/合并框架 工作窃取Fork/Join 框架：就是在必要的情况下，将一个大任务，进行拆分(fork)成若干个小任务（拆到不可再拆时），再将一个个的小任务运算的结果进行 join 汇总。 前面学过 归并排序，实际上这种思想和归并排序是一样的。 采用 “工作窃取”模式（work-stealing）：当执行新的任务时它可以将其拆分分成更小的任务执行，并将小任务加到线程队列中，然后再从一个随机线程的队列中偷一个并把它放在自己的队列中。 相对于一般的线程池实现，fork/join框架的优势体现在对其中包含的任务的处理方式上.在一般的线程池中，如果一个线程正在执行的任务由于某些原因无法继续运行，那么该线程会处于等待状态。而在fork/join框架实现中，如果某个子问题由于等待另外一个子问题的完成而无法继续运行。那么处理该子问题的线程会主动寻找其他尚未运行的子问题来执行.这种方式减少了线程的等待时间，提高了性能。 模拟拆分： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class TestForkJoinPool { public static void main(String[] args) { // 创建fork/join对象 ForkJoinPool pool = new ForkJoinPool(); // 创建任务对象 ForkJoinTask&lt;Long&gt; task = new ForkJoinSumCalculate(0L, 100000000L); // 执行任务 Long sum = pool.invoke(task); System.out.println(sum); }}// 创建自己的fork/join任务，计算从start开始end个数的和。需要继承递归任务类。class ForkJoinSumCalculate extends RecursiveTask&lt;Long&gt; { private long start; private long end; /** * 拆分临界值：定义子任务（子线程队列）到多大时不再拆分，开始计算每个子任务的值。 * - 如果临界值 = 任务总大小，就不会拆分，直接循环计算所有值。 * - 如果临界值 = 1L，就拆到每个子线程队列大小为1时停止拆分 */ private static final long THURSHOLD = 10000L; public ForkJoinSumCalculate(long start, long end) { this.start = start; this.end = end; } @Override protected Long compute() { long len = end - start; if (len &lt;= THURSHOLD) { long sum = 0L; for (long i = start; i &lt;= end; i++) { sum += i; } return sum; } else { long mid = (end + start) / 2; ForkJoinSumCalculate left = new ForkJoinSumCalculate(start, mid); left.fork(); ForkJoinSumCalculate right = new ForkJoinSumCalculate(mid + 1, end); right.fork(); return left.join() + right.join(); } }}","link":"/2018/09/01/线程高级/"},{"title":"基于 Spring Boot 技术栈构建企业级博客系统的开发记录","text":"基于 Spring Boot 技术栈构建企业级博客系统的开发记录- 该项目构建基于 Gradle，目的在于通过博客系统的开发了解企业级开发的完整流程，学习掌握 Spring Boot 及其周边前沿技术。- preview：http://blog.yuzh.xyz 前端 BootStrap 样式框架 Thymeleaf 模板引擎 JQuery js 函数库 HTML5 页面结构 JavaScript 脚本 CSS 样式 后端 Spring 解耦合 Spring MVC 控制层框架 Spring Boot 快捷开发，整合 Spring 全家桶 Spring Data 持久层框架，简化数据库操作 Spring Security 安全权限控制 Hibernate 遵循 JPA 规范的持久层实现 数据存储 MySql 关系型数据库 H2 内存数据库 MongoDB 文件存储 其他 Elastic Search 全文检索 Gradle 项目构建 插件 catalog-generator.js 博客目录生成插件 tether.js 下拉框插件 thinker-md.vendor.js markdown 编辑器 toastr.min.js 提示框 cropbox.js 图片裁剪 … … 一、 使用 Gradle / Spring Initializer 搭建 Spring Boot 运行环境1.1 安装 Gradle 环境下载 gradle 二进制文件，解压到指定目录； 配置 GRADLE_HOME 环境变量，值为解压路径； 添加 %GRADLE_HOME%/bin 到 Path 变量。 命令行 gradle -v 查看版本： 1.2 使用 Spring Initializer 快速生成 Spring Boot 应用使用 Spring 快速开始向导，创建一个项目并下载到本地。 使用 gradle 编译项目，进入根目录执行： 1gradle build 编译完成之后会在目录生成一个 build 文件夹，里面存放着编译后的文件以及安装的jar。 运行这个 jar ： 1java -jar spring-boot-blog-0.0.1-SNAPSHOT.jar 一个简单的 spring boot 应用启动起来了，接下来可以正常访问。 1.3 项目结构 .gradle gradle 运行时相关配置文件，不用多说了。 文件夹 build 项目编译后路径 文件夹 gradle 文件夹 wrapper 统一管理 gradle 版本，优点是即使没有装 gradle 环境可以运行里面的 jar 直接构建项目。 build.gradle gradle的用户配置文件（构建脚本），相当于 maven 的 pom.xml. gradlew gradle 环境搭建的脚本（linux） gradlew.bat gradle 环境搭建的脚本（windows） settings.gradle 其他用户配置 1.4 自定义存储仓库更改 build.gradle 配置文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// buildscript 代码块中脚本优先执行buildscript { // ext 用于定义动态属性 ext { springBootVersion = '1.5.17.BUILD-SNAPSHOT' } // 使用了 Maven 的中央仓库（也可以指定其他仓库） repositories { mavenCentral() maven { url \"https://repo.spring.io/snapshot\" } maven { url \"https://repo.spring.io/milestone\" } // 使用 aliyun 镜像仓库// maven { url 'http://maven.aliyun.com/nexus/content/groups/public/' } } // 依赖关系 dependencies { // classpath 声明说明了在执行其余的脚本时，ClassLoader 可以使用这些依赖项 classpath(\"org.springframework.boot:spring-boot-gradle-plugin:${springBootVersion}\") }}// 使用插件apply plugin: 'java'apply plugin: 'eclipse'apply plugin: 'org.springframework.boot'group = 'xyz.yuzh.spring.boot.blog'// 打包的类型为 jar，并指定了生成的打包的文件名称和版本jar { baseName = 'hello-world' version = '0.0.1-SNAPSHOT'}version = '0.0.1-SNAPSHOT'// 指定编译 .java 文件的 JDK 版本sourceCompatibility = 1.8// 默认使用了 Maven 的中央仓库。repositories { mavenCentral() maven { url \"https://repo.spring.io/snapshot\" } maven { url \"https://repo.spring.io/milestone\" }// maven { url 'http://maven.aliyun.com/nexus/content/groups/public/' }}// 依赖关系dependencies { // 该依赖对于编译发行是必须的 compile('org.springframework.boot:spring-boot-starter-web') // 该依赖对于编译测试是必须的，默认包含编译产品依赖和编译时依 testCompile('org.springframework.boot:spring-boot-starter-test')} 1.5 编写程序代码及测试用例控制层： 1234567@RestControllerpublic class HelloController { @RequestMapping(value = \"/hello\") public String hello(){ return \"hello gradle!\"; }} 用例代码：使用了 Spring Mvc 单元测试类 MockMVC，详解参考 123456789101112131415161718@RunWith(SpringRunner.class)@SpringBootTest@AutoConfigureMockMvcpublic class SpringBootBlogApplicationTests { @Autowired private MockMvc mockMvc; @Test public void testHello() throws Exception { ResultActions actions = mockMvc.perform(MockMvcRequestBuilders.get(\"/hello\"). accept(MediaType.APPLICATION_JSON)); // 指定客户端能够接收的内容类型 actions.andExpect(status().isOk()); // 添加断言, 添加ResultMatcher验证规则，验证控制器执行完成后结果是否正确. actions.andExpect(content().string(equalTo(\"hello gradle!\"))); // 添加断言,返回结果内容是否是指定的. actions.andDo(MockMvcResultHandlers.print()); // 添加一个结果处理器，输出整个响应结果信息. actions.andReturn(); // 执行完毕返回相应的结果 }} 1.6 以 Gradle / Wrapper 编译项目当本地没有装 gradle 环境时，可以通过 wrapper 构建项目，只需在根目录执行即可打包： 1gradlew build 运行： 1.7 Gradle 项目运行的三种方式1). 使用 java -jar 2). 通过 SpringApplication.run() 3). 使用 Spring Boot Gradle 插件 1gradle bootRun / gradlew bootRun (wrapper 方式) 二、 Thymeleaf 模板引擎2.1 Thymeleaf官方文档 Java 模板引擎。能够处理 Html / XML / JavaScript / CSS / 甚至纯文本 。类似于 JSP / FreeMarker 自然模板。原型即页面 语法优雅易懂。支持 OGNL / SpringEL 遵从 Web 标准。支持 HTML5 2.2 标准方言（语法）名称空间 &lt;span th:text=&quot;…&quot;&gt; 需要引入命名空间: &lt;html xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; 或 &lt;span data-th-text=&quot;…&quot;&gt; 符合html5标准，不需要引入命名空间 变量表达式 - ${…} &lt;span th:text=&quot;${book.author.name}&quot;&gt; 消息表达式（i8n / 国际化）- #{…} &lt;th th:text=&quot;#{header.address.city}&quot;&gt;…&lt;/th&gt; &lt;th th:text=&quot;#{header.address.country}&quot;&gt;…&lt;/th&gt; 选择表达式 - *{…} &lt;div th:object=&quot;${book}&quot;&gt; ... &lt;span th:text=&quot;*{title}&quot;&gt;...&lt;/span&gt; ... &lt;/div&gt; 与变量表达式的区别：它是在当前选择的对象而不是整个上下文变量映射上执行。${book} 取的是整个上下文中的变量，而 *{title} 是在当前 ${book} 里边的变量。因此变量表达式一定程度上提高了效率。 链接表达式 - @{…} 链接表达式可以是相对的，在这种情况下，应用程序上下文将不会作为 URL 的前缀 &lt;a th:href=&quot;@{../documents/report}&quot;&gt;…&lt;/a&gt; 也可以是服务器相对的，同样也没有应用程序上下文前缀 &lt;a th:href=&quot;@{~/contents/main}&quot;&gt;…&lt;/a&gt; 协议相对的（类似绝对 URL，但浏览器将使用在显示的页面中使用的相同的 HTTP 或 HTTPS 协议） &lt;a th:href=&quot;@{//static.mycompany.com/res/initial}&quot;&gt;…&lt;/a&gt; 也可以是绝对的 &lt;a th:href=&quot;@{http://static.mycompany.com/main}&quot;&gt;…&lt;/a&gt; 模板布局 th:insert 将公共片段整个插入到声明引入的元素中 th:replace 将声明引入的元素替换为公共片段 th:include 将被引入的片段的内容包含进这个标签 &lt;footer th:fragment=&quot;copy&quot;&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/footer&gt; 引入方式 &lt;div th:insert=&quot;footer :: copy&quot;&gt;&lt;/div&gt; &lt;div th:replace=&quot;footer :: copy&quot;&gt;&lt;/div&gt; &lt;div th:include=&quot;footer :: copy&quot;&gt;&lt;/div&gt; 效果 &lt;div&gt; &lt;footer&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/footer&gt; &lt;/div&gt; &lt;footer&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/footer&gt; &lt;div&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/div&gt; 也可以使用指定的 id 来替代 th:fragment=&quot;copy&quot; 引用时指定 #id 字面量 文本 &lt;span th:text=&quot;'web application'&quot;&gt; 单引号包裹 数字 &lt;span th:text=&quot;2015&quot;&gt; or &lt;span th:text=&quot;2980 + 3&quot;&gt; 布尔：&lt;span th:if=&quot;${user.isAdmin()} == false&quot;&gt; or &lt;span th:if=&quot;${user.name} == null 算术操作 (+ 、-、*、/、%)：&lt;span th:with=&quot;isEven=(${prodStat.count} % 2 == 0)&quot;&gt; 比较和等价：&gt; 、&lt; 、&gt;= 、 &lt;= （gt、lt、ge、le） 等价： == 、 != (eq、ne) 条件运算 &lt;span th:class=&quot;${row.even} ? ‘even&apos; : ‘odd&apos; &quot;&gt;&lt;/span&gt; 无操作 - __ &lt;span th:text=&quot;${user.name} ? : __&quot;&gt;no user authenticated&lt;/span&gt; 用户名不存在取无操作运算符，保留原始文本值。 设置属性值 设置任意属性值 th:attr th:attr=&quot;action=@{/subsctibe}&quot; 设置action属性值 设置指定属性值，比如: th:action / th:value / th:text 固定布尔属性， th:checked=&quot;${user.active}&quot; 如果结果为 true 设置为选中状态 迭代器 基本迭代 th:each &lt;li th:each=“book : ${books}” th:text=“${book.title}”&gt;En las Orillas del Sar&lt;/li&gt; 状态变量：index（0开始）、count（1开始）、size、current、even/odd、first、last 条件语句 th:if / th:unless （成立时 / 不成立时） th:switch &lt;div th:switch=&quot;${user.role}&quot;&gt; &lt;p th:case=&quot;&apos;admin&apos;&quot;&gt;user is an administrator&lt;/p&gt; &lt;p th:case=&quot;${roles.manager}&quot;&gt;user is an manager&lt;/p&gt; &lt;p th:case=&quot;*&quot;&gt;user is some other thing&lt;/p&gt; &lt;/div&gt; 注释 1). 标准的 html 注释 &lt;!-- --&gt; 2). thymeleaf 解析器注释块 &lt;!--/* */--&gt; 删除 &lt;!--/* 和 */--&gt; 之间的所有内容 &lt;!--/*--&gt; &lt;div&gt;you can see me only before thymeleaf processes me!&lt;/div&gt; &lt;!--*/--&gt; 3). 原型注释块：当模板静态打开时（比如原型设计），原型注释块所注释的代码将被注释，而在模板执行时，这些注释的代码，会被显示出来。 原型设计代码： &lt;span&gt;hello&lt;/span&gt; &lt;!--/*/ &lt;div th:th:text=&quot;${...}&quot;&gt; ... &lt;/div&gt; /*/--&gt; &lt;span&gt;goodbye!&lt;/span&gt; 模板渲染执行后： &lt;span&gt;hello&lt;/span&gt; &lt;div th:th:text=&quot;${...}&quot;&gt; ... &lt;/div&gt; &lt;span&gt;goodbye!&lt;/span&gt; 内联表达式 [[…]] 或 [(…)] 分别对应于 th:text（会转译特殊字符） 和 th:utext（不会转译特殊字符） 禁用内联：th:inline=&quot;none&quot; Javascript 内联：th:inline=&quot;JavaScript&quot; CSS 内联：th:inline=&quot;css&quot; 2.3 表达式基本对象#ctx：上下文对象。是 org.thymeleaf.context.IContext 或者 org.thymeleaf.context.IWebContext 的实现。 #locale： 直接访问与 java.util.Locale 关联的当前的请求。 ${#ctx.locale} ${#ctx.bariableNames} ${#ctx.request} ${#ctx.response} ${#ctx.session} ${#ctx.servletContext} ${#locale} Request/session 等属性 param：用于检索请求参数 session：用于检索session属性 application：用于检索application/servlet上下文属性 ${#param.foo} ${#param.size()} ${#param.isEmpty()} ${#param.containsKey(&apos;foo&apos;)} ${#session.foo} ${#session.size()} ${#session.isEmpty()} ${#session.containsKey(&apos;foo&apos;)} ${#application.foo} ${#application.size()} ${#application.isEmpty()} ${#application.containsKey(&apos;foo&apos;)} Web上下文对象 #request：直接访问与当前请求关联的 HttpServletRequest 对象 #session：直接访问与当前请求关联的 HttpSession 对象 #servletContext：直接访问与当前请求关联的 servletContext 对象 ${#request.getAttribute(&apos;foo&apos;)} ${#request.getParameter(&apos;foo&apos;)} ${#request.getContextPath()} ${#request.getRequestName())} ${#session.getAttribute(&apos;foo&apos;)} ${#session.id} ${#session.lastAccessedTime} ${#servletContext.getAttribute(&apos;foo&apos;)} ${#servletContext.contextPath} 2.4 集成 Spring Boot修改 buid.gradle。添加对 Thymeleaf 的依赖，自定义 Thymeleaf 和 Thyme leaf Layout Dialect 的版本。 123456789101112131415161718buildscript { // ext 用于定义动态属性（统一管理版本） ext { springBootVersion = '1.5.17.BUILD-SNAPSHOT' } // 指定 Thymeleaf 和 Thymeleaf Layout Dialect 的版本 ext['thymeleaf.version'] = '3.0.3.RELEASE' ext['thymeleaf-layout-dialect.version'] = '2.2.0' ......}......// 依赖关系dependencies { ...... // 添加 Thymeleaf 依赖 testCompile('org.springframework.boot:spring-boot-starter-thymeleaf')} 修改 Spring Boot 的 application.properties（或 application.yml ） 123456spring: thymeleaf: encoding: UTF-8 cache: false # 使用 HTML5 标准 mode: HTML5 2.5 Thymeleaf 实战接口设计 接口 描述 GET /users 返回用于展示用户列表的 list.html GET /users/{id} 返回用于展示用户的 view.html GET /users/form 返回用于新增或者修改用户的 form.html POST /users 新增或修改用户，成功后重定向到 list.html GET /users/delete/{id} 根据 id 删除相应的用户数据，成功后重定向到 list.html GET /users/modify/{id} 根据 id 获取相应的用户数据，并返回 form.html 用来执行修改 后台编码 1234567891011121314151617181920212223242526272829303132333435363738@Repositorypublic class UserRepositoryImpl implements UserRepository { /** * 累加器 */ private static AtomicLong counter = new AtomicLong(); /** * 暂存数据 */ ConcurrentMap&lt;Long, User&gt; userMap = new ConcurrentHashMap&lt;&gt;(); @Override public User saveOrUpdateUser(User user) { Long id = user.getId(); if (id &lt;= 0) { id = counter.incrementAndGet(); user.setId(id); } userMap.put(id, user); return null; } @Override public void deleteUser(Long id) { userMap.remove(id); } @Override public User getUserById(Long id) { return userMap.get(id); } @Override public List&lt;User&gt; listUser() { return new ArrayList&lt;&gt;(userMap.values()); }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475@RestController@RequestMapping(value = \"/users\")public class UserController { @Autowired private UserRepository userRepository; public List&lt;User&gt; getUserList() { return userRepository.listUser(); } /** * 查询所有用户 [ GET /users ] * */ @GetMapping public ModelAndView list(ModelMap map) { map.addAttribute(\"users\", getUserList()); map.addAttribute(\"title\", \"用户管理\"); return new ModelAndView(\"users/list\", \"userModel\", map); } /** * 根据 id 查询用户 [ GET /users/{id} ] */ @GetMapping(value = \"/{id}\") public ModelAndView getUserById(@PathVariable(\"id\") Long id, ModelMap map) { User user = userRepository.getUserById(id); System.out.println(user); map.addAttribute(\"user\", user); map.addAttribute(\"title\", \"查看用户\"); return new ModelAndView(\"users/view\", \"userModel\", map); } /** * 跳转到新建用户 [ GET /users/form ] */ @GetMapping(value = \"/form\") public ModelAndView createForm(ModelMap map) { map.addAttribute(\"user\", new User()); map.addAttribute(\"title\", \"创建用户\"); return new ModelAndView(\"users/form\", \"userModel\", map); } /** * 新建及修改 [ POST /users ] */ @PostMapping public ModelAndView create(User user) { userRepository.saveOrUpdateUser(user); return new ModelAndView(\"redirect:/users\"); } /** * 删除用户 [ GET /users/delete/{id} ] */ @GetMapping(value = \"delete/{id}\") public ModelAndView delete(@PathVariable(\"id\") Long id, ModelMap map) { userRepository.deleteUser(id); map.addAttribute(\"users\", getUserList()); return new ModelAndView(\"redirect:/users\"); } /** * 跳转修改页面 [ GET /users/modify/{id} ] */ @GetMapping(value = \"modify/{id}\") public ModelAndView update(@PathVariable(\"id\") Long id, ModelMap map) { User user = userRepository.getUserById(id); map.addAttribute(\"user\", user); map.addAttribute(\"title\", \"修改用户\"); return new ModelAndView(\"users/form\", \"userModel\", map); }} 前台设计 fragment/header.html：共用的头部页面 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\" xmlns:layout=\"http://www.ultraq.net.nz/thymeleaf/layout\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Thymeleaf in action&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div th:fragment=\"header\"&gt; &lt;h1&gt;Thymeleaf in action&lt;/h1&gt; &lt;a th:href=\"@{~/users}\"&gt;首页&lt;/a&gt; &lt;a th:href=\"@{~/users/form}\"&gt;新增&lt;/a&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; fragment/footer.html：共用的底部页面 123&lt;div th:fragment=\"footer\"&gt; &lt;a th:href=\"@{http://blog.yuzh.xyz}\"&gt;welcome to blog.yuzh.xyz&lt;/a&gt;&lt;/div&gt; users/form.html 新增/修改 12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\" xmlns:layout=\"http://www.ultraq.net.nz/thymeleaf/layout\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Thymeleaf in action&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div th:replace=\"~{fragments/header::header}\"&gt;&lt;/div&gt;&lt;h3 th:text=\"${userModel.title}\"&gt;&lt;/h3&gt;&lt;form th:action=\"@{~/users}\" method=\"post\"&gt; &lt;input type=\"text\" name=\"name\" th:value=\"${userModel!=null}?${userModel.user.name}\" placeholder=\"name\"&gt; &lt;input type=\"email\" name=\"email\" th:value=\"${userModel!=null}?${userModel.user.email}\" placeholder=\"email\"&gt; &lt;input type=\"text\" name=\"age\" th:value=\"${userModel!=null}?${userModel.user.age}\" placeholder=\"age\"&gt; &lt;input type=\"submit\" th:value=\"${userModel.title=='创建用户'} ? 'register' : 'modify'\"&gt; &lt;input type=\"hidden\" name=\"id\" th:if=\"${userModel.title=='修改用户'}\" th:value=\"${userModel.user.id}\"&gt;&lt;/form&gt;&lt;div th:replace=\"~{fragments/footer::footer}\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; users/list.html 列表展示 1234567891011121314151617181920212223242526272829303132333435363738&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\" xmlns:layout=\"http://www.ultraq.net.nz/thymeleaf/layout\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Thymeleaf in action&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div th:replace=\"~{fragments/header :: header}\"&gt;&lt;/div&gt;&lt;h3 th:text=\"${userModel!=null}?${userModel.title}\"&gt;yuzh&lt;/h3&gt;&lt;table border=\"1\"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;Email&lt;/th&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Age&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr th:if=\"${userModel.users.size()}==0\"&gt; &lt;td colspan=\"5\"&gt;没有用户信息！&lt;/td&gt; &lt;/tr&gt; &lt;tr th:each=\"user:${userModel.users}\"&gt; &lt;td th:text=\"${user.id}\"&gt;&lt;/td&gt; &lt;td th:text=\"${user.email}\"&gt;&lt;/td&gt; &lt;td th:text=\"${user.name}\"&gt;&lt;/td&gt; &lt;td th:text=\"${user.age}\"&gt;&lt;/td&gt; &lt;td&gt; &lt;a href=\"\" th:href=\"@{~/users/}+${user.id}\"&gt;修改&lt;/a&gt; &lt;a href=\"\" th:href=\"@{~/users/delete/}+${user.id}\"&gt;删除&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt;&lt;div th:replace=\"~{fragments/footer::footer}\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; users/view 查看用户 1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\" xmlns:layout=\"http://www.ultraq.net.nz/thymeleaf/layout\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Thymeleaf in action&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div th:replace=\"~{fragments/header :: header}\"&gt;&lt;/div&gt;&lt;h3&gt;[[${userModel.title}]]&lt;/h3&gt;&lt;a th:href=\"@{~/users/modify/}+${userModel.user.id}\"&gt;修改信息&lt;/a&gt;&lt;p&gt;ID：[[${userModel.user.id}]]&lt;/p&gt;&lt;p&gt;Name：[[${userModel.user.name}]]&lt;/p&gt;&lt;p&gt;Email：[[${userModel.user.email}]]&lt;/p&gt;&lt;p&gt;Age：[[${userModel.user.age}]]&lt;/p&gt;&lt;div th:replace=\"~{fragments/footer :: footer}\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 三、 Spring Data JPA 数据持久化3.1 JPA 简介JPA (Java Persistence API) 是用于管理 JavaEE 和 JavaSE环境中的持久化，以及对象/关系映射的 Java API。 JPA 是用于处理数据持久化的接口（规范），基于 JPA 规范的实现有 EclipiseLink、Hibernate、Apache OpenJPA 3.2 JPA 核心概念理解 jpa 的核心概念，才能更好的使用 jpa 持久化。没有符合任意一项都不能成功完成持久化！ 实体 实体表示关系型数据库中表 每个实体实例对应于表中的行 类必须使用 javax.persistence.Entity 注解 类必须有一个 public 或 protected 的无参数构造器 实体实例被当作以分离对象方式进行传递（例如通过会话 bean 的远程业务接口），则该类必须实现 Serializable 接口 必须要有唯一的对象标识符：简单主键（javax.persistence.Id）、复合主键（javax.persistence.Embeddedld 和 javax.persistence.IdClass） 关系 一对一：@OneToOne 一对多：@OneToMany 多对一：@ManyToOne 多对多：@ManyToMany EntityManager (管理实体的接口 管理实体的接口 定义用于与持久化上下文进行交互的方法 创建和删除持久实体实例，通过实体的主键查找实体 允许在实体上运行查询 获取 EntityManager 实例 12345678910111213141516@PersistenceUnit EntityManagerFactory emf; // 用于创建 EntityManager 的工厂类EntityManager em;@ResourceUserTransaction utx; // 事务...em = emf.createEmtityManager(); // 创建 EntityManager try{ utx.begin(); // 事务开始 em.persist(SomeEntity); // 通过实体管理器持久化一个实体对象 em.merge(AnotherEntity); // 通过实体管理器合并一个实体对象 em.remove(ThirdEntity); // 通过实体管理器移除一个实体对象 utx.commit(); // 事务提交} catch (Exception e){ utx.rollback(); // 回滚} 查找实体 1234567@PersistenceContextEntityManager em;public void enterOrder(int custID, CustomerOrder newOrder){ Customer cust = em.find(Customer.class, custID); // 通过实体管理器查找指定类型的实体 cust.getOrders().add(newOrder); newOrder.setCustomer(cust);} 3.3 Spring Data JPA 使用概括什么是 Spring Data JPA： Spring Data 家族的一部分 对基于 JPA 的数据访问层的增强支持 更容易构建基于使用 Spring 的数据访问技术栈的应用程序 常用接口： CrudRepository 定义了一些增删改查的通用接口 PagingAndSortingRepository 用于分页和排序的接口，扩展于 CrudRepository 自定义接口：继承 Repository 及子类 3.4. Spring Data JPA / Hibernate / Spring Boot 集成修改 build.gradle 12345678910111213141516171819buildscript { ...... // 自定义 Hibernate 的版本 ext['hibernate.version'] = '5.2.8.Final' ......}// 依赖关系dependencies { ...... // 添加 Spring Data JPA 的依赖 compile('org.springframework.boot:spring-boot-starter-data-jpa') // 添加 MySQL连接驱动 的依赖 compile('mysql:mysql-connector-java:6.0.5') // 添加 H2 的依赖 内存数据库 runtime('com.h2database:h2:1.4.193') ......} 3.5 数据持久化实战3.5.1 H2 内存数据库后台编码 实体 User 资源库 UserRepository 控制器 UserController 修改实体：实现 Serializable 接口、添加 @Entity 、设置主键 @Id 和自增策略 @GeneratedValue 123456789101112131415161718192021222324252627282930@Entity // 实体public class User implements Serializable { @Id // 主键 @GeneratedValue(strategy = GenerationType.IDENTITY) // 自增策略 private long id; private String name; private String email; private int age; protected User() { // JPA 的规范要求无参构造函数；设为 protected 防止直接使用 } public User(long id, String name, String email, int age) { this.id = id; this.name = name; this.email = email; this.age = age; } @Override public String toString() { return \"User{\" + \"id=\" + id + \", name='\" + name + '\\'' + \", email='\" + email + '\\'' + \", age=\" + age + '}'; }} 修改资源库：删除自己的实现、继承 JPA 的 @Repository 接口 1234567/** * @author yu.zh [yuzh233@gmail.com] 2018/09/25 21:57 * &lt;p&gt; * CrudRepository 提供了常用接口，自己无需编写接口。 */public interface UserRepository extends CrudRepository&lt;User, Long&gt; {} 修改控制器：将自己的实现方法的调用改为 JPA 的常用 api，如：findAll() / findOne(id) / save(user) / delete(id) 访问与验证数据 能正常访问与操作，数据存储在了 内存数据库 H2 ,使用 h2 的 控制台 访问数据。 设置显示 h2 控制台： 123spring: # 使用 H2 控制台 h2.console.enabled: true 访问控制台： http://localhost:8080/h2-console/ 注意：JDBC URL 需要手动更改为 jdbc:h2:mem:testdb 才能正常访问，否则看不到保存的表。接着点击 connect 可以看到 JPA 在内存型数据中自动保存了一张 USER 表，就是 User 实体所映射的表，并且根据主键关系与实体属性映射了添加的数据，我们可以与使用关系型数据库一样的方式对内存型数据库执行 SQL 操作。 3.5.2 MySql 物理数据库修改配置文件： 1234567891011121314151617181920212223spring: # 模板引擎 thymeleaf: encoding: UTF-8 cache: false mode: HTML5 # 使用 H2 控制台 h2.console.enabled: true # 数据源 datasource: url: jdbc:mysql://localhost/blog?characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=UTC username: root password: admin driver-class-name: com.mysql.cj.jdbc.Driver # JPA jpa: show-sql: true hibernate: # 每次启动都会删除之前的表结构和数据并重新生成新的表结构 ddl-auto: create-drop 启动项目，可以看到 hibernate 自动创建了表结构，字段和实体属性一一对应。 浏览器存入了两条数据之后，查看数据库： 数据成功存入，并且 h2 数据库没有存入，说明指定了 mysql 作为数据源， h2 的配置可有可无了。 在实际场景中使用 MySql 这种大型数据库，在开发测试过程中建议使用 H2 这种内存数据库，提高开发效率。 四、Elastic Search 全文搜索概念：全文搜索是一种将文件中所有文本与搜索项匹配的文字资料检索方法 实现原理： 建立文本库：搜索的数据源 建立索引：提取规律，以便快速查找。 执行搜索：用户请求 过滤结果：对搜索结果处理 Elastic Search 是什么： 高度可扩展的开源全文搜索和分析引擎 快速、近实时地对大数据进行存储、搜索和分析 用来支持又复杂的数据搜索需求的企业级应用 Elastic Search 特点： 分布式 高可用 多 API 面向文档 异步写入 近实时 基于 Lucene 搜索引擎 遵循 Apache 协议 Elastic Search 核心概念： 近实时：根据刷新策略定期刷新索引到索引库，在存入索引库和读取索引库数据效率之间折中。 集群：一个或多个的节点的集合，用于保存应用的全部数据并提供基于全部节点的集成式搜索功能。 节点：集群中的单台服务器，用来保存数据并参与集群保存和搜索数据的操作。 索引：用于加快搜索速度，在 ES 中，索引是相似文档的集合。 类型：对索引中包含文档的细分，区分不同类型的索引。 文档：进行索引的基本单位，与索引中的类型是相对应的。每一个具体的索引有一个文档与之对应，使用 json 格式表示。文档的实例就是对应关系型数据中的实体（具体的数据）。 分片：当索引超出单个节点所能承受的范围，可以使用分片来存储索引的部分数据，ES 会自动处理索引的分片与聚合。 副本：分片的副本，有利于提高搜索效率和吞吐量。默认 ES 为每个索引分配 5 个分片和一个副本。 4.1 集成 Spring Boot环境： Elastic Search 2.4.4 Spring Data Elastic Search 2.1.4.RELEASE – Spring Boot 对 ES 的支持模块 JNA 4.3.0 – ES 依赖模块 依赖： 123456dependencies { // 添加 Spring Data Elasticsearch 的依赖 compile('org.springframework.boot:spring-boot-starter-data-elasticsearch') // 添加 JNA 的依赖 compile('net.java.dev.jna:jna:4.3.0')} 配置： 1234567891011spring: data: elasticsearch: # 服务地址 cluster-nodes: localhost:9300 # 连接超时时间 properties: transport: tcp: connect_timeout：120 开启 Elastic Search： 下载二进制文件：官网 解压到指定目录 进入 bin，根据系统平台执行 elasticsearch 命令 后台编码： 索引库实体：EsBlog 资源库：EsBlogRepository 测试用例：EsBlogRepositoryTest 控制器：BlogController 文档库实体：123456789101112131415@Document(indexName = \"blog\", type = \"blog\") // 标注为文档实体类public class EsBlog implements Serializable { @Id private String id; private String title; private String summary; // 关键字 private String content; // 遵循 JPA 规范 protected EsBlog() { } ......} 资源库：123456789101112public interface EsBlogRepository extends ElasticsearchRepository&lt;EsBlog, String&gt; { /** * 分页查询博客（去重） * JPA 自动根据方法名执行查询 */ Page&lt;EsBlog&gt; findDistinctEsBlogByTitleContainingOrSummaryContainingOrContentContaining( String title, String summary, String content, Pageable pageable);} 测试用例：1234567891011121314151617181920212223242526272829303132333435363738@RunWith(SpringRunner.class)@SpringBootTestpublic class TestEsBlogRepository { @Autowired private EsBlogRepository esBlogRepository; /** * 测试文档库之前存入数据 */ @Before public void initEsBlogRepository() { esBlogRepository.deleteAll(); esBlogRepository.save(new EsBlog(\"登鹤雀楼\", \"王之涣的登鹤雀楼\", \"白日依山尽，黄河入海流。欲穷千里目，更上一层楼。\")); esBlogRepository.save(new EsBlog(\"相思\", \"王维的相思\", \"红豆生南国，春来发几枝。愿君多采颉，此物最相思。\")); esBlogRepository.save(new EsBlog(\"静夜思\", \"李白的静夜思\", \"床前明月光，疑是地上霜。举头望明月，低头思故乡。\")); } @Test public void testFindDistinctEsBlogByTitleContainingOrSummaryContainingOrContentContaining() { Pageable pageRequest = new PageRequest(0, 20); // 搜索条件 String title = \"思\"; String summary = \"思\"; String content = \"相思\"; Page&lt;EsBlog&gt; page = esBlogRepository.findDistinctEsBlogByTitleContainingOrSummaryContainingOrContentContaining( title, summary, content, pageRequest); // 断言根据指定的 title、summary、content 来搜索 记录有两条 assertThat(page.getTotalElements()).isEqualTo(2); // 打印结果 for (EsBlog blog : page.getContent()){ System.out.println(blog); } }} 控制器：123456789101112131415161718192021@RestController@RequestMapping(\"/\")public class BlogController { @Autowired private EsBlogRepository esBlogRepository; @RequestMapping(value = \"/blogs\") public List&lt;EsBlog&gt; list(@RequestParam(value = \"title\") String title, @RequestParam(value = \"summary\") String summary, @RequestParam(value = \"content\") String content, @RequestParam(value = \"pageIndex\", defaultValue = \"0\") int pageIndex, @RequestParam(value = \"pageSize\", defaultValue = \"10\") int pageSize ) { Pageable pageable = new PageRequest(0, 10); Page&lt;EsBlog&gt; page = esBlogRepository.findDistinctEsBlogByTitleContainingOrSummaryContainingOrContentContaining( title, summary, content, pageable); return page.getContent(); }} 访问： 五、集成 BootStrap是什么： 基于 HTML、CSS、JavaScript 响应式布局 移动设备优先 如何实现： 文档必须是 HTML5 设置响应式的 meta 标签 &lt;meta bane=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;&gt; 通过 Normalize.css 达到浏览器一致性适配 使用 Normalize 建立跨浏览器的一致性 额外支持的 Reboot 核心概念： 移动设备优先策略 基础的 CSS 是移动优先。优先设计更小的宽度 媒体查询。针对平板电脑、台式电脑再做宽屏适配 渐进增强。随着屏幕大小的增加而添加元素 网格系统 响应式：viewport 尺寸的增加，系统会自动分为最多 12 格： 实例：12345678910111213141516171819202122&lt;!-- 此为一行，该行中有两列 --&gt;&lt;div class=\"row\"&gt; &lt;!-- 此为一列：移动设备下占满 12 格，中型PC下占 8 格 --&gt; &lt;div class=\"col-xs-12 col-md-8\"&gt;.col-xs-12 col-md-8 .col-xs-12 col-md-8&lt;/div&gt; &lt;div class=\"col-xs-6 col-md-4\"&gt;.col-xs-6 .col-md-4&lt;/div&gt;&lt;/div&gt;&lt;!-- 一行中有三列 --&gt;&lt;div class=\"row\"&gt; &lt;!-- 三列各占网格的 4 格刚好占满一行 --&gt; &lt;div class=\"col-xs-6 col-md-4\"&gt;.col-xs-6 .col-md-4&lt;/div&gt; &lt;div class=\"col-xs-6 col-md-4\"&gt;.col-xs-6 .col-md-4&lt;/div&gt; &lt;div class=\"col-xs-6 col-md-4\"&gt;.col-xs-6 .col-md-4&lt;/div&gt;&lt;/div&gt;&lt;!-- 一行中有两列 --&gt;&lt;div class=\"row\"&gt; &lt;!-- 该行中有两列，每列占 6 格刚好占满一行 --&gt; &lt;div class=\"col-xs-6\"&gt;.col-xs-6&lt;/div&gt; &lt;div class=\"col-xs-6\"&gt;.col-xs-6&lt;/div&gt;&lt;/div&gt;&lt;!-- --&gt; 效果： 常用组件、样式 Typography 处理印刷 Table Form Button Dropdown 下拉框 ButtonGroup InputGroup Bavbar Pagination 分页 Tag Alert 提示框 Modal Dialog 模态框 Progress Bar 进度条 List Group 列表 Card 卡片 Tooltip 提示 六、Spring Security 安全权限框架角色 代表一系列行为或责任的实体 限定能做什么、不能做什么 用户账号往往与角色相关联 RBAC 基于角色的访问控制（Role-Base Access Control） 隐式访问控制：与角色关联的访问控制 显式访问控制：与权限关联的访问控制（更灵活） 安全领域核心概念 认证（authentication）：“认证”是建立主体（principal）的过程。“主体”通常是指可以在您的应用程序中执行操作的用户、设备或其他系统。 授权（authorization）：或称为：“访问控制（access-control）”，“授权”是指决定是否允许主体在应用程序中执行操作。 支持的身份验证功能 HTTP BASIC HTTP Digest HTTP X.509 LDAP 基于表单的认证 OpenID 单点登陆 Remmenber-Me 匿名身份验证 Run-ad JAAS JavaEE 容器认证 提供的模块 Core - Spring-security-core.jar —— 核心模块 Remoting - spring-security-remoting.jar —— 与 Spring Remoting 整合包 Web - spring-security-web.jar —— web 支持 Config - spring-security-config.jar —— 安全配置 LDAP - spring-security-idap.jar —— 用于 LDAP 认证及配置 ACL - spring-secutiry-acl.jar —— 访问控制列表的实现，对特定对象的实例进行安全配置 CAS - spring-secutiry-cas.jar —— 可作为单点登陆服务器 OpenID - spring-secutiry-openid.jar Test - spring-secutiry-test.jar 与 Spring Boot 集成 环境： Spring Secutiry 4.2.2.RELEASE Thymeleaf Spring Secutiry 3.0.2.RELEASE 依赖： 123456dependencies { // 添加 Spring Security 依赖 compile('org.springframework.boot:spring-boot-starter-security') // 添加 Thymeleaf Spring Security 依赖，与 Thymeleaf 版本一致都是 3.x compile('org.thymeleaf.extras:thymeleaf-extras-springsecurity4:3.0.2.RELEASE')} 后台编码： 安全配置类 控制器 前台编码： index.html header.html login.html 123456789101112131415161718192021222324252627282930@EnableWebSecuritypublic class SpringSecurityConfig extends WebSecurityConfigurerAdapter { /** * 自定义配置 */ @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(\"/css/**\", \"/js/**\", \"/fonts/**\", \"/index\").permitAll() // 都可以访问 .antMatchers(\"/users/**\").hasRole(\"ADMIN\") // 需要相应的角色才能访问 .and() .formLogin() // 基于 Form 表单登录验证 .loginPage(\"/login\") // 跳转到登陆地址 .failureUrl(\"/login-error\"); // 登陆失败跳转地址 } /** * 认证信息管理 * * @param auth * @throws Exception */ @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception { auth.inMemoryAuthentication() // 认证信息存储内存中 .withUser(\"yuzh\").password(\"admin\").roles(\"ADMIN\"); // 硬编码测试 }} 七、用户管理需求/核心功能 需求分析 注册 /register：[GET] 获取注册页面 /register：[POST] 注册成功，跳转登陆页面 User 用户对象 登陆: /login: [get] 获取登陆页面 /login: [post] 登陆 username password remember-me 是否记住我 用户管理 /users: [get] 用户列表 async pageIndex pageSize name 用户名称关键字 /users/add: [get] 获取添加用户页面 /users/add: [post] 保存添加的用户 User authorityId 角色ID /users/{id}: [delete] 删除用户 id /users/edit/{id}: [get] 获取某个具体用户编辑页面 id 流程图 首页用户注册： 后台管理-修改用户： 后台实现 原有基础上添加依赖： // 添加 Apache Commons Lang 依赖 compile(&apos;org.apache.commons:commons-lang3:3.5&apos;) 对 User 实体添加持久化和校验注解： 123456789101112131415161718192021222324252627282930313233343536@Data@Entitypublic class User implements Serializable { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private long id; @NotEmpty(message = \"姓名不能为空\") @Size(min=2, max=20) @Column(nullable = false, length = 20) // 映射为字段，值不能为空 private String name; @NotEmpty(message = \"邮箱不能为空\") @Size(max=50) @Email(message= \"邮箱格式不对\" ) @Column(nullable = false, length = 50, unique = true) private String email; @NotEmpty(message = \"账号不能为空\") @Size(min=3, max=20) @Column(nullable = false, length = 20, unique = true) private String username; // 用户账号，用户登录时的唯一标识 @NotEmpty(message = \"密码不能为空\") @Size(max=100) @Column(length = 100) private String password; // 登录时密码 @Column(length = 200) private String avatar; // 头像图片地址 private int age; protected User() { }} 实现 JpaRepository 接口，根据规范的方法名执行查询： 123456789101112131415161718192021222324252627282930public interface UserRepository extends JpaRepository&lt;User, Long&gt; { /** * 根据用户名分页查询列表 * * @param name * @param pageable * @return */ Page&lt;User&gt; findByNameLike(String name, Pageable pageable); /** * 根据用户账号查询用户 * * @param username * @return */ User findByUsername(String username); /** * 查找用户名是否被占用 */ boolean existsByUsername(String primaryKey); /** * 查找邮箱是否被占用 */ boolean existsByEmail(String primaryKey);} UserService 接口及实现 xyz.yuzh.spring.boot.blog.vo.Response 全局响应结果对象 AdminController 后台管理控制器 —— 跳转后台管理页面 UserController 后台管理用户管理控制器 —— 增删改查 UserOperationExcption 用户操作异常类 GlobalExceptionHandler 全局异常处理类 前台实现 login.html register.html /users/*.html /admins/*.html js/admins/*.js js/users/*.js 问题解决 如何给通过脚本添加的元素注册事件 解决使用 bootstrap 更新操作时 —— 模态框回显传值问题 八、角色权限管理需求分析 User 对象实现 UserDetails 接口 实现 getAuthorities 方法，返回权限实体集合（需要自定义的 Authority 转为 SimpleGrantedAuthority） UserServiceImpl 实现 UserDetailsService 实现 security 默认方法 loadUserByUsername，返回数据库查到的用户实体 SecurityConfig 123456789101112131415161718192021222324252627282930313233343536373839404142434445@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true)public class SecurityConfig extends WebSecurityConfigurerAdapter { private static final String KEY = \"yuzh.xyz\"; @Autowired private UserDetailsService userDetailsService; @Bean public AuthenticationProvider authenticationProvider() { DaoAuthenticationProvider authenticationProvider = new DaoAuthenticationProvider(); authenticationProvider.setUserDetailsService(userDetailsService); return authenticationProvider; } @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(\"/css/**\", \"/js/**\", \"/fonts/**\", \"/\", \"/index\").permitAll() .antMatchers(\"/h2-console/**\").permitAll() // 数据库中的字段因该是 ROLE_ADMIN ，这里不需要写 ROLE_ 前缀。 .antMatchers(\" /admins/**\").hasRole(\"ADMIN\") .and() .formLogin() .loginPage(\"/login\") .failureUrl(\"/login-error\") .and() .rememberMe().key(KEY) .and() .exceptionHandling().accessDeniedPage(\"/403\"); http.csrf().ignoringAntMatchers(\"/h2-console/**\"); http.headers().frameOptions().sameOrigin(); } @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(userDetailsService); auth.authenticationProvider(authenticationProvider()); }} 数据库的权限存入的格式例如 ROLE_ADMIN / ROLE_USER 给需要授权才能访问的方法授权 给类授权：@PreAuthorize(&quot;hasAuthority('ROLE_ADMIN')&quot;) // 指定角色权限才能操作方法 给方法授权：如当请求参数中的 username 被查询到已认证才允许进入方法 12@PostMapping(\"/{username}/blogs/edit\")@PreAuthorize(\"authentication.name.equals(#username)\") 当表单发起 /login 的 post 请求并携带固定名称的 username、password 参数，security 会自动处理登陆，若登陆失败，跳到配置好的登陆失败页面。 九、博客管理需求分析 用户主页实现 个人资料设置 个人头像更换 user space API：用户主页空间接口 /blogs: [get] order：排序类型，new/hot，默认是 new keyword：搜索关键字。博客的标签，即为关键字。 async：是否为异步请求页面 pageIndex pageSize /u/{username}: [get] 具体某个用户的主页 username 用户账号 /u/{username}/profile: [get] 获取个人设置页面 username 用户账号 /u/{username}/profile: [post] 保存个人设置页面 username 用户账号 User 待保存的对象 /u/{username}/avatar: [get] 获取个人头像 username 用户账号 /u/{username}/avatar: [post] 保存个人头像 username 用户账号 /u/{username}/blogs: [get] 查询用户博客 order：排序类型，new/hot，默认是 new catalog：博客分类 ID，默认为空 keyword：搜索关键字。博客的标签，即为关键字。 async：是否为异步请求页面 pageIndex pageSize /u/{username}/blogs/edits: [get] 获取新增博客页面 username 用户账号 /u/{username}/blogs/edit/{id}: [get] 获取编辑博客的页面 username 用户账号 id 博客ID /u/{username}/blogs/edit: [post] 保存博客 username 用户账号 Blog 待保存的博客对象 /u/{username}/blogs/delete/{id}: [delete] 删除博客 username 用户账号 id 博客ID /u/{username}/blogs/{id}: [get] 获取博客展示页面 username 用户账号 id 博客ID 后台实现 添加 markdown 解析器的依赖： 1compile('es.nitaur.markdown:txtmark:0.16') MongoDB File Server 文件服务器 https://github.com/waylau/mongodb-file-server 用户个人设置 十、评论管理需求分析 comments API：评论管理接口 /comments: [get] 获取评论列表 blogid 博客id /comments: [post] 保存评论 blogid 博客idcommentContent 评论内容 /comments/{id}: [delete] 删除评论 blogid 博客id id 评论id 十一、点赞管理需求分析 votes API：点赞管理接口 /votes: [post] 保存点赞 blogid 博客id /votes/{id}: [delete] 删除点赞 blogid 博客id id 点赞id 十二、分类管理需求分析 catalogs API：分类管理接口 /catalogs: [get] 获取用户博客的分类列表 username 用户账号 /catalogs: [post] 保存用户博客的分类 username 用户账号 CatalogVO 包含 username、Catalog /catalogs/edit: [get] 获取编辑分类界面 /catalogs/edit/{id}: [get] 获取某ID分类编辑的分类界面 /catalogs/{id}: [delete] 删除分类 id 分类ID username 用户账号 十三、标签管理需求分析 使用插件：Jquery Tags Input 1.3.6 http://xoxco.com/projects/code/tagsinput 十四、首页搜索需求分析 index API：包含最新、最热文章、最热标签、最热用户等 /blogs: [get] order：排序类型，new/hot keyword：搜索关键字（包含博客标签） async：是否异步 pageIndex pageSize 环境： Elastic Search 2.4.4 Spring Data Elastic Search 2.1.4.RELEASE – Spring Boot 对 ES 的支持模块 JNA 4.3.0 – ES 依赖模块 十五、部署相关15.1 使用外部 MongoDB 存储文件服务器数据之前使用的是文件服务器内嵌的 mongoDB，项目停止之后图片数据不会保存。更换外部 mongoDB： window 下 下载 mongoDB https://www.mongodb.com/download-center#community 选择 msi 文件下载安装 MongoDB将数据目录存储在 db 目录下。但是这个数据目录不会主动创建，需要手动创建。（如：d:/mongoData/db） 修改文件服务器 build.gradle 文件，取消使用内嵌 mongoDB 12// 添加 Embedded MongoDB 的依赖用于测试// compile('de.flapdoodle.embed:de.flapdoodle.embed.mongo') 修改文件服务器 application.yml 文件，连接独立的 MongoDB 12# independent MongoDB serverspring.data.mongodb.uri=mongodb://localhost:27017/test 从 MongoDB 目录的 bin 目录中执行 mongod.exe 文件 1如：C:\\mongodb\\bin\\mongod --dbpath d:\\mongoData\\db 运行 mongo.exe 命令即可连接 MongoDB 更多细节见：http://www.runoob.com/mongodb/mongodb-window-install.html linux 下 1234567891011121314curl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.0.6.tgz # 下载tar -zxvf mongodb-linux-x86_64-3.0.6.tgz # 解压mv mongodb-linux-x86_64-3.0.6.tgz mongodb # 重命名vim /etc/profile # 配置环境变量---------------------export PATH=/opt/mongodb/bin:${PATH}---------------------resource /etc/profile # 刷新环境变量cd /opt/mongodbmkdir data &amp; cd data &amp; mkdir db # 创建文件存放目录mongod --dbpath=/opt/mongodb/data/db # 启动 mongodb 15.2 应用启动后台运行：nohup cmd &amp; 启动 mongoDB 启动文件服务器（gradlew bootRun） 进入 elastic search，删除 data 文件（测试环境下），执行 ./elasticsearch 启动 blog-full （gradlew bootRun）","link":"/2018/10/28/基于 Spring Boot 技术栈构建企业级博客系统的开发记录/"}],"tags":[{"name":"无关代码","slug":"无关代码","link":"/tags/无关代码/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"idea","slug":"idea","link":"/tags/idea/"},{"name":"maven","slug":"maven","link":"/tags/maven/"},{"name":"tomcat","slug":"tomcat","link":"/tags/tomcat/"},{"name":"aliyun","slug":"aliyun","link":"/tags/aliyun/"},{"name":"dubbo","slug":"dubbo","link":"/tags/dubbo/"},{"name":"aop","slug":"aop","link":"/tags/aop/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"分布式","slug":"分布式","link":"/tags/分布式/"},{"name":"freeMarker","slug":"freeMarker","link":"/tags/freeMarker/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"cokie","slug":"cokie","link":"/tags/cokie/"},{"name":"jsonp","slug":"jsonp","link":"/tags/jsonp/"},{"name":"sso","slug":"sso","link":"/tags/sso/"},{"name":"算法","slug":"算法","link":"/tags/算法/"},{"name":"数据结构","slug":"数据结构","link":"/tags/数据结构/"},{"name":"solr","slug":"solr","link":"/tags/solr/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"集群","slug":"集群","link":"/tags/集群/"},{"name":"jms","slug":"jms","link":"/tags/jms/"},{"name":"nio","slug":"nio","link":"/tags/nio/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"线程","slug":"线程","link":"/tags/线程/"},{"name":"springboot","slug":"springboot","link":"/tags/springboot/"}],"categories":[{"name":"interview","slug":"interview","link":"/categories/interview/"},{"name":"bug-fix","slug":"bug-fix","link":"/categories/bug-fix/"},{"name":"spring-boot","slug":"spring-boot","link":"/categories/spring-boot/"}]}